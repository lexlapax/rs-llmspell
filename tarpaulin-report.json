{"files":[{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","docs","archives","research","traits.rs"],"content":"// ABOUTME: Core trait definitions for rs-llmspell architecture\n// ABOUTME: Demonstrates the trait-based design patterns for LLM orchestration\n\n//! # Core Traits for Rs-LLMSpell\n//! \n//! This file contains the fundamental trait definitions that form the backbone\n//! of the rs-llmspell architecture. These traits demonstrate:\n//! \n//! - Provider abstraction patterns\n//! - Async-first design\n//! - Type-safe error handling\n//! - Composable agent patterns\n//! - Tool system design\n//! - Workflow orchestration\n\nuse std::collections::HashMap;\nuse std::future::Future;\nuse std::pin::Pin;\nuse std::time::Duration;\n\nuse async_trait::async_trait;\nuse futures_util::Stream;\nuse serde::{Deserialize, Serialize};\nuse thiserror::Error;\n\n// ================================================================================================\n// CORE TYPES\n// ================================================================================================\n\n/// Unique identifier type for various entities\npub type Id = String;\n\n/// Token usage statistics\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TokenUsage {\n    pub prompt_tokens: u32,\n    pub completion_tokens: u32,\n    pub total_tokens: u32,\n}\n\n/// Message roles in LLM conversations\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum Role {\n    System,\n    User,\n    Assistant,\n    Tool,\n}\n\n/// Content types for messages\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum Content {\n    Text(String),\n    Multimodal(Vec<ContentPart>),\n}\n\n/// Parts of multimodal content\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum ContentPart {\n    Text(String),\n    Image { \n        url: Option<String>, \n        data: Option<Vec<u8>>, \n        mime_type: String,\n    },\n}\n\n/// Message in LLM conversation\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Message {\n    pub role: Role,\n    pub content: Content,\n    pub metadata: Option<MessageMetadata>,\n}\n\n/// Additional message metadata\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MessageMetadata {\n    pub timestamp: chrono::DateTime<chrono::Utc>,\n    pub id: Option<Id>,\n    pub tags: Vec<String>,\n}\n\n/// Completion request to LLM provider\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CompletionRequest {\n    pub messages: Vec<Message>,\n    pub model: String,\n    pub temperature: Option<f32>,\n    pub max_tokens: Option<u32>,\n    pub stop_sequences: Option<Vec<String>>,\n    pub tools: Option<Vec<ToolDefinition>>,\n    pub stream: bool,\n}\n\n/// Response from LLM provider\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CompletionResponse {\n    pub message: Message,\n    pub usage: TokenUsage,\n    pub model: String,\n    pub finish_reason: FinishReason,\n    pub metadata: ResponseMetadata,\n}\n\n/// Streaming chunk from LLM provider\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CompletionChunk {\n    pub delta: ContentDelta,\n    pub usage: Option<TokenUsage>,\n    pub finish_reason: Option<FinishReason>,\n}\n\n/// Delta content for streaming\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum ContentDelta {\n    Text(String),\n    ToolCall { name: String, input: serde_json::Value },\n    Done,\n}\n\n/// Reason for completion finishing\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum FinishReason {\n    Stop,\n    Length,\n    ToolCall,\n    ContentFilter,\n    Error,\n}\n\n/// Response metadata\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ResponseMetadata {\n    pub request_id: Option<String>,\n    pub created_at: chrono::DateTime<chrono::Utc>,\n    pub processing_time_ms: u64,\n    pub provider: String,\n}\n\n/// Tool definition for LLM\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ToolDefinition {\n    pub name: String,\n    pub description: String,\n    pub parameters: serde_json::Value, // JSON Schema\n}\n\n/// Embedding request\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct EmbeddingRequest {\n    pub input: Vec<String>,\n    pub model: String,\n}\n\n/// Embedding response\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct EmbeddingResponse {\n    pub embeddings: Vec<Vec<f32>>,\n    pub usage: TokenUsage,\n    pub model: String,\n}\n\n/// Model information\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ModelInfo {\n    pub id: String,\n    pub name: String,\n    pub description: String,\n    pub max_tokens: Option<u32>,\n    pub supports_streaming: bool,\n    pub supports_tools: bool,\n    pub supports_vision: bool,\n}\n\n// ================================================================================================\n// ERROR TYPES\n// ================================================================================================\n\n/// Core error type for rs-llmspell\n#[derive(Debug, Error)]\npub enum LlmError {\n    #[error(\"Provider error: {0}\")]\n    Provider(#[from] Box<dyn std::error::Error + Send + Sync>),\n    \n    #[error(\"Configuration error: {message}\")]\n    Configuration { message: String },\n    \n    #[error(\"Validation error in {field}: {message}\")]\n    Validation { field: String, message: String },\n    \n    #[error(\"Network error: {0}\")]\n    Network(#[from] reqwest::Error),\n    \n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n    \n    #[error(\"Timeout after {duration:?}\")]\n    Timeout { duration: Duration },\n    \n    #[error(\"Rate limit exceeded: retry after {retry_after:?}\")]\n    RateLimit { retry_after: Option<Duration> },\n    \n    #[error(\"Authentication failed: {message}\")]\n    Authentication { message: String },\n    \n    #[error(\"Resource not found: {resource_type} {id}\")]\n    NotFound { resource_type: String, id: String },\n    \n    #[error(\"Operation cancelled\")]\n    Cancelled,\n}\n\n/// Agent-specific errors\n#[derive(Debug, Error)]\npub enum AgentError {\n    #[error(\"LLM error: {0}\")]\n    Llm(#[from] LlmError),\n    \n    #[error(\"Tool error: {tool_name}: {source}\")]\n    Tool {\n        tool_name: String,\n        #[source]\n        source: Box<dyn std::error::Error + Send + Sync>,\n    },\n    \n    #[error(\"Context error: {message}\")]\n    Context { message: String },\n    \n    #[error(\"Configuration error: {message}\")]\n    Configuration { message: String },\n}\n\n/// Tool-specific errors\n#[derive(Debug, Error)]\npub enum ToolError {\n    #[error(\"Execution failed: {message}\")]\n    Execution { message: String },\n    \n    #[error(\"Invalid input: {field}: {message}\")]\n    InvalidInput { field: String, message: String },\n    \n    #[error(\"Missing dependency: {dependency}\")]\n    MissingDependency { dependency: String },\n    \n    #[error(\"Permission denied: {operation}\")]\n    PermissionDenied { operation: String },\n    \n    #[error(\"Resource unavailable: {resource}\")]\n    ResourceUnavailable { resource: String },\n}\n\n/// Workflow-specific errors\n#[derive(Debug, Error)]\npub enum WorkflowError {\n    #[error(\"Step {step_name} failed: {source}\")]\n    StepFailed {\n        step_name: String,\n        #[source]\n        source: Box<dyn std::error::Error + Send + Sync>,\n    },\n    \n    #[error(\"Agent error: {0}\")]\n    Agent(#[from] AgentError),\n    \n    #[error(\"Dependency cycle detected in workflow\")]\n    CyclicDependency,\n    \n    #[error(\"Context error: {message}\")]\n    Context { message: String },\n    \n    #[error(\"Validation error: {message}\")]\n    Validation { message: String },\n}\n\n// ================================================================================================\n// PROVIDER TRAIT\n// ================================================================================================\n\n/// Core trait for LLM providers\n/// \n/// This trait abstracts over different LLM providers (OpenAI, Anthropic, etc.)\n/// and allows switching between them without changing application code.\n#[async_trait]\npub trait Provider: Send + Sync + Clone {\n    /// Provider-specific error type\n    type Error: std::error::Error + Send + Sync + 'static;\n    \n    /// Provider-specific configuration type\n    type Config: Clone + Send + Sync;\n    \n    /// Create a new provider instance with configuration\n    async fn new(config: Self::Config) -> Result<Self, Self::Error>;\n    \n    /// Complete a text generation request\n    async fn complete(&self, request: CompletionRequest) -> Result<CompletionResponse, Self::Error>;\n    \n    /// Stream a text generation request\n    fn complete_stream(&self, request: CompletionRequest) \n        -> Pin<Box<dyn Stream<Item = Result<CompletionChunk, Self::Error>> + Send>>;\n    \n    /// Generate embeddings for text\n    async fn embed(&self, request: EmbeddingRequest) -> Result<EmbeddingResponse, Self::Error>;\n    \n    /// Get available models and their capabilities\n    async fn models(&self) -> Result<Vec<ModelInfo>, Self::Error>;\n    \n    /// Validate configuration without making API calls\n    fn validate_config(config: &Self::Config) -> Result<(), Self::Error>;\n    \n    /// Get provider name for debugging/logging\n    fn name(&self) -> &'static str;\n    \n    /// Check if provider is healthy (optional health check)\n    async fn health_check(&self) -> Result<(), Self::Error> {\n        // Default implementation does nothing\n        Ok(())\n    }\n}\n\n// ================================================================================================\n// AGENT TRAIT\n// ================================================================================================\n\n/// Configuration for agent behavior\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AgentConfig {\n    pub model: String,\n    pub temperature: Option<f32>,\n    pub max_tokens: Option<u32>,\n    pub timeout: Duration,\n    pub max_retries: u32,\n    pub enable_streaming: bool,\n}\n\nimpl Default for AgentConfig {\n    fn default() -> Self {\n        Self {\n            model: \"gpt-3.5-turbo\".to_string(),\n            temperature: Some(0.7),\n            max_tokens: Some(1000),\n            timeout: Duration::from_secs(30),\n            max_retries: 3,\n            enable_streaming: false,\n        }\n    }\n}\n\n/// Response from agent execution\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AgentResponse {\n    pub content: Content,\n    pub usage: TokenUsage,\n    pub tool_calls: Vec<ToolCall>,\n    pub metadata: AgentMetadata,\n}\n\n/// Tool call made by agent\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ToolCall {\n    pub id: String,\n    pub name: String,\n    pub input: serde_json::Value,\n    pub output: Option<serde_json::Value>,\n    pub error: Option<String>,\n}\n\n/// Agent execution metadata\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AgentMetadata {\n    pub agent_id: String,\n    pub execution_time_ms: u64,\n    pub retry_count: u32,\n    pub provider_used: String,\n}\n\n/// Streaming chunk from agent\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum AgentChunk {\n    Content(String),\n    ToolCall(ToolCall),\n    Done(AgentMetadata),\n    Error(AgentError),\n}\n\n/// Context for conversation agents\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ConversationContext {\n    pub messages: Vec<Message>,\n    pub metadata: HashMap<String, serde_json::Value>,\n}\n\n/// High-level agent trait for LLM interactions\n/// \n/// Agents encapsulate the logic for interacting with LLMs, including\n/// system prompts, tool usage, and conversation management.\n#[async_trait]\npub trait Agent: Send + Sync + Clone {\n    /// Agent-specific error type\n    type Error: std::error::Error + Send + Sync + 'static;\n    \n    /// Provider type this agent uses\n    type Provider: Provider;\n    \n    /// Tool type this agent can use\n    type Tool: Tool;\n    \n    /// Create a new agent with a provider\n    fn new(provider: Self::Provider) -> Self;\n    \n    /// Configure the agent's system prompt\n    fn with_system_prompt(self, prompt: impl Into<String>) -> Self;\n    \n    /// Add tools to the agent\n    fn with_tools(self, tools: Vec<Self::Tool>) -> Self;\n    \n    /// Configure agent behavior\n    fn with_config(self, config: AgentConfig) -> Self;\n    \n    /// Execute a single request\n    async fn run(&self, input: &str) -> Result<AgentResponse, Self::Error>;\n    \n    /// Execute with conversation context\n    async fn run_with_context(&self, input: &str, context: &ConversationContext) \n        -> Result<AgentResponse, Self::Error>;\n    \n    /// Stream responses in real-time\n    fn run_stream(&self, input: &str) \n        -> Pin<Box<dyn Stream<Item = Result<AgentChunk, Self::Error>> + Send>>;\n    \n    /// Get available tools\n    fn tools(&self) -> &[Self::Tool];\n    \n    /// Validate agent configuration\n    fn validate(&self) -> Result<(), Self::Error>;\n    \n    /// Get agent metadata\n    fn metadata(&self) -> AgentMetadata;\n}\n\n// ================================================================================================\n// TOOL TRAIT\n// ================================================================================================\n\n/// Tool execution context\n#[derive(Debug, Clone)]\npub struct ToolContext {\n    pub agent_id: String,\n    pub execution_id: String,\n    pub metadata: HashMap<String, serde_json::Value>,\n}\n\n/// Tool execution result\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ToolResult<T> {\n    pub output: T,\n    pub metadata: ToolMetadata,\n}\n\n/// Tool execution metadata\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ToolMetadata {\n    pub execution_time_ms: u64,\n    pub success: bool,\n    pub error_message: Option<String>,\n}\n\n/// Tool trait for extending agent capabilities\n/// \n/// Tools provide specific functionality that agents can invoke,\n/// such as web search, file operations, calculations, etc.\n#[async_trait]\npub trait Tool: Send + Sync + Clone {\n    /// Tool-specific error type\n    type Error: std::error::Error + Send + Sync + 'static;\n    \n    /// Strongly-typed input for this tool\n    type Input: serde::de::DeserializeOwned + Send + Sync;\n    \n    /// Strongly-typed output from this tool\n    type Output: serde::Serialize + Send + Sync;\n    \n    /// Tool name (must be unique within a toolset)\n    fn name(&self) -> &str;\n    \n    /// Human-readable description\n    fn description(&self) -> &str;\n    \n    /// JSON Schema for parameters\n    fn parameters_schema(&self) -> serde_json::Value;\n    \n    /// Execute the tool with typed input\n    async fn execute(&self, input: Self::Input, context: ToolContext) \n        -> Result<ToolResult<Self::Output>, Self::Error>;\n    \n    /// Validate input without executing\n    fn validate_input(&self, input: &serde_json::Value) -> Result<(), Self::Error>;\n    \n    /// Check if tool is available (e.g., API keys present)\n    async fn health_check(&self) -> Result<(), Self::Error>;\n    \n    /// Get tool categories/tags\n    fn categories(&self) -> Vec<String> {\n        vec![]\n    }\n    \n    /// Whether tool requires special permissions\n    fn requires_permission(&self) -> bool {\n        false\n    }\n}\n\n// ================================================================================================\n// WORKFLOW TRAITS\n// ================================================================================================\n\n/// Context passed between workflow steps\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct WorkflowContext {\n    pub variables: HashMap<String, serde_json::Value>,\n    pub step_results: HashMap<String, serde_json::Value>,\n    pub metadata: HashMap<String, serde_json::Value>,\n}\n\nimpl WorkflowContext {\n    pub fn new() -> Self {\n        Self {\n            variables: HashMap::new(),\n            step_results: HashMap::new(),\n            metadata: HashMap::new(),\n        }\n    }\n    \n    pub fn set_variable(&mut self, key: impl Into<String>, value: impl Serialize) {\n        if let Ok(json_value) = serde_json::to_value(value) {\n            self.variables.insert(key.into(), json_value);\n        }\n    }\n    \n    pub fn get_variable<T>(&self, key: &str) -> Option<T> \n    where \n        T: serde::de::DeserializeOwned\n    {\n        self.variables.get(key)\n            .and_then(|v| serde_json::from_value(v.clone()).ok())\n    }\n}\n\n/// Result from workflow execution\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct WorkflowResult {\n    pub success: bool,\n    pub step_results: HashMap<String, serde_json::Value>,\n    pub final_output: Option<serde_json::Value>,\n    pub execution_time_ms: u64,\n    pub metadata: WorkflowMetadata,\n}\n\n/// Workflow execution metadata\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct WorkflowMetadata {\n    pub workflow_id: String,\n    pub execution_id: String,\n    pub started_at: chrono::DateTime<chrono::Utc>,\n    pub completed_at: Option<chrono::DateTime<chrono::Utc>>,\n    pub step_count: usize,\n    pub errors: Vec<String>,\n}\n\n/// Progress information during workflow execution\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct WorkflowProgress {\n    pub current_step: String,\n    pub completed_steps: usize,\n    pub total_steps: usize,\n    pub percentage: f32,\n    pub estimated_remaining_ms: Option<u64>,\n}\n\n/// Individual step in a workflow\n#[async_trait]\npub trait WorkflowStep: Send + Sync {\n    /// Step-specific error type\n    type Error: std::error::Error + Send + Sync + 'static;\n    \n    /// Execute this step with the given context\n    async fn execute(&self, context: &mut WorkflowContext) \n        -> Result<serde_json::Value, Self::Error>;\n    \n    /// Get step name for identification\n    fn name(&self) -> &str;\n    \n    /// Get step description\n    fn description(&self) -> &str;\n    \n    /// Validate step configuration\n    fn validate(&self) -> Result<(), Self::Error>;\n    \n    /// Get step dependencies (for DAG workflows)\n    fn dependencies(&self) -> Vec<String> {\n        vec![]\n    }\n    \n    /// Whether this step can be retried on failure\n    fn is_retryable(&self) -> bool {\n        true\n    }\n    \n    /// Maximum retry attempts\n    fn max_retries(&self) -> u32 {\n        3\n    }\n}\n\n/// Workflow orchestration trait\n/// \n/// Workflows coordinate multiple agents and tools to accomplish\n/// complex tasks through structured execution patterns.\n#[async_trait]\npub trait Workflow: Send + Sync {\n    /// Workflow-specific error type\n    type Error: std::error::Error + Send + Sync + 'static;\n    \n    /// Step type used in this workflow\n    type Step: WorkflowStep;\n    \n    /// Add a step to the workflow\n    fn add_step(self, step: Self::Step) -> Self;\n    \n    /// Execute the entire workflow\n    async fn run(&self, context: WorkflowContext) -> Result<WorkflowResult, Self::Error>;\n    \n    /// Execute with progress reporting\n    fn run_with_progress(&self, context: WorkflowContext) \n        -> Pin<Box<dyn Stream<Item = Result<WorkflowProgress, Self::Error>> + Send>>;\n    \n    /// Validate workflow configuration\n    fn validate(&self) -> Result<(), Self::Error>;\n    \n    /// Get workflow metadata\n    fn metadata(&self) -> WorkflowMetadata;\n    \n    /// Cancel workflow execution\n    async fn cancel(&self) -> Result<(), Self::Error> {\n        // Default implementation does nothing\n        Ok(())\n    }\n    \n    /// Pause workflow execution (if supported)\n    async fn pause(&self) -> Result<(), Self::Error> {\n        Err(self.unsupported_operation(\"pause\"))\n    }\n    \n    /// Resume paused workflow (if supported)\n    async fn resume(&self) -> Result<(), Self::Error> {\n        Err(self.unsupported_operation(\"resume\"))\n    }\n    \n    /// Helper for unsupported operations\n    fn unsupported_operation(&self, operation: &str) -> Self::Error {\n        // This is a placeholder - actual implementation would depend on the concrete error type\n        panic!(\"Operation '{}' not supported by this workflow type\", operation)\n    }\n}\n\n// ================================================================================================\n// CONFIGURATION TRAITS\n// ================================================================================================\n\n/// Trait for types that can be configured\npub trait Configurable {\n    type Config: Clone + Send + Sync;\n    type Error: std::error::Error + Send + Sync + 'static;\n    \n    /// Apply configuration\n    fn configure(&mut self, config: Self::Config) -> Result<(), Self::Error>;\n    \n    /// Get current configuration\n    fn config(&self) -> &Self::Config;\n    \n    /// Validate configuration\n    fn validate_config(config: &Self::Config) -> Result<(), Self::Error>;\n}\n\n/// Trait for types that can be observed/monitored\npub trait Observable {\n    type Event: Clone + Send + Sync;\n    \n    /// Subscribe to events from this object\n    fn subscribe(&self) -> Pin<Box<dyn Stream<Item = Self::Event> + Send>>;\n    \n    /// Get current metrics\n    fn metrics(&self) -> HashMap<String, f64> {\n        HashMap::new()\n    }\n}\n\n// ================================================================================================\n// UTILITY TRAITS\n// ================================================================================================\n\n/// Trait for types that can be retried with backoff\n#[async_trait]\npub trait Retryable {\n    type Output;\n    type Error: std::error::Error + Send + Sync + 'static;\n    \n    /// Execute operation with retry logic\n    async fn execute_with_retry(&self, max_attempts: u32, base_delay: Duration) \n        -> Result<Self::Output, Self::Error>;\n    \n    /// Check if error is retryable\n    fn is_retryable_error(&self, error: &Self::Error) -> bool;\n}\n\n/// Trait for types that support timeouts\n#[async_trait]\npub trait Timeout {\n    type Output;\n    type Error: std::error::Error + Send + Sync + 'static;\n    \n    /// Execute with timeout\n    async fn execute_with_timeout(&self, timeout: Duration) \n        -> Result<Self::Output, Self::Error>;\n}\n\n/// Trait for types that can be validated\npub trait Validatable {\n    type Error: std::error::Error + Send + Sync + 'static;\n    \n    /// Validate the object\n    fn validate(&self) -> Result<(), Self::Error>;\n}\n\n// ================================================================================================\n// EXAMPLE IMPLEMENTATIONS\n// ================================================================================================\n\n/// Example agent step for workflows\npub struct AgentStep<A: Agent> {\n    pub name: String,\n    pub agent: A,\n    pub input_template: String,\n}\n\n#[async_trait]\nimpl<A: Agent> WorkflowStep for AgentStep<A> {\n    type Error = A::Error;\n    \n    async fn execute(&self, context: &mut WorkflowContext) \n        -> Result<serde_json::Value, Self::Error> {\n        // Template the input with context variables\n        let input = self.render_template(&self.input_template, context);\n        \n        // Execute agent\n        let response = self.agent.run(&input).await?;\n        \n        // Store result in context\n        let result_value = serde_json::to_value(&response)\n            .map_err(|e| panic!(\"Serialization error: {}\", e))?; // In real impl, handle properly\n            \n        context.step_results.insert(self.name.clone(), result_value.clone());\n        \n        Ok(result_value)\n    }\n    \n    fn name(&self) -> &str {\n        &self.name\n    }\n    \n    fn description(&self) -> &str {\n        \"Execute agent with templated input\"\n    }\n    \n    fn validate(&self) -> Result<(), Self::Error> {\n        self.agent.validate()\n    }\n}\n\nimpl<A: Agent> AgentStep<A> {\n    fn render_template(&self, template: &str, context: &WorkflowContext) -> String {\n        // Simple template rendering - in real implementation would be more sophisticated\n        let mut result = template.to_string();\n        \n        for (key, value) in &context.variables {\n            if let Ok(string_value) = serde_json::from_value::<String>(value.clone()) {\n                result = result.replace(&format!(\"{{{{{}}}}}\", key), &string_value);\n            }\n        }\n        \n        result\n    }\n}\n\n/// Example tool step for workflows\npub struct ToolStep<T: Tool> {\n    pub name: String,\n    pub tool: T,\n    pub input: T::Input,\n}\n\n#[async_trait]\nimpl<T: Tool> WorkflowStep for ToolStep<T> {\n    type Error = T::Error;\n    \n    async fn execute(&self, context: &mut WorkflowContext) \n        -> Result<serde_json::Value, Self::Error> {\n        let tool_context = ToolContext {\n            agent_id: \"workflow\".to_string(),\n            execution_id: \"step\".to_string(),\n            metadata: HashMap::new(),\n        };\n        \n        let result = self.tool.execute(self.input.clone(), tool_context).await?;\n        \n        let result_value = serde_json::to_value(&result.output)\n            .map_err(|e| panic!(\"Serialization error: {}\", e))?; // In real impl, handle properly\n            \n        context.step_results.insert(self.name.clone(), result_value.clone());\n        \n        Ok(result_value)\n    }\n    \n    fn name(&self) -> &str {\n        &self.name\n    }\n    \n    fn description(&self) -> &str {\n        \"Execute tool with provided input\"\n    }\n    \n    fn validate(&self) -> Result<(), Self::Error> {\n        // Validate tool input\n        let input_json = serde_json::to_value(&self.input)\n            .map_err(|e| panic!(\"Serialization error: {}\", e))?; // In real impl, handle properly\n        self.tool.validate_input(&input_json)\n    }\n}","traces":[{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":503,"address":[],"length":0,"stats":{"Line":0}},{"line":504,"address":[],"length":0,"stats":{"Line":0}},{"line":508,"address":[],"length":0,"stats":{"Line":0}},{"line":509,"address":[],"length":0,"stats":{"Line":0}},{"line":534,"address":[],"length":0,"stats":{"Line":0}},{"line":535,"address":[],"length":0,"stats":{"Line":0}},{"line":536,"address":[],"length":0,"stats":{"Line":0}},{"line":544,"address":[],"length":0,"stats":{"Line":0}},{"line":545,"address":[],"length":0,"stats":{"Line":0}},{"line":600,"address":[],"length":0,"stats":{"Line":0}},{"line":601,"address":[],"length":0,"stats":{"Line":0}},{"line":605,"address":[],"length":0,"stats":{"Line":0}},{"line":606,"address":[],"length":0,"stats":{"Line":0}},{"line":610,"address":[],"length":0,"stats":{"Line":0}},{"line":611,"address":[],"length":0,"stats":{"Line":0}},{"line":644,"address":[],"length":0,"stats":{"Line":0}},{"line":646,"address":[],"length":0,"stats":{"Line":0}},{"line":650,"address":[],"length":0,"stats":{"Line":0}},{"line":651,"address":[],"length":0,"stats":{"Line":0}},{"line":655,"address":[],"length":0,"stats":{"Line":0}},{"line":656,"address":[],"length":0,"stats":{"Line":0}},{"line":660,"address":[],"length":0,"stats":{"Line":0}},{"line":662,"address":[],"length":0,"stats":{"Line":0}},{"line":693,"address":[],"length":0,"stats":{"Line":0}},{"line":694,"address":[],"length":0,"stats":{"Line":0}},{"line":753,"address":[],"length":0,"stats":{"Line":0}},{"line":756,"address":[],"length":0,"stats":{"Line":0}},{"line":759,"address":[],"length":0,"stats":{"Line":0}},{"line":762,"address":[],"length":0,"stats":{"Line":0}},{"line":764,"address":[],"length":0,"stats":{"Line":0}},{"line":767,"address":[],"length":0,"stats":{"Line":0}},{"line":768,"address":[],"length":0,"stats":{"Line":0}},{"line":771,"address":[],"length":0,"stats":{"Line":0}},{"line":772,"address":[],"length":0,"stats":{"Line":0}},{"line":775,"address":[],"length":0,"stats":{"Line":0}},{"line":776,"address":[],"length":0,"stats":{"Line":0}},{"line":781,"address":[],"length":0,"stats":{"Line":0}},{"line":783,"address":[],"length":0,"stats":{"Line":0}},{"line":785,"address":[],"length":0,"stats":{"Line":0}},{"line":786,"address":[],"length":0,"stats":{"Line":0}},{"line":787,"address":[],"length":0,"stats":{"Line":0}},{"line":791,"address":[],"length":0,"stats":{"Line":0}},{"line":809,"address":[],"length":0,"stats":{"Line":0}},{"line":810,"address":[],"length":0,"stats":{"Line":0}},{"line":811,"address":[],"length":0,"stats":{"Line":0}},{"line":814,"address":[],"length":0,"stats":{"Line":0}},{"line":816,"address":[],"length":0,"stats":{"Line":0}},{"line":819,"address":[],"length":0,"stats":{"Line":0}},{"line":821,"address":[],"length":0,"stats":{"Line":0}},{"line":824,"address":[],"length":0,"stats":{"Line":0}},{"line":825,"address":[],"length":0,"stats":{"Line":0}},{"line":828,"address":[],"length":0,"stats":{"Line":0}},{"line":829,"address":[],"length":0,"stats":{"Line":0}},{"line":832,"address":[],"length":0,"stats":{"Line":0}},{"line":834,"address":[],"length":0,"stats":{"Line":0}},{"line":836,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":58},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-agents","src","lib.rs"],"content":"//! ABOUTME: llmspell-agents implementation crate\n//! ABOUTME: Foundation stub for future implementation\n\n// Module stub - to be implemented in later phases\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","engine","bridge.rs"],"content":"//! ABOUTME: ScriptEngineBridge trait defining language-agnostic script engine interface\n//! ABOUTME: Foundation for multi-language script execution (Lua, JavaScript, Python, etc.)\n\nuse async_trait::async_trait;\nuse llmspell_core::{error::LLMSpellError, types::AgentStream};\nuse serde_json::Value;\nuse std::sync::Arc;\n\n/// Core abstraction for script execution engines\n///\n/// This trait enables language-agnostic script execution by providing\n/// a common interface that all script engines must implement.\n#[async_trait]\npub trait ScriptEngineBridge: Send + Sync {\n    /// Execute a script and return the output\n    async fn execute_script(&self, script: &str) -> Result<ScriptOutput, LLMSpellError>;\n\n    /// Execute a script with streaming output support\n    async fn execute_script_streaming(&self, script: &str) -> Result<ScriptStream, LLMSpellError>;\n\n    /// Inject language-agnostic APIs into the engine\n    ///\n    /// This method is called during initialization to inject:\n    /// - Agent creation and execution APIs\n    /// - Tool discovery and execution APIs\n    /// - Workflow orchestration APIs\n    /// - Provider access APIs\n    fn inject_apis(\n        &mut self,\n        registry: &Arc<crate::ComponentRegistry>,\n        providers: &Arc<crate::ProviderManager>,\n    ) -> Result<(), LLMSpellError>;\n\n    /// Get the name of this script engine\n    fn get_engine_name(&self) -> &'static str;\n\n    /// Check if this engine supports streaming execution\n    fn supports_streaming(&self) -> bool;\n\n    /// Check if this engine supports multimodal content\n    fn supports_multimodal(&self) -> bool;\n\n    /// Get the features supported by this engine\n    fn supported_features(&self) -> EngineFeatures;\n\n    /// Get the current execution context\n    fn get_execution_context(&self) -> Result<ExecutionContext, LLMSpellError>;\n\n    /// Set the execution context\n    fn set_execution_context(&mut self, context: ExecutionContext) -> Result<(), LLMSpellError>;\n}\n\n/// Output from script execution\n#[derive(Debug, Clone)]\npub struct ScriptOutput {\n    /// The main output value\n    pub output: Value,\n    /// Any console/print output captured\n    pub console_output: Vec<String>,\n    /// Execution metadata\n    pub metadata: ScriptMetadata,\n}\n\n/// Streaming output from script execution\npub struct ScriptStream {\n    /// The underlying stream of outputs\n    pub stream: AgentStream,\n    /// Execution metadata\n    pub metadata: ScriptMetadata,\n}\n\n/// Metadata about script execution\n#[derive(Debug, Clone)]\npub struct ScriptMetadata {\n    /// Engine that executed the script\n    pub engine: String,\n    /// Execution time in milliseconds\n    pub execution_time_ms: u64,\n    /// Memory usage in bytes\n    pub memory_usage_bytes: Option<usize>,\n    /// Any warnings generated\n    pub warnings: Vec<String>,\n}\n\n/// Features supported by a script engine\n#[derive(Debug, Clone, Default)]\npub struct EngineFeatures {\n    /// Supports async/await or coroutines\n    pub async_execution: bool,\n    /// Supports streaming output\n    pub streaming: bool,\n    /// Supports multimodal content\n    pub multimodal: bool,\n    /// Supports debugging/breakpoints\n    pub debugging: bool,\n    /// Supports module imports\n    pub modules: bool,\n    /// Maximum script size in bytes\n    pub max_script_size: Option<usize>,\n    /// Maximum execution time in milliseconds\n    pub max_execution_time_ms: Option<u64>,\n}\n\n/// Execution context for scripts\n#[derive(Debug, Clone, Default)]\npub struct ExecutionContext {\n    /// Current working directory\n    pub working_directory: String,\n    /// Environment variables\n    pub environment: std::collections::HashMap<String, String>,\n    /// Script-specific state\n    pub state: Value,\n    /// Security restrictions\n    pub security: SecurityContext,\n}\n\n/// Security context for script execution\n#[derive(Debug, Clone, Default)]\npub struct SecurityContext {\n    /// Allow file system access\n    pub allow_file_access: bool,\n    /// Allow network access\n    pub allow_network_access: bool,\n    /// Allow process spawning\n    pub allow_process_spawn: bool,\n    /// Maximum memory usage in bytes\n    pub max_memory_bytes: Option<usize>,\n    /// Maximum execution time in milliseconds\n    pub max_execution_time_ms: Option<u64>,\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_engine_features_default() {\n        let features = EngineFeatures::default();\n        assert!(!features.async_execution);\n        assert!(!features.streaming);\n        assert!(!features.multimodal);\n        assert!(features.max_script_size.is_none());\n    }\n\n    #[test]\n    fn test_security_context_default() {\n        let security = SecurityContext::default();\n        assert!(!security.allow_file_access);\n        assert!(!security.allow_network_access);\n        assert!(!security.allow_process_spawn);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","engine","factory.rs"],"content":"//! ABOUTME: Engine factory for creating script engines by name or configuration\n//! ABOUTME: Supports built-in engines (Lua, JavaScript) and third-party plugins\n\nuse crate::engine::bridge::{EngineFeatures, ScriptEngineBridge};\nuse llmspell_core::error::LLMSpellError;\nuse serde_json::Value;\nuse std::collections::HashMap;\nuse std::sync::{Arc, RwLock};\n\n/// Factory for creating script engines\npub struct EngineFactory;\n\nimpl EngineFactory {\n    /// Create a Lua engine with the given configuration\n    pub fn create_lua_engine(\n        config: &LuaConfig,\n    ) -> Result<Box<dyn ScriptEngineBridge>, LLMSpellError> {\n        #[cfg(feature = \"lua\")]\n        {\n            use crate::lua::LuaEngine;\n            Ok(Box::new(LuaEngine::new(config)?))\n        }\n        #[cfg(not(feature = \"lua\"))]\n        {\n            Err(LLMSpellError::Component {\n                message: \"Lua engine not enabled. Enable the 'lua' feature.\".to_string(),\n                source: None,\n            })\n        }\n    }\n\n    /// Create a JavaScript engine with the given configuration\n    #[allow(unused_variables)]\n    pub fn create_javascript_engine(\n        config: &JSConfig,\n    ) -> Result<Box<dyn ScriptEngineBridge>, LLMSpellError> {\n        #[cfg(feature = \"javascript\")]\n        {\n            use crate::javascript::JSEngine;\n            Ok(Box::new(JSEngine::new(config)?))\n        }\n        #[cfg(not(feature = \"javascript\"))]\n        {\n            Err(LLMSpellError::Component {\n                message: \"JavaScript engine not enabled. Enable the 'javascript' feature.\"\n                    .to_string(),\n                source: None,\n            })\n        }\n    }\n\n    /// Create an engine by name with the given configuration\n    pub fn create_from_name(\n        name: &str,\n        config: &Value,\n    ) -> Result<Box<dyn ScriptEngineBridge>, LLMSpellError> {\n        match name {\n            \"lua\" => {\n                let lua_config =\n                    serde_json::from_value::<LuaConfig>(config.clone()).map_err(|e| {\n                        LLMSpellError::Validation {\n                            field: Some(\"config\".to_string()),\n                            message: format!(\"Invalid Lua configuration: {}\", e),\n                        }\n                    })?;\n                Self::create_lua_engine(&lua_config)\n            }\n            \"javascript\" | \"js\" => {\n                let js_config =\n                    serde_json::from_value::<JSConfig>(config.clone()).map_err(|e| {\n                        LLMSpellError::Validation {\n                            field: Some(\"config\".to_string()),\n                            message: format!(\"Invalid JavaScript configuration: {}\", e),\n                        }\n                    })?;\n                Self::create_javascript_engine(&js_config)\n            }\n            _ => {\n                // Check if it's a registered plugin\n                let registry = PLUGIN_REGISTRY.read().unwrap();\n                if let Some(plugin) = registry.get(name) {\n                    plugin.create_engine(config.clone())\n                } else {\n                    Err(LLMSpellError::Validation {\n                        field: Some(\"engine\".to_string()),\n                        message: format!(\"Unknown engine: {}. Available: lua, javascript\", name),\n                    })\n                }\n            }\n        }\n    }\n\n    /// List all available engines (built-in and plugins)\n    pub fn list_available_engines() -> Vec<EngineInfo> {\n        let mut engines = vec![];\n\n        #[cfg(feature = \"lua\")]\n        engines.push(EngineInfo {\n            name: \"lua\".to_string(),\n            description: \"Lua 5.4 scripting engine\".to_string(),\n            version: \"5.4\".to_string(),\n            features: crate::lua::LuaEngine::engine_features(),\n        });\n\n        #[cfg(feature = \"javascript\")]\n        engines.push(EngineInfo {\n            name: \"javascript\".to_string(),\n            description: \"JavaScript (ES2020) engine\".to_string(),\n            version: \"ES2020\".to_string(),\n            features: crate::javascript::JSEngine::engine_features(),\n        });\n\n        // Add registered plugins\n        let registry = PLUGIN_REGISTRY.read().unwrap();\n        for (name, plugin) in registry.iter() {\n            engines.push(EngineInfo {\n                name: name.clone(),\n                description: plugin.description(),\n                version: plugin.version(),\n                features: plugin.supported_features(),\n            });\n        }\n\n        engines\n    }\n}\n\n/// Information about an available engine\n#[derive(Debug, Clone)]\npub struct EngineInfo {\n    pub name: String,\n    pub description: String,\n    pub version: String,\n    pub features: EngineFeatures,\n}\n\n/// Configuration for the Lua engine\n#[derive(Debug, Clone, serde::Deserialize, serde::Serialize)]\n#[serde(default)]\npub struct LuaConfig {\n    /// Standard library access level\n    pub stdlib: StdlibLevel,\n    /// Maximum memory usage in bytes\n    pub max_memory: Option<usize>,\n    /// Enable debug features\n    pub debug: bool,\n    /// Custom package paths\n    pub package_paths: Vec<String>,\n}\n\nimpl Default for LuaConfig {\n    fn default() -> Self {\n        Self {\n            stdlib: StdlibLevel::Safe,\n            max_memory: Some(50_000_000), // 50MB default\n            debug: false,\n            package_paths: vec![],\n        }\n    }\n}\n\n/// Lua standard library access levels\n#[derive(Debug, Clone, Copy, serde::Deserialize, serde::Serialize)]\n#[serde(rename_all = \"lowercase\")]\npub enum StdlibLevel {\n    /// No standard library\n    None,\n    /// Safe subset only\n    Safe,\n    /// Full standard library\n    Full,\n}\n\n/// Configuration for the JavaScript engine\n#[derive(Debug, Clone, serde::Deserialize, serde::Serialize)]\n#[serde(default)]\npub struct JSConfig {\n    /// Enable strict mode\n    pub strict_mode: bool,\n    /// Maximum heap size in bytes\n    pub max_heap_size: Option<usize>,\n    /// Enable console API\n    pub enable_console: bool,\n    /// Module resolution strategy\n    pub module_resolution: ModuleResolution,\n}\n\nimpl Default for JSConfig {\n    fn default() -> Self {\n        Self {\n            strict_mode: true,\n            max_heap_size: Some(100_000_000), // 100MB default\n            enable_console: true,\n            module_resolution: ModuleResolution::Node,\n        }\n    }\n}\n\n/// JavaScript module resolution strategies\n#[derive(Debug, Clone, Copy, serde::Deserialize, serde::Serialize)]\n#[serde(rename_all = \"lowercase\")]\npub enum ModuleResolution {\n    /// Node.js-style resolution\n    Node,\n    /// Browser-style resolution\n    Browser,\n    /// Deno-style resolution\n    Deno,\n}\n\n// Plugin system for third-party engines\n\nlazy_static::lazy_static! {\n    static ref PLUGIN_REGISTRY: Arc<RwLock<HashMap<String, Box<dyn ScriptEnginePlugin>>>> =\n        Arc::new(RwLock::new(HashMap::new()));\n}\n\n/// Plugin interface for third-party script engines\npub trait ScriptEnginePlugin: Send + Sync {\n    /// Get the name of this engine\n    fn engine_name(&self) -> &str;\n\n    /// Get a description of this engine\n    fn description(&self) -> String;\n\n    /// Get the version of this engine\n    fn version(&self) -> String;\n\n    /// Create an instance of this engine\n    fn create_engine(&self, config: Value) -> Result<Box<dyn ScriptEngineBridge>, LLMSpellError>;\n\n    /// Get the features supported by this engine\n    fn supported_features(&self) -> EngineFeatures;\n}\n\n/// Register a third-party engine plugin\npub fn register_engine_plugin<P: ScriptEnginePlugin + 'static>(plugin: P) {\n    let mut registry = PLUGIN_REGISTRY.write().unwrap();\n    registry.insert(plugin.engine_name().to_string(), Box::new(plugin));\n}\n\n/// Unregister an engine plugin\npub fn unregister_engine_plugin(name: &str) -> bool {\n    let mut registry = PLUGIN_REGISTRY.write().unwrap();\n    registry.remove(name).is_some()\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_lua_config_default() {\n        let config = LuaConfig::default();\n        assert_eq!(config.max_memory, Some(50_000_000));\n        assert!(!config.debug);\n        assert!(config.package_paths.is_empty());\n    }\n\n    #[test]\n    fn test_js_config_default() {\n        let config = JSConfig::default();\n        assert!(config.strict_mode);\n        assert_eq!(config.max_heap_size, Some(100_000_000));\n        assert!(config.enable_console);\n    }\n\n    #[test]\n    fn test_engine_factory_unknown_engine() {\n        let result = EngineFactory::create_from_name(\"unknown\", &Value::Null);\n        assert!(result.is_err());\n        if let Err(e) = result {\n            match e {\n                LLMSpellError::Validation { field, .. } => {\n                    assert_eq!(field, Some(\"engine\".to_string()));\n                }\n                _ => panic!(\"Expected validation error\"),\n            }\n        }\n    }\n}\n","traces":[{"line":15,"address":[],"length":0,"stats":{"Line":143}},{"line":21,"address":[],"length":0,"stats":{"Line":143}},{"line":34,"address":[],"length":0,"stats":{"Line":2}},{"line":40,"address":[],"length":0,"stats":{"Line":2}},{"line":44,"address":[],"length":0,"stats":{"Line":2}},{"line":45,"address":[],"length":0,"stats":{"Line":2}},{"line":46,"address":[],"length":0,"stats":{"Line":2}},{"line":47,"address":[],"length":0,"stats":{"Line":2}},{"line":53,"address":[],"length":0,"stats":{"Line":11}},{"line":57,"address":[],"length":0,"stats":{"Line":11}},{"line":58,"address":[],"length":0,"stats":{"Line":11}},{"line":59,"address":[],"length":0,"stats":{"Line":6}},{"line":60,"address":[],"length":0,"stats":{"Line":6}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":10}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":5}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":5}},{"line":85,"address":[],"length":0,"stats":{"Line":5}},{"line":86,"address":[],"length":0,"stats":{"Line":5}},{"line":94,"address":[],"length":0,"stats":{"Line":4}},{"line":95,"address":[],"length":0,"stats":{"Line":4}},{"line":98,"address":[],"length":0,"stats":{"Line":4}},{"line":99,"address":[],"length":0,"stats":{"Line":4}},{"line":100,"address":[],"length":0,"stats":{"Line":4}},{"line":101,"address":[],"length":0,"stats":{"Line":4}},{"line":102,"address":[],"length":0,"stats":{"Line":4}},{"line":106,"address":[],"length":0,"stats":{"Line":4}},{"line":107,"address":[],"length":0,"stats":{"Line":4}},{"line":108,"address":[],"length":0,"stats":{"Line":4}},{"line":109,"address":[],"length":0,"stats":{"Line":4}},{"line":110,"address":[],"length":0,"stats":{"Line":4}},{"line":114,"address":[],"length":0,"stats":{"Line":4}},{"line":115,"address":[],"length":0,"stats":{"Line":4}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":4}},{"line":152,"address":[],"length":0,"stats":{"Line":155}},{"line":155,"address":[],"length":0,"stats":{"Line":155}},{"line":157,"address":[],"length":0,"stats":{"Line":155}},{"line":189,"address":[],"length":0,"stats":{"Line":45}},{"line":192,"address":[],"length":0,"stats":{"Line":45}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}}],"covered":38,"coverable":58},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","engine","mod.rs"],"content":"//! ABOUTME: Language abstraction layer for script engines\n//! ABOUTME: Provides ScriptEngineBridge trait and factory pattern for multi-language support\n\npub mod bridge;\npub mod factory;\npub mod types;\n\npub use bridge::{\n    EngineFeatures, ExecutionContext, ScriptEngineBridge, ScriptMetadata, ScriptOutput,\n    ScriptStream, SecurityContext,\n};\n\npub use factory::{\n    register_engine_plugin, unregister_engine_plugin, EngineFactory, EngineInfo, JSConfig,\n    LuaConfig, ModuleResolution, ScriptEnginePlugin, StdlibLevel,\n};\n\npub use types::{\n    AgentApiDefinition, ApiSurface, ScriptEngineError, StreamType, StreamingApiDefinition,\n    ToolApiDefinition, WorkflowApiDefinition,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","engine","types.rs"],"content":"//! ABOUTME: Common types for script engine abstraction layer\n//! ABOUTME: Shared types for language-agnostic API definitions and conversions\n\nuse serde::{Deserialize, Serialize};\n\n/// Language-agnostic API surface definition\n#[derive(Debug, Clone)]\npub struct ApiSurface {\n    pub agent_api: AgentApiDefinition,\n    pub tool_api: ToolApiDefinition,\n    pub workflow_api: WorkflowApiDefinition,\n    pub streaming_api: StreamingApiDefinition,\n}\n\nimpl ApiSurface {\n    /// Create the standard API surface that all engines should implement\n    pub fn standard() -> Self {\n        Self {\n            agent_api: AgentApiDefinition::standard(),\n            tool_api: ToolApiDefinition::standard(),\n            workflow_api: WorkflowApiDefinition::standard(),\n            streaming_api: StreamingApiDefinition::standard(),\n        }\n    }\n}\n\n/// Agent API definition for script engines\n#[derive(Debug, Clone)]\npub struct AgentApiDefinition {\n    /// Global object name (e.g., \"Agent\" in Lua/JS)\n    pub global_name: String,\n    /// Constructor function name\n    pub constructor: String,\n    /// Method names\n    pub methods: AgentMethods,\n}\n\nimpl AgentApiDefinition {\n    pub fn standard() -> Self {\n        Self {\n            global_name: \"Agent\".to_string(),\n            constructor: \"create\".to_string(),\n            methods: AgentMethods {\n                execute: \"execute\".to_string(),\n                stream_execute: \"streamExecute\".to_string(),\n                get_config: \"getConfig\".to_string(),\n                get_state: \"getState\".to_string(),\n                set_state: \"setState\".to_string(),\n            },\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct AgentMethods {\n    pub execute: String,\n    pub stream_execute: String,\n    pub get_config: String,\n    pub get_state: String,\n    pub set_state: String,\n}\n\n/// Tool API definition for script engines\n#[derive(Debug, Clone)]\npub struct ToolApiDefinition {\n    /// Global object name (e.g., \"Tool\" in Lua/JS)\n    pub global_name: String,\n    /// Function to get tools\n    pub get_function: String,\n    /// Function to list available tools\n    pub list_function: String,\n    /// Method names\n    pub methods: ToolMethods,\n}\n\nimpl ToolApiDefinition {\n    pub fn standard() -> Self {\n        Self {\n            global_name: \"Tool\".to_string(),\n            get_function: \"get\".to_string(),\n            list_function: \"list\".to_string(),\n            methods: ToolMethods {\n                execute: \"execute\".to_string(),\n                get_schema: \"getSchema\".to_string(),\n                validate_input: \"validateInput\".to_string(),\n            },\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct ToolMethods {\n    pub execute: String,\n    pub get_schema: String,\n    pub validate_input: String,\n}\n\n/// Workflow API definition for script engines\n#[derive(Debug, Clone)]\npub struct WorkflowApiDefinition {\n    /// Global object name\n    pub global_name: String,\n    /// Workflow type constructors\n    pub constructors: WorkflowConstructors,\n}\n\nimpl WorkflowApiDefinition {\n    pub fn standard() -> Self {\n        Self {\n            global_name: \"Workflow\".to_string(),\n            constructors: WorkflowConstructors {\n                sequential: \"sequential\".to_string(),\n                parallel: \"parallel\".to_string(),\n                conditional: \"conditional\".to_string(),\n                loop_workflow: \"loop\".to_string(),\n            },\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct WorkflowConstructors {\n    pub sequential: String,\n    pub parallel: String,\n    pub conditional: String,\n    pub loop_workflow: String,\n}\n\n/// Streaming API definition for script engines\n#[derive(Debug, Clone)]\npub struct StreamingApiDefinition {\n    /// How to create streams (coroutines in Lua, async generators in JS)\n    pub stream_type: StreamType,\n    /// Chunk handling\n    pub chunk_methods: ChunkMethods,\n}\n\nimpl StreamingApiDefinition {\n    pub fn standard() -> Self {\n        Self {\n            stream_type: StreamType::Coroutine, // Default, engines override\n            chunk_methods: ChunkMethods {\n                yield_chunk: \"yield\".to_string(),\n                next_chunk: \"next\".to_string(),\n                is_done: \"isDone\".to_string(),\n            },\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub enum StreamType {\n    /// Lua-style coroutines\n    Coroutine,\n    /// JavaScript async generators\n    AsyncGenerator,\n    /// Python async iterators\n    AsyncIterator,\n    /// Custom streaming mechanism\n    Custom(String),\n}\n\n#[derive(Debug, Clone)]\npub struct ChunkMethods {\n    pub yield_chunk: String,\n    pub next_chunk: String,\n    pub is_done: String,\n}\n\n/// Common error types for script engines\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum ScriptEngineError {\n    /// Script execution failed\n    ExecutionError { engine: String, details: String },\n\n    /// Script syntax error\n    SyntaxError {\n        engine: String,\n        message: String,\n        line: Option<u32>,\n        column: Option<u32>,\n    },\n\n    /// API injection failed\n    ApiInjectionError { engine: String, api_name: String },\n\n    /// Feature not supported by engine\n    UnsupportedFeature { engine: String, feature: String },\n\n    /// Type conversion failed\n    TypeConversionError { engine: String, details: String },\n\n    /// Engine not found\n    EngineNotFound { engine_name: String },\n\n    /// Engine configuration invalid\n    ConfigurationError { engine: String, details: String },\n\n    /// Resource limit exceeded\n    ResourceLimitExceeded {\n        engine: String,\n        resource: String,\n        limit: String,\n    },\n}\n\nimpl From<ScriptEngineError> for llmspell_core::error::LLMSpellError {\n    fn from(err: ScriptEngineError) -> Self {\n        match err {\n            ScriptEngineError::ExecutionError { engine, details } => {\n                llmspell_core::error::LLMSpellError::Component {\n                    message: format!(\"{} engine execution error: {}\", engine, details),\n                    source: None,\n                }\n            }\n            ScriptEngineError::SyntaxError {\n                engine,\n                message,\n                line,\n                ..\n            } => {\n                let detail = if let Some(l) = line {\n                    format!(\"{} at line {}\", message, l)\n                } else {\n                    message\n                };\n                llmspell_core::error::LLMSpellError::Validation {\n                    field: Some(\"script\".to_string()),\n                    message: format!(\"{} syntax error: {}\", engine, detail),\n                }\n            }\n            ScriptEngineError::UnsupportedFeature { engine, feature } => {\n                llmspell_core::error::LLMSpellError::Component {\n                    message: format!(\"Feature '{}' not supported by {} engine\", feature, engine),\n                    source: None,\n                }\n            }\n            _ => llmspell_core::error::LLMSpellError::Component {\n                message: format!(\"Script engine error: {:?}\", err),\n                source: None,\n            },\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_standard_api_surface() {\n        let api = ApiSurface::standard();\n        assert_eq!(api.agent_api.global_name, \"Agent\");\n        assert_eq!(api.tool_api.global_name, \"Tool\");\n        assert_eq!(api.workflow_api.global_name, \"Workflow\");\n    }\n\n    #[test]\n    fn test_script_engine_error_conversion() {\n        let err = ScriptEngineError::ExecutionError {\n            engine: \"lua\".to_string(),\n            details: \"test error\".to_string(),\n        };\n\n        let llm_err: llmspell_core::error::LLMSpellError = err.into();\n        match llm_err {\n            llmspell_core::error::LLMSpellError::Component { message, .. } => {\n                assert!(message.contains(\"lua engine\"));\n            }\n            _ => panic!(\"Expected component error\"),\n        }\n    }\n}\n","traces":[{"line":17,"address":[],"length":0,"stats":{"Line":118}},{"line":19,"address":[],"length":0,"stats":{"Line":118}},{"line":20,"address":[],"length":0,"stats":{"Line":118}},{"line":21,"address":[],"length":0,"stats":{"Line":118}},{"line":22,"address":[],"length":0,"stats":{"Line":118}},{"line":39,"address":[],"length":0,"stats":{"Line":118}},{"line":41,"address":[],"length":0,"stats":{"Line":118}},{"line":42,"address":[],"length":0,"stats":{"Line":118}},{"line":43,"address":[],"length":0,"stats":{"Line":118}},{"line":77,"address":[],"length":0,"stats":{"Line":118}},{"line":79,"address":[],"length":0,"stats":{"Line":118}},{"line":80,"address":[],"length":0,"stats":{"Line":118}},{"line":81,"address":[],"length":0,"stats":{"Line":118}},{"line":82,"address":[],"length":0,"stats":{"Line":118}},{"line":108,"address":[],"length":0,"stats":{"Line":118}},{"line":110,"address":[],"length":0,"stats":{"Line":118}},{"line":111,"address":[],"length":0,"stats":{"Line":118}},{"line":139,"address":[],"length":0,"stats":{"Line":118}},{"line":142,"address":[],"length":0,"stats":{"Line":118}},{"line":208,"address":[],"length":0,"stats":{"Line":13}},{"line":209,"address":[],"length":0,"stats":{"Line":13}},{"line":210,"address":[],"length":0,"stats":{"Line":13}},{"line":212,"address":[],"length":0,"stats":{"Line":13}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}}],"covered":23,"coverable":33},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","javascript","api","agent.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","javascript","api","mod.rs"],"content":"//! ABOUTME: JavaScript-specific API injection modules\n//! ABOUTME: Provides Agent, Tool, Workflow, and Streaming APIs for JavaScript scripts\n\npub mod agent;\npub mod streaming;\npub mod tool;\npub mod workflow;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","javascript","api","streaming.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","javascript","api","tool.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","javascript","api","workflow.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","javascript","engine.rs"],"content":"//! ABOUTME: JSEngine implementation of ScriptEngineBridge trait\n//! ABOUTME: Provides JavaScript (ES2020) execution with async generator streaming\n\nuse crate::engine::{\n    EngineFeatures, ExecutionContext, JSConfig, ScriptEngineBridge, ScriptOutput, ScriptStream,\n};\nuse crate::{ComponentRegistry, ProviderManager};\nuse async_trait::async_trait;\nuse llmspell_core::error::LLMSpellError;\nuse std::sync::Arc;\n\n/// JavaScript script engine implementation\npub struct JSEngine {\n    _config: JSConfig,\n}\n\nimpl JSEngine {\n    /// Create a new JavaScript engine with the given configuration\n    pub fn new(config: &JSConfig) -> Result<Self, LLMSpellError> {\n        Ok(Self {\n            _config: config.clone(),\n        })\n    }\n\n    /// Get the supported features for JavaScript\n    pub fn engine_features() -> EngineFeatures {\n        EngineFeatures {\n            async_execution: true, // Native async/await\n            streaming: true,       // Via async generators\n            multimodal: true,\n            debugging: true,\n            modules: true,\n            max_script_size: Some(20_000_000),    // 20MB\n            max_execution_time_ms: Some(600_000), // 10 minutes\n        }\n    }\n}\n\n#[async_trait]\nimpl ScriptEngineBridge for JSEngine {\n    async fn execute_script(&self, _script: &str) -> Result<ScriptOutput, LLMSpellError> {\n        // TODO: Implement script execution\n        Err(LLMSpellError::Component {\n            message: \"JavaScript execution not implemented yet - will be added in Phase 5\"\n                .to_string(),\n            source: None,\n        })\n    }\n\n    async fn execute_script_streaming(&self, _script: &str) -> Result<ScriptStream, LLMSpellError> {\n        // TODO: Implement streaming execution\n        Err(LLMSpellError::Component {\n            message: \"JavaScript streaming not implemented yet - will be added in Phase 5\"\n                .to_string(),\n            source: None,\n        })\n    }\n\n    fn inject_apis(\n        &mut self,\n        _registry: &Arc<ComponentRegistry>,\n        _providers: &Arc<ProviderManager>,\n    ) -> Result<(), LLMSpellError> {\n        // TODO: Implement API injection\n        Ok(())\n    }\n\n    fn get_engine_name(&self) -> &'static str {\n        \"javascript\"\n    }\n\n    fn supports_streaming(&self) -> bool {\n        true\n    }\n\n    fn supports_multimodal(&self) -> bool {\n        true\n    }\n\n    fn supported_features(&self) -> EngineFeatures {\n        Self::engine_features()\n    }\n\n    fn get_execution_context(&self) -> Result<ExecutionContext, LLMSpellError> {\n        // TODO: Implement context retrieval\n        Ok(ExecutionContext::default())\n    }\n\n    fn set_execution_context(&mut self, _context: ExecutionContext) -> Result<(), LLMSpellError> {\n        // TODO: Implement context setting\n        Ok(())\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","javascript","mod.rs"],"content":"//! ABOUTME: JavaScript script engine implementation of ScriptEngineBridge\n//! ABOUTME: Provides ES2020 JavaScript with async/await and generator-based streaming\n\npub mod api;\npub mod engine;\n\npub use engine::JSEngine;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","lib.rs"],"content":"//! ABOUTME: llmspell-bridge - Language-agnostic script runtime with bridge pattern\n//! ABOUTME: Supports multiple script engines (Lua, JavaScript, Python) through ScriptEngineBridge\n//!\n//! # LLMSpell Bridge\n//!\n//! The bridge crate provides a language-agnostic runtime for executing scripts that\n//! interact with LLM agents, tools, and workflows. It implements the Bridge pattern\n//! to support multiple scripting languages through a common interface.\n//!\n//! ## Key Features\n//!\n//! - **Multi-Language Support**: Execute scripts in Lua (Phase 1), JavaScript (Phase 5),\n//!   and Python (Phase 9)\n//! - **Streaming Execution**: Support for streaming responses from LLM providers\n//! - **Provider Integration**: Access multiple LLM providers through a unified API\n//! - **Security Controls**: Fine-grained security settings for script execution\n//! - **Component Registry**: Dynamic registration of agents, tools, and workflows\n//!\n//! ## Architecture\n//!\n//! The bridge uses a three-layer architecture:\n//!\n//! 1. **ScriptEngineBridge Trait**: Defines the common interface for all script engines\n//! 2. **Language Implementations**: Concrete implementations for each scripting language\n//! 3. **ScriptRuntime**: High-level runtime that manages engines and provides the user API\n//!\n//! ## Quick Start\n//!\n//! ```rust,no_run\n//! use llmspell_bridge::{ScriptRuntime, RuntimeConfig};\n//!\n//! # async fn example() -> Result<(), Box<dyn std::error::Error>> {\n//! // Create a runtime with Lua engine\n//! let runtime = ScriptRuntime::new_with_lua(RuntimeConfig::default()).await?;\n//!\n//! // Execute a simple script\n//! let output = runtime.execute_script(r#\"\n//!     print(\"Hello from Lua!\")\n//!     return { message = \"Script completed\" }\n//! \"#).await?;\n//!\n//! println!(\"Output: {:?}\", output.output);\n//! # Ok(())\n//! # }\n//! ```\n//!\n//! ## Configuration\n//!\n//! The runtime can be configured through `RuntimeConfig`:\n//!\n//! ```rust,no_run\n//! use llmspell_bridge::{RuntimeConfig, ScriptRuntime};\n//!\n//! # async fn example() -> Result<(), Box<dyn std::error::Error>> {\n//! let mut config = RuntimeConfig::default();\n//!\n//! // Configure security settings\n//! config.runtime.security.allow_file_access = false;\n//! config.runtime.security.allow_network_access = true;\n//! config.runtime.security.max_memory_bytes = Some(50_000_000); // 50MB\n//!\n//! // Set default engine\n//! config.default_engine = \"lua\".to_string();\n//!\n//! let runtime = ScriptRuntime::new_with_engine_name(\"lua\", config).await?;\n//! # Ok(())\n//! # }\n//! ```\n//!\n//! ## Provider Access\n//!\n//! Scripts can access LLM providers configured in the runtime:\n//!\n//! ```rust,no_run\n//! # use llmspell_bridge::{ScriptRuntime, RuntimeConfig};\n//! # async fn example() -> Result<(), Box<dyn std::error::Error>> {\n//! let runtime = ScriptRuntime::new_with_lua(RuntimeConfig::default()).await?;\n//!\n//! let script = r#\"\n//!     -- List available providers\n//!     local providers = Provider.list()\n//!     for _, p in ipairs(providers) do\n//!         print(\"Provider: \" .. p.name)\n//!     end\n//!     \n//!     return providers\n//! \"#;\n//!\n//! let output = runtime.execute_script(script).await?;\n//! # Ok(())\n//! # }\n//! ```\n\n// Core modules\npub mod engine;\npub mod providers;\npub mod registry;\npub mod runtime;\n\n// Language-specific implementations (feature-gated)\n#[cfg(feature = \"lua\")]\npub mod lua;\n\n#[cfg(feature = \"javascript\")]\npub mod javascript;\n\n// Re-exports for convenience\npub use engine::{\n    register_engine_plugin, unregister_engine_plugin, EngineFactory, EngineFeatures, EngineInfo,\n    ExecutionContext, ScriptEngineBridge, ScriptEnginePlugin, ScriptMetadata, ScriptOutput,\n    ScriptStream, SecurityContext,\n};\n\npub use providers::{ProviderManager, ProviderManagerConfig};\npub use registry::ComponentRegistry;\npub use runtime::{RuntimeConfig, ScriptRuntime};\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","lua","api","agent.rs"],"content":"//! ABOUTME: Lua Agent API implementation providing Agent.create() and agent methods\n//! ABOUTME: Bridges between Lua scripts and Rust Agent implementations\n\nuse crate::engine::types::AgentApiDefinition;\nuse crate::{ComponentRegistry, ProviderManager};\nuse async_trait::async_trait;\nuse llmspell_core::error::LLMSpellError;\nuse llmspell_core::{\n    traits::{\n        agent::{Agent, AgentConfig, ConversationMessage},\n        base_agent::BaseAgent,\n    },\n    types::{AgentInput, AgentOutput, ExecutionContext},\n    ComponentMetadata, Result,\n};\nuse llmspell_providers::{ModelSpecifier, ProviderInstance};\nuse mlua::{Lua, Table, UserData, UserDataMethods};\nuse std::sync::Arc;\n\n/// Inject the Agent API into the Lua environment\npub fn inject_agent_api(\n    lua: &Lua,\n    api_def: &AgentApiDefinition,\n    registry: Arc<ComponentRegistry>,\n    providers: Arc<ProviderManager>,\n) -> Result<()> {\n    // Create the Agent global table\n    let agent_table = lua.create_table().map_err(|e| LLMSpellError::Component {\n        message: format!(\"Failed to create Agent table: {}\", e),\n        source: None,\n    })?;\n\n    // Clone Arc for the closure\n    let registry_clone = registry.clone();\n    let providers_clone = providers.clone();\n\n    // Create the Agent.create() function\n    let create_fn = lua\n        .create_async_function(move |_lua, args: Table| {\n            let registry = registry_clone.clone();\n            let providers = providers_clone.clone();\n\n            async move {\n                // Extract configuration from Lua table\n                let system_prompt: Option<String> = args.get(\"system_prompt\").ok();\n                let temperature: Option<f32> = args.get(\"temperature\").ok();\n                let max_tokens: Option<usize> = args.get(\"max_tokens\").ok();\n                let max_conversation_length: Option<usize> =\n                    args.get(\"max_conversation_length\").ok();\n                let base_url: Option<String> = args.get(\"base_url\").ok();\n                let api_key: Option<String> = args.get(\"api_key\").ok();\n\n                // Create a basic agent configuration\n                let agent_config = AgentConfig {\n                    system_prompt,\n                    temperature,\n                    max_tokens,\n                    max_conversation_length,\n                };\n\n                // Handle model specification with new syntax support\n                let provider = if let Some(model_str) =\n                    args.get::<_, Option<String>>(\"model\").ok().flatten()\n                {\n                    // New syntax: \"provider/model\" or \"model\"\n                    let model_spec = ModelSpecifier::parse(&model_str).map_err(|e| {\n                        mlua::Error::RuntimeError(format!(\n                            \"Invalid model specification '{}': {}\",\n                            model_str, e\n                        ))\n                    })?;\n\n                    providers\n                        .as_ref()\n                        .create_agent_from_spec(model_spec, base_url.as_deref(), api_key.as_deref())\n                        .await\n                        .map_err(|e| {\n                            mlua::Error::RuntimeError(format!(\n                                \"Failed to create agent from spec: {}\",\n                                e\n                            ))\n                        })?\n                } else if let (Some(provider_name), Some(model_name)) = (\n                    args.get::<_, Option<String>>(\"provider\").ok().flatten(),\n                    args.get::<_, Option<String>>(\"model_name\").ok().flatten(),\n                ) {\n                    // Legacy syntax: separate provider and model_name fields\n                    let model_spec = ModelSpecifier::with_provider(provider_name, model_name);\n                    providers\n                        .as_ref()\n                        .create_agent_from_spec(model_spec, base_url.as_deref(), api_key.as_deref())\n                        .await\n                        .map_err(|e| {\n                            mlua::Error::RuntimeError(format!(\n                                \"Failed to create agent from legacy spec: {}\",\n                                e\n                            ))\n                        })?\n                } else if let Some(provider_name) =\n                    args.get::<_, Option<String>>(\"provider\").ok().flatten()\n                {\n                    // Legacy syntax with just provider (use default model)\n                    providers\n                        .get_provider(Some(&provider_name))\n                        .await\n                        .map_err(|e| {\n                            mlua::Error::RuntimeError(format!(\n                                \"Failed to get provider '{}': {}\",\n                                provider_name, e\n                            ))\n                        })?\n                } else {\n                    // No provider specified, use default\n                    providers.get_default_provider().await.map_err(|e| {\n                        mlua::Error::RuntimeError(format!(\"Failed to get default provider: {}\", e))\n                    })?\n                };\n\n                // Create a simple agent wrapper\n                let agent: Box<dyn Agent> = Box::new(SimpleProviderAgent::new(\n                    agent_config,\n                    provider,\n                    \"default\".to_string(), // This will be overridden by the provider's model\n                ));\n\n                // Create the Lua wrapper\n                let wrapper = LuaAgentWrapper {\n                    agent: Arc::new(agent),\n                    _registry: registry,\n                    _providers: providers,\n                };\n\n                Ok(wrapper)\n            }\n        })\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to create Agent.create function: {}\", e),\n            source: None,\n        })?;\n\n    // Add the create function to the Agent table\n    agent_table\n        .set(&api_def.constructor[..], create_fn)\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to set Agent.create: {}\", e),\n            source: None,\n        })?;\n\n    // Set the Agent table as a global\n    lua.globals()\n        .set(&api_def.global_name[..], agent_table)\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to set Agent global: {}\", e),\n            source: None,\n        })?;\n\n    Ok(())\n}\n\n/// Wrapper around Agent for Lua\n#[derive(Clone)]\nstruct LuaAgentWrapper {\n    agent: Arc<Box<dyn Agent>>,\n    _registry: Arc<ComponentRegistry>,\n    _providers: Arc<ProviderManager>,\n}\n\nimpl UserData for LuaAgentWrapper {\n    fn add_methods<'lua, M: UserDataMethods<'lua, Self>>(methods: &mut M) {\n        // execute method\n        methods.add_async_method(\"execute\", |lua, this, input: Table| async move {\n            // Convert Lua table to AgentInput\n            let text: String = input.get(\"text\")?;\n\n            let agent_input = AgentInput::text(text);\n            let context = ExecutionContext::new();\n\n            // Execute the agent\n            let result = this\n                .agent\n                .execute(agent_input, context)\n                .await\n                .map_err(|e| mlua::Error::ExternalError(Arc::new(e)))?;\n\n            // Convert AgentOutput to Lua table\n            let output_table = lua.create_table()?;\n            output_table.set(\"text\", result.text)?;\n\n            Ok(output_table)\n        });\n\n        // getConfig method\n        methods.add_method(\"getConfig\", |lua, this, ()| {\n            let config_table = lua.create_table()?;\n            let config = this.agent.config();\n\n            if let Some(prompt) = &config.system_prompt {\n                config_table.set(\"system_prompt\", prompt.clone())?;\n            }\n            if let Some(temp) = config.temperature {\n                config_table.set(\"temperature\", temp)?;\n            }\n            if let Some(tokens) = config.max_tokens {\n                config_table.set(\"max_tokens\", tokens)?;\n            }\n\n            Ok(config_table)\n        });\n\n        // getState method\n        methods.add_method(\"getState\", |lua, _this, ()| {\n            let state_table = lua.create_table()?;\n            // TODO: Implement state retrieval from agent\n            Ok(state_table)\n        });\n\n        // setState method\n        methods.add_method(\"setState\", |_lua, _this, _state: Table| {\n            // TODO: Implement state setting on agent\n            Ok(())\n        });\n    }\n}\n\n/// Simple agent implementation that uses a provider directly\nstruct SimpleProviderAgent {\n    metadata: ComponentMetadata,\n    config: AgentConfig,\n    provider: Arc<Box<dyn ProviderInstance>>,\n    _model: String,\n    conversation: tokio::sync::Mutex<Vec<ConversationMessage>>,\n}\n\nimpl SimpleProviderAgent {\n    fn new(config: AgentConfig, provider: Arc<Box<dyn ProviderInstance>>, model: String) -> Self {\n        let metadata = ComponentMetadata::new(\n            \"SimpleProviderAgent\".to_string(),\n            \"A basic agent that uses a provider directly\".to_string(),\n        );\n\n        Self {\n            metadata,\n            config,\n            provider,\n            _model: model,\n            conversation: tokio::sync::Mutex::new(Vec::new()),\n        }\n    }\n}\n\n#[async_trait]\nimpl BaseAgent for SimpleProviderAgent {\n    fn metadata(&self) -> &ComponentMetadata {\n        &self.metadata\n    }\n\n    async fn execute(\n        &self,\n        mut input: AgentInput,\n        _context: ExecutionContext,\n    ) -> Result<AgentOutput> {\n        // Add system prompt to the input if configured\n        if let Some(ref system_prompt) = self.config.system_prompt {\n            // Prepend system prompt to the input text\n            input.text = format!(\"{}\\n\\n{}\", system_prompt, input.text);\n        }\n\n        // Use the provider to complete the request\n        let output = self.provider.complete(&input).await?;\n        Ok(output)\n    }\n\n    async fn validate_input(&self, _input: &AgentInput) -> Result<()> {\n        // Basic validation - ensure text is not empty\n        Ok(())\n    }\n\n    async fn handle_error(&self, error: LLMSpellError) -> Result<AgentOutput> {\n        Ok(AgentOutput::text(format!(\"Error: {}\", error)))\n    }\n}\n\n#[async_trait]\nimpl Agent for SimpleProviderAgent {\n    fn config(&self) -> &AgentConfig {\n        &self.config\n    }\n\n    async fn get_conversation(&self) -> Result<Vec<ConversationMessage>> {\n        let conv = self.conversation.lock().await;\n        Ok(conv.clone())\n    }\n\n    async fn add_message(&mut self, message: ConversationMessage) -> Result<()> {\n        let mut conv = self.conversation.lock().await;\n        conv.push(message);\n        Ok(())\n    }\n\n    async fn clear_conversation(&mut self) -> Result<()> {\n        let mut conv = self.conversation.lock().await;\n        conv.clear();\n        Ok(())\n    }\n}\n","traces":[{"line":21,"address":[],"length":0,"stats":{"Line":117}},{"line":28,"address":[],"length":0,"stats":{"Line":234}},{"line":29,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":117}},{"line":39,"address":[],"length":0,"stats":{"Line":6}},{"line":40,"address":[],"length":0,"stats":{"Line":6}},{"line":41,"address":[],"length":0,"stats":{"Line":6}},{"line":43,"address":[],"length":0,"stats":{"Line":6}},{"line":45,"address":[],"length":0,"stats":{"Line":6}},{"line":46,"address":[],"length":0,"stats":{"Line":6}},{"line":47,"address":[],"length":0,"stats":{"Line":6}},{"line":48,"address":[],"length":0,"stats":{"Line":6}},{"line":49,"address":[],"length":0,"stats":{"Line":6}},{"line":50,"address":[],"length":0,"stats":{"Line":6}},{"line":51,"address":[],"length":0,"stats":{"Line":6}},{"line":54,"address":[],"length":0,"stats":{"Line":6}},{"line":55,"address":[],"length":0,"stats":{"Line":6}},{"line":56,"address":[],"length":0,"stats":{"Line":6}},{"line":57,"address":[],"length":0,"stats":{"Line":6}},{"line":58,"address":[],"length":0,"stats":{"Line":6}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":6}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":6}},{"line":85,"address":[],"length":0,"stats":{"Line":6}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":2}},{"line":100,"address":[],"length":0,"stats":{"Line":6}},{"line":106,"address":[],"length":0,"stats":{"Line":4}},{"line":107,"address":[],"length":0,"stats":{"Line":2}},{"line":108,"address":[],"length":0,"stats":{"Line":2}},{"line":109,"address":[],"length":0,"stats":{"Line":2}},{"line":114,"address":[],"length":0,"stats":{"Line":12}},{"line":115,"address":[],"length":0,"stats":{"Line":4}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":117}},{"line":151,"address":[],"length":0,"stats":{"Line":117}},{"line":152,"address":[],"length":0,"stats":{"Line":117}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":117}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}}],"covered":34,"coverable":111},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","lua","api","mod.rs"],"content":"//! ABOUTME: Lua-specific API injection modules for Agent, Tool, and Workflow access\n//! ABOUTME: Handles type conversions between Rust and Lua for LLMSpell components\n\nmod agent;\nmod streaming;\nmod tool;\nmod workflow;\n\npub use agent::inject_agent_api;\npub use streaming::{create_lua_stream_bridge, inject_streaming_api};\npub use tool::inject_tool_api;\npub use workflow::inject_workflow_api;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","lua","api","streaming.rs"],"content":"//! ABOUTME: Lua streaming API implementation using coroutines\n//! ABOUTME: Provides async generator-like functionality for streaming LLM responses\n\nuse crate::engine::types::StreamingApiDefinition;\nuse llmspell_core::error::LLMSpellError;\nuse mlua::{\n    AnyUserDataExt, Function, Lua, Result as LuaResult, Table, TableExt, UserData, UserDataMethods,\n    Value,\n};\nuse std::sync::Arc;\nuse tokio::sync::{mpsc, Mutex};\n\n/// Inject streaming API into Lua environment\npub fn inject_streaming_api(\n    lua: &Lua,\n    _api_def: &StreamingApiDefinition,\n) -> Result<(), LLMSpellError> {\n    // Create the streaming utilities table\n    let streaming_table = lua.create_table().map_err(|e| LLMSpellError::Component {\n        message: format!(\"Failed to create streaming table: {}\", e),\n        source: None,\n    })?;\n\n    // Create a coroutine wrapper for streaming\n    let create_stream_fn = lua\n        .create_function(|lua, f: Function| -> LuaResult<Table> {\n            // Create a coroutine from the function\n            let thread = lua.create_thread(f)?;\n\n            // Create stream object with coroutine\n            let stream = lua.create_table()?;\n            stream.set(\"_coroutine\", thread)?;\n            stream.set(\"_done\", false)?;\n\n            // Add next() method\n            stream.set(\n                \"next\",\n                lua.create_function(|_lua, stream: Table| -> LuaResult<Value> {\n                    let thread: mlua::Thread = stream.get(\"_coroutine\")?;\n                    let done: bool = stream.get(\"_done\")?;\n\n                    if done {\n                        return Ok(Value::Nil);\n                    }\n\n                    match thread.resume::<_, Value>(()) {\n                        Ok(value) => {\n                            if thread.status() == mlua::ThreadStatus::Resumable {\n                                Ok(value)\n                            } else {\n                                stream.set(\"_done\", true)?;\n                                Ok(value)\n                            }\n                        }\n                        Err(e) => {\n                            stream.set(\"_done\", true)?;\n                            Err(e)\n                        }\n                    }\n                })?,\n            )?;\n\n            // Add isDone() method\n            stream.set(\n                \"isDone\",\n                lua.create_function(|_lua, stream: Table| -> LuaResult<bool> {\n                    stream.get(\"_done\")\n                })?,\n            )?;\n\n            // Add collect() method to get all values\n            stream.set(\n                \"collect\",\n                lua.create_function(|lua, stream: Table| -> LuaResult<Table> {\n                    let results = lua.create_table()?;\n                    let mut idx = 1;\n\n                    while !stream.call_method::<_, bool>(\"isDone\", ())? {\n                        if let Ok(value) = stream.call_method::<_, Value>(\"next\", ()) {\n                            if !value.is_nil() {\n                                results.set(idx, value)?;\n                                idx += 1;\n                            }\n                        }\n                    }\n\n                    Ok(results)\n                })?,\n            )?;\n\n            Ok(stream)\n        })\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to create stream constructor: {}\", e),\n            source: None,\n        })?;\n\n    // Add the create function to streaming table\n    streaming_table\n        .set(\"create\", create_stream_fn)\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to set streaming.create: {}\", e),\n            source: None,\n        })?;\n\n    // Create yield helper for use inside coroutines\n    let yield_fn = lua\n        .create_function(|_lua, value: Value| -> LuaResult<()> {\n            // In a real coroutine context, this would yield the value\n            // For now, this is a placeholder\n            mlua::Error::external(format!(\"Yield called with: {:?}\", value));\n            Ok(())\n        })\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to create yield function: {}\", e),\n            source: None,\n        })?;\n\n    streaming_table\n        .set(\"yield\", yield_fn)\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to set streaming.yield: {}\", e),\n            source: None,\n        })?;\n\n    // Set the streaming table as a global\n    lua.globals()\n        .set(\"Streaming\", streaming_table)\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to set Streaming global: {}\", e),\n            source: None,\n        })?;\n\n    Ok(())\n}\n\n/// Wrapper for tokio mpsc Receiver to work with mlua\n#[derive(Clone)]\nstruct StreamReceiver {\n    receiver: Arc<Mutex<mpsc::Receiver<String>>>,\n}\n\nimpl UserData for StreamReceiver {\n    fn add_methods<'lua, M: UserDataMethods<'lua, Self>>(methods: &mut M) {\n        // Add async next method\n        methods.add_async_method(\"next\", |lua, this, ()| async move {\n            let mut receiver = this.receiver.lock().await;\n            match receiver.recv().await {\n                Some(chunk) => Ok(Value::String(lua.create_string(&chunk)?)),\n                None => Ok(Value::Nil),\n            }\n        });\n\n        // Add try_next for non-blocking receive\n        methods.add_method(\"try_next\", |lua, this, ()| {\n            let mut receiver = this.receiver.blocking_lock();\n            match receiver.try_recv() {\n                Ok(chunk) => Ok(Value::String(lua.create_string(&chunk)?)),\n                Err(_) => Ok(Value::Nil),\n            }\n        });\n\n        // Add is_closed method\n        methods.add_method(\"is_closed\", |_lua, this, ()| {\n            let receiver = this.receiver.blocking_lock();\n            Ok(receiver.is_closed())\n        });\n    }\n}\n\n/// Create a Lua-compatible stream from a Rust async stream\npub fn create_lua_stream_bridge(lua: &Lua, receiver: mpsc::Receiver<String>) -> LuaResult<Table> {\n    let stream = lua.create_table()?;\n\n    // Create the receiver wrapper\n    let receiver_wrapper = StreamReceiver {\n        receiver: Arc::new(Mutex::new(receiver)),\n    };\n\n    // Store the receiver as userdata\n    stream.set(\"_receiver\", receiver_wrapper)?;\n    stream.set(\"_done\", false)?;\n\n    // Add next method that delegates to receiver\n    stream.set(\n        \"next\",\n        lua.create_async_function(|_lua, stream: Table| async move {\n            let done: bool = stream.get(\"_done\")?;\n            if done {\n                return Ok(Value::Nil);\n            }\n\n            let receiver_ud: mlua::AnyUserData = stream.get(\"_receiver\")?;\n            let result = receiver_ud\n                .call_async_method::<_, Value>(\"next\", ())\n                .await?;\n\n            if result.is_nil() {\n                stream.set(\"_done\", true)?;\n            }\n\n            Ok(result)\n        })?,\n    )?;\n\n    // Add isDone method\n    stream.set(\n        \"isDone\",\n        lua.create_function(|_lua, stream: Table| -> LuaResult<bool> { stream.get(\"_done\") })?,\n    )?;\n\n    // Add collect method for gathering all values\n    stream.set(\n        \"collect\",\n        lua.create_async_function(|lua, stream: Table| async move {\n            let results = lua.create_table()?;\n            let mut idx = 1;\n\n            while !stream.call_method::<_, bool>(\"isDone\", ())? {\n                let value = stream.call_async_method::<_, Value>(\"next\", ()).await?;\n                if !value.is_nil() {\n                    results.set(idx, value)?;\n                    idx += 1;\n                }\n            }\n\n            Ok(results)\n        })?,\n    )?;\n\n    Ok(stream)\n}\n","traces":[{"line":14,"address":[],"length":0,"stats":{"Line":117}},{"line":19,"address":[],"length":0,"stats":{"Line":234}},{"line":20,"address":[],"length":0,"stats":{"Line":0}},{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":117}},{"line":26,"address":[],"length":0,"stats":{"Line":10}},{"line":28,"address":[],"length":0,"stats":{"Line":20}},{"line":31,"address":[],"length":0,"stats":{"Line":10}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":10}},{"line":36,"address":[],"length":0,"stats":{"Line":10}},{"line":37,"address":[],"length":0,"stats":{"Line":10}},{"line":38,"address":[],"length":0,"stats":{"Line":52}},{"line":39,"address":[],"length":0,"stats":{"Line":84}},{"line":40,"address":[],"length":0,"stats":{"Line":42}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":42}},{"line":47,"address":[],"length":0,"stats":{"Line":40}},{"line":48,"address":[],"length":0,"stats":{"Line":40}},{"line":49,"address":[],"length":0,"stats":{"Line":34}},{"line":51,"address":[],"length":0,"stats":{"Line":6}},{"line":52,"address":[],"length":0,"stats":{"Line":6}},{"line":55,"address":[],"length":0,"stats":{"Line":2}},{"line":56,"address":[],"length":0,"stats":{"Line":2}},{"line":57,"address":[],"length":0,"stats":{"Line":2}},{"line":64,"address":[],"length":0,"stats":{"Line":10}},{"line":65,"address":[],"length":0,"stats":{"Line":10}},{"line":66,"address":[],"length":0,"stats":{"Line":58}},{"line":67,"address":[],"length":0,"stats":{"Line":48}},{"line":72,"address":[],"length":0,"stats":{"Line":10}},{"line":73,"address":[],"length":0,"stats":{"Line":10}},{"line":74,"address":[],"length":0,"stats":{"Line":14}},{"line":75,"address":[],"length":0,"stats":{"Line":8}},{"line":78,"address":[],"length":0,"stats":{"Line":30}},{"line":79,"address":[],"length":0,"stats":{"Line":52}},{"line":81,"address":[],"length":0,"stats":{"Line":22}},{"line":82,"address":[],"length":0,"stats":{"Line":22}},{"line":87,"address":[],"length":0,"stats":{"Line":4}},{"line":91,"address":[],"length":0,"stats":{"Line":10}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":234}},{"line":108,"address":[],"length":0,"stats":{"Line":117}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":117}},{"line":128,"address":[],"length":0,"stats":{"Line":117}},{"line":129,"address":[],"length":0,"stats":{"Line":117}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":117}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":221,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":231,"address":[],"length":0,"stats":{"Line":0}}],"covered":41,"coverable":105},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","lua","api","tool.rs"],"content":"//! ABOUTME: Lua Tool API implementation providing Tool.get() and tool methods\n//! ABOUTME: Bridges between Lua scripts and Rust Tool implementations\n\nuse crate::engine::types::ToolApiDefinition;\nuse crate::ComponentRegistry;\nuse llmspell_core::error::LLMSpellError;\nuse mlua::Lua;\nuse std::sync::Arc;\n\n/// Inject the Tool API into the Lua environment\npub fn inject_tool_api(\n    lua: &Lua,\n    api_def: &ToolApiDefinition,\n    registry: Arc<ComponentRegistry>,\n) -> Result<(), LLMSpellError> {\n    // Create the Tool global table\n    let tool_table = lua.create_table().map_err(|e| LLMSpellError::Component {\n        message: format!(\"Failed to create Tool table: {}\", e),\n        source: None,\n    })?;\n\n    // Clone registry for closures\n    let _registry_clone = registry.clone();\n\n    // Implement Tool.get() function\n    let get_fn = lua\n        .create_function(move |lua, tool_name: String| -> mlua::Result<mlua::Table> {\n            // TODO: Actually get tool from registry\n            // For now, return a mock tool\n            let tool = lua.create_table()?;\n            tool.set(\"name\", tool_name.clone())?;\n            tool.set(\"description\", format!(\"Tool: {}\", tool_name))?;\n\n            // Add execute method\n            let tool_name_for_execute = tool_name.clone();\n            tool.set(\n                \"execute\",\n                lua.create_async_function(move |lua, _args: mlua::Table| {\n                    let tool_name_in_async = tool_name_for_execute.clone();\n                    async move {\n                        // Mock execution\n                        let result = lua.create_table()?;\n                        result.set(\"success\", true)?;\n                        result.set(\"output\", format!(\"Executed tool: {}\", tool_name_in_async))?;\n                        Ok(result)\n                    }\n                })?,\n            )?;\n\n            // Add getSchema method\n            tool.set(\n                \"getSchema\",\n                lua.create_function(|lua, _: ()| {\n                    let schema = lua.create_table()?;\n                    schema.set(\"parameters\", lua.create_table()?)?;\n                    Ok(schema)\n                })?,\n            )?;\n\n            Ok(tool)\n        })\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to create Tool.get function: {}\", e),\n            source: None,\n        })?;\n\n    // Implement Tool.list() function\n    let list_fn = lua\n        .create_function(move |lua, _: ()| -> mlua::Result<mlua::Table> {\n            // TODO: Get actual tools from registry\n            let tools = lua.create_table()?;\n            tools.set(1, \"calculator\")?;\n            tools.set(2, \"web_search\")?;\n            tools.set(3, \"file_reader\")?;\n            Ok(tools)\n        })\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to create Tool.list function: {}\", e),\n            source: None,\n        })?;\n\n    // Add functions to Tool table\n    tool_table\n        .set(&api_def.get_function[..], get_fn)\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to set Tool.get: {}\", e),\n            source: None,\n        })?;\n\n    tool_table\n        .set(&api_def.list_function[..], list_fn)\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to set Tool.list: {}\", e),\n            source: None,\n        })?;\n\n    // Set the Tool table as a global\n    lua.globals()\n        .set(&api_def.global_name[..], tool_table)\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to set Tool global: {}\", e),\n            source: None,\n        })?;\n\n    Ok(())\n}\n","traces":[{"line":11,"address":[],"length":0,"stats":{"Line":117}},{"line":17,"address":[],"length":0,"stats":{"Line":234}},{"line":18,"address":[],"length":0,"stats":{"Line":0}},{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":117}},{"line":27,"address":[],"length":0,"stats":{"Line":2}},{"line":30,"address":[],"length":0,"stats":{"Line":4}},{"line":31,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":2}},{"line":35,"address":[],"length":0,"stats":{"Line":2}},{"line":36,"address":[],"length":0,"stats":{"Line":2}},{"line":37,"address":[],"length":0,"stats":{"Line":2}},{"line":38,"address":[],"length":0,"stats":{"Line":2}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":2}},{"line":52,"address":[],"length":0,"stats":{"Line":2}},{"line":53,"address":[],"length":0,"stats":{"Line":2}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":2}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":117}},{"line":69,"address":[],"length":0,"stats":{"Line":2}},{"line":71,"address":[],"length":0,"stats":{"Line":4}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":2}},{"line":74,"address":[],"length":0,"stats":{"Line":2}},{"line":75,"address":[],"length":0,"stats":{"Line":2}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":117}},{"line":91,"address":[],"length":0,"stats":{"Line":117}},{"line":92,"address":[],"length":0,"stats":{"Line":117}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":117}},{"line":99,"address":[],"length":0,"stats":{"Line":117}},{"line":100,"address":[],"length":0,"stats":{"Line":117}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":117}}],"covered":27,"coverable":53},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","lua","api","workflow.rs"],"content":"//! ABOUTME: Lua Workflow API implementation providing workflow constructors\n//! ABOUTME: Bridges between Lua scripts and Rust Workflow implementations\n\nuse crate::engine::types::WorkflowApiDefinition;\nuse crate::ComponentRegistry;\nuse llmspell_core::error::LLMSpellError;\nuse mlua::Lua;\nuse std::sync::Arc;\n\n/// Inject the Workflow API into the Lua environment\npub fn inject_workflow_api(\n    lua: &Lua,\n    api_def: &WorkflowApiDefinition,\n    registry: Arc<ComponentRegistry>,\n) -> Result<(), LLMSpellError> {\n    // Create the Workflow global table\n    let workflow_table = lua.create_table().map_err(|e| LLMSpellError::Component {\n        message: format!(\"Failed to create Workflow table: {}\", e),\n        source: None,\n    })?;\n\n    // Clone registry for closures\n    let _registry_clone = registry.clone();\n\n    // Implement Workflow.sequential() constructor\n    let sequential_fn = lua\n        .create_function(|lua, steps: mlua::Table| -> mlua::Result<mlua::Table> {\n            let workflow = lua.create_table()?;\n            workflow.set(\"type\", \"sequential\")?;\n            workflow.set(\"steps\", steps)?;\n\n            // Add execute method\n            workflow.set(\n                \"execute\",\n                lua.create_async_function(|lua, _args: mlua::Table| async move {\n                    // Mock execution - run steps in sequence\n                    let result = lua.create_table()?;\n                    result.set(\"success\", true)?;\n                    result.set(\"message\", \"Sequential workflow executed\")?;\n                    Ok(result)\n                })?,\n            )?;\n\n            Ok(workflow)\n        })\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to create Workflow.sequential: {}\", e),\n            source: None,\n        })?;\n\n    // Implement Workflow.parallel() constructor\n    let parallel_fn = lua\n        .create_function(|lua, steps: mlua::Table| -> mlua::Result<mlua::Table> {\n            let workflow = lua.create_table()?;\n            workflow.set(\"type\", \"parallel\")?;\n            workflow.set(\"steps\", steps)?;\n\n            // Add execute method\n            workflow.set(\n                \"execute\",\n                lua.create_async_function(|lua, _args: mlua::Table| async move {\n                    // Mock execution - would run steps in parallel\n                    let result = lua.create_table()?;\n                    result.set(\"success\", true)?;\n                    result.set(\"message\", \"Parallel workflow executed\")?;\n                    Ok(result)\n                })?,\n            )?;\n\n            Ok(workflow)\n        })\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to create Workflow.parallel: {}\", e),\n            source: None,\n        })?;\n\n    // Add constructors to Workflow table\n    workflow_table\n        .set(&api_def.constructors.sequential[..], sequential_fn)\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to set Workflow.sequential: {}\", e),\n            source: None,\n        })?;\n\n    workflow_table\n        .set(&api_def.constructors.parallel[..], parallel_fn)\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to set Workflow.parallel: {}\", e),\n            source: None,\n        })?;\n\n    // Add placeholder for conditional and loop\n    let placeholder = lua\n        .create_function(|_lua, _: mlua::Value| -> mlua::Result<mlua::Table> {\n            Err(mlua::Error::RuntimeError(\n                \"Workflow type not yet implemented\".to_string(),\n            ))\n        })\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to create placeholder: {}\", e),\n            source: None,\n        })?;\n\n    workflow_table\n        .set(&api_def.constructors.conditional[..], placeholder.clone())\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to set Workflow.conditional: {}\", e),\n            source: None,\n        })?;\n\n    workflow_table\n        .set(&api_def.constructors.loop_workflow[..], placeholder)\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to set Workflow.loop: {}\", e),\n            source: None,\n        })?;\n\n    // Set the Workflow table as a global\n    lua.globals()\n        .set(&api_def.global_name[..], workflow_table)\n        .map_err(|e| LLMSpellError::Component {\n            message: format!(\"Failed to set Workflow global: {}\", e),\n            source: None,\n        })?;\n\n    Ok(())\n}\n","traces":[{"line":11,"address":[],"length":0,"stats":{"Line":117}},{"line":17,"address":[],"length":0,"stats":{"Line":234}},{"line":18,"address":[],"length":0,"stats":{"Line":0}},{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":117}},{"line":27,"address":[],"length":0,"stats":{"Line":2}},{"line":28,"address":[],"length":0,"stats":{"Line":4}},{"line":29,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":2}},{"line":33,"address":[],"length":0,"stats":{"Line":2}},{"line":34,"address":[],"length":0,"stats":{"Line":2}},{"line":35,"address":[],"length":0,"stats":{"Line":2}},{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":2}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":117}},{"line":53,"address":[],"length":0,"stats":{"Line":2}},{"line":54,"address":[],"length":0,"stats":{"Line":4}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":2}},{"line":59,"address":[],"length":0,"stats":{"Line":2}},{"line":60,"address":[],"length":0,"stats":{"Line":2}},{"line":61,"address":[],"length":0,"stats":{"Line":2}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":2}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":117}},{"line":86,"address":[],"length":0,"stats":{"Line":117}},{"line":87,"address":[],"length":0,"stats":{"Line":117}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":234}},{"line":94,"address":[],"length":0,"stats":{"Line":117}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":117}},{"line":112,"address":[],"length":0,"stats":{"Line":117}},{"line":113,"address":[],"length":0,"stats":{"Line":117}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":117}},{"line":120,"address":[],"length":0,"stats":{"Line":117}},{"line":121,"address":[],"length":0,"stats":{"Line":117}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":117}}],"covered":30,"coverable":65},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","lua","engine.rs"],"content":"//! ABOUTME: LuaEngine implementation of ScriptEngineBridge trait\n//! ABOUTME: Provides Lua 5.4 script execution with coroutine-based streaming\n\nuse crate::engine::types::{ApiSurface, ScriptEngineError};\nuse crate::engine::{\n    factory::{LuaConfig, StdlibLevel},\n    EngineFeatures, ExecutionContext, ScriptEngineBridge, ScriptMetadata, ScriptOutput,\n    ScriptStream,\n};\nuse crate::{ComponentRegistry, ProviderManager};\nuse async_trait::async_trait;\nuse llmspell_core::error::LLMSpellError;\nuse serde_json::Value;\nuse std::sync::Arc;\nuse std::time::Instant;\n\n/// Lua script engine implementation\n///\n/// Note: mlua requires unsafe Send/Sync implementation for thread safety\npub struct LuaEngine {\n    #[cfg(feature = \"lua\")]\n    lua: Arc<parking_lot::Mutex<mlua::Lua>>,\n    _config: LuaConfig,\n    #[cfg(feature = \"lua\")]\n    api_injected: bool,\n    execution_context: ExecutionContext,\n}\n\n// SAFETY: We ensure thread safety by using Mutex for all Lua access\nunsafe impl Send for LuaEngine {}\nunsafe impl Sync for LuaEngine {}\n\nimpl LuaEngine {\n    /// Create a new Lua engine with the given configuration\n    pub fn new(config: &LuaConfig) -> Result<Self, LLMSpellError> {\n        #[cfg(feature = \"lua\")]\n        {\n            use mlua::Lua;\n            let lua = match config.stdlib {\n                StdlibLevel::None => Lua::new(),\n                StdlibLevel::Safe => Lua::new(), // TODO: restrict stdlib\n                StdlibLevel::Full => Lua::new(),\n            };\n\n            Ok(Self {\n                lua: Arc::new(parking_lot::Mutex::new(lua)),\n                _config: config.clone(),\n                api_injected: false,\n                execution_context: ExecutionContext::default(),\n            })\n        }\n\n        #[cfg(not(feature = \"lua\"))]\n        {\n            Err(LLMSpellError::Component {\n                message: \"Lua feature not enabled\".to_string(),\n                source: None,\n            })\n        }\n    }\n\n    /// Get the supported features for Lua\n    pub fn engine_features() -> EngineFeatures {\n        EngineFeatures {\n            async_execution: true, // Via coroutines\n            streaming: true,\n            multimodal: true,\n            debugging: false, // Not implemented yet\n            modules: true,\n            max_script_size: Some(10_000_000),    // 10MB\n            max_execution_time_ms: Some(300_000), // 5 minutes\n        }\n    }\n}\n\n#[async_trait]\nimpl ScriptEngineBridge for LuaEngine {\n    async fn execute_script(&self, script: &str) -> Result<ScriptOutput, LLMSpellError> {\n        #[cfg(feature = \"lua\")]\n        {\n            if !self.api_injected {\n                return Err(LLMSpellError::Component {\n                    message: \"APIs not injected. Call inject_apis first\".to_string(),\n                    source: None,\n                });\n            }\n\n            let start_time = Instant::now();\n            let lua = self.lua.lock();\n\n            // Execute the script\n            let result: mlua::Result<mlua::Value> = lua.load(script).eval();\n\n            match result {\n                Ok(value) => {\n                    // Convert Lua value to JSON\n                    let output = lua_value_to_json(&lua, value)?;\n\n                    Ok(ScriptOutput {\n                        output,\n                        console_output: vec![], // TODO: Capture console output\n                        metadata: ScriptMetadata {\n                            engine: \"lua\".to_string(),\n                            execution_time_ms: start_time.elapsed().as_millis() as u64,\n                            memory_usage_bytes: None, // TODO: Track memory usage\n                            warnings: vec![],\n                        },\n                    })\n                }\n                Err(e) => Err(ScriptEngineError::ExecutionError {\n                    engine: \"lua\".to_string(),\n                    details: e.to_string(),\n                }\n                .into()),\n            }\n        }\n\n        #[cfg(not(feature = \"lua\"))]\n        {\n            Err(LLMSpellError::Component {\n                message: \"Lua feature not enabled\".to_string(),\n                source: None,\n            })\n        }\n    }\n\n    async fn execute_script_streaming(&self, script: &str) -> Result<ScriptStream, LLMSpellError> {\n        #[cfg(feature = \"lua\")]\n        {\n            if !self.api_injected {\n                return Err(LLMSpellError::Component {\n                    message: \"APIs not injected. Call inject_apis first\".to_string(),\n                    source: None,\n                });\n            }\n\n            // For now, implement a simple non-streaming execution that returns a single chunk\n            // Full streaming with coroutines requires more complex handling due to Send constraints\n            let start_time = Instant::now();\n            let lua = self.lua.lock();\n\n            // Execute the script\n            let result: mlua::Result<mlua::Value> = lua.load(script).eval();\n\n            // Create a single chunk with the result\n            let chunk = match result {\n                Ok(value) => {\n                    // Convert Lua value to JSON\n                    let output = lua_value_to_json(&lua, value)?;\n                    llmspell_core::types::AgentChunk {\n                        stream_id: \"lua-stream\".to_string(),\n                        chunk_index: 0,\n                        content: llmspell_core::types::ChunkContent::Text(\n                            serde_json::to_string(&output).unwrap_or_else(|_| \"null\".to_string()),\n                        ),\n                        metadata: llmspell_core::types::ChunkMetadata {\n                            is_final: true,\n                            token_count: None,\n                            model: None,\n                            reasoning_step: None,\n                        },\n                        timestamp: chrono::Utc::now(),\n                    }\n                }\n                Err(e) => llmspell_core::types::AgentChunk {\n                    stream_id: \"lua-stream\".to_string(),\n                    chunk_index: 0,\n                    content: llmspell_core::types::ChunkContent::Control(\n                        llmspell_core::types::ControlMessage::StreamCancelled {\n                            reason: format!(\"Script execution failed: {}\", e),\n                        },\n                    ),\n                    metadata: Default::default(),\n                    timestamp: chrono::Utc::now(),\n                },\n            };\n\n            // Create a stream from a single chunk\n            use futures::stream;\n            let chunk_stream = stream::once(async move { Ok(chunk) });\n            let boxed_stream: llmspell_core::types::AgentStream = Box::pin(chunk_stream);\n\n            Ok(ScriptStream {\n                stream: boxed_stream,\n                metadata: ScriptMetadata {\n                    engine: \"lua\".to_string(),\n                    execution_time_ms: start_time.elapsed().as_millis() as u64,\n                    memory_usage_bytes: None,\n                    warnings: vec![],\n                },\n            })\n        }\n\n        #[cfg(not(feature = \"lua\"))]\n        {\n            Err(LLMSpellError::Component {\n                message: \"Lua feature not enabled\".to_string(),\n                source: None,\n            })\n        }\n    }\n\n    fn inject_apis(\n        &mut self,\n        registry: &Arc<ComponentRegistry>,\n        providers: &Arc<ProviderManager>,\n    ) -> Result<(), LLMSpellError> {\n        #[cfg(feature = \"lua\")]\n        {\n            let lua = self.lua.lock();\n\n            // Get the API surface definition\n            let api_surface = ApiSurface::standard();\n\n            // Inject Agent API\n            super::api::inject_agent_api(\n                &lua,\n                &api_surface.agent_api,\n                registry.clone(),\n                providers.clone(),\n            )?;\n\n            // Inject Tool API\n            super::api::inject_tool_api(&lua, &api_surface.tool_api, registry.clone())?;\n\n            // Inject Workflow API\n            super::api::inject_workflow_api(&lua, &api_surface.workflow_api, registry.clone())?;\n\n            // Inject Streaming API\n            super::api::inject_streaming_api(&lua, &api_surface.streaming_api)?;\n\n            self.api_injected = true;\n        }\n        Ok(())\n    }\n\n    fn get_engine_name(&self) -> &'static str {\n        \"lua\"\n    }\n\n    fn supports_streaming(&self) -> bool {\n        true\n    }\n\n    fn supports_multimodal(&self) -> bool {\n        true\n    }\n\n    fn supported_features(&self) -> EngineFeatures {\n        Self::engine_features()\n    }\n\n    fn get_execution_context(&self) -> Result<ExecutionContext, LLMSpellError> {\n        Ok(self.execution_context.clone())\n    }\n\n    fn set_execution_context(&mut self, context: ExecutionContext) -> Result<(), LLMSpellError> {\n        self.execution_context = context;\n        Ok(())\n    }\n}\n\n#[cfg(feature = \"lua\")]\n/// Convert a Lua value to JSON\nfn lua_value_to_json(_lua: &mlua::Lua, value: mlua::Value) -> Result<Value, LLMSpellError> {\n    use mlua::Value as LuaValue;\n\n    match value {\n        LuaValue::Nil => Ok(Value::Null),\n        LuaValue::Boolean(b) => Ok(Value::Bool(b)),\n        LuaValue::Integer(i) => Ok(Value::Number(i.into())),\n        LuaValue::Number(n) => Ok(Value::from(n)),\n        LuaValue::String(s) => {\n            let str = s.to_str().map_err(|e| LLMSpellError::Component {\n                message: format!(\"Failed to convert Lua string: {}\", e),\n                source: None,\n            })?;\n            Ok(Value::String(str.to_string()))\n        }\n        LuaValue::Table(table) => {\n            // Check if it's an array\n            if is_lua_array(&table) {\n                let mut array = Vec::new();\n                for i in 1..=table.len().map_err(|e| LLMSpellError::Component {\n                    message: format!(\"Failed to get table length: {}\", e),\n                    source: None,\n                })? {\n                    let value: LuaValue = table.get(i).map_err(|e| LLMSpellError::Component {\n                        message: format!(\"Failed to get table value: {}\", e),\n                        source: None,\n                    })?;\n                    array.push(lua_value_to_json(_lua, value)?);\n                }\n                Ok(Value::Array(array))\n            } else {\n                // It's an object\n                let mut map = serde_json::Map::new();\n                for pair in table.pairs::<LuaValue, LuaValue>() {\n                    let (k, v) = pair.map_err(|e| LLMSpellError::Component {\n                        message: format!(\"Failed to iterate table: {}\", e),\n                        source: None,\n                    })?;\n\n                    if let LuaValue::String(key_str) = k {\n                        let key = key_str.to_str().map_err(|e| LLMSpellError::Component {\n                            message: format!(\"Failed to convert table key: {}\", e),\n                            source: None,\n                        })?;\n                        map.insert(key.to_string(), lua_value_to_json(_lua, v)?);\n                    }\n                }\n                Ok(Value::Object(map))\n            }\n        }\n        _ => Ok(Value::String(format!(\"<{:?}>\", value))),\n    }\n}\n\n#[cfg(feature = \"lua\")]\n/// Check if a Lua table is an array (has sequential numeric keys starting at 1)\nfn is_lua_array(table: &mlua::Table) -> bool {\n    if let Ok(len) = table.len() {\n        if len == 0 {\n            return false;\n        }\n        // Check if all keys from 1 to len exist\n        for i in 1..=len {\n            if table.get::<_, mlua::Value>(i).is_err() {\n                return false;\n            }\n        }\n        // Check if there are any non-numeric keys\n        for (k, _) in table.clone().pairs::<mlua::Value, mlua::Value>().flatten() {\n            match k {\n                mlua::Value::Integer(i) if i >= 1 && i <= len => continue,\n                _ => return false,\n            }\n        }\n        true\n    } else {\n        false\n    }\n}\n","traces":[{"line":35,"address":[],"length":0,"stats":{"Line":143}},{"line":39,"address":[],"length":0,"stats":{"Line":286}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":143}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":143}},{"line":46,"address":[],"length":0,"stats":{"Line":143}},{"line":47,"address":[],"length":0,"stats":{"Line":143}},{"line":48,"address":[],"length":0,"stats":{"Line":143}},{"line":49,"address":[],"length":0,"stats":{"Line":143}},{"line":55,"address":[],"length":0,"stats":{"Line":143}},{"line":56,"address":[],"length":0,"stats":{"Line":143}},{"line":57,"address":[],"length":0,"stats":{"Line":143}},{"line":63,"address":[],"length":0,"stats":{"Line":10}},{"line":70,"address":[],"length":0,"stats":{"Line":10}},{"line":71,"address":[],"length":0,"stats":{"Line":10}},{"line":78,"address":[],"length":0,"stats":{"Line":4129}},{"line":81,"address":[],"length":0,"stats":{"Line":4129}},{"line":82,"address":[],"length":0,"stats":{"Line":8}},{"line":83,"address":[],"length":0,"stats":{"Line":8}},{"line":84,"address":[],"length":0,"stats":{"Line":8}},{"line":88,"address":[],"length":0,"stats":{"Line":4121}},{"line":89,"address":[],"length":0,"stats":{"Line":4121}},{"line":92,"address":[],"length":0,"stats":{"Line":4121}},{"line":94,"address":[],"length":0,"stats":{"Line":4121}},{"line":95,"address":[],"length":0,"stats":{"Line":4109}},{"line":97,"address":[],"length":0,"stats":{"Line":4109}},{"line":110,"address":[],"length":0,"stats":{"Line":12}},{"line":111,"address":[],"length":0,"stats":{"Line":12}},{"line":112,"address":[],"length":0,"stats":{"Line":12}},{"line":114,"address":[],"length":0,"stats":{"Line":12}},{"line":127,"address":[],"length":0,"stats":{"Line":10}},{"line":130,"address":[],"length":0,"stats":{"Line":10}},{"line":131,"address":[],"length":0,"stats":{"Line":2}},{"line":132,"address":[],"length":0,"stats":{"Line":2}},{"line":133,"address":[],"length":0,"stats":{"Line":2}},{"line":139,"address":[],"length":0,"stats":{"Line":8}},{"line":140,"address":[],"length":0,"stats":{"Line":8}},{"line":143,"address":[],"length":0,"stats":{"Line":8}},{"line":146,"address":[],"length":0,"stats":{"Line":16}},{"line":147,"address":[],"length":0,"stats":{"Line":8}},{"line":149,"address":[],"length":0,"stats":{"Line":8}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":2}},{"line":203,"address":[],"length":0,"stats":{"Line":117}},{"line":210,"address":[],"length":0,"stats":{"Line":117}},{"line":213,"address":[],"length":0,"stats":{"Line":117}},{"line":217,"address":[],"length":0,"stats":{"Line":117}},{"line":218,"address":[],"length":0,"stats":{"Line":117}},{"line":219,"address":[],"length":0,"stats":{"Line":117}},{"line":220,"address":[],"length":0,"stats":{"Line":117}},{"line":224,"address":[],"length":0,"stats":{"Line":117}},{"line":227,"address":[],"length":0,"stats":{"Line":117}},{"line":230,"address":[],"length":0,"stats":{"Line":117}},{"line":232,"address":[],"length":0,"stats":{"Line":117}},{"line":234,"address":[],"length":0,"stats":{"Line":117}},{"line":237,"address":[],"length":0,"stats":{"Line":14}},{"line":238,"address":[],"length":0,"stats":{"Line":14}},{"line":241,"address":[],"length":0,"stats":{"Line":14}},{"line":242,"address":[],"length":0,"stats":{"Line":14}},{"line":245,"address":[],"length":0,"stats":{"Line":12}},{"line":246,"address":[],"length":0,"stats":{"Line":12}},{"line":249,"address":[],"length":0,"stats":{"Line":6}},{"line":250,"address":[],"length":0,"stats":{"Line":6}},{"line":253,"address":[],"length":0,"stats":{"Line":6}},{"line":254,"address":[],"length":0,"stats":{"Line":6}},{"line":257,"address":[],"length":0,"stats":{"Line":204}},{"line":258,"address":[],"length":0,"stats":{"Line":204}},{"line":259,"address":[],"length":0,"stats":{"Line":204}},{"line":265,"address":[],"length":0,"stats":{"Line":4804}},{"line":268,"address":[],"length":0,"stats":{"Line":4804}},{"line":269,"address":[],"length":0,"stats":{"Line":2}},{"line":270,"address":[],"length":0,"stats":{"Line":56}},{"line":271,"address":[],"length":0,"stats":{"Line":4245}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":272}},{"line":274,"address":[],"length":0,"stats":{"Line":544}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":229}},{"line":282,"address":[],"length":0,"stats":{"Line":229}},{"line":283,"address":[],"length":0,"stats":{"Line":6}},{"line":284,"address":[],"length":0,"stats":{"Line":24}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":36}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":6}},{"line":297,"address":[],"length":0,"stats":{"Line":223}},{"line":298,"address":[],"length":0,"stats":{"Line":669}},{"line":299,"address":[],"length":0,"stats":{"Line":1338}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":669}},{"line":305,"address":[],"length":0,"stats":{"Line":669}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":223}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":321,"address":[],"length":0,"stats":{"Line":229}},{"line":322,"address":[],"length":0,"stats":{"Line":458}},{"line":324,"address":[],"length":0,"stats":{"Line":223}},{"line":327,"address":[],"length":0,"stats":{"Line":18}},{"line":328,"address":[],"length":0,"stats":{"Line":18}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":333,"address":[],"length":0,"stats":{"Line":24}},{"line":334,"address":[],"length":0,"stats":{"Line":18}},{"line":335,"address":[],"length":0,"stats":{"Line":54}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":6}},{"line":341,"address":[],"length":0,"stats":{"Line":0}}],"covered":94,"coverable":117},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","lua","mod.rs"],"content":"//! ABOUTME: Lua script engine implementation of ScriptEngineBridge\n//! ABOUTME: Provides Lua 5.4 scripting with coroutine-based streaming\n\npub mod api;\npub mod engine;\n\npub use engine::LuaEngine;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","providers.rs"],"content":"//! ABOUTME: Provider management for LLM providers accessible from scripts\n//! ABOUTME: Manages provider configuration, capability detection, and access control\n\nuse llmspell_core::error::LLMSpellError;\nuse llmspell_providers::{\n    ModelSpecifier, ProviderCapabilities, ProviderConfig as ProviderInstanceConfig,\n    ProviderInstance, ProviderManager as CoreProviderManager,\n};\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\nuse std::sync::Arc;\n\n/// Manages LLM providers for script access\npub struct ProviderManager {\n    core_manager: CoreProviderManager,\n    config: ProviderManagerConfig,\n}\n\nimpl ProviderManager {\n    /// Create a new provider manager with configuration\n    pub async fn new(config: ProviderManagerConfig) -> Result<Self, LLMSpellError> {\n        let core_manager = CoreProviderManager::new();\n        let manager = Self {\n            core_manager,\n            config: config.clone(),\n        };\n\n        // Register the rig provider factory\n        manager.register_rig_provider().await?;\n\n        // Initialize configured providers\n        manager.initialize_providers().await?;\n\n        Ok(manager)\n    }\n\n    /// Register the rig provider factory\n    async fn register_rig_provider(&self) -> Result<(), LLMSpellError> {\n        self.core_manager\n            .register_provider(\"rig\", llmspell_providers::create_rig_provider)\n            .await;\n        Ok(())\n    }\n\n    /// Initialize providers from configuration\n    async fn initialize_providers(&self) -> Result<(), LLMSpellError> {\n        // Initialize each configured provider\n        for (name, config) in &self.config.providers {\n            let provider_config = self.create_provider_config(name, config)?;\n            self.core_manager.init_provider(provider_config).await?;\n        }\n\n        // Set default provider if specified\n        if let Some(ref default) = self.config.default_provider {\n            if !self.config.providers.contains_key(default) {\n                return Err(LLMSpellError::Validation {\n                    field: Some(\"default_provider\".to_string()),\n                    message: format!(\"Default provider '{}' not found in configuration\", default),\n                });\n            }\n            // The default will be set based on the provider:model format\n            let model = self.config.providers[default]\n                .model\n                .as_ref()\n                .ok_or_else(|| LLMSpellError::Validation {\n                    field: Some(\"model\".to_string()),\n                    message: format!(\"Model not specified for provider '{}'\", default),\n                })?;\n            self.core_manager\n                .set_default_provider(format!(\"{}:{}\", default, model))\n                .await?;\n        }\n\n        Ok(())\n    }\n\n    /// Create a provider config from our configuration\n    fn create_provider_config(\n        &self,\n        name: &str,\n        config: &ProviderConfig,\n    ) -> Result<ProviderInstanceConfig, LLMSpellError> {\n        // Map provider_type to the actual provider name\n        let provider_name = match config.provider_type.as_str() {\n            \"openai\" | \"anthropic\" | \"cohere\" => \"rig\",\n            other => other,\n        };\n\n        let model = config\n            .model\n            .as_ref()\n            .ok_or_else(|| LLMSpellError::Validation {\n                field: Some(\"model\".to_string()),\n                message: format!(\"Model not specified for provider '{}'\", name),\n            })?;\n\n        let mut provider_config = ProviderInstanceConfig::new(provider_name, model);\n\n        // Set API key from environment if specified\n        if let Some(ref api_key_env) = config.api_key_env {\n            let api_key = std::env::var(api_key_env).map_err(|_| LLMSpellError::Configuration {\n                message: format!(\n                    \"Environment variable '{}' not found for provider '{}'\",\n                    api_key_env, name\n                ),\n                source: None,\n            })?;\n            provider_config.api_key = Some(api_key);\n        }\n\n        // Set other configuration\n        if let Some(ref base_url) = config.base_url {\n            provider_config.endpoint = Some(base_url.clone());\n        }\n\n        // Add extra configuration\n        for (key, value) in &config.extra {\n            provider_config\n                .custom_config\n                .insert(key.clone(), value.clone());\n        }\n\n        Ok(provider_config)\n    }\n\n    /// Get a provider by name\n    pub async fn get_provider(\n        &self,\n        name: Option<&str>,\n    ) -> Result<Arc<Box<dyn ProviderInstance>>, LLMSpellError> {\n        self.core_manager.get_provider(name).await\n    }\n\n    /// Get the default provider\n    pub async fn get_default_provider(\n        &self,\n    ) -> Result<Arc<Box<dyn ProviderInstance>>, LLMSpellError> {\n        self.core_manager.get_provider(None).await\n    }\n\n    /// Set the default provider\n    pub async fn set_default_provider(&self, name: String) -> Result<(), LLMSpellError> {\n        self.core_manager.set_default_provider(name).await\n    }\n\n    /// Create and initialize a provider from a ModelSpecifier\n    ///\n    /// This is a bridge method that delegates to the core provider manager's\n    /// create_agent_from_spec method. It supports the new \"provider/model\" syntax.\n    pub async fn create_agent_from_spec(\n        &self,\n        spec: ModelSpecifier,\n        base_url_override: Option<&str>,\n        api_key: Option<&str>,\n    ) -> Result<Arc<Box<dyn ProviderInstance>>, LLMSpellError> {\n        self.core_manager\n            .create_agent_from_spec(spec, base_url_override, api_key)\n            .await\n    }\n\n    /// List all registered providers\n    pub async fn list_providers(&self) -> Vec<ProviderInfo> {\n        let providers = self.core_manager.list_providers().await;\n        let mut infos = Vec::new();\n\n        for provider_name in providers {\n            if let Ok(capabilities) = self\n                .core_manager\n                .query_capabilities(Some(&provider_name))\n                .await\n            {\n                infos.push(ProviderInfo {\n                    name: provider_name,\n                    capabilities,\n                });\n            }\n        }\n\n        infos\n    }\n\n    /// Check if a provider supports a specific capability\n    pub async fn provider_supports(&self, provider_name: &str, capability: &str) -> bool {\n        if let Ok(caps) = self\n            .core_manager\n            .query_capabilities(Some(provider_name))\n            .await\n        {\n            match capability {\n                \"streaming\" => caps.supports_streaming,\n                \"multimodal\" => caps.supports_multimodal,\n                _ => false,\n            }\n        } else {\n            false\n        }\n    }\n}\n\n/// Information about a registered provider\n#[derive(Debug, Clone)]\npub struct ProviderInfo {\n    pub name: String,\n    pub capabilities: ProviderCapabilities,\n}\n\n/// Configuration for the provider manager\n#[derive(Debug, Clone, Default, Deserialize, Serialize)]\npub struct ProviderManagerConfig {\n    /// Default provider to use\n    pub default_provider: Option<String>,\n    /// Provider-specific configurations\n    pub providers: HashMap<String, ProviderConfig>,\n}\n\n/// Configuration for a specific provider\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct ProviderConfig {\n    /// Provider type (e.g., \"openai\", \"anthropic\", \"local\")\n    pub provider_type: String,\n    /// API key or authentication\n    pub api_key_env: Option<String>,\n    /// Base URL override\n    pub base_url: Option<String>,\n    /// Model to use\n    pub model: Option<String>,\n    /// Maximum tokens\n    pub max_tokens: Option<u32>,\n    /// Additional provider-specific settings\n    #[serde(flatten)]\n    pub extra: HashMap<String, serde_json::Value>,\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_provider_manager_creation() {\n        let config = ProviderManagerConfig::default();\n        let manager = ProviderManager::new(config).await.unwrap();\n        assert!(manager.get_default_provider().await.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_provider_config_validation() {\n        let mut config = ProviderManagerConfig::default();\n        config.default_provider = Some(\"nonexistent\".to_string());\n\n        let result = ProviderManager::new(config).await;\n        assert!(result.is_err());\n    }\n}\n","traces":[{"line":21,"address":[],"length":0,"stats":{"Line":193}},{"line":22,"address":[],"length":0,"stats":{"Line":66}},{"line":25,"address":[],"length":0,"stats":{"Line":66}},{"line":29,"address":[],"length":0,"stats":{"Line":66}},{"line":32,"address":[],"length":0,"stats":{"Line":70}},{"line":34,"address":[],"length":0,"stats":{"Line":62}},{"line":38,"address":[],"length":0,"stats":{"Line":193}},{"line":39,"address":[],"length":0,"stats":{"Line":66}},{"line":40,"address":[],"length":0,"stats":{"Line":66}},{"line":41,"address":[],"length":0,"stats":{"Line":66}},{"line":42,"address":[],"length":0,"stats":{"Line":66}},{"line":46,"address":[],"length":0,"stats":{"Line":193}},{"line":48,"address":[],"length":0,"stats":{"Line":69}},{"line":49,"address":[],"length":0,"stats":{"Line":6}},{"line":50,"address":[],"length":0,"stats":{"Line":3}},{"line":54,"address":[],"length":0,"stats":{"Line":64}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":1}},{"line":57,"address":[],"length":0,"stats":{"Line":1}},{"line":58,"address":[],"length":0,"stats":{"Line":1}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":62}},{"line":78,"address":[],"length":0,"stats":{"Line":6}},{"line":84,"address":[],"length":0,"stats":{"Line":12}},{"line":85,"address":[],"length":0,"stats":{"Line":14}},{"line":86,"address":[],"length":0,"stats":{"Line":2}},{"line":89,"address":[],"length":0,"stats":{"Line":12}},{"line":90,"address":[],"length":0,"stats":{"Line":6}},{"line":92,"address":[],"length":0,"stats":{"Line":6}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":4}},{"line":101,"address":[],"length":0,"stats":{"Line":4}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":6}},{"line":117,"address":[],"length":0,"stats":{"Line":6}},{"line":127,"address":[],"length":0,"stats":{"Line":2}},{"line":131,"address":[],"length":0,"stats":{"Line":2}},{"line":135,"address":[],"length":0,"stats":{"Line":5}},{"line":138,"address":[],"length":0,"stats":{"Line":5}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}}],"covered":35,"coverable":78},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","registry.rs"],"content":"//! ABOUTME: Component registry for managing agents, tools, and workflows\n//! ABOUTME: Central registry for all scriptable components accessible from engines\n\nuse llmspell_core::{Agent, LLMSpellError, Tool, Workflow};\nuse std::collections::HashMap;\nuse std::sync::{Arc, RwLock};\n\n/// Central registry for all components accessible from scripts\npub struct ComponentRegistry {\n    agents: Arc<RwLock<HashMap<String, Arc<dyn Agent>>>>,\n    tools: Arc<RwLock<HashMap<String, Arc<dyn Tool>>>>,\n    workflows: Arc<RwLock<HashMap<String, Arc<dyn Workflow>>>>,\n}\n\nimpl ComponentRegistry {\n    /// Create a new empty registry\n    pub fn new() -> Self {\n        Self {\n            agents: Arc::new(RwLock::new(HashMap::new())),\n            tools: Arc::new(RwLock::new(HashMap::new())),\n            workflows: Arc::new(RwLock::new(HashMap::new())),\n        }\n    }\n\n    /// Register an agent\n    pub fn register_agent(&self, name: String, agent: Arc<dyn Agent>) -> Result<(), LLMSpellError> {\n        let mut agents = self.agents.write().unwrap();\n        if agents.contains_key(&name) {\n            return Err(LLMSpellError::Validation {\n                field: Some(\"agent_name\".to_string()),\n                message: format!(\"Agent '{}' already registered\", name),\n            });\n        }\n        agents.insert(name, agent);\n        Ok(())\n    }\n\n    /// Get an agent by name\n    pub fn get_agent(&self, name: &str) -> Option<Arc<dyn Agent>> {\n        let agents = self.agents.read().unwrap();\n        agents.get(name).cloned()\n    }\n\n    /// List all registered agents\n    pub fn list_agents(&self) -> Vec<String> {\n        let agents = self.agents.read().unwrap();\n        agents.keys().cloned().collect()\n    }\n\n    /// Register a tool\n    pub fn register_tool(&self, name: String, tool: Arc<dyn Tool>) -> Result<(), LLMSpellError> {\n        let mut tools = self.tools.write().unwrap();\n        if tools.contains_key(&name) {\n            return Err(LLMSpellError::Validation {\n                field: Some(\"tool_name\".to_string()),\n                message: format!(\"Tool '{}' already registered\", name),\n            });\n        }\n        tools.insert(name, tool);\n        Ok(())\n    }\n\n    /// Get a tool by name\n    pub fn get_tool(&self, name: &str) -> Option<Arc<dyn Tool>> {\n        let tools = self.tools.read().unwrap();\n        tools.get(name).cloned()\n    }\n\n    /// List all registered tools\n    pub fn list_tools(&self) -> Vec<String> {\n        let tools = self.tools.read().unwrap();\n        tools.keys().cloned().collect()\n    }\n\n    /// Register a workflow\n    pub fn register_workflow(\n        &self,\n        name: String,\n        workflow: Arc<dyn Workflow>,\n    ) -> Result<(), LLMSpellError> {\n        let mut workflows = self.workflows.write().unwrap();\n        if workflows.contains_key(&name) {\n            return Err(LLMSpellError::Validation {\n                field: Some(\"workflow_name\".to_string()),\n                message: format!(\"Workflow '{}' already registered\", name),\n            });\n        }\n        workflows.insert(name, workflow);\n        Ok(())\n    }\n\n    /// Get a workflow by name\n    pub fn get_workflow(&self, name: &str) -> Option<Arc<dyn Workflow>> {\n        let workflows = self.workflows.read().unwrap();\n        workflows.get(name).cloned()\n    }\n\n    /// List all registered workflows\n    pub fn list_workflows(&self) -> Vec<String> {\n        let workflows = self.workflows.read().unwrap();\n        workflows.keys().cloned().collect()\n    }\n}\n\nimpl Default for ComponentRegistry {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use async_trait::async_trait;\n    use llmspell_core::traits::agent::AgentConfig;\n    use llmspell_core::types::{AgentInput, AgentOutput, ExecutionContext};\n    use llmspell_core::BaseAgent;\n\n    struct MockAgent {\n        metadata: llmspell_core::ComponentMetadata,\n        config: AgentConfig,\n    }\n\n    impl MockAgent {\n        fn new() -> Self {\n            Self {\n                metadata: llmspell_core::ComponentMetadata::new(\n                    \"mock\".to_string(),\n                    \"Mock agent\".to_string(),\n                ),\n                config: AgentConfig::default(),\n            }\n        }\n    }\n\n    #[async_trait]\n    impl BaseAgent for MockAgent {\n        fn metadata(&self) -> &llmspell_core::ComponentMetadata {\n            &self.metadata\n        }\n\n        async fn execute(\n            &self,\n            _input: AgentInput,\n            _context: ExecutionContext,\n        ) -> Result<AgentOutput, LLMSpellError> {\n            Ok(AgentOutput::text(\"mock output\"))\n        }\n\n        async fn validate_input(&self, _input: &AgentInput) -> Result<(), LLMSpellError> {\n            Ok(())\n        }\n\n        async fn handle_error(&self, error: LLMSpellError) -> Result<AgentOutput, LLMSpellError> {\n            Ok(AgentOutput::text(format!(\"Error: {}\", error)))\n        }\n    }\n\n    #[async_trait]\n    impl Agent for MockAgent {\n        fn config(&self) -> &AgentConfig {\n            &self.config\n        }\n\n        async fn get_conversation(\n            &self,\n        ) -> Result<Vec<llmspell_core::traits::agent::ConversationMessage>, LLMSpellError> {\n            Ok(vec![])\n        }\n\n        async fn add_message(\n            &mut self,\n            _message: llmspell_core::traits::agent::ConversationMessage,\n        ) -> Result<(), LLMSpellError> {\n            Ok(())\n        }\n\n        async fn clear_conversation(&mut self) -> Result<(), LLMSpellError> {\n            Ok(())\n        }\n    }\n\n    #[test]\n    fn test_agent_registration() {\n        let registry = ComponentRegistry::new();\n        let agent = Arc::new(MockAgent::new());\n\n        assert!(registry.register_agent(\"test\".to_string(), agent).is_ok());\n        assert!(registry.get_agent(\"test\").is_some());\n        assert_eq!(registry.list_agents(), vec![\"test\"]);\n\n        // Duplicate registration should fail\n        let agent2 = Arc::new(MockAgent::new());\n        assert!(registry.register_agent(\"test\".to_string(), agent2).is_err());\n    }\n}\n","traces":[{"line":17,"address":[],"length":0,"stats":{"Line":120}},{"line":19,"address":[],"length":0,"stats":{"Line":120}},{"line":20,"address":[],"length":0,"stats":{"Line":120}},{"line":21,"address":[],"length":0,"stats":{"Line":120}},{"line":26,"address":[],"length":0,"stats":{"Line":4}},{"line":27,"address":[],"length":0,"stats":{"Line":4}},{"line":28,"address":[],"length":0,"stats":{"Line":4}},{"line":29,"address":[],"length":0,"stats":{"Line":1}},{"line":30,"address":[],"length":0,"stats":{"Line":1}},{"line":31,"address":[],"length":0,"stats":{"Line":1}},{"line":34,"address":[],"length":0,"stats":{"Line":3}},{"line":35,"address":[],"length":0,"stats":{"Line":3}},{"line":39,"address":[],"length":0,"stats":{"Line":3}},{"line":40,"address":[],"length":0,"stats":{"Line":3}},{"line":41,"address":[],"length":0,"stats":{"Line":3}},{"line":45,"address":[],"length":0,"stats":{"Line":3}},{"line":46,"address":[],"length":0,"stats":{"Line":3}},{"line":47,"address":[],"length":0,"stats":{"Line":3}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}}],"covered":18,"coverable":48},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","src","runtime.rs"],"content":"//! ABOUTME: Language-agnostic script runtime using ScriptEngineBridge abstraction\n//! ABOUTME: Central execution orchestrator supporting multiple script engines\n\nuse crate::{\n    engine::{EngineFactory, JSConfig, LuaConfig, ScriptEngineBridge, ScriptOutput, ScriptStream},\n    providers::{ProviderManager, ProviderManagerConfig},\n    registry::ComponentRegistry,\n};\nuse llmspell_core::error::LLMSpellError;\nuse serde::{Deserialize, Serialize};\nuse std::sync::{Arc, RwLock};\n\n/// Central script runtime that uses ScriptEngineBridge abstraction\n///\n/// The `ScriptRuntime` is the main entry point for executing scripts in LLMSpell.\n/// It provides a language-agnostic interface that can work with multiple script\n/// engines (Lua, JavaScript, Python, etc.) through the `ScriptEngineBridge` trait.\n///\n/// # Examples\n///\n/// ## Basic Script Execution\n///\n/// ```rust,no_run\n/// use llmspell_bridge::{ScriptRuntime, RuntimeConfig};\n///\n/// # async fn example() -> Result<(), Box<dyn std::error::Error>> {\n/// // Create a runtime with default configuration\n/// let config = RuntimeConfig::default();\n/// let runtime = ScriptRuntime::new_with_lua(config).await?;\n///\n/// // Execute a simple Lua script\n/// let output = runtime.execute_script(\"return 42\").await?;\n/// println!(\"Result: {:?}\", output.output);\n/// # Ok(())\n/// # }\n/// ```\n///\n/// ## Working with Agents (Placeholder - Phase 2)\n///\n/// ```rust,no_run\n/// use llmspell_bridge::{ScriptRuntime, RuntimeConfig};\n///\n/// # async fn example() -> Result<(), Box<dyn std::error::Error>> {\n/// let runtime = ScriptRuntime::new_with_lua(RuntimeConfig::default()).await?;\n///\n/// let script = r#\"\n///     -- Create an agent (placeholder functionality)\n///     local agent = Agent.create({\n///         name = \"assistant\",\n///         system_prompt = \"You are a helpful assistant\"\n///     })\n///     \n///     -- Execute the agent (returns placeholder response)\n///     local response = agent:execute(\"Hello!\")\n///     return response.text\n/// \"#;\n///\n/// let output = runtime.execute_script(script).await?;\n/// # Ok(())\n/// # }\n/// ```\n///\n/// ## Streaming Execution\n///\n/// ```rust,no_run\n/// use llmspell_bridge::{ScriptRuntime, RuntimeConfig};\n/// use futures::StreamExt;\n///\n/// # async fn example() -> Result<(), Box<dyn std::error::Error>> {\n/// let runtime = ScriptRuntime::new_with_lua(RuntimeConfig::default()).await?;\n///\n/// // Check if streaming is supported\n/// if runtime.supports_streaming() {\n///     let mut stream = runtime.execute_script_streaming(\"return 'streaming output'\").await?;\n///     \n///     // Process chunks as they arrive\n///     while let Some(chunk) = stream.stream.next().await {\n///         let chunk = chunk?;\n///         println!(\"Received chunk: {:?}\", chunk);\n///     }\n/// }\n/// # Ok(())\n/// # }\n/// ```\npub struct ScriptRuntime {\n    /// Language-agnostic script engine\n    engine: Box<dyn ScriptEngineBridge>,\n    /// Component registry for agents, tools, workflows\n    registry: Arc<ComponentRegistry>,\n    /// Provider manager for LLM access\n    provider_manager: Arc<ProviderManager>,\n    /// Execution context\n    execution_context: Arc<RwLock<crate::engine::ExecutionContext>>,\n    /// Runtime configuration\n    _config: RuntimeConfig,\n}\n\nimpl ScriptRuntime {\n    /// Create a new runtime with Lua engine\n    ///\n    /// # Examples\n    ///\n    /// ```rust,no_run\n    /// use llmspell_bridge::{ScriptRuntime, RuntimeConfig};\n    ///\n    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {\n    /// // With default configuration\n    /// let runtime = ScriptRuntime::new_with_lua(RuntimeConfig::default()).await?;\n    ///\n    /// // With custom configuration\n    /// let mut config = RuntimeConfig::default();\n    /// config.runtime.security.allow_file_access = true;\n    /// let runtime = ScriptRuntime::new_with_lua(config).await?;\n    /// # Ok(())\n    /// # }\n    /// ```\n    pub async fn new_with_lua(config: RuntimeConfig) -> Result<Self, LLMSpellError> {\n        let lua_config = config.engines.lua.clone();\n        let engine = EngineFactory::create_lua_engine(&lua_config)?;\n        Self::new_with_engine(engine, config).await\n    }\n\n    /// Create a new runtime with JavaScript engine\n    pub async fn new_with_javascript(config: RuntimeConfig) -> Result<Self, LLMSpellError> {\n        let js_config = config.engines.javascript.clone();\n        let engine = EngineFactory::create_javascript_engine(&js_config)?;\n        Self::new_with_engine(engine, config).await\n    }\n\n    /// Create a new runtime with a specific engine by name\n    pub async fn new_with_engine_name(\n        engine_name: &str,\n        config: RuntimeConfig,\n    ) -> Result<Self, LLMSpellError> {\n        let engine_config = config.get_engine_config(engine_name)?;\n        let engine = EngineFactory::create_from_name(engine_name, &engine_config)?;\n        Self::new_with_engine(engine, config).await\n    }\n\n    /// Core initialization with any engine\n    async fn new_with_engine(\n        mut engine: Box<dyn ScriptEngineBridge>,\n        config: RuntimeConfig,\n    ) -> Result<Self, LLMSpellError> {\n        // Create component registry\n        let registry = Arc::new(ComponentRegistry::new());\n\n        // Create provider manager\n        let provider_config = config.providers.clone();\n        let provider_manager = Arc::new(ProviderManager::new(provider_config).await?);\n\n        // Inject APIs into the engine\n        engine.inject_apis(&registry, &provider_manager)?;\n\n        // Create execution context\n        let execution_context = Arc::new(RwLock::new(crate::engine::ExecutionContext {\n            working_directory: std::env::current_dir()\n                .unwrap_or_default()\n                .to_string_lossy()\n                .to_string(),\n            environment: std::env::vars().collect(),\n            state: serde_json::Value::Object(serde_json::Map::new()),\n            security: config.runtime.security.clone().into(),\n        }));\n\n        Ok(Self {\n            engine,\n            registry,\n            provider_manager,\n            execution_context,\n            _config: config,\n        })\n    }\n\n    /// Execute a script and return the output\n    pub async fn execute_script(&self, script: &str) -> Result<ScriptOutput, LLMSpellError> {\n        self.engine.execute_script(script).await\n    }\n\n    /// Execute a script with streaming output\n    pub async fn execute_script_streaming(\n        &self,\n        script: &str,\n    ) -> Result<ScriptStream, LLMSpellError> {\n        if !self.engine.supports_streaming() {\n            return Err(LLMSpellError::Component {\n                message: format!(\n                    \"{} engine does not support streaming execution\",\n                    self.engine.get_engine_name()\n                ),\n                source: None,\n            });\n        }\n        self.engine.execute_script_streaming(script).await\n    }\n\n    /// Get the name of the current engine\n    pub fn get_engine_name(&self) -> &'static str {\n        self.engine.get_engine_name()\n    }\n\n    /// Check if the engine supports streaming\n    pub fn supports_streaming(&self) -> bool {\n        self.engine.supports_streaming()\n    }\n\n    /// Check if the engine supports multimodal content\n    pub fn supports_multimodal(&self) -> bool {\n        self.engine.supports_multimodal()\n    }\n\n    /// Get the engine's supported features\n    pub fn get_engine_features(&self) -> crate::engine::EngineFeatures {\n        self.engine.supported_features()\n    }\n\n    /// Get the component registry\n    pub fn registry(&self) -> &Arc<ComponentRegistry> {\n        &self.registry\n    }\n\n    /// Get the provider manager\n    pub fn provider_manager(&self) -> &Arc<ProviderManager> {\n        &self.provider_manager\n    }\n\n    /// Get the current execution context\n    pub fn get_execution_context(&self) -> crate::engine::ExecutionContext {\n        self.execution_context.read().unwrap().clone()\n    }\n\n    /// Update the execution context\n    pub fn set_execution_context(\n        &self,\n        context: crate::engine::ExecutionContext,\n    ) -> Result<(), LLMSpellError> {\n        let mut ctx = self.execution_context.write().unwrap();\n        *ctx = context;\n        Ok(())\n    }\n}\n\n/// Runtime configuration supporting multiple engines\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct RuntimeConfig {\n    /// Default script engine to use\n    pub default_engine: String,\n    /// Engine-specific configurations\n    pub engines: EngineConfigs,\n    /// Provider configurations\n    pub providers: ProviderManagerConfig,\n    /// Global runtime settings\n    pub runtime: GlobalRuntimeConfig,\n}\n\nimpl Default for RuntimeConfig {\n    fn default() -> Self {\n        Self {\n            default_engine: \"lua\".to_string(),\n            engines: EngineConfigs::default(),\n            providers: ProviderManagerConfig::default(),\n            runtime: GlobalRuntimeConfig::default(),\n        }\n    }\n}\n\nimpl RuntimeConfig {\n    /// Get engine-specific configuration\n    pub fn get_engine_config(&self, engine_name: &str) -> Result<serde_json::Value, LLMSpellError> {\n        match engine_name {\n            \"lua\" => Ok(serde_json::to_value(&self.engines.lua)?),\n            \"javascript\" | \"js\" => Ok(serde_json::to_value(&self.engines.javascript)?),\n            custom => {\n                self.engines\n                    .custom\n                    .get(custom)\n                    .cloned()\n                    .ok_or_else(|| LLMSpellError::Validation {\n                        field: Some(\"engine\".to_string()),\n                        message: format!(\"Engine configuration not found for '{}'\", custom),\n                    })\n            }\n        }\n    }\n\n    /// Check if an engine is configured\n    pub fn supports_engine(&self, engine_name: &str) -> bool {\n        match engine_name {\n            \"lua\" | \"javascript\" | \"js\" => true,\n            custom => self.engines.custom.contains_key(custom),\n        }\n    }\n}\n\n/// Engine configurations\n#[derive(Debug, Clone, Default, Deserialize, Serialize)]\npub struct EngineConfigs {\n    pub lua: LuaConfig,\n    pub javascript: JSConfig,\n    #[serde(flatten)]\n    pub custom: std::collections::HashMap<String, serde_json::Value>,\n}\n\n/// Global runtime configuration\n#[derive(Debug, Clone, Deserialize, Serialize)]\n#[serde(default)]\npub struct GlobalRuntimeConfig {\n    /// Maximum concurrent scripts\n    pub max_concurrent_scripts: usize,\n    /// Script execution timeout in seconds\n    pub script_timeout_seconds: u64,\n    /// Enable streaming by default\n    pub enable_streaming: bool,\n    /// Security settings\n    pub security: SecurityConfig,\n}\n\nimpl Default for GlobalRuntimeConfig {\n    fn default() -> Self {\n        Self {\n            max_concurrent_scripts: 10,\n            script_timeout_seconds: 300,\n            enable_streaming: true,\n            security: SecurityConfig::default(),\n        }\n    }\n}\n\n/// Security configuration\n#[derive(Debug, Clone, Deserialize, Serialize)]\n#[serde(default)]\npub struct SecurityConfig {\n    /// Allow file system access\n    pub allow_file_access: bool,\n    /// Allow network access\n    pub allow_network_access: bool,\n    /// Allow process spawning\n    pub allow_process_spawn: bool,\n    /// Maximum memory usage in bytes\n    pub max_memory_bytes: Option<usize>,\n    /// Maximum execution time in milliseconds\n    pub max_execution_time_ms: Option<u64>,\n}\n\nimpl Default for SecurityConfig {\n    fn default() -> Self {\n        Self {\n            allow_file_access: false,\n            allow_network_access: true,\n            allow_process_spawn: false,\n            max_memory_bytes: Some(50_000_000),   // 50MB\n            max_execution_time_ms: Some(300_000), // 5 minutes\n        }\n    }\n}\n\nimpl From<SecurityConfig> for crate::engine::SecurityContext {\n    fn from(config: SecurityConfig) -> Self {\n        Self {\n            allow_file_access: config.allow_file_access,\n            allow_network_access: config.allow_network_access,\n            allow_process_spawn: config.allow_process_spawn,\n            max_memory_bytes: config.max_memory_bytes,\n            max_execution_time_ms: config.max_execution_time_ms,\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_runtime_config_default() {\n        let config = RuntimeConfig::default();\n        assert_eq!(config.default_engine, \"lua\");\n        assert!(config.supports_engine(\"lua\"));\n        assert!(config.supports_engine(\"javascript\"));\n        assert!(!config.supports_engine(\"python\"));\n    }\n\n    #[test]\n    fn test_security_config_conversion() {\n        let config = SecurityConfig::default();\n        let context: crate::engine::SecurityContext = config.into();\n        assert!(!context.allow_file_access);\n        assert!(context.allow_network_access);\n        assert!(!context.allow_process_spawn);\n    }\n}\n","traces":[{"line":117,"address":[],"length":0,"stats":{"Line":30}},{"line":118,"address":[],"length":0,"stats":{"Line":11}},{"line":119,"address":[],"length":0,"stats":{"Line":22}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":3}},{"line":125,"address":[],"length":0,"stats":{"Line":1}},{"line":126,"address":[],"length":0,"stats":{"Line":2}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":4}},{"line":135,"address":[],"length":0,"stats":{"Line":4}},{"line":136,"address":[],"length":0,"stats":{"Line":1}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":21}},{"line":146,"address":[],"length":0,"stats":{"Line":12}},{"line":149,"address":[],"length":0,"stats":{"Line":12}},{"line":150,"address":[],"length":0,"stats":{"Line":24}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":11}},{"line":157,"address":[],"length":0,"stats":{"Line":11}},{"line":158,"address":[],"length":0,"stats":{"Line":11}},{"line":159,"address":[],"length":0,"stats":{"Line":11}},{"line":160,"address":[],"length":0,"stats":{"Line":11}},{"line":161,"address":[],"length":0,"stats":{"Line":11}},{"line":162,"address":[],"length":0,"stats":{"Line":11}},{"line":163,"address":[],"length":0,"stats":{"Line":11}},{"line":166,"address":[],"length":0,"stats":{"Line":11}},{"line":167,"address":[],"length":0,"stats":{"Line":11}},{"line":168,"address":[],"length":0,"stats":{"Line":11}},{"line":169,"address":[],"length":0,"stats":{"Line":11}},{"line":170,"address":[],"length":0,"stats":{"Line":11}},{"line":171,"address":[],"length":0,"stats":{"Line":11}},{"line":176,"address":[],"length":0,"stats":{"Line":12}},{"line":177,"address":[],"length":0,"stats":{"Line":5}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":8}},{"line":199,"address":[],"length":0,"stats":{"Line":8}},{"line":203,"address":[],"length":0,"stats":{"Line":4}},{"line":204,"address":[],"length":0,"stats":{"Line":4}},{"line":208,"address":[],"length":0,"stats":{"Line":4}},{"line":209,"address":[],"length":0,"stats":{"Line":4}},{"line":213,"address":[],"length":0,"stats":{"Line":2}},{"line":214,"address":[],"length":0,"stats":{"Line":2}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":4}},{"line":229,"address":[],"length":0,"stats":{"Line":4}},{"line":233,"address":[],"length":0,"stats":{"Line":2}},{"line":237,"address":[],"length":0,"stats":{"Line":2}},{"line":238,"address":[],"length":0,"stats":{"Line":2}},{"line":239,"address":[],"length":0,"stats":{"Line":2}},{"line":257,"address":[],"length":0,"stats":{"Line":40}},{"line":259,"address":[],"length":0,"stats":{"Line":40}},{"line":260,"address":[],"length":0,"stats":{"Line":40}},{"line":261,"address":[],"length":0,"stats":{"Line":40}},{"line":262,"address":[],"length":0,"stats":{"Line":40}},{"line":269,"address":[],"length":0,"stats":{"Line":4}},{"line":270,"address":[],"length":0,"stats":{"Line":4}},{"line":271,"address":[],"length":0,"stats":{"Line":6}},{"line":272,"address":[],"length":0,"stats":{"Line":4}},{"line":273,"address":[],"length":0,"stats":{"Line":2}},{"line":274,"address":[],"length":0,"stats":{"Line":2}},{"line":275,"address":[],"length":0,"stats":{"Line":2}},{"line":276,"address":[],"length":0,"stats":{"Line":2}},{"line":278,"address":[],"length":0,"stats":{"Line":4}},{"line":279,"address":[],"length":0,"stats":{"Line":2}},{"line":280,"address":[],"length":0,"stats":{"Line":2}},{"line":287,"address":[],"length":0,"stats":{"Line":13}},{"line":288,"address":[],"length":0,"stats":{"Line":13}},{"line":289,"address":[],"length":0,"stats":{"Line":34}},{"line":290,"address":[],"length":0,"stats":{"Line":5}},{"line":319,"address":[],"length":0,"stats":{"Line":44}},{"line":324,"address":[],"length":0,"stats":{"Line":44}},{"line":346,"address":[],"length":0,"stats":{"Line":49}},{"line":351,"address":[],"length":0,"stats":{"Line":49}},{"line":352,"address":[],"length":0,"stats":{"Line":49}},{"line":358,"address":[],"length":0,"stats":{"Line":20}},{"line":360,"address":[],"length":0,"stats":{"Line":20}},{"line":361,"address":[],"length":0,"stats":{"Line":20}},{"line":362,"address":[],"length":0,"stats":{"Line":20}},{"line":363,"address":[],"length":0,"stats":{"Line":20}},{"line":364,"address":[],"length":0,"stats":{"Line":20}}],"covered":74,"coverable":90},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","tests","bridge_abstraction_test.rs"],"content":"//! ABOUTME: Comprehensive tests for ScriptEngineBridge abstraction\n//! ABOUTME: Validates language-agnostic bridge pattern and engine compliance\n\nuse llmspell_bridge::{\n    engine::{\n        bridge::{EngineFeatures, ExecutionContext, ScriptEngineBridge, SecurityContext},\n        factory::{EngineFactory, EngineInfo, LuaConfig, StdlibLevel},\n    },\n    ComponentRegistry, ProviderManager, ProviderManagerConfig,\n};\nuse llmspell_core::error::LLMSpellError;\nuse std::collections::HashMap;\nuse std::sync::Arc;\n\n/// Test that engines implement the bridge trait correctly\n#[tokio::test]\nasync fn test_bridge_trait_implementation() {\n    // Create Lua engine through factory\n    let lua_config = LuaConfig::default();\n    let engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    // Verify it implements ScriptEngineBridge\n    assert_engine_compliance(&*engine);\n}\n\n/// Test engine factory pattern\n#[tokio::test]\nasync fn test_engine_factory_pattern() {\n    // Test Lua engine creation\n    let lua_config = LuaConfig::default();\n    let lua_engine = EngineFactory::create_lua_engine(&lua_config);\n    assert!(lua_engine.is_ok(), \"Failed to create Lua engine\");\n\n    // Test creating from name\n    let config_json = serde_json::to_value(&lua_config).unwrap();\n    let from_name = EngineFactory::create_from_name(\"lua\", &config_json);\n    assert!(from_name.is_ok(), \"Failed to create engine from name\");\n\n    // Test invalid engine name\n    let invalid = EngineFactory::create_from_name(\"ruby\", &config_json);\n    assert!(invalid.is_err(), \"Should fail for unknown engine\");\n}\n\n/// Test engine capability detection\n#[tokio::test]\nasync fn test_engine_capabilities() {\n    let lua_config = LuaConfig::default();\n    let engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    // Check basic capabilities\n    assert!(engine.supports_streaming(), \"Lua should support streaming\");\n    assert!(\n        engine.supports_multimodal(),\n        \"Lua should support multimodal\"\n    );\n\n    // Check feature struct\n    let features = engine.supported_features();\n    assert!(features.async_execution, \"Should support async execution\");\n    assert!(features.streaming, \"Should support streaming\");\n    assert!(features.multimodal, \"Should support multimodal\");\n    assert!(features.modules, \"Should support modules\");\n}\n\n/// Test execution context management\n#[tokio::test]\nasync fn test_execution_context() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    // Get default context\n    let default_ctx = engine.get_execution_context().unwrap();\n    assert_eq!(default_ctx.working_directory, \"\");\n    assert!(default_ctx.environment.is_empty());\n\n    // Set custom context\n    let custom_ctx = ExecutionContext {\n        working_directory: \"/test/dir\".to_string(),\n        environment: HashMap::from([(\"TEST_VAR\".to_string(), \"test_value\".to_string())]),\n        state: serde_json::json!({\"custom\": \"state\"}),\n        security: SecurityContext {\n            allow_file_access: true,\n            allow_network_access: false,\n            ..Default::default()\n        },\n    };\n\n    engine.set_execution_context(custom_ctx.clone()).unwrap();\n\n    // Verify context was set\n    let retrieved = engine.get_execution_context().unwrap();\n    assert_eq!(retrieved.working_directory, custom_ctx.working_directory);\n    assert_eq!(\n        retrieved.environment.get(\"TEST_VAR\"),\n        Some(&\"test_value\".to_string())\n    );\n}\n\n/// Test API injection mechanism\n#[tokio::test]\nasync fn test_api_injection() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    // Create dependencies\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    // Inject APIs - should succeed\n    let result = engine.inject_apis(&registry, &providers);\n    assert!(result.is_ok(), \"API injection should succeed\");\n\n    // Verify APIs are available\n    let script = \"return type(Agent) == 'table'\";\n    let output = engine.execute_script(script).await.unwrap();\n    assert_eq!(\n        output.output.as_bool(),\n        Some(true),\n        \"Agent API should be injected\"\n    );\n}\n\n/// Test error handling across bridge\n#[tokio::test]\nasync fn test_bridge_error_handling() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    // Inject APIs first\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Test syntax error\n    let syntax_error = engine.execute_script(\"invalid syntax {{\").await;\n    assert!(syntax_error.is_err(), \"Should fail on syntax error\");\n    match syntax_error {\n        Err(LLMSpellError::Validation { field, .. }) => {\n            assert_eq!(field, Some(\"script\".to_string()));\n        }\n        Err(LLMSpellError::Component { .. }) => {\n            // Also acceptable for execution errors\n        }\n        _ => panic!(\"Expected Validation or Component error\"),\n    }\n\n    // Test runtime error\n    let runtime_error = engine.execute_script(\"error('test error')\").await;\n    assert!(runtime_error.is_err(), \"Should fail on runtime error\");\n    match runtime_error {\n        Err(LLMSpellError::Component { .. }) => {\n            // Expected for execution errors\n        }\n        _ => panic!(\"Expected Component error for runtime error\"),\n    }\n}\n\n/// Test script output format consistency\n#[tokio::test]\nasync fn test_output_format_consistency() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    // Inject APIs first\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Test various output types\n    let test_cases = vec![\n        (\"return 42\", serde_json::json!(42)),\n        (\"return 'hello'\", serde_json::json!(\"hello\")),\n        (\"return true\", serde_json::json!(true)),\n        (\"return {a=1, b=2}\", serde_json::json!({\"a\": 1, \"b\": 2})),\n        (\"return {1, 2, 3}\", serde_json::json!([1, 2, 3])),\n    ];\n\n    for (script, expected) in test_cases {\n        let output = engine.execute_script(script).await.unwrap();\n        assert_eq!(\n            output.output, expected,\n            \"Output mismatch for script: {}\",\n            script\n        );\n    }\n}\n\n/// Test console output capture\n#[tokio::test]\nasync fn test_console_output_capture() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    // Inject APIs first\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    let script = r#\"\n        print(\"Line 1\")\n        print(\"Line 2\")\n        return \"done\"\n    \"#;\n\n    let output = engine.execute_script(script).await.unwrap();\n    assert_eq!(output.output.as_str(), Some(\"done\"));\n    // Console output capture might not be implemented yet\n    // assert_eq!(output.console_output.len(), 2);\n    // assert_eq!(output.console_output[0], \"Line 1\");\n    // assert_eq!(output.console_output[1], \"Line 2\");\n}\n\n/// Test metadata in script output\n#[tokio::test]\nasync fn test_output_metadata() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    // Inject APIs first\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    let output = engine.execute_script(\"return 42\").await.unwrap();\n\n    // Check metadata\n    assert_eq!(output.metadata.engine, \"lua\");\n    // Execution time is always non-negative (u64)\n    // This assertion is redundant as u64 can't be negative\n    assert!(output.metadata.warnings.is_empty());\n}\n\n/// Test security context enforcement\n#[tokio::test]\nasync fn test_security_enforcement() {\n    let lua_config = LuaConfig::default();\n    // Default config has StdlibLevel::Safe\n    assert!(matches!(lua_config.stdlib, StdlibLevel::Safe));\n\n    let engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    // These should fail due to security restrictions with Safe stdlib level\n    let _io_test = engine.execute_script(\"return io\").await;\n    let _os_test = engine.execute_script(\"return os\").await;\n\n    // In Safe mode, dangerous libraries should not be available\n    // The actual behavior depends on the Lua engine implementation\n}\n\n/// Test memory limits\n#[tokio::test]\nasync fn test_memory_limits() {\n    let mut lua_config = LuaConfig::default();\n    lua_config.max_memory = Some(1024 * 1024); // 1MB limit\n\n    let engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    // Try to allocate large table (this test may be implementation-specific)\n    let script = r#\"\n        local t = {}\n        for i = 1, 1000000 do\n            t[i] = string.rep(\"x\", 1000)\n        end\n        return #t\n    \"#;\n\n    let _result = engine.execute_script(script).await;\n    // Should either fail or be limited by memory\n    // The actual behavior depends on the Lua implementation\n}\n\n/// Helper to verify engine compliance with bridge trait\nfn assert_engine_compliance(engine: &dyn ScriptEngineBridge) {\n    // Check required methods exist and return reasonable values\n    let name = engine.get_engine_name();\n    assert!(!name.is_empty(), \"Engine name should not be empty\");\n\n    let supports_streaming = engine.supports_streaming();\n    assert!(supports_streaming == true || supports_streaming == false);\n\n    let supports_multimodal = engine.supports_multimodal();\n    assert!(supports_multimodal == true || supports_multimodal == false);\n\n    let features = engine.supported_features();\n    // Features should be internally consistent\n    if features.streaming {\n        assert!(\n            engine.supports_streaming(),\n            \"Feature flag mismatch for streaming\"\n        );\n    }\n}\n\n/// Test engine info and registration\n#[tokio::test]\nasync fn test_engine_info() {\n    let info = EngineInfo {\n        name: \"test\".to_string(),\n        version: \"1.0.0\".to_string(),\n        description: \"Test engine\".to_string(),\n        features: EngineFeatures::default(),\n    };\n\n    assert_eq!(info.name, \"test\");\n    assert_eq!(info.version, \"1.0.0\");\n}\n\n/// Test cross-engine compatibility framework (for Phase 5)\n#[tokio::test]\nasync fn test_cross_engine_compatibility_framework() {\n    // This test validates that our framework is ready for multiple engines\n\n    // Test that engine names are consistent\n    let lua_engine = EngineFactory::create_lua_engine(&LuaConfig::default()).unwrap();\n    assert_eq!(lua_engine.get_engine_name(), \"lua\");\n\n    // Test that configuration can be serialized/deserialized\n    let lua_config = LuaConfig::default();\n    let serialized = serde_json::to_string(&lua_config).unwrap();\n    let deserialized: LuaConfig = serde_json::from_str(&serialized).unwrap();\n    assert_eq!(lua_config.max_memory, deserialized.max_memory);\n\n    // Test that errors are engine-agnostic\n    let error = LLMSpellError::Script {\n        message: \"Test error\".to_string(),\n        language: Some(\"lua\".to_string()),\n        line: None,\n        source: None,\n    };\n\n    match error {\n        LLMSpellError::Script { language, .. } => {\n            assert_eq!(language, Some(\"lua\".to_string()));\n        }\n        _ => panic!(\"Wrong error type\"),\n    }\n}\n\n/// Test streaming execution stub\n#[tokio::test]\nasync fn test_streaming_execution_stub() {\n    let lua_config = LuaConfig::default();\n    let engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    // Streaming might return Component error for now\n    let stream_result = engine.execute_script_streaming(\"return 42\").await;\n\n    // The streaming implementation is still a stub\n    assert!(\n        stream_result.is_err(),\n        \"Streaming is not fully implemented yet\"\n    );\n}\n","traces":[{"line":278,"address":[],"length":0,"stats":{"Line":1}},{"line":280,"address":[],"length":0,"stats":{"Line":1}},{"line":281,"address":[],"length":0,"stats":{"Line":1}},{"line":283,"address":[],"length":0,"stats":{"Line":1}},{"line":284,"address":[],"length":0,"stats":{"Line":1}},{"line":286,"address":[],"length":0,"stats":{"Line":1}},{"line":287,"address":[],"length":0,"stats":{"Line":1}},{"line":289,"address":[],"length":0,"stats":{"Line":1}},{"line":291,"address":[],"length":0,"stats":{"Line":1}},{"line":292,"address":[],"length":0,"stats":{"Line":1}},{"line":293,"address":[],"length":0,"stats":{"Line":1}},{"line":294,"address":[],"length":0,"stats":{"Line":0}}],"covered":11,"coverable":12},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","tests","bridge_provider_test.rs"],"content":"//! ABOUTME: Tests for provider access through the script engine bridge\n//! ABOUTME: Validates that scripts can access and use providers correctly\n\nuse llmspell_bridge::{\n    engine::factory::{EngineFactory, LuaConfig},\n    providers::{ProviderConfig, ProviderManager, ProviderManagerConfig},\n    ComponentRegistry,\n};\nuse llmspell_core::error::LLMSpellError;\nuse std::sync::Arc;\n\n/// Test provider manager creation\n#[tokio::test]\nasync fn test_provider_manager_creation() {\n    let config = ProviderManagerConfig::default();\n    let manager = ProviderManager::new(config).await;\n    assert!(\n        manager.is_ok(),\n        \"Provider manager should be created successfully\"\n    );\n}\n\n/// Test injecting providers into engine\n#[tokio::test]\nasync fn test_inject_providers() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    // Should inject successfully\n    let result = engine.inject_apis(&registry, &providers);\n    assert!(result.is_ok(), \"API injection should succeed\");\n}\n\n/// Test accessing providers from script\n#[tokio::test]\nasync fn test_script_provider_access() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Check that Agent API exists (providers are accessed through agents)\n    let script = \"return type(Agent) == 'table'\";\n    let output = engine.execute_script(script).await.unwrap();\n    assert_eq!(\n        output.output.as_bool(),\n        Some(true),\n        \"Agent API should be available\"\n    );\n}\n\n/// Test listing providers from script\n#[tokio::test]\nasync fn test_script_list_providers() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Agent.create should be available\n    let script = \"return type(Agent.create) == 'function'\";\n    let output = engine.execute_script(script).await.unwrap();\n    assert_eq!(\n        output.output.as_bool(),\n        Some(true),\n        \"Agent.create should be a function\"\n    );\n}\n\n/// Test that scripts without API injection fail appropriately\n#[tokio::test]\nasync fn test_script_without_api_injection() {\n    let lua_config = LuaConfig::default();\n    let engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    // Should fail with Component error\n    let result = engine.execute_script(\"return 42\").await;\n    assert!(result.is_err(), \"Should fail without API injection\");\n\n    match result {\n        Err(LLMSpellError::Component { message, .. }) => {\n            assert!(\n                message.contains(\"APIs not injected\"),\n                \"Error should mention API injection\"\n            );\n        }\n        _ => panic!(\"Expected Component error\"),\n    }\n}\n\n/// Test provider configuration validation\n#[tokio::test]\nasync fn test_provider_config_validation() {\n    let mut config = ProviderManagerConfig::default();\n\n    // Test default configuration\n    assert!(\n        config.default_provider.is_none(),\n        \"Default provider should be None\"\n    );\n    assert!(\n        config.providers.is_empty(),\n        \"Providers should be empty by default\"\n    );\n\n    // Test that we can add provider configurations\n    config.providers.insert(\n        \"test-provider\".to_string(),\n        ProviderConfig {\n            provider_type: \"openai\".to_string(),\n            api_key_env: Some(\"OPENAI_API_KEY\".to_string()),\n            base_url: None,\n            model: Some(\"gpt-3.5-turbo\".to_string()),\n            max_tokens: Some(1000),\n            extra: std::collections::HashMap::new(),\n        },\n    );\n\n    // Manager creation might fail if API key env var is not set, but that's expected\n    let _ = ProviderManager::new(config).await;\n}\n\n/// Test concurrent provider access\n#[tokio::test]\nasync fn test_concurrent_provider_access() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Create multiple tasks that access providers\n    let engine = Arc::new(engine);\n    let mut handles = vec![];\n\n    for i in 0..5 {\n        let engine_clone = engine.clone();\n        let handle = tokio::spawn(async move {\n            let script = format!(\"return 'task {}'\", i);\n            engine_clone.execute_script(&script).await\n        });\n        handles.push(handle);\n    }\n\n    // All should succeed\n    for handle in handles {\n        let result = handle.await.unwrap();\n        assert!(result.is_ok(), \"Concurrent access should succeed\");\n    }\n}\n\n/// Test provider error handling in scripts\n#[tokio::test]\nasync fn test_script_provider_error_handling() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Try to create an agent without a provider configured\n    let script = r#\"\n        local status, err = pcall(function()\n            return Agent.create({\n                name = \"test-agent\",\n                provider = \"non-existent-provider\"\n            })\n        end)\n        return not status\n    \"#;\n\n    let output = engine.execute_script(script).await.unwrap();\n    assert_eq!(\n        output.output.as_bool(),\n        Some(true),\n        \"Creating agent with non-existent provider should fail\"\n    );\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","tests","integration_test.rs"],"content":"//! ABOUTME: End-to-end integration tests for the script engine bridge\n//! ABOUTME: Validates complete workflows from script execution to provider calls\n\nuse llmspell_bridge::{\n    engine::factory::{EngineFactory, LuaConfig},\n    providers::{ProviderConfig, ProviderManager, ProviderManagerConfig},\n    ComponentRegistry,\n};\nuse llmspell_core::{\n    traits::agent::{AgentConfig, ConversationMessage},\n    Agent,\n};\nuse std::collections::HashMap;\nuse std::sync::Arc;\n\n/// Test complete script execution through bridge abstraction\n#[tokio::test]\nasync fn test_script_execution_through_bridge() {\n    // Create engine through factory\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    // Set up dependencies\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    // Inject APIs\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Execute a simple script\n    let script = r#\"\n        local result = {}\n        result.engine = \"lua\"\n        result.version = _VERSION\n        result.apis = {\n            agent = type(Agent) == 'table',\n            tool = type(Tool) == 'table',\n            workflow = type(Workflow) == 'table'\n        }\n        return result\n    \"#;\n\n    let output = engine.execute_script(script).await.unwrap();\n\n    // Verify output\n    let result = output.output.as_object().unwrap();\n    assert_eq!(result.get(\"engine\").unwrap().as_str().unwrap(), \"lua\");\n    assert!(result\n        .get(\"version\")\n        .unwrap()\n        .as_str()\n        .unwrap()\n        .contains(\"Lua\"));\n\n    let apis = result.get(\"apis\").unwrap().as_object().unwrap();\n    assert_eq!(apis.get(\"agent\").unwrap().as_bool().unwrap(), true);\n    assert_eq!(apis.get(\"tool\").unwrap().as_bool().unwrap(), true);\n    assert_eq!(apis.get(\"workflow\").unwrap().as_bool().unwrap(), true);\n}\n\n/// Test engine switching capability (even with only Lua)\n#[tokio::test]\nasync fn test_engine_switching_integration() {\n    // Test that we can create engines by name\n    let config = serde_json::json!({\n        \"stdlib\": \"safe\",\n        \"max_memory\": 50000000,\n        \"debug\": false,\n        \"package_paths\": []\n    });\n\n    // Create Lua engine by name\n    let engine = EngineFactory::create_from_name(\"lua\", &config);\n    assert!(engine.is_ok(), \"Should create Lua engine by name\");\n\n    // Try to create non-existent engine\n    let unknown = EngineFactory::create_from_name(\"python\", &config);\n    assert!(unknown.is_err(), \"Should fail for unknown engine\");\n\n    // List available engines\n    let engines = EngineFactory::list_available_engines();\n    assert!(\n        engines.iter().any(|e| e.name == \"lua\"),\n        \"Lua should be in available engines\"\n    );\n}\n\n/// Test streaming capabilities through bridge\n#[tokio::test]\nasync fn test_streaming_through_bridge() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    // Verify streaming support\n    assert!(engine.supports_streaming(), \"Lua should support streaming\");\n\n    // Set up dependencies\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Try streaming execution (stub for now)\n    let result = engine\n        .execute_script_streaming(\"return 'streaming test'\")\n        .await;\n    // Streaming returns a stub implementation or error\n    match result {\n        Err(e) => {\n            // Expected for now - streaming not fully implemented\n            println!(\"Streaming returned error as expected: {}\", e);\n        }\n        Ok(stream) => {\n            // If it succeeds, it should return a valid stream\n            assert_eq!(stream.metadata.engine, \"lua\");\n        }\n    }\n}\n\n/// Test provider integration through scripts\n#[tokio::test]\nasync fn test_provider_integration() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    // Set up provider configuration\n    let mut provider_config = ProviderManagerConfig::default();\n\n    // Note: This test will fail if OPENAI_API_KEY is not set\n    // In a real test, we'd use a mock provider\n    provider_config.providers.insert(\n        \"test-openai\".to_string(),\n        ProviderConfig {\n            provider_type: \"openai\".to_string(),\n            api_key_env: Some(\"OPENAI_API_KEY\".to_string()),\n            base_url: None,\n            model: Some(\"gpt-3.5-turbo\".to_string()),\n            max_tokens: Some(100),\n            extra: HashMap::new(),\n        },\n    );\n\n    let registry = Arc::new(ComponentRegistry::new());\n    let providers = Arc::new(match ProviderManager::new(provider_config).await {\n        Ok(manager) => manager,\n        Err(_) => {\n            // If provider creation fails (no API key), create empty manager\n            ProviderManager::new(ProviderManagerConfig::default())\n                .await\n                .unwrap()\n        }\n    });\n\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Test that we can access provider functionality\n    let script = r#\"\n        -- Test that Agent API is available\n        return Agent ~= nil and type(Agent.create) == 'function'\n    \"#;\n\n    let output = engine.execute_script(script).await.unwrap();\n    assert_eq!(output.output.as_bool(), Some(true));\n}\n\n/// Test error propagation from scripts\n#[tokio::test]\nasync fn test_error_propagation() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Test various error scenarios\n    let error_cases = vec![\n        (\"syntax error {{\", \"syntax\"),\n        (\"error('runtime error')\", \"runtime\"),\n        (\"nil + 1\", \"type\"),\n        (\"unknown_function()\", \"undefined\"),\n    ];\n\n    for (script, error_type) in error_cases {\n        let result = engine.execute_script(script).await;\n        assert!(result.is_err(), \"Script '{}' should fail\", script);\n\n        let error_msg = result.unwrap_err().to_string();\n        println!(\"Error for {}: {}\", error_type, error_msg);\n    }\n}\n\n/// Test multimodal type access from scripts\n#[tokio::test]\nasync fn test_multimodal_types_access() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    assert!(\n        engine.supports_multimodal(),\n        \"Lua should support multimodal\"\n    );\n\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Test creating multimodal content (when API is available)\n    let script = r#\"\n        -- For now, just verify APIs are injected\n        return {\n            agent_available = Agent ~= nil,\n            tool_available = Tool ~= nil,\n            workflow_available = Workflow ~= nil\n        }\n    \"#;\n\n    let output = engine.execute_script(script).await.unwrap();\n    let result = output.output.as_object().unwrap();\n\n    assert_eq!(result.get(\"agent_available\").unwrap().as_bool(), Some(true));\n    assert_eq!(result.get(\"tool_available\").unwrap().as_bool(), Some(true));\n    assert_eq!(\n        result.get(\"workflow_available\").unwrap().as_bool(),\n        Some(true)\n    );\n}\n\n/// Test execution context management\n#[tokio::test]\nasync fn test_execution_context_integration() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Set custom execution context\n    let mut context = llmspell_bridge::engine::bridge::ExecutionContext::default();\n    context.working_directory = \"/test/dir\".to_string();\n    context\n        .environment\n        .insert(\"TEST_VAR\".to_string(), \"test_value\".to_string());\n    context.state = serde_json::json!({\"custom\": \"state\"});\n\n    engine.set_execution_context(context.clone()).unwrap();\n\n    // Verify context was set\n    let retrieved = engine.get_execution_context().unwrap();\n    assert_eq!(retrieved.working_directory, \"/test/dir\");\n    assert_eq!(\n        retrieved.environment.get(\"TEST_VAR\"),\n        Some(&\"test_value\".to_string())\n    );\n}\n\n/// Test performance benchmarks with bridge overhead\n#[tokio::test]\nasync fn test_bridge_performance_overhead() {\n    use std::time::Instant;\n\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Benchmark simple script execution\n    let script = \"return 1 + 1\";\n    let iterations = 100;\n\n    let start = Instant::now();\n    for _ in 0..iterations {\n        let _ = engine.execute_script(script).await.unwrap();\n    }\n    let duration = start.elapsed();\n\n    let avg_time = duration.as_micros() / iterations;\n    println!(\"Average execution time: {}μs\", avg_time);\n\n    // Bridge overhead should be minimal (< 1ms per execution)\n    assert!(avg_time < 1000, \"Bridge overhead should be < 1ms\");\n}\n\n/// Test component registration and access\n#[tokio::test]\nasync fn test_component_registration_integration() {\n    use async_trait::async_trait;\n    use llmspell_core::error::LLMSpellError;\n    use llmspell_core::types::{AgentInput, AgentOutput, ExecutionContext};\n    use llmspell_core::{BaseAgent, ComponentMetadata};\n\n    // Create a mock agent\n    struct MockAgent {\n        metadata: ComponentMetadata,\n        config: AgentConfig,\n    }\n\n    #[async_trait]\n    impl BaseAgent for MockAgent {\n        fn metadata(&self) -> &ComponentMetadata {\n            &self.metadata\n        }\n\n        async fn execute(\n            &self,\n            _input: AgentInput,\n            _context: ExecutionContext,\n        ) -> Result<AgentOutput, LLMSpellError> {\n            Ok(AgentOutput::text(\"Mock response\"))\n        }\n\n        async fn validate_input(&self, _input: &AgentInput) -> Result<(), LLMSpellError> {\n            Ok(())\n        }\n\n        async fn handle_error(&self, error: LLMSpellError) -> Result<AgentOutput, LLMSpellError> {\n            Ok(AgentOutput::text(format!(\"Error: {}\", error)))\n        }\n    }\n\n    #[async_trait]\n    impl Agent for MockAgent {\n        fn config(&self) -> &AgentConfig {\n            &self.config\n        }\n\n        async fn get_conversation(&self) -> Result<Vec<ConversationMessage>, LLMSpellError> {\n            Ok(vec![])\n        }\n\n        async fn add_message(\n            &mut self,\n            _message: ConversationMessage,\n        ) -> Result<(), LLMSpellError> {\n            Ok(())\n        }\n\n        async fn clear_conversation(&mut self) -> Result<(), LLMSpellError> {\n            Ok(())\n        }\n    }\n\n    // Set up engine and registry\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    let registry = Arc::new(ComponentRegistry::new());\n\n    // Register mock agent\n    let mock_agent = Arc::new(MockAgent {\n        metadata: ComponentMetadata::new(\"mock-agent\".to_string(), \"A mock agent\".to_string()),\n        config: AgentConfig::default(),\n    });\n\n    registry\n        .register_agent(\"mock-agent\".to_string(), mock_agent)\n        .unwrap();\n\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Verify registry works\n    assert_eq!(registry.list_agents(), vec![\"mock-agent\"]);\n    assert!(registry.get_agent(\"mock-agent\").is_some());\n}\n\n/// Test concurrent script execution\n#[tokio::test]\nasync fn test_concurrent_script_execution() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    let engine = Arc::new(engine);\n\n    // Run multiple scripts concurrently\n    let mut handles = vec![];\n\n    for i in 0..10 {\n        let engine_clone = engine.clone();\n        let handle = tokio::spawn(async move {\n            let script = format!(\"return {}\", i * i);\n            engine_clone.execute_script(&script).await\n        });\n        handles.push(handle);\n    }\n\n    // All should complete successfully\n    for (i, handle) in handles.into_iter().enumerate() {\n        let result = handle.await.unwrap();\n        assert!(result.is_ok());\n        let output = result.unwrap();\n        assert_eq!(output.output.as_i64(), Some((i * i) as i64));\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","tests","lua_coroutine_test.rs"],"content":"//! ABOUTME: Tests for advanced Lua coroutine streaming functionality\n//! ABOUTME: Validates true async streaming with Lua coroutines and yield\n\n#[cfg(feature = \"lua\")]\nmod tests {\n    use futures::StreamExt;\n    use llmspell_bridge::{\n        engine::factory::{EngineFactory, LuaConfig},\n        providers::{ProviderManager, ProviderManagerConfig},\n        registry::ComponentRegistry,\n    };\n    use std::sync::Arc;\n\n    #[tokio::test]\n    async fn test_lua_coroutine_iteration() {\n        let config = LuaConfig::default();\n        let mut engine = EngineFactory::create_lua_engine(&config).unwrap();\n\n        // Create mock registry and provider manager\n        let registry = Arc::new(ComponentRegistry::new());\n        let provider_config = ProviderManagerConfig::default();\n        let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n        // Inject APIs\n        engine.inject_apis(&registry, &providers).unwrap();\n\n        // Test streaming with coroutine iteration\n        let script = r#\"\n            -- Create a streaming generator\n            local stream = Streaming.create(function()\n                for i = 1, 5 do\n                    coroutine.yield(\"chunk_\" .. i)\n                end\n            end)\n            \n            -- Iterate through the stream\n            local chunks = {}\n            while not stream:isDone() do\n                local chunk = stream:next()\n                if chunk then\n                    table.insert(chunks, chunk)\n                end\n            end\n            \n            return {\n                count = #chunks,\n                first = chunks[1],\n                last = chunks[#chunks],\n                all = chunks\n            }\n        \"#;\n\n        let output = engine.execute_script(script).await;\n\n        match output {\n            Ok(result) => {\n                let obj = result.output.as_object().expect(\"Expected object result\");\n                assert_eq!(obj.get(\"count\").and_then(|v| v.as_i64()), Some(5));\n                assert_eq!(obj.get(\"first\").and_then(|v| v.as_str()), Some(\"chunk_1\"));\n                assert_eq!(obj.get(\"last\").and_then(|v| v.as_str()), Some(\"chunk_5\"));\n\n                let all = obj\n                    .get(\"all\")\n                    .and_then(|v| v.as_array())\n                    .expect(\"Expected array\");\n                assert_eq!(all.len(), 5);\n                for (i, chunk) in all.iter().enumerate() {\n                    let expected = format!(\"chunk_{}\", i + 1);\n                    assert_eq!(chunk.as_str(), Some(&expected[..]));\n                }\n            }\n            Err(e) => panic!(\"Script execution failed: {:?}\", e),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_lua_coroutine_collect() {\n        let config = LuaConfig::default();\n        let mut engine = EngineFactory::create_lua_engine(&config).unwrap();\n\n        // Create mock registry and provider manager\n        let registry = Arc::new(ComponentRegistry::new());\n        let provider_config = ProviderManagerConfig::default();\n        let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n        // Inject APIs\n        engine.inject_apis(&registry, &providers).unwrap();\n\n        // Test collect method\n        let script = r#\"\n            -- Create a streaming generator\n            local stream = Streaming.create(function()\n                coroutine.yield(\"hello\")\n                coroutine.yield(\"world\")\n                coroutine.yield(\"from\")\n                coroutine.yield(\"lua\")\n            end)\n            \n            -- Collect all chunks at once\n            local all = stream:collect()\n            \n            return {\n                count = #all,\n                joined = table.concat(all, \" \")\n            }\n        \"#;\n\n        let output = engine.execute_script(script).await;\n\n        match output {\n            Ok(result) => {\n                let obj = result.output.as_object().expect(\"Expected object result\");\n                assert_eq!(obj.get(\"count\").and_then(|v| v.as_i64()), Some(4));\n                assert_eq!(\n                    obj.get(\"joined\").and_then(|v| v.as_str()),\n                    Some(\"hello world from lua\")\n                );\n            }\n            Err(e) => panic!(\"Script execution failed: {:?}\", e),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_lua_streaming_execution_with_chunks() {\n        let config = LuaConfig::default();\n        let mut engine = EngineFactory::create_lua_engine(&config).unwrap();\n\n        // Create mock registry and provider manager\n        let registry = Arc::new(ComponentRegistry::new());\n        let provider_config = ProviderManagerConfig::default();\n        let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n        // Inject APIs\n        engine.inject_apis(&registry, &providers).unwrap();\n\n        // Script that would produce streaming output\n        let script = r#\"\n            -- Simulate a streaming LLM response\n            local function simulateLLMStream()\n                return Streaming.create(function()\n                    local tokens = {\"The\", \" \", \"quick\", \" \", \"brown\", \" \", \"fox\"}\n                    for _, token in ipairs(tokens) do\n                        coroutine.yield(token)\n                    end\n                end)\n            end\n            \n            -- Get the stream and convert to result\n            local stream = simulateLLMStream()\n            local result = stream:collect()\n            return table.concat(result, \"\")\n        \"#;\n\n        // Execute with streaming\n        let stream_result = engine.execute_script_streaming(script).await.unwrap();\n\n        // Collect chunks from the stream\n        let mut chunks = Vec::new();\n        let mut stream = stream_result.stream;\n\n        while let Some(chunk_result) = stream.next().await {\n            match chunk_result {\n                Ok(chunk) => {\n                    if let llmspell_core::types::ChunkContent::Text(text) = &chunk.content {\n                        chunks.push(text.clone());\n                    }\n                }\n                Err(e) => panic!(\"Stream error: {:?}\", e),\n            }\n        }\n\n        // Should have at least one chunk (our current implementation)\n        assert!(!chunks.is_empty(), \"Expected at least one chunk\");\n\n        // The result should contain the expected output\n        let combined = chunks.join(\"\");\n        assert!(\n            combined.contains(\"The quick brown fox\")\n                || combined.contains(\"\\\"The quick brown fox\\\"\"),\n            \"Expected result to contain 'The quick brown fox', got: {}\",\n            combined\n        );\n    }\n\n    #[tokio::test]\n    async fn test_lua_coroutine_error_handling() {\n        let config = LuaConfig::default();\n        let mut engine = EngineFactory::create_lua_engine(&config).unwrap();\n\n        // Create mock registry and provider manager\n        let registry = Arc::new(ComponentRegistry::new());\n        let provider_config = ProviderManagerConfig::default();\n        let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n        // Inject APIs\n        engine.inject_apis(&registry, &providers).unwrap();\n\n        // Test error in coroutine\n        let script = r#\"\n            local stream = Streaming.create(function()\n                coroutine.yield(\"chunk1\")\n                error(\"Stream error!\")\n                coroutine.yield(\"chunk2\") -- Never reached\n            end)\n            \n            local chunks = {}\n            local success, err = pcall(function()\n                while not stream:isDone() do\n                    local chunk = stream:next()\n                    if chunk then\n                        table.insert(chunks, chunk)\n                    end\n                end\n            end)\n            \n            return {\n                success = success,\n                chunks_before_error = chunks,\n                error_occurred = err ~= nil\n            }\n        \"#;\n\n        let output = engine.execute_script(script).await;\n\n        match output {\n            Ok(result) => {\n                let obj = result.output.as_object().expect(\"Expected object result\");\n                assert_eq!(obj.get(\"success\").and_then(|v| v.as_bool()), Some(false));\n\n                let chunks = obj\n                    .get(\"chunks_before_error\")\n                    .and_then(|v| v.as_array())\n                    .expect(\"Expected array\");\n                assert_eq!(chunks.len(), 1);\n                assert_eq!(chunks[0].as_str(), Some(\"chunk1\"));\n\n                assert_eq!(\n                    obj.get(\"error_occurred\").and_then(|v| v.as_bool()),\n                    Some(true)\n                );\n            }\n            Err(e) => panic!(\"Script execution failed: {:?}\", e),\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","tests","lua_engine_test.rs"],"content":"//! ABOUTME: Integration tests for LuaEngine implementation\n//! ABOUTME: Validates basic script execution and API injection\n\n#[cfg(feature = \"lua\")]\nmod tests {\n    use llmspell_bridge::{\n        engine::factory::{EngineFactory, LuaConfig},\n        providers::{ProviderManager, ProviderManagerConfig},\n        registry::ComponentRegistry,\n    };\n    use std::sync::Arc;\n\n    #[tokio::test]\n    async fn test_lua_engine_creation() {\n        let config = LuaConfig::default();\n        let engine = EngineFactory::create_lua_engine(&config);\n        assert!(engine.is_ok(), \"Failed to create Lua engine\");\n\n        let engine = engine.unwrap();\n        assert_eq!(engine.get_engine_name(), \"lua\");\n        assert!(engine.supports_streaming());\n        assert!(engine.supports_multimodal());\n    }\n\n    #[tokio::test]\n    async fn test_lua_simple_execution() {\n        let config = LuaConfig::default();\n        let mut engine = EngineFactory::create_lua_engine(&config).unwrap();\n\n        // Create mock registry and provider manager\n        let registry = Arc::new(ComponentRegistry::new());\n        let provider_config = ProviderManagerConfig::default();\n        let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n        // Inject APIs\n        let result = engine.inject_apis(&registry, &providers);\n        assert!(result.is_ok(), \"Failed to inject APIs\");\n\n        // Execute simple script\n        let script = \"return 42\";\n        let output = engine.execute_script(script).await;\n\n        match output {\n            Ok(result) => {\n                assert_eq!(result.output.as_i64(), Some(42));\n            }\n            Err(e) => panic!(\"Script execution failed: {:?}\", e),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_lua_api_injection() {\n        let config = LuaConfig::default();\n        let mut engine = EngineFactory::create_lua_engine(&config).unwrap();\n\n        // Create mock registry and provider manager\n        let registry = Arc::new(ComponentRegistry::new());\n        let provider_config = ProviderManagerConfig::default();\n        let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n        // Inject APIs\n        engine.inject_apis(&registry, &providers).unwrap();\n\n        // Test that Agent global exists\n        let script = \"return Agent ~= nil\";\n        let output = engine.execute_script(script).await;\n\n        match output {\n            Ok(result) => {\n                assert_eq!(\n                    result.output.as_bool(),\n                    Some(true),\n                    \"Agent global not found\"\n                );\n            }\n            Err(e) => panic!(\"Script execution failed: {:?}\", e),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_lua_agent_create_placeholder() {\n        let config = LuaConfig::default();\n        let mut engine = EngineFactory::create_lua_engine(&config).unwrap();\n\n        // Create mock registry and provider manager\n        let registry = Arc::new(ComponentRegistry::new());\n        let provider_config = ProviderManagerConfig::default();\n        let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n        // Inject APIs\n        engine.inject_apis(&registry, &providers).unwrap();\n\n        // Test that Agent.create exists but returns error (placeholder)\n        let script = r#\"\n            local ok, err = pcall(function()\n                return Agent.create({system_prompt = \"test\"})\n            end)\n            return {ok = ok, error = tostring(err)}\n        \"#;\n\n        let output = engine.execute_script(script).await;\n\n        match output {\n            Ok(result) => {\n                let obj = result.output.as_object().expect(\"Expected object result\");\n                assert_eq!(obj.get(\"ok\").and_then(|v| v.as_bool()), Some(false));\n                let error = obj.get(\"error\").and_then(|v| v.as_str()).unwrap_or(\"\");\n                assert!(\n                    error.contains(\"Failed to get default provider\"),\n                    \"Expected provider error\"\n                );\n            }\n            Err(e) => panic!(\"Script execution failed: {:?}\", e),\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","tests","performance_test.rs"],"content":"//! ABOUTME: Performance and memory validation tests for the bridge\n//! ABOUTME: Ensures memory usage and performance targets are met\n\nuse llmspell_bridge::{\n    engine::factory::{EngineFactory, LuaConfig},\n    providers::{ProviderManager, ProviderManagerConfig},\n    ComponentRegistry,\n};\nuse std::sync::Arc;\nuse std::time::{Duration, Instant};\n\n/// Test memory usage stays under 50MB for simple scripts\n#[tokio::test]\nasync fn test_memory_usage_simple_scripts() {\n    // Note: Actual memory measurement would require memory_stats crate\n    // For now, we validate that scripts execute without issues\n\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Execute multiple simple scripts\n    let start = Instant::now();\n    for i in 0..100 {\n        let script = format!(\"return {}\", i);\n        let _ = engine.execute_script(&script).await.unwrap();\n    }\n    let duration = start.elapsed();\n\n    println!(\"Executed 100 scripts in {:?}\", duration);\n\n    // Verify the configured memory limit is reasonable\n    assert_eq!(\n        lua_config.max_memory,\n        Some(50_000_000),\n        \"Default memory limit should be 50MB\"\n    );\n}\n\n/// Test for memory leaks with repeated execution\n#[tokio::test]\nasync fn test_no_memory_leaks() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Warm up\n    for _ in 0..10 {\n        let _ = engine.execute_script(\"return 'warmup'\").await.unwrap();\n    }\n\n    // Track execution time as proxy for memory issues\n    let mut timings = vec![];\n\n    // Execute many scripts\n    for i in 0..1000 {\n        let script = format!(\"local t = {{}}; for j=1,100 do t[j] = {} end; return #t\", i);\n        let start = Instant::now();\n        let _ = engine.execute_script(&script).await.unwrap();\n        timings.push(start.elapsed());\n    }\n\n    // Calculate average time for first 100 vs last 100\n    let first_100_avg = timings[..100].iter().map(|d| d.as_micros()).sum::<u128>() / 100;\n    let last_100_avg = timings[900..].iter().map(|d| d.as_micros()).sum::<u128>() / 100;\n\n    println!(\n        \"First 100 avg: {}μs, Last 100 avg: {}μs\",\n        first_100_avg, last_100_avg\n    );\n\n    // Performance should not degrade significantly (indicates memory issues)\n    let degradation = last_100_avg as f64 / first_100_avg as f64;\n    assert!(\n        degradation < 2.0,\n        \"Performance degraded by {:.2}x, possible memory leak\",\n        degradation\n    );\n}\n\n/// Test script startup time < 100ms\n#[tokio::test]\nasync fn test_script_startup_time() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    // Measure time to inject APIs and execute first script\n    let start = Instant::now();\n    engine.inject_apis(&registry, &providers).unwrap();\n    let _ = engine.execute_script(\"return 'hello'\").await.unwrap();\n    let startup_time = start.elapsed();\n\n    println!(\"Script startup time: {:?}\", startup_time);\n    assert!(\n        startup_time < Duration::from_millis(100),\n        \"Startup time {:?} should be < 100ms\",\n        startup_time\n    );\n}\n\n/// Test streaming latency < 50ms\n#[tokio::test]\nasync fn test_streaming_latency() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Measure time to start streaming\n    let start = Instant::now();\n    let result = engine\n        .execute_script_streaming(\"return 'stream test'\")\n        .await;\n    let latency = start.elapsed();\n\n    match result {\n        Ok(_) => {\n            println!(\"Streaming latency: {:?}\", latency);\n            assert!(\n                latency < Duration::from_millis(50),\n                \"Streaming latency {:?} should be < 50ms\",\n                latency\n            );\n        }\n        Err(e) => {\n            // Streaming not fully implemented yet\n            println!(\"Streaming returned error (expected): {}\", e);\n        }\n    }\n}\n\n/// Benchmark various script operations\n#[tokio::test]\nasync fn test_operation_benchmarks() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Benchmark different operations\n    let operations = vec![\n        (\"simple return\", \"return 42\"),\n        (\"table creation\", \"return {a=1, b=2, c=3}\"),\n        (\n            \"loop\",\n            \"local sum = 0; for i=1,100 do sum = sum + i end; return sum\",\n        ),\n        (\n            \"function call\",\n            \"local function f(x) return x * 2 end; return f(21)\",\n        ),\n        (\"string concat\", \"return 'hello' .. ' ' .. 'world'\"),\n    ];\n\n    for (name, script) in operations {\n        let iterations = 100;\n        let start = Instant::now();\n\n        for _ in 0..iterations {\n            let _ = engine.execute_script(script).await.unwrap();\n        }\n\n        let duration = start.elapsed();\n        let avg_micros = duration.as_micros() / iterations as u128;\n\n        println!(\"Operation '{}': avg {}μs\", name, avg_micros);\n\n        // All basic operations should be fast\n        assert!(\n            avg_micros < 5000,\n            \"Operation '{}' too slow: {}μs\",\n            name,\n            avg_micros\n        );\n    }\n}\n\n/// Test concurrent execution performance\n#[tokio::test]\nasync fn test_concurrent_performance() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    let engine = Arc::new(engine);\n\n    // Benchmark sequential vs concurrent execution\n    let script_count = 100;\n\n    // Sequential execution\n    let seq_start = Instant::now();\n    for i in 0..script_count {\n        let script = format!(\"return {}\", i);\n        let _ = engine.execute_script(&script).await.unwrap();\n    }\n    let seq_duration = seq_start.elapsed();\n\n    // Concurrent execution\n    let conc_start = Instant::now();\n    let mut handles = vec![];\n\n    for i in 0..script_count {\n        let engine_clone = engine.clone();\n        let handle = tokio::spawn(async move {\n            let script = format!(\"return {}\", i);\n            engine_clone.execute_script(&script).await\n        });\n        handles.push(handle);\n    }\n\n    for handle in handles {\n        let _ = handle.await.unwrap().unwrap();\n    }\n    let conc_duration = conc_start.elapsed();\n\n    println!(\"Sequential execution: {:?}\", seq_duration);\n    println!(\"Concurrent execution: {:?}\", conc_duration);\n\n    // Concurrent should be faster or at least not significantly slower\n    let speedup = seq_duration.as_secs_f64() / conc_duration.as_secs_f64();\n    println!(\"Speedup factor: {:.2}x\", speedup);\n\n    // Should have some speedup with concurrent execution\n    // Note: On systems with fewer cores or higher task spawning overhead,\n    // concurrent might be slightly slower, so we use a lower threshold\n    assert!(\n        speedup > 0.5,\n        \"Concurrent execution should not be significantly slower (speedup: {:.2}x)\",\n        speedup\n    );\n}\n\n/// Test memory usage with large scripts\n#[tokio::test]\nasync fn test_large_script_memory() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Create a large script (but under 10MB limit)\n    let mut large_script = String::new();\n    large_script.push_str(\"local data = {\\n\");\n    for i in 0..10000 {\n        large_script.push_str(&format!(\n            \"  ['key_{}'] = 'value_{}_with_some_padding',\\n\",\n            i, i\n        ));\n    }\n    large_script.push_str(\"}\\nreturn #data\");\n\n    let script_size_mb = large_script.len() as f64 / (1024.0 * 1024.0);\n    println!(\"Large script size: {:.2} MB\", script_size_mb);\n\n    // Verify script is under limit\n    assert!(\n        large_script.len() < 10_000_000,\n        \"Script should be under 10MB limit\"\n    );\n\n    // Execute large script and measure time\n    let start = Instant::now();\n    let result = engine.execute_script(&large_script).await;\n    let duration = start.elapsed();\n\n    assert!(result.is_ok(), \"Large script should execute successfully\");\n    println!(\"Large script execution time: {:?}\", duration);\n\n    // Large scripts should still execute reasonably fast\n    assert!(\n        duration < Duration::from_secs(1),\n        \"Large script execution should be under 1 second\"\n    );\n}\n\n/// Test API injection performance overhead\n#[tokio::test]\nasync fn test_api_injection_overhead() {\n    let lua_config = LuaConfig::default();\n    let iterations = 10;\n\n    let mut total_time = Duration::ZERO;\n\n    for _ in 0..iterations {\n        let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n        let registry = Arc::new(ComponentRegistry::new());\n        let provider_config = ProviderManagerConfig::default();\n        let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n        let start = Instant::now();\n        engine.inject_apis(&registry, &providers).unwrap();\n        total_time += start.elapsed();\n    }\n\n    let avg_time = total_time / iterations;\n    println!(\"Average API injection time: {:?}\", avg_time);\n\n    // API injection should be fast\n    assert!(\n        avg_time < Duration::from_millis(10),\n        \"API injection overhead {:?} should be < 10ms\",\n        avg_time\n    );\n}\n\n/// Test execution context switching overhead\n#[tokio::test]\nasync fn test_context_switching_overhead() {\n    let lua_config = LuaConfig::default();\n    let mut engine = EngineFactory::create_lua_engine(&lua_config).unwrap();\n\n    let registry = Arc::new(ComponentRegistry::new());\n    let provider_config = ProviderManagerConfig::default();\n    let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n    engine.inject_apis(&registry, &providers).unwrap();\n\n    // Create different contexts\n    let mut contexts = vec![];\n    for i in 0..5 {\n        let mut ctx = llmspell_bridge::engine::bridge::ExecutionContext::default();\n        ctx.working_directory = format!(\"/test/dir/{}\", i);\n        ctx.environment.insert(\"CTX_ID\".to_string(), i.to_string());\n        contexts.push(ctx);\n    }\n\n    // Measure context switching overhead\n    let iterations = 100;\n    let start = Instant::now();\n\n    for i in 0..iterations {\n        let ctx = &contexts[i % contexts.len()];\n        engine.set_execution_context(ctx.clone()).unwrap();\n        let _ = engine.execute_script(\"return 1\").await.unwrap();\n    }\n\n    let duration = start.elapsed();\n    let avg_micros = duration.as_micros() / iterations as u128;\n\n    println!(\"Context switching overhead: avg {}μs\", avg_micros);\n\n    // Context switching should have minimal overhead\n    assert!(\n        avg_micros < 1000,\n        \"Context switching overhead too high: {}μs\",\n        avg_micros\n    );\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","tests","provider_integration_test.rs"],"content":"//! Test provider integration with script runtime\n\nuse llmspell_bridge::{\n    providers::{ProviderConfig, ProviderManagerConfig},\n    RuntimeConfig, ScriptRuntime,\n};\nuse std::collections::HashMap;\n\n#[tokio::test]\nasync fn test_lua_agent_creation_with_mock_provider() {\n    // Create runtime config with a mock provider\n    let mut provider_config = HashMap::new();\n    provider_config.insert(\n        \"test\".to_string(),\n        ProviderConfig {\n            provider_type: \"mock\".to_string(),\n            api_key_env: None,\n            base_url: None,\n            model: Some(\"test-model\".to_string()),\n            max_tokens: None,\n            extra: HashMap::new(),\n        },\n    );\n\n    let runtime_config = RuntimeConfig {\n        default_engine: \"lua\".to_string(),\n        providers: ProviderManagerConfig {\n            default_provider: Some(\"test\".to_string()),\n            providers: provider_config,\n        },\n        ..Default::default()\n    };\n\n    // Create runtime with Lua engine\n    let runtime = ScriptRuntime::new_with_lua(runtime_config).await;\n\n    // For now, we expect this to fail since we don't have a mock provider implementation\n    assert!(runtime.is_err());\n}\n\n#[tokio::test]\nasync fn test_lua_script_provider_access() {\n    let runtime_config = RuntimeConfig::default();\n    let runtime = ScriptRuntime::new_with_lua(runtime_config).await.unwrap();\n\n    // Test script that tries to create an agent\n    let script = r#\"\n        -- Try to create an agent (will fail without provider config)\n        local success, result = pcall(function()\n            return Agent.create({\n                system_prompt = \"You are a helpful assistant\",\n                temperature = 0.7\n            })\n        end)\n        \n        -- We expect this to fail for now\n        return not success\n    \"#;\n\n    let result = runtime.execute_script(script).await;\n    assert!(result.is_ok());\n\n    // The script should return true (meaning Agent.create failed as expected)\n    if let Ok(output) = result {\n        assert_eq!(output.output, serde_json::Value::Bool(true));\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","tests","runtime_test.rs"],"content":"//! ABOUTME: Integration tests for ScriptRuntime with multiple engines\n//! ABOUTME: Validates language-agnostic runtime and engine switching\n\nuse llmspell_bridge::{\n    engine::factory::EngineFactory,\n    runtime::{RuntimeConfig, ScriptRuntime},\n};\n\n#[tokio::test]\nasync fn test_runtime_with_lua_engine() {\n    let config = RuntimeConfig::default();\n    assert_eq!(config.default_engine, \"lua\");\n\n    let runtime = ScriptRuntime::new_with_lua(config).await;\n    assert!(runtime.is_ok(), \"Failed to create runtime with Lua engine\");\n\n    let runtime = runtime.unwrap();\n    assert_eq!(runtime.get_engine_name(), \"lua\");\n    assert!(runtime.supports_streaming());\n    assert!(runtime.supports_multimodal());\n}\n\n#[tokio::test]\nasync fn test_runtime_with_engine_name() {\n    let config = RuntimeConfig::default();\n\n    // Test creating with Lua by name\n    let runtime = ScriptRuntime::new_with_engine_name(\"lua\", config.clone()).await;\n    assert!(\n        runtime.is_ok(),\n        \"Failed to create runtime with engine name 'lua'\"\n    );\n\n    let runtime = runtime.unwrap();\n    assert_eq!(runtime.get_engine_name(), \"lua\");\n}\n\n#[tokio::test]\nasync fn test_runtime_execute_script() {\n    let config = RuntimeConfig::default();\n    let runtime = ScriptRuntime::new_with_lua(config).await.unwrap();\n\n    // Execute a simple script\n    let result = runtime.execute_script(\"return 1 + 1\").await;\n\n    match result {\n        Ok(output) => {\n            assert_eq!(output.output.as_i64(), Some(2));\n        }\n        Err(e) => panic!(\"Script execution failed: {:?}\", e),\n    }\n}\n\n#[tokio::test]\nasync fn test_runtime_capability_detection() {\n    let config = RuntimeConfig::default();\n    let runtime = ScriptRuntime::new_with_lua(config).await.unwrap();\n\n    // Test capability detection\n    let features = runtime.get_engine_features();\n    assert!(features.async_execution);\n    assert!(features.streaming);\n    assert!(features.multimodal);\n    assert!(features.modules);\n\n    // Test individual capability methods\n    assert!(runtime.supports_streaming());\n    assert!(runtime.supports_multimodal());\n}\n\n#[tokio::test]\nasync fn test_runtime_configuration() {\n    let mut config = RuntimeConfig::default();\n\n    // Test that configuration supports multiple engines\n    assert!(config.supports_engine(\"lua\"));\n    assert!(config.supports_engine(\"javascript\"));\n    assert!(!config.supports_engine(\"python\")); // Not configured\n\n    // Test engine-specific configuration\n    config.engines.lua.debug = true;\n    config.engines.javascript.strict_mode = false;\n\n    let runtime = ScriptRuntime::new_with_lua(config).await.unwrap();\n    assert_eq!(runtime.get_engine_name(), \"lua\");\n}\n\n#[tokio::test]\nasync fn test_runtime_execution_context() {\n    let config = RuntimeConfig::default();\n    let runtime = ScriptRuntime::new_with_lua(config).await.unwrap();\n\n    // Get initial context\n    let context = runtime.get_execution_context();\n    assert!(!context.working_directory.is_empty());\n\n    // Update context\n    let mut new_context = context.clone();\n    new_context.state = serde_json::json!({ \"test\": \"value\" });\n\n    runtime.set_execution_context(new_context.clone()).unwrap();\n\n    // Verify update\n    let updated = runtime.get_execution_context();\n    assert_eq!(updated.state, serde_json::json!({ \"test\": \"value\" }));\n}\n\n#[tokio::test]\nasync fn test_runtime_engine_switching_placeholder() {\n    // This test demonstrates the architecture supports engine switching\n    // even though JavaScript engine is not yet implemented\n\n    let config = RuntimeConfig::default();\n\n    // Create with Lua\n    let lua_runtime = ScriptRuntime::new_with_lua(config.clone()).await.unwrap();\n    assert_eq!(lua_runtime.get_engine_name(), \"lua\");\n\n    // Attempt to create with JavaScript (will fail but shows the API)\n    let js_runtime = ScriptRuntime::new_with_javascript(config).await;\n\n    // Currently fails because JavaScript not implemented in Phase 1\n    assert!(js_runtime.is_err());\n\n    // But the error should indicate feature not enabled\n    if let Err(e) = js_runtime {\n        let error_msg = format!(\"{:?}\", e);\n        assert!(error_msg.contains(\"JavaScript\") || error_msg.contains(\"not enabled\"));\n    }\n}\n\n#[tokio::test]\nasync fn test_runtime_with_custom_engine_name() {\n    let config = RuntimeConfig::default();\n\n    // Test unknown engine\n    let result = ScriptRuntime::new_with_engine_name(\"unknown\", config).await;\n    assert!(result.is_err());\n\n    if let Err(e) = result {\n        match e {\n            llmspell_core::error::LLMSpellError::Validation { field, .. } => {\n                assert_eq!(field, Some(\"engine\".to_string()));\n            }\n            _ => panic!(\"Expected validation error for unknown engine\"),\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_available_engines() {\n    let engines = EngineFactory::list_available_engines();\n\n    // At least Lua should be available\n    assert!(!engines.is_empty());\n\n    let lua_engine = engines.iter().find(|e| e.name == \"lua\");\n    assert!(lua_engine.is_some());\n\n    let lua = lua_engine.unwrap();\n    assert_eq!(lua.name, \"lua\");\n    assert!(lua.features.streaming);\n    assert!(lua.features.multimodal);\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-bridge","tests","streaming_test.rs"],"content":"//! ABOUTME: Integration tests for Lua streaming support\n//! ABOUTME: Validates coroutine-based streaming and API functionality\n\n#[cfg(feature = \"lua\")]\nmod tests {\n    use llmspell_bridge::{\n        engine::factory::{EngineFactory, LuaConfig},\n        providers::{ProviderManager, ProviderManagerConfig},\n        registry::ComponentRegistry,\n    };\n    use std::sync::Arc;\n\n    #[tokio::test]\n    async fn test_lua_streaming_api_injection() {\n        let config = LuaConfig::default();\n        let mut engine = EngineFactory::create_lua_engine(&config).unwrap();\n\n        // Create mock registry and provider manager\n        let registry = Arc::new(ComponentRegistry::new());\n        let provider_config = ProviderManagerConfig::default();\n        let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n        // Inject APIs including streaming\n        let result = engine.inject_apis(&registry, &providers);\n        assert!(result.is_ok(), \"Failed to inject APIs with streaming\");\n\n        // Test that Streaming global exists\n        let script = \"return Streaming ~= nil\";\n        let output = engine.execute_script(script).await;\n\n        match output {\n            Ok(result) => {\n                assert_eq!(\n                    result.output.as_bool(),\n                    Some(true),\n                    \"Streaming global not found\"\n                );\n            }\n            Err(e) => panic!(\"Script execution failed: {:?}\", e),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_lua_coroutine_streaming() {\n        let config = LuaConfig::default();\n        let mut engine = EngineFactory::create_lua_engine(&config).unwrap();\n\n        // Create mock registry and provider manager\n        let registry = Arc::new(ComponentRegistry::new());\n        let provider_config = ProviderManagerConfig::default();\n        let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n        // Inject APIs\n        engine.inject_apis(&registry, &providers).unwrap();\n\n        // Test creating a stream with coroutines\n        let script = r#\"\n            local stream = Streaming.create(function()\n                coroutine.yield(\"chunk1\")\n                coroutine.yield(\"chunk2\")\n                coroutine.yield(\"chunk3\")\n            end)\n            \n            return {\n                exists = stream ~= nil,\n                hasNext = type(stream.next) == \"function\",\n                hasIsDone = type(stream.isDone) == \"function\",\n                hasCollect = type(stream.collect) == \"function\"\n            }\n        \"#;\n\n        let output = engine.execute_script(script).await;\n\n        match output {\n            Ok(result) => {\n                let obj = result.output.as_object().expect(\"Expected object result\");\n                assert_eq!(obj.get(\"exists\").and_then(|v| v.as_bool()), Some(true));\n                assert_eq!(obj.get(\"hasNext\").and_then(|v| v.as_bool()), Some(true));\n                assert_eq!(obj.get(\"hasIsDone\").and_then(|v| v.as_bool()), Some(true));\n                assert_eq!(obj.get(\"hasCollect\").and_then(|v| v.as_bool()), Some(true));\n            }\n            Err(e) => panic!(\"Script execution failed: {:?}\", e),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_lua_tool_api() {\n        let config = LuaConfig::default();\n        let mut engine = EngineFactory::create_lua_engine(&config).unwrap();\n\n        // Create mock registry and provider manager\n        let registry = Arc::new(ComponentRegistry::new());\n        let provider_config = ProviderManagerConfig::default();\n        let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n        // Inject APIs\n        engine.inject_apis(&registry, &providers).unwrap();\n\n        // Test Tool API\n        let script = r#\"\n            -- Check Tool global exists\n            local toolExists = Tool ~= nil\n            \n            -- Get list of tools\n            local tools = Tool.list()\n            local hasTools = #tools > 0\n            \n            -- Try to get a tool\n            local calc = Tool.get(\"calculator\")\n            local toolWorks = calc ~= nil and calc.name == \"calculator\"\n            \n            return {\n                toolExists = toolExists,\n                hasTools = hasTools,\n                toolWorks = toolWorks\n            }\n        \"#;\n\n        let output = engine.execute_script(script).await;\n\n        match output {\n            Ok(result) => {\n                let obj = result.output.as_object().expect(\"Expected object result\");\n                assert_eq!(obj.get(\"toolExists\").and_then(|v| v.as_bool()), Some(true));\n                assert_eq!(obj.get(\"hasTools\").and_then(|v| v.as_bool()), Some(true));\n                assert_eq!(obj.get(\"toolWorks\").and_then(|v| v.as_bool()), Some(true));\n            }\n            Err(e) => panic!(\"Script execution failed: {:?}\", e),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_lua_workflow_api() {\n        let config = LuaConfig::default();\n        let mut engine = EngineFactory::create_lua_engine(&config).unwrap();\n\n        // Create mock registry and provider manager\n        let registry = Arc::new(ComponentRegistry::new());\n        let provider_config = ProviderManagerConfig::default();\n        let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n        // Inject APIs\n        engine.inject_apis(&registry, &providers).unwrap();\n\n        // Test Workflow API\n        let script = r#\"\n            -- Check Workflow global exists\n            local workflowExists = Workflow ~= nil\n            \n            -- Create sequential workflow\n            local seq = Workflow.sequential({\n                {type = \"step1\"},\n                {type = \"step2\"}\n            })\n            \n            -- Create parallel workflow\n            local par = Workflow.parallel({\n                {type = \"task1\"},\n                {type = \"task2\"}\n            })\n            \n            return {\n                workflowExists = workflowExists,\n                seqType = seq and seq.type or nil,\n                parType = par and par.type or nil,\n                seqHasExecute = seq and type(seq.execute) == \"function\",\n                parHasExecute = par and type(par.execute) == \"function\"\n            }\n        \"#;\n\n        let output = engine.execute_script(script).await;\n\n        match output {\n            Ok(result) => {\n                let obj = result.output.as_object().expect(\"Expected object result\");\n                assert_eq!(\n                    obj.get(\"workflowExists\").and_then(|v| v.as_bool()),\n                    Some(true)\n                );\n                assert_eq!(\n                    obj.get(\"seqType\").and_then(|v| v.as_str()),\n                    Some(\"sequential\")\n                );\n                assert_eq!(\n                    obj.get(\"parType\").and_then(|v| v.as_str()),\n                    Some(\"parallel\")\n                );\n                assert_eq!(\n                    obj.get(\"seqHasExecute\").and_then(|v| v.as_bool()),\n                    Some(true)\n                );\n                assert_eq!(\n                    obj.get(\"parHasExecute\").and_then(|v| v.as_bool()),\n                    Some(true)\n                );\n            }\n            Err(e) => panic!(\"Script execution failed: {:?}\", e),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_lua_streaming_execution() {\n        let config = LuaConfig::default();\n        let mut engine = EngineFactory::create_lua_engine(&config).unwrap();\n\n        // Create mock registry and provider manager\n        let registry = Arc::new(ComponentRegistry::new());\n        let provider_config = ProviderManagerConfig::default();\n        let providers = Arc::new(ProviderManager::new(provider_config).await.unwrap());\n\n        // Inject APIs first\n        engine.inject_apis(&registry, &providers).unwrap();\n\n        // Test that streaming execution returns appropriate error for now\n        let script = \"return 'test'\";\n        let stream_result = engine.execute_script_streaming(script).await;\n\n        // For now, this should work as we have a basic implementation\n        match stream_result {\n            Ok(_) => println!(\"Streaming execution succeeded\"),\n            Err(e) => panic!(\"Streaming execution failed: {:?}\", e),\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-cli","src","cli.rs"],"content":"//! ABOUTME: CLI argument parsing and command structures\n//! ABOUTME: Defines the command-line interface with multi-engine support\n\nuse clap::{Parser, Subcommand, ValueEnum};\nuse std::path::PathBuf;\n\n/// Command-line interface for LLMSpell\n#[derive(Parser, Debug)]\n#[command(name = \"llmspell\")]\n#[command(version)]\n#[command(about = \"LLMSpell - Scriptable LLM interactions\")]\n#[command(propagate_version = true)]\npub struct Cli {\n    /// Script engine to use\n    #[arg(long, value_enum, default_value = \"lua\", env = \"LLMSPELL_ENGINE\")]\n    pub engine: ScriptEngine,\n\n    /// Configuration file path\n    #[arg(short, long, env = \"LLMSPELL_CONFIG\")]\n    pub config: Option<PathBuf>,\n\n    /// Enable verbose output\n    #[arg(short, long, global = true)]\n    pub verbose: bool,\n\n    /// Output format\n    #[arg(long, value_enum, default_value = \"text\")]\n    pub output: OutputFormat,\n\n    #[command(subcommand)]\n    pub command: Commands,\n}\n\n/// Available script engines\n#[derive(Debug, Clone, Copy, PartialEq, Eq, ValueEnum)]\npub enum ScriptEngine {\n    /// Lua 5.4 engine\n    Lua,\n    /// JavaScript engine (future)\n    #[clap(alias = \"js\")]\n    Javascript,\n    /// Python engine (future)\n    Python,\n}\n\nimpl ScriptEngine {\n    pub fn as_str(&self) -> &'static str {\n        match self {\n            ScriptEngine::Lua => \"lua\",\n            ScriptEngine::Javascript => \"javascript\",\n            ScriptEngine::Python => \"python\",\n        }\n    }\n\n    pub fn is_available(&self) -> bool {\n        match self {\n            ScriptEngine::Lua => true,         // Available in Phase 1\n            ScriptEngine::Javascript => false, // Phase 5\n            ScriptEngine::Python => false,     // Phase 9\n        }\n    }\n\n    pub fn availability_message(&self) -> &'static str {\n        match self {\n            ScriptEngine::Lua => \"Available\",\n            ScriptEngine::Javascript => \"Coming in Phase 5\",\n            ScriptEngine::Python => \"Coming in Phase 9\",\n        }\n    }\n}\n\n/// Output format options\n#[derive(Debug, Clone, Copy, PartialEq, Eq, ValueEnum)]\npub enum OutputFormat {\n    /// Plain text output\n    Text,\n    /// JSON output\n    Json,\n    /// Pretty-printed output\n    Pretty,\n}\n\n/// Available subcommands\n#[derive(Subcommand, Debug)]\npub enum Commands {\n    /// Execute a script file\n    Run {\n        /// Script file to execute\n        script: PathBuf,\n\n        /// Enable streaming output\n        #[arg(long)]\n        stream: bool,\n\n        /// Script arguments\n        #[arg(last = true)]\n        args: Vec<String>,\n    },\n\n    /// Execute inline script\n    Exec {\n        /// Script code to execute\n        #[arg(value_name = \"CODE\")]\n        code: String,\n\n        /// Enable streaming output\n        #[arg(long)]\n        stream: bool,\n    },\n\n    /// Start interactive REPL\n    Repl {\n        /// History file path\n        #[arg(long)]\n        history: Option<PathBuf>,\n    },\n\n    /// Available Providers\n    Providers {\n        /// Show detailed information\n        #[arg(long)]\n        detailed: bool,\n    },\n\n    /// Validate configuration\n    Validate {\n        /// Configuration file to validate\n        #[arg(short, long)]\n        config: Option<PathBuf>,\n    },\n\n    /// Show engine information\n    Info {\n        /// Show all engines (including unavailable)\n        #[arg(long)]\n        all: bool,\n    },\n\n    /// Initialize configuration file\n    Init {\n        /// Output path for configuration file\n        #[arg(short, long, default_value = \"llmspell.toml\")]\n        output: PathBuf,\n\n        /// Force overwrite existing file\n        #[arg(short, long)]\n        force: bool,\n    },\n}\n\nimpl Cli {\n    /// Validate the selected engine is available\n    pub fn validate_engine(&self) -> anyhow::Result<()> {\n        if !self.engine.is_available() {\n            anyhow::bail!(\n                \"Script engine '{}' is not available yet. {}\",\n                self.engine.as_str(),\n                self.engine.availability_message()\n            );\n        }\n        Ok(())\n    }\n\n    /// Get the configuration file path\n    pub fn config_path(&self) -> Option<PathBuf> {\n        self.config.clone().or_else(|| {\n            // Try default locations\n            let home = dirs::home_dir()?;\n            let config_path = home.join(\".llmspell\").join(\"config.toml\");\n            if config_path.exists() {\n                Some(config_path)\n            } else {\n                None\n            }\n        })\n    }\n}\n","traces":[{"line":47,"address":[],"length":0,"stats":{"Line":5}},{"line":48,"address":[],"length":0,"stats":{"Line":5}},{"line":49,"address":[],"length":0,"stats":{"Line":3}},{"line":50,"address":[],"length":0,"stats":{"Line":1}},{"line":51,"address":[],"length":0,"stats":{"Line":1}},{"line":55,"address":[],"length":0,"stats":{"Line":10}},{"line":56,"address":[],"length":0,"stats":{"Line":10}},{"line":57,"address":[],"length":0,"stats":{"Line":8}},{"line":58,"address":[],"length":0,"stats":{"Line":1}},{"line":59,"address":[],"length":0,"stats":{"Line":1}},{"line":63,"address":[],"length":0,"stats":{"Line":3}},{"line":64,"address":[],"length":0,"stats":{"Line":3}},{"line":65,"address":[],"length":0,"stats":{"Line":1}},{"line":66,"address":[],"length":0,"stats":{"Line":1}},{"line":67,"address":[],"length":0,"stats":{"Line":1}},{"line":153,"address":[],"length":0,"stats":{"Line":9}},{"line":154,"address":[],"length":0,"stats":{"Line":9}},{"line":155,"address":[],"length":0,"stats":{"Line":2}},{"line":156,"address":[],"length":0,"stats":{"Line":2}},{"line":157,"address":[],"length":0,"stats":{"Line":2}},{"line":158,"address":[],"length":0,"stats":{"Line":2}},{"line":161,"address":[],"length":0,"stats":{"Line":7}},{"line":165,"address":[],"length":0,"stats":{"Line":7}},{"line":166,"address":[],"length":0,"stats":{"Line":14}},{"line":168,"address":[],"length":0,"stats":{"Line":14}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":7}}],"covered":26,"coverable":29},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-cli","src","commands","exec.rs"],"content":"//! ABOUTME: Exec command implementation for inline script execution\n//! ABOUTME: Executes script code provided directly on the command line\n\nuse crate::cli::{OutputFormat, ScriptEngine};\nuse crate::output::{format_output, print_stream};\nuse anyhow::Result;\nuse llmspell_bridge::RuntimeConfig;\n\n/// Execute inline script code\npub async fn execute_inline_script(\n    code: String,\n    engine: ScriptEngine,\n    runtime_config: RuntimeConfig,\n    stream: bool,\n    output_format: OutputFormat,\n) -> Result<()> {\n    // Create runtime for the selected engine\n    let runtime = super::create_runtime(engine, runtime_config).await?;\n\n    // Execute script\n    if stream && runtime.supports_streaming() {\n        // Execute with streaming\n        let mut stream = runtime.execute_script_streaming(&code).await?;\n        print_stream(&mut stream, output_format).await?;\n    } else {\n        // Execute without streaming\n        let result = runtime.execute_script(&code).await?;\n        println!(\"{}\", format_output(&result, output_format)?);\n    }\n\n    Ok(())\n}\n","traces":[{"line":10,"address":[],"length":0,"stats":{"Line":2}},{"line":18,"address":[],"length":0,"stats":{"Line":4}},{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":4}},{"line":28,"address":[],"length":0,"stats":{"Line":2}},{"line":31,"address":[],"length":0,"stats":{"Line":2}}],"covered":5,"coverable":8},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-cli","src","commands","info.rs"],"content":"//! ABOUTME: Info command implementation showing engine information\n//! ABOUTME: Displays available engines and their capabilities\n\nuse crate::cli::{OutputFormat, ScriptEngine};\nuse anyhow::Result;\nuse serde_json::json;\n\n/// Show engine information\npub async fn show_engine_info(\n    current_engine: ScriptEngine,\n    show_all: bool,\n    output_format: OutputFormat,\n) -> Result<()> {\n    let engines = if show_all {\n        vec![\n            ScriptEngine::Lua,\n            ScriptEngine::Javascript,\n            ScriptEngine::Python,\n        ]\n    } else {\n        vec![ScriptEngine::Lua] // Only show available engines\n    };\n\n    match output_format {\n        OutputFormat::Json => {\n            let info = engines\n                .iter()\n                .map(|engine| {\n                    json!({\n                        \"name\": engine.as_str(),\n                        \"available\": engine.is_available(),\n                        \"status\": engine.availability_message(),\n                        \"current\": *engine == current_engine,\n                    })\n                })\n                .collect::<Vec<_>>();\n            println!(\"{}\", serde_json::to_string_pretty(&info)?);\n        }\n        OutputFormat::Text | OutputFormat::Pretty => {\n            println!(\"LLMSpell Script Engines:\");\n            println!();\n            for engine in engines {\n                let marker = if engine == current_engine { \"→\" } else { \" \" };\n                let status = if engine.is_available() { \"✓\" } else { \"✗\" };\n                println!(\n                    \"{} {} {} - {}\",\n                    marker,\n                    status,\n                    engine.as_str(),\n                    engine.availability_message()\n                );\n            }\n            println!();\n            println!(\"Current engine: {}\", current_engine.as_str());\n        }\n    }\n\n    Ok(())\n}\n","traces":[{"line":9,"address":[],"length":0,"stats":{"Line":1}},{"line":14,"address":[],"length":0,"stats":{"Line":2}},{"line":15,"address":[],"length":0,"stats":{"Line":0}},{"line":16,"address":[],"length":0,"stats":{"Line":0}},{"line":17,"address":[],"length":0,"stats":{"Line":0}},{"line":18,"address":[],"length":0,"stats":{"Line":0}},{"line":21,"address":[],"length":0,"stats":{"Line":1}},{"line":24,"address":[],"length":0,"stats":{"Line":1}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}},{"line":29,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":0}},{"line":31,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":1}},{"line":41,"address":[],"length":0,"stats":{"Line":1}},{"line":42,"address":[],"length":0,"stats":{"Line":3}},{"line":43,"address":[],"length":0,"stats":{"Line":1}},{"line":44,"address":[],"length":0,"stats":{"Line":1}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":1}}],"covered":10,"coverable":30},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-cli","src","commands","init.rs"],"content":"//! ABOUTME: Init command implementation for creating configuration files\n//! ABOUTME: Generates default configuration with helpful comments\n\nuse crate::config;\nuse anyhow::Result;\nuse std::path::PathBuf;\n\n/// Initialize configuration file\npub async fn init_config(output: PathBuf, force: bool) -> Result<()> {\n    // Check if file already exists\n    if output.exists() && !force {\n        anyhow::bail!(\n            \"Configuration file already exists: {}. Use --force to overwrite.\",\n            output.display()\n        );\n    }\n\n    // Create the configuration file\n    config::create_default_config(&output).await?;\n\n    println!(\"✓ Created configuration file: {}\", output.display());\n    println!();\n    println!(\"Next steps:\");\n    println!(\"  1. Edit {} to configure your settings\", output.display());\n    println!(\"  2. Set API keys:\");\n    println!(\"     - OPENAI_API_KEY for OpenAI provider\");\n    println!(\"     - ANTHROPIC_API_KEY for Anthropic provider\");\n    println!(\"     - COHERE_API_KEY for Cohere provider\");\n    println!(\"  3. Run 'llmspell validate' to check your configuration\");\n    println!(\"  4. Run 'llmspell run <script>' to execute scripts\");\n\n    Ok(())\n}\n","traces":[{"line":9,"address":[],"length":0,"stats":{"Line":0}},{"line":11,"address":[],"length":0,"stats":{"Line":0}},{"line":12,"address":[],"length":0,"stats":{"Line":0}},{"line":13,"address":[],"length":0,"stats":{"Line":0}},{"line":14,"address":[],"length":0,"stats":{"Line":0}},{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}},{"line":29,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":17},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-cli","src","commands","mod.rs"],"content":"//! ABOUTME: Command handler implementations\n//! ABOUTME: Executes CLI commands with multi-engine support\n\npub mod exec;\npub mod info;\npub mod init;\npub mod providers;\npub mod repl;\npub mod run;\npub mod validate;\n\nuse crate::cli::{Commands, OutputFormat, ScriptEngine};\nuse anyhow::Result;\nuse llmspell_bridge::{RuntimeConfig, ScriptRuntime};\n\n/// Execute a command with the given runtime configuration\npub async fn execute_command(\n    command: Commands,\n    engine: ScriptEngine,\n    runtime_config: RuntimeConfig,\n    output_format: OutputFormat,\n) -> Result<()> {\n    match command {\n        Commands::Run {\n            script,\n            stream,\n            args,\n        } => {\n            run::execute_script_file(script, engine, runtime_config, stream, args, output_format)\n                .await\n        }\n        Commands::Exec { code, stream } => {\n            exec::execute_inline_script(code, engine, runtime_config, stream, output_format).await\n        }\n        Commands::Repl { history } => repl::start_repl(engine, runtime_config, history).await,\n        Commands::Providers { detailed } => {\n            providers::list_providers(runtime_config, detailed, output_format).await\n        }\n        Commands::Validate { config } => validate::validate_config(config, output_format).await,\n        Commands::Info { all } => info::show_engine_info(engine, all, output_format).await,\n        Commands::Init { output, force } => init::init_config(output, force).await,\n    }\n}\n\n/// Create a script runtime for the specified engine\npub async fn create_runtime(engine: ScriptEngine, config: RuntimeConfig) -> Result<ScriptRuntime> {\n    match engine {\n        ScriptEngine::Lua => ScriptRuntime::new_with_lua(config)\n            .await\n            .map_err(|e| anyhow::anyhow!(\"Failed to create Lua runtime: {}\", e)),\n        ScriptEngine::Javascript => {\n            anyhow::bail!(\"JavaScript engine not available yet (coming in Phase 5)\")\n        }\n        ScriptEngine::Python => {\n            anyhow::bail!(\"Python engine not available yet (coming in Phase 9)\")\n        }\n    }\n}\n","traces":[{"line":17,"address":[],"length":0,"stats":{"Line":7}},{"line":23,"address":[],"length":0,"stats":{"Line":7}},{"line":25,"address":[],"length":0,"stats":{"Line":2}},{"line":26,"address":[],"length":0,"stats":{"Line":2}},{"line":27,"address":[],"length":0,"stats":{"Line":2}},{"line":28,"address":[],"length":0,"stats":{"Line":2}},{"line":29,"address":[],"length":0,"stats":{"Line":2}},{"line":30,"address":[],"length":0,"stats":{"Line":2}},{"line":32,"address":[],"length":0,"stats":{"Line":2}},{"line":33,"address":[],"length":0,"stats":{"Line":2}},{"line":35,"address":[],"length":0,"stats":{"Line":1}},{"line":36,"address":[],"length":0,"stats":{"Line":1}},{"line":37,"address":[],"length":0,"stats":{"Line":1}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":1}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":6}},{"line":47,"address":[],"length":0,"stats":{"Line":3}},{"line":48,"address":[],"length":0,"stats":{"Line":3}},{"line":49,"address":[],"length":0,"stats":{"Line":3}},{"line":50,"address":[],"length":0,"stats":{"Line":6}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}}],"covered":19,"coverable":23},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-cli","src","commands","providers.rs"],"content":"//! ABOUTME: Providers command implementation for listing LLM providers\n//! ABOUTME: Shows available providers and their capabilities\n\nuse crate::cli::OutputFormat;\nuse anyhow::Result;\nuse llmspell_bridge::RuntimeConfig;\nuse serde_json::json;\n\n/// List available providers\npub async fn list_providers(\n    _runtime_config: RuntimeConfig,\n    detailed: bool,\n    output_format: OutputFormat,\n) -> Result<()> {\n    // TODO: Query actual providers from runtime\n    let providers = vec![json!({\n        \"name\": \"rig\",\n        \"models\": [\"openai/gpt-4\", \"anthropic/claude-3\", \"cohere/command\"],\n        \"capabilities\": {\n            \"streaming\": false,\n            \"multimodal\": true,\n        }\n    })];\n\n    match output_format {\n        OutputFormat::Json => {\n            println!(\"{}\", serde_json::to_string_pretty(&providers)?);\n        }\n        OutputFormat::Text | OutputFormat::Pretty => {\n            println!(\"Available Providers:\");\n            println!();\n            for provider in &providers {\n                if let Some(name) = provider.get(\"name\").and_then(|v| v.as_str()) {\n                    println!(\"• {}\", name);\n                    if detailed {\n                        if let Some(models) = provider.get(\"models\").and_then(|v| v.as_array()) {\n                            println!(\"  Models:\");\n                            for model in models {\n                                if let Some(model_str) = model.as_str() {\n                                    println!(\"    - {}\", model_str);\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    Ok(())\n}\n","traces":[{"line":10,"address":[],"length":0,"stats":{"Line":1}},{"line":16,"address":[],"length":0,"stats":{"Line":1}},{"line":17,"address":[],"length":0,"stats":{"Line":1}},{"line":18,"address":[],"length":0,"stats":{"Line":1}},{"line":19,"address":[],"length":0,"stats":{"Line":1}},{"line":20,"address":[],"length":0,"stats":{"Line":1}},{"line":21,"address":[],"length":0,"stats":{"Line":1}},{"line":25,"address":[],"length":0,"stats":{"Line":1}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":1}},{"line":31,"address":[],"length":0,"stats":{"Line":1}},{"line":32,"address":[],"length":0,"stats":{"Line":3}},{"line":33,"address":[],"length":0,"stats":{"Line":2}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":1}}],"covered":13,"coverable":21},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-cli","src","commands","repl.rs"],"content":"//! ABOUTME: REPL command implementation for interactive scripting\n//! ABOUTME: Provides an interactive read-eval-print loop\n\nuse crate::cli::ScriptEngine;\nuse anyhow::Result;\nuse llmspell_bridge::RuntimeConfig;\nuse std::path::PathBuf;\n\n/// Start an interactive REPL session\npub async fn start_repl(\n    engine: ScriptEngine,\n    _runtime_config: RuntimeConfig,\n    _history_file: Option<PathBuf>,\n) -> Result<()> {\n    println!(\"LLMSpell REPL - {} engine\", engine.as_str());\n    println!(\"Type 'exit' or press Ctrl+D to quit\");\n    println!();\n\n    // TODO: Implement full REPL in Phase 2\n    anyhow::bail!(\"REPL mode not implemented yet (coming in Phase 2)\")\n}\n","traces":[{"line":10,"address":[],"length":0,"stats":{"Line":1}},{"line":15,"address":[],"length":0,"stats":{"Line":1}},{"line":16,"address":[],"length":0,"stats":{"Line":1}},{"line":17,"address":[],"length":0,"stats":{"Line":1}},{"line":20,"address":[],"length":0,"stats":{"Line":1}}],"covered":5,"coverable":5},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-cli","src","commands","run.rs"],"content":"//! ABOUTME: Run command implementation for executing script files\n//! ABOUTME: Handles script execution with streaming and output formatting\n\nuse crate::cli::{OutputFormat, ScriptEngine};\nuse crate::output::{format_output, print_stream};\nuse anyhow::Result;\nuse llmspell_bridge::RuntimeConfig;\nuse std::path::PathBuf;\nuse tokio::fs;\n\n/// Execute a script file\npub async fn execute_script_file(\n    script_path: PathBuf,\n    engine: ScriptEngine,\n    runtime_config: RuntimeConfig,\n    stream: bool,\n    args: Vec<String>,\n    output_format: OutputFormat,\n) -> Result<()> {\n    // Validate script file exists\n    if !script_path.exists() {\n        anyhow::bail!(\"Script file not found: {}\", script_path.display());\n    }\n\n    // Read script content\n    let script_content = fs::read_to_string(&script_path).await?;\n\n    // Create runtime for the selected engine\n    let runtime = super::create_runtime(engine, runtime_config).await?;\n\n    // TODO: Pass script arguments to the runtime\n    if !args.is_empty() {\n        tracing::debug!(\"Script arguments: {:?}\", args);\n    }\n\n    // Execute script\n    if stream && runtime.supports_streaming() {\n        // Execute with streaming\n        let mut stream = runtime.execute_script_streaming(&script_content).await?;\n        print_stream(&mut stream, output_format).await?;\n    } else {\n        // Execute without streaming\n        let result = runtime.execute_script(&script_content).await?;\n        println!(\"{}\", format_output(&result, output_format)?);\n    }\n\n    Ok(())\n}\n","traces":[{"line":12,"address":[],"length":0,"stats":{"Line":2}},{"line":21,"address":[],"length":0,"stats":{"Line":2}},{"line":22,"address":[],"length":0,"stats":{"Line":1}},{"line":26,"address":[],"length":0,"stats":{"Line":2}},{"line":29,"address":[],"length":0,"stats":{"Line":1}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":2}},{"line":44,"address":[],"length":0,"stats":{"Line":1}},{"line":47,"address":[],"length":0,"stats":{"Line":1}}],"covered":8,"coverable":13},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-cli","src","commands","validate.rs"],"content":"//! ABOUTME: Validate command implementation for configuration validation\n//! ABOUTME: Checks configuration files for errors and completeness\n\nuse crate::cli::OutputFormat;\nuse crate::config;\nuse anyhow::Result;\nuse serde_json::json;\nuse std::path::{Path, PathBuf};\n\n/// Validate configuration file\npub async fn validate_config(\n    config_path: Option<PathBuf>,\n    output_format: OutputFormat,\n) -> Result<()> {\n    let path = config_path.as_deref();\n    let mut warnings = Vec::new();\n    let mut errors = Vec::new();\n\n    // Try to load the configuration\n    let (config_result, actual_path) = match path {\n        Some(p) => {\n            let result = config::load_runtime_config(Some(p)).await;\n            (result, p.to_string_lossy().to_string())\n        }\n        None => {\n            // Try to discover config file\n            let result = config::load_runtime_config(None).await;\n            let discovered_path = discover_actual_path().await;\n            (result, discovered_path)\n        }\n    };\n\n    // Check if configuration loaded successfully\n    let valid = match config_result {\n        Ok(config) => {\n            // Validate the loaded configuration\n            match config::validate_config(&config) {\n                Ok(_) => {\n                    // Additional checks\n                    if config.providers.providers.is_empty() {\n                        warnings.push(\"No providers configured\".to_string());\n                    }\n\n                    if !config.runtime.security.allow_network_access {\n                        warnings.push(\n                            \"Network access is disabled - LLM providers won't work\".to_string(),\n                        );\n                    }\n\n                    true\n                }\n                Err(e) => {\n                    errors.push(format!(\"Validation error: {}\", e));\n                    false\n                }\n            }\n        }\n        Err(e) => {\n            errors.push(format!(\"Failed to load configuration: {}\", e));\n            false\n        }\n    };\n\n    let validation_result = json!({\n        \"valid\": valid,\n        \"path\": actual_path,\n        \"warnings\": warnings,\n        \"errors\": errors\n    });\n\n    match output_format {\n        OutputFormat::Json => {\n            println!(\"{}\", serde_json::to_string_pretty(&validation_result)?);\n        }\n        OutputFormat::Text | OutputFormat::Pretty => {\n            println!(\"Configuration validation:\");\n            println!(\"  File: {}\", actual_path);\n\n            if valid {\n                println!(\"  Status: ✓ Valid\");\n            } else {\n                println!(\"  Status: ✗ Invalid\");\n            }\n\n            if !warnings.is_empty() {\n                println!(\"\\nWarnings:\");\n                for warning in &warnings {\n                    println!(\"  ⚠ {}\", warning);\n                }\n            }\n\n            if !errors.is_empty() {\n                println!(\"\\nErrors:\");\n                for error in &errors {\n                    println!(\"  ✗ {}\", error);\n                }\n            }\n        }\n    }\n\n    if !valid {\n        anyhow::bail!(\"Configuration validation failed\");\n    }\n\n    Ok(())\n}\n\n/// Try to discover which config file would be used\nasync fn discover_actual_path() -> String {\n    // Check standard paths\n    for path in &[\"llmspell.toml\", \".llmspell.toml\", \"config/llmspell.toml\"] {\n        if Path::new(path).exists() {\n            return path.to_string();\n        }\n    }\n\n    // Check home directory\n    if let Ok(home) = std::env::var(\"HOME\").or_else(|_| std::env::var(\"USERPROFILE\")) {\n        for filename in &[\".llmspell.toml\", \".config/llmspell.toml\"] {\n            let path = PathBuf::from(&home).join(filename);\n            if path.exists() {\n                return path.display().to_string();\n            }\n        }\n    }\n\n    \"(no config file found - using defaults)\".to_string()\n}\n","traces":[{"line":11,"address":[],"length":0,"stats":{"Line":0}},{"line":15,"address":[],"length":0,"stats":{"Line":0}},{"line":16,"address":[],"length":0,"stats":{"Line":0}},{"line":17,"address":[],"length":0,"stats":{"Line":0}},{"line":20,"address":[],"length":0,"stats":{"Line":0}},{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}},{"line":29,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":59},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-cli","src","config.rs"],"content":"//! ABOUTME: Configuration loading and management for CLI\n//! ABOUTME: Handles loading runtime configuration from files and environment\n\nuse anyhow::{Context, Result};\nuse llmspell_bridge::RuntimeConfig;\nuse std::env;\nuse std::path::{Path, PathBuf};\nuse tokio::fs;\n\n/// Configuration file discovery order\nconst CONFIG_SEARCH_PATHS: &[&str] = &[\n    \"llmspell.toml\",\n    \".llmspell.toml\",\n    \"config/llmspell.toml\",\n    \".config/llmspell.toml\",\n];\n\n/// Environment variable prefix\nconst ENV_PREFIX: &str = \"LLMSPELL_\";\n\n/// Load runtime configuration from file or use defaults\npub async fn load_runtime_config(config_path: Option<&Path>) -> Result<RuntimeConfig> {\n    // If explicit path provided, use it\n    if let Some(path) = config_path {\n        if path.exists() {\n            return load_from_file(path).await;\n        } else {\n            anyhow::bail!(\"Configuration file not found: {}\", path.display());\n        }\n    }\n\n    // Try to discover config file\n    if let Some(path) = discover_config_file().await? {\n        tracing::info!(\"Found configuration file: {}\", path.display());\n        let mut config = load_from_file(&path).await?;\n\n        // Apply environment overrides\n        apply_environment_overrides(&mut config)?;\n\n        return Ok(config);\n    }\n\n    // No config file found, use defaults with environment overrides\n    let mut config = RuntimeConfig::default();\n    apply_environment_overrides(&mut config)?;\n\n    Ok(config)\n}\n\n/// Discover configuration file in standard locations\nasync fn discover_config_file() -> Result<Option<PathBuf>> {\n    // Check current directory first\n    for path in CONFIG_SEARCH_PATHS {\n        let path = PathBuf::from(path);\n        if path.exists() {\n            return Ok(Some(path));\n        }\n    }\n\n    // Check home directory\n    if let Ok(home_dir) = env::var(\"HOME\").or_else(|_| env::var(\"USERPROFILE\")) {\n        let home_path = PathBuf::from(home_dir);\n\n        for filename in &[\".llmspell.toml\", \".config/llmspell.toml\"] {\n            let path = home_path.join(filename);\n            if path.exists() {\n                return Ok(Some(path));\n            }\n        }\n    }\n\n    // Check system config directories\n    if let Some(config_dir) = dirs::config_dir() {\n        let path = config_dir.join(\"llmspell\").join(\"config.toml\");\n        if path.exists() {\n            return Ok(Some(path));\n        }\n    }\n\n    Ok(None)\n}\n\n/// Load configuration from TOML file\nasync fn load_from_file(path: &Path) -> Result<RuntimeConfig> {\n    let content = fs::read_to_string(path)\n        .await\n        .with_context(|| format!(\"Failed to read config file: {}\", path.display()))?;\n\n    let config = toml::from_str(&content)\n        .with_context(|| format!(\"Failed to parse config file: {}\", path.display()))?;\n\n    Ok(config)\n}\n\n/// Apply environment variable overrides\nfn apply_environment_overrides(config: &mut RuntimeConfig) -> Result<()> {\n    // Override default engine\n    if let Ok(engine) = env::var(format!(\"{}DEFAULT_ENGINE\", ENV_PREFIX)) {\n        config.default_engine = engine;\n    }\n\n    // Provider API keys are handled via api_key_env in provider config\n    // Set default provider if specified\n    if let Ok(provider) = env::var(format!(\"{}DEFAULT_PROVIDER\", ENV_PREFIX)) {\n        config.providers.default_provider = Some(provider);\n    }\n\n    // Override security settings\n    if let Ok(val) = env::var(format!(\"{}ALLOW_FILE_ACCESS\", ENV_PREFIX)) {\n        config.runtime.security.allow_file_access = val\n            .parse()\n            .with_context(|| \"Invalid boolean value for LLMSPELL_ALLOW_FILE_ACCESS\")?;\n    }\n\n    if let Ok(val) = env::var(format!(\"{}ALLOW_NETWORK_ACCESS\", ENV_PREFIX)) {\n        config.runtime.security.allow_network_access = val\n            .parse()\n            .with_context(|| \"Invalid boolean value for LLMSPELL_ALLOW_NETWORK_ACCESS\")?;\n    }\n\n    if let Ok(val) = env::var(format!(\"{}MAX_MEMORY_MB\", ENV_PREFIX)) {\n        let mb: usize = val\n            .parse()\n            .with_context(|| \"Invalid value for LLMSPELL_MAX_MEMORY_MB\")?;\n        config.runtime.security.max_memory_bytes = Some(mb * 1024 * 1024);\n    }\n\n    // Override runtime settings\n    if let Ok(val) = env::var(format!(\"{}SCRIPT_TIMEOUT\", ENV_PREFIX)) {\n        config.runtime.script_timeout_seconds = val\n            .parse()\n            .with_context(|| \"Invalid value for LLMSPELL_SCRIPT_TIMEOUT\")?;\n    }\n\n    if let Ok(val) = env::var(format!(\"{}ENABLE_STREAMING\", ENV_PREFIX)) {\n        config.runtime.enable_streaming = val\n            .parse()\n            .with_context(|| \"Invalid boolean value for LLMSPELL_ENABLE_STREAMING\")?;\n    }\n\n    Ok(())\n}\n\n/// Create default configuration file\npub async fn create_default_config(path: &Path) -> Result<()> {\n    let default_config = RuntimeConfig::default();\n    let toml_content = toml::to_string_pretty(&default_config)\n        .context(\"Failed to serialize default configuration\")?;\n\n    // Create parent directories if needed\n    if let Some(parent) = path.parent() {\n        fs::create_dir_all(parent)\n            .await\n            .with_context(|| format!(\"Failed to create config directory: {}\", parent.display()))?;\n    }\n\n    // Write the configuration file\n    fs::write(path, toml_content)\n        .await\n        .with_context(|| format!(\"Failed to write config file: {}\", path.display()))?;\n\n    tracing::info!(\"Created default configuration at: {}\", path.display());\n    Ok(())\n}\n\n/// Validate configuration\npub fn validate_config(config: &RuntimeConfig) -> Result<()> {\n    // Validate engine is supported\n    if !config.supports_engine(&config.default_engine) {\n        anyhow::bail!(\n            \"Default engine '{}' is not configured\",\n            config.default_engine\n        );\n    }\n\n    // Validate security settings\n    if config.runtime.security.max_memory_bytes == Some(0) {\n        anyhow::bail!(\"Invalid max_memory_bytes: cannot be zero\");\n    }\n\n    if config.runtime.security.max_execution_time_ms == Some(0) {\n        anyhow::bail!(\"Invalid max_execution_time_ms: cannot be zero\");\n    }\n\n    // Validate runtime settings\n    if config.runtime.max_concurrent_scripts == 0 {\n        anyhow::bail!(\"Invalid max_concurrent_scripts: cannot be zero\");\n    }\n\n    if config.runtime.script_timeout_seconds == 0 {\n        anyhow::bail!(\"Invalid script_timeout_seconds: cannot be zero\");\n    }\n\n    Ok(())\n}\n","traces":[{"line":22,"address":[],"length":0,"stats":{"Line":38}},{"line":24,"address":[],"length":0,"stats":{"Line":18}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":2}},{"line":28,"address":[],"length":0,"stats":{"Line":1}},{"line":33,"address":[],"length":0,"stats":{"Line":13}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":1}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":1}},{"line":44,"address":[],"length":0,"stats":{"Line":11}},{"line":45,"address":[],"length":0,"stats":{"Line":11}},{"line":47,"address":[],"length":0,"stats":{"Line":11}},{"line":51,"address":[],"length":0,"stats":{"Line":29}},{"line":53,"address":[],"length":0,"stats":{"Line":101}},{"line":54,"address":[],"length":0,"stats":{"Line":45}},{"line":55,"address":[],"length":0,"stats":{"Line":45}},{"line":56,"address":[],"length":0,"stats":{"Line":1}},{"line":61,"address":[],"length":0,"stats":{"Line":22}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":55}},{"line":65,"address":[],"length":0,"stats":{"Line":22}},{"line":66,"address":[],"length":0,"stats":{"Line":22}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":22}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":11}},{"line":84,"address":[],"length":0,"stats":{"Line":9}},{"line":85,"address":[],"length":0,"stats":{"Line":6}},{"line":86,"address":[],"length":0,"stats":{"Line":3}},{"line":87,"address":[],"length":0,"stats":{"Line":6}},{"line":89,"address":[],"length":0,"stats":{"Line":2}},{"line":90,"address":[],"length":0,"stats":{"Line":2}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":17}},{"line":98,"address":[],"length":0,"stats":{"Line":19}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":17}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":19}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":17}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":19}},{"line":122,"address":[],"length":0,"stats":{"Line":2}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":19}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":19}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":17}},{"line":145,"address":[],"length":0,"stats":{"Line":6}},{"line":146,"address":[],"length":0,"stats":{"Line":2}},{"line":147,"address":[],"length":0,"stats":{"Line":4}},{"line":151,"address":[],"length":0,"stats":{"Line":2}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":4}},{"line":158,"address":[],"length":0,"stats":{"Line":2}},{"line":159,"address":[],"length":0,"stats":{"Line":2}},{"line":160,"address":[],"length":0,"stats":{"Line":4}},{"line":162,"address":[],"length":0,"stats":{"Line":2}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":4}},{"line":169,"address":[],"length":0,"stats":{"Line":4}},{"line":170,"address":[],"length":0,"stats":{"Line":2}},{"line":171,"address":[],"length":0,"stats":{"Line":2}},{"line":172,"address":[],"length":0,"stats":{"Line":2}},{"line":177,"address":[],"length":0,"stats":{"Line":2}},{"line":178,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":2}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":2}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":2}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":2}}],"covered":56,"coverable":88},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-cli","src","lib.rs"],"content":"//! ABOUTME: Command-line interface library for rs-llmspell\n//! ABOUTME: Provides CLI argument parsing and command handling functionality\n\npub mod cli;\npub mod commands;\npub mod config;\npub mod output;\n\n// Re-export commonly used types for testing\npub use cli::OutputFormat;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-cli","src","main.rs"],"content":"//! ABOUTME: Main entry point for the llmspell command-line tool\n//! ABOUTME: Handles argument parsing and dispatches to appropriate command handlers\n\nuse anyhow::Result;\nuse clap::Parser;\nuse llmspell_cli::{cli::Cli, commands::execute_command, config::load_runtime_config};\n\n#[tokio::main]\nasync fn main() -> Result<()> {\n    // Initialize logging based on verbosity\n    let cli = Cli::parse();\n\n    let log_level = if cli.verbose {\n        tracing::Level::DEBUG\n    } else {\n        tracing::Level::INFO\n    };\n\n    tracing_subscriber::fmt()\n        .with_max_level(log_level)\n        .with_target(false)\n        .init();\n\n    // Validate engine selection\n    cli.validate_engine()?;\n\n    // Load runtime configuration\n    let config_path = cli.config_path();\n    let runtime_config = load_runtime_config(config_path.as_deref()).await?;\n\n    // Execute the command\n    execute_command(cli.command, cli.engine, runtime_config, cli.output).await?;\n\n    Ok(())\n}\n","traces":[{"line":9,"address":[],"length":0,"stats":{"Line":28}},{"line":11,"address":[],"length":0,"stats":{"Line":28}},{"line":13,"address":[],"length":0,"stats":{"Line":42}},{"line":14,"address":[],"length":0,"stats":{"Line":14}},{"line":16,"address":[],"length":0,"stats":{"Line":28}},{"line":19,"address":[],"length":0,"stats":{"Line":28}},{"line":20,"address":[],"length":0,"stats":{"Line":28}},{"line":25,"address":[],"length":0,"stats":{"Line":30}},{"line":28,"address":[],"length":0,"stats":{"Line":26}},{"line":29,"address":[],"length":0,"stats":{"Line":21}},{"line":32,"address":[],"length":0,"stats":{"Line":16}},{"line":34,"address":[],"length":0,"stats":{"Line":19}}],"covered":12,"coverable":12},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-cli","src","output.rs"],"content":"//! ABOUTME: Output formatting utilities for different output modes\n//! ABOUTME: Handles text, JSON, and pretty-printed output formats\n\nuse crate::cli::OutputFormat;\nuse anyhow::Result;\nuse futures::StreamExt;\nuse indicatif::{ProgressBar, ProgressStyle};\nuse llmspell_bridge::engine::{ScriptOutput, ScriptStream};\nuse std::sync::Arc;\nuse std::time::Duration;\nuse tokio::signal;\nuse tokio::sync::Mutex;\n\n/// Format script output according to the specified format\npub fn format_output(output: &ScriptOutput, format: OutputFormat) -> Result<String> {\n    match format {\n        OutputFormat::Json => Ok(serde_json::to_string_pretty(&output.output)?),\n        OutputFormat::Text => {\n            // Simple text representation\n            match output.output {\n                serde_json::Value::String(ref s) => Ok(s.clone()),\n                _ => Ok(output.output.to_string()),\n            }\n        }\n        OutputFormat::Pretty => {\n            // Pretty-printed output with metadata\n            let mut result = String::new();\n\n            // Add console output if any\n            if !output.console_output.is_empty() {\n                result.push_str(\"Console Output:\\n\");\n                for line in &output.console_output {\n                    result.push_str(&format!(\"  {}\\n\", line));\n                }\n                result.push('\\n');\n            }\n\n            result.push_str(&format!(\n                \"Output: {}\\n\",\n                serde_json::to_string_pretty(&output.output)?\n            ));\n\n            // Add metadata\n            result.push_str(&format!(\"Engine: {}\\n\", output.metadata.engine));\n            result.push_str(&format!(\n                \"Execution time: {}ms\\n\",\n                output.metadata.execution_time_ms\n            ));\n\n            if !output.metadata.warnings.is_empty() {\n                result.push_str(\"\\nWarnings:\\n\");\n                for warning in &output.metadata.warnings {\n                    result.push_str(&format!(\"  ⚠ {}\\n\", warning));\n                }\n            }\n\n            Ok(result)\n        }\n    }\n}\n\n/// Print streaming output with the specified format\npub async fn print_stream(stream: &mut ScriptStream, format: OutputFormat) -> Result<()> {\n    // Set up signal handler for graceful shutdown\n    let interrupted = Arc::new(Mutex::new(false));\n    let interrupted_clone = interrupted.clone();\n\n    tokio::spawn(async move {\n        signal::ctrl_c().await.expect(\"Failed to listen for Ctrl+C\");\n        *interrupted_clone.lock().await = true;\n    });\n\n    match format {\n        OutputFormat::Json => print_stream_json(stream, interrupted).await,\n        OutputFormat::Text => print_stream_text(stream, false, interrupted).await,\n        OutputFormat::Pretty => print_stream_text(stream, true, interrupted).await,\n    }\n}\n\n/// Print streaming output as JSON\nasync fn print_stream_json(stream: &mut ScriptStream, interrupted: Arc<Mutex<bool>>) -> Result<()> {\n    // Show progress while collecting chunks\n    let spinner = ProgressBar::new_spinner();\n    spinner.set_style(\n        ProgressStyle::default_spinner()\n            .template(\"{spinner:.cyan} {msg}\")\n            .unwrap(),\n    );\n    spinner.set_message(\"Collecting stream data...\");\n    spinner.enable_steady_tick(Duration::from_millis(100));\n\n    let mut chunks = Vec::new();\n    while let Some(chunk) = stream.stream.next().await {\n        // Check if interrupted\n        if *interrupted.lock().await {\n            spinner.finish_with_message(\"Stream interrupted by user\");\n            eprintln!(\"\\n⚠️ Stream interrupted by Ctrl+C\");\n            break;\n        }\n\n        chunks.push(chunk?);\n        spinner.set_message(format!(\"Collected {} chunks\", chunks.len()));\n    }\n\n    spinner.finish_and_clear();\n    println!(\"{}\", serde_json::to_string_pretty(&chunks)?);\n    Ok(())\n}\n\n/// Print streaming output as text with optional progress indicators\nasync fn print_stream_text(\n    stream: &mut ScriptStream,\n    show_progress: bool,\n    interrupted: Arc<Mutex<bool>>,\n) -> Result<()> {\n    use std::io::{self, Write};\n\n    let progress = if show_progress {\n        let pb = ProgressBar::new_spinner();\n        pb.set_style(\n            ProgressStyle::default_spinner()\n                .template(\"{spinner:.green} {msg}\")\n                .unwrap(),\n        );\n        pb.set_message(\"Streaming output...\");\n        pb.enable_steady_tick(Duration::from_millis(100));\n        Some(pb)\n    } else {\n        None\n    };\n\n    let mut chunk_count = 0;\n    let mut in_tool_call = false;\n\n    while let Some(chunk) = stream.stream.next().await {\n        // Check if interrupted\n        if *interrupted.lock().await {\n            if let Some(ref pb) = progress {\n                pb.finish_with_message(\"Stream interrupted by user\");\n            }\n            eprintln!(\"\\n⚠️ Stream interrupted by Ctrl+C\");\n            break;\n        }\n\n        let chunk = chunk?;\n        chunk_count += 1;\n\n        // Update progress message\n        if let Some(ref pb) = progress {\n            pb.set_message(format!(\"Processing chunk {}\", chunk_count));\n        }\n\n        // Print chunk content based on its type\n        match &chunk.content {\n            llmspell_core::types::ChunkContent::Text(text) => {\n                if in_tool_call && progress.is_some() {\n                    // Clear the progress bar before printing text\n                    if let Some(ref pb) = progress {\n                        pb.suspend(|| {\n                            print!(\"{}\", text);\n                            io::stdout().flush().ok();\n                        });\n                    }\n                } else {\n                    print!(\"{}\", text);\n                    io::stdout().flush()?;\n                }\n            }\n            llmspell_core::types::ChunkContent::ToolCallProgress { tool_name, .. } => {\n                in_tool_call = true;\n                if let Some(ref pb) = progress {\n                    pb.suspend(|| {\n                        println!(\"\\n🔧 Calling tool: {}...\", tool_name);\n                    });\n                    pb.set_message(format!(\"Tool: {}\", tool_name));\n                } else {\n                    println!(\"\\n[Calling tool: {}...]\", tool_name);\n                }\n            }\n            llmspell_core::types::ChunkContent::ToolCallComplete { tool_name, .. } => {\n                in_tool_call = false;\n                if let Some(ref pb) = progress {\n                    pb.suspend(|| {\n                        println!(\"✓ Tool call complete: {}\", tool_name);\n                    });\n                } else {\n                    println!(\"[Tool call complete: {}]\", tool_name);\n                }\n            }\n            llmspell_core::types::ChunkContent::Media { caption, .. } => {\n                let media_msg = if let Some(cap) = caption {\n                    format!(\"📎 Media: {}\", cap)\n                } else {\n                    \"📎 Media content\".to_string()\n                };\n\n                if let Some(ref pb) = progress {\n                    pb.suspend(|| {\n                        println!(\"\\n{}\", media_msg);\n                    });\n                } else {\n                    println!(\"\\n[{}]\", media_msg);\n                }\n            }\n            llmspell_core::types::ChunkContent::Control(msg) => {\n                // Handle control messages\n                use llmspell_core::types::ControlMessage;\n                tracing::debug!(\"Control message: {:?}\", msg);\n                if let Some(ref pb) = progress {\n                    match msg {\n                        ControlMessage::StreamStart { .. } => {\n                            pb.set_message(\"Stream started\");\n                        }\n                        ControlMessage::StreamEnd { .. } => {\n                            pb.set_message(\"Stream ending...\");\n                        }\n                        ControlMessage::StreamCancelled { reason } => {\n                            pb.set_message(format!(\"Stream cancelled: {}\", reason));\n                        }\n                        ControlMessage::Heartbeat => {\n                            // Keep spinner alive\n                        }\n                        ControlMessage::RateLimit { remaining, .. } => {\n                            pb.set_message(format!(\"Rate limited ({} remaining)\", remaining));\n                        }\n                        ControlMessage::Custom { .. } => {\n                            // Custom control messages\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    // Clean up progress bar\n    if let Some(pb) = progress {\n        pb.finish_with_message(\"Stream complete\");\n        pb.finish_and_clear();\n    }\n\n    println!(); // Final newline\n    Ok(())\n}\n","traces":[{"line":15,"address":[],"length":0,"stats":{"Line":3}},{"line":16,"address":[],"length":0,"stats":{"Line":3}},{"line":17,"address":[],"length":0,"stats":{"Line":1}},{"line":20,"address":[],"length":0,"stats":{"Line":2}},{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":22,"address":[],"length":0,"stats":{"Line":2}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":0}},{"line":31,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":12}},{"line":65,"address":[],"length":0,"stats":{"Line":4}},{"line":66,"address":[],"length":0,"stats":{"Line":4}},{"line":68,"address":[],"length":0,"stats":{"Line":4}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":4}},{"line":74,"address":[],"length":0,"stats":{"Line":1}},{"line":75,"address":[],"length":0,"stats":{"Line":1}},{"line":76,"address":[],"length":0,"stats":{"Line":2}},{"line":81,"address":[],"length":0,"stats":{"Line":3}},{"line":83,"address":[],"length":0,"stats":{"Line":1}},{"line":84,"address":[],"length":0,"stats":{"Line":1}},{"line":85,"address":[],"length":0,"stats":{"Line":1}},{"line":86,"address":[],"length":0,"stats":{"Line":1}},{"line":87,"address":[],"length":0,"stats":{"Line":1}},{"line":89,"address":[],"length":0,"stats":{"Line":1}},{"line":90,"address":[],"length":0,"stats":{"Line":1}},{"line":92,"address":[],"length":0,"stats":{"Line":1}},{"line":93,"address":[],"length":0,"stats":{"Line":5}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":2}},{"line":102,"address":[],"length":0,"stats":{"Line":2}},{"line":105,"address":[],"length":0,"stats":{"Line":1}},{"line":106,"address":[],"length":0,"stats":{"Line":1}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":6}},{"line":118,"address":[],"length":0,"stats":{"Line":6}},{"line":119,"address":[],"length":0,"stats":{"Line":2}},{"line":120,"address":[],"length":0,"stats":{"Line":2}},{"line":121,"address":[],"length":0,"stats":{"Line":2}},{"line":122,"address":[],"length":0,"stats":{"Line":2}},{"line":123,"address":[],"length":0,"stats":{"Line":2}},{"line":125,"address":[],"length":0,"stats":{"Line":2}},{"line":126,"address":[],"length":0,"stats":{"Line":2}},{"line":127,"address":[],"length":0,"stats":{"Line":2}},{"line":129,"address":[],"length":0,"stats":{"Line":1}},{"line":132,"address":[],"length":0,"stats":{"Line":3}},{"line":133,"address":[],"length":0,"stats":{"Line":3}},{"line":135,"address":[],"length":0,"stats":{"Line":23}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":10}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":7}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":4}},{"line":156,"address":[],"length":0,"stats":{"Line":4}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":4}},{"line":166,"address":[],"length":0,"stats":{"Line":4}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":1}},{"line":191,"address":[],"length":0,"stats":{"Line":3}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":2}},{"line":198,"address":[],"length":0,"stats":{"Line":1}},{"line":199,"address":[],"length":0,"stats":{"Line":1}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":5}},{"line":208,"address":[],"length":0,"stats":{"Line":5}},{"line":209,"address":[],"length":0,"stats":{"Line":9}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":1}},{"line":212,"address":[],"length":0,"stats":{"Line":1}},{"line":214,"address":[],"length":0,"stats":{"Line":1}},{"line":215,"address":[],"length":0,"stats":{"Line":1}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":1}},{"line":223,"address":[],"length":0,"stats":{"Line":1}},{"line":224,"address":[],"length":0,"stats":{"Line":1}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":5}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":241,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":0}}],"covered":63,"coverable":125},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-cli","tests","cli_integration_test.rs"],"content":"//! ABOUTME: Integration tests for the CLI\n//! ABOUTME: Tests end-to-end CLI functionality\n\nuse assert_cmd::Command;\nuse predicates::prelude::*;\nuse std::fs;\nuse tempfile::tempdir;\n\n#[test]\nfn test_cli_help() {\n    let mut cmd = Command::cargo_bin(\"llmspell\").unwrap();\n    cmd.arg(\"--help\")\n        .assert()\n        .success()\n        .stdout(predicate::str::contains(\n            \"LLMSpell - Scriptable LLM interactions\",\n        ));\n}\n\n#[test]\nfn test_cli_version() {\n    let mut cmd = Command::cargo_bin(\"llmspell\").unwrap();\n    cmd.arg(\"--version\")\n        .assert()\n        .success()\n        .stdout(predicate::str::contains(\"llmspell\"));\n}\n\n#[test]\nfn test_run_command_help() {\n    let mut cmd = Command::cargo_bin(\"llmspell\").unwrap();\n    cmd.arg(\"run\")\n        .arg(\"--help\")\n        .assert()\n        .success()\n        .stdout(predicate::str::contains(\"Execute a script file\"));\n}\n\n#[test]\nfn test_invalid_engine() {\n    let mut cmd = Command::cargo_bin(\"llmspell\").unwrap();\n    cmd.arg(\"--engine\")\n        .arg(\"ruby\")\n        .arg(\"run\")\n        .arg(\"test.rb\")\n        .assert()\n        .failure()\n        .stderr(predicate::str::contains(\"invalid value 'ruby'\"));\n}\n\n#[test]\nfn test_javascript_not_implemented() {\n    let mut cmd = Command::cargo_bin(\"llmspell\").unwrap();\n    cmd.arg(\"--engine\")\n        .arg(\"javascript\")\n        .arg(\"run\")\n        .arg(\"test.js\")\n        .assert()\n        .failure()\n        .stderr(predicate::str::contains(\n            \"Script engine 'javascript' is not available yet\",\n        ));\n}\n\n#[test]\nfn test_python_not_implemented() {\n    let mut cmd = Command::cargo_bin(\"llmspell\").unwrap();\n    cmd.arg(\"--engine\")\n        .arg(\"python\")\n        .arg(\"run\")\n        .arg(\"test.py\")\n        .assert()\n        .failure()\n        .stderr(predicate::str::contains(\n            \"Script engine 'python' is not available yet\",\n        ));\n}\n\n#[test]\nfn test_run_missing_file() {\n    let mut cmd = Command::cargo_bin(\"llmspell\").unwrap();\n    cmd.arg(\"run\")\n        .arg(\"nonexistent.lua\")\n        .assert()\n        .failure()\n        .stderr(predicate::str::contains(\"Script file not found\"));\n}\n\n#[test]\nfn test_run_simple_lua_script() {\n    let dir = tempdir().unwrap();\n    let script_path = dir.path().join(\"test.lua\");\n    fs::write(&script_path, \"print('Hello from test!')\").unwrap();\n\n    let mut cmd = Command::cargo_bin(\"llmspell\").unwrap();\n    cmd.arg(\"run\")\n        .arg(&script_path)\n        .assert()\n        .success()\n        .stdout(predicate::str::contains(\"Hello from test!\"));\n}\n\n#[test]\nfn test_exec_inline_code() {\n    let mut cmd = Command::cargo_bin(\"llmspell\").unwrap();\n    cmd.arg(\"exec\")\n        .arg(\"print('Inline execution works!')\")\n        .assert()\n        .success()\n        .stdout(predicate::str::contains(\"Inline execution works!\"));\n}\n\n#[test]\nfn test_output_format_json() {\n    let mut cmd = Command::cargo_bin(\"llmspell\").unwrap();\n    cmd.arg(\"--output\")\n        .arg(\"json\")\n        .arg(\"exec\")\n        .arg(\"return {result = 42}\")\n        .assert()\n        .success()\n        .stdout(predicate::str::contains(\"\\\"result\\\": 42\"));\n}\n\n#[test]\nfn test_providers_command() {\n    let mut cmd = Command::cargo_bin(\"llmspell\").unwrap();\n    cmd.arg(\"providers\")\n        .assert()\n        .success()\n        .stdout(predicate::str::contains(\"Available Providers\"));\n}\n\n#[test]\nfn test_info_command() {\n    let mut cmd = Command::cargo_bin(\"llmspell\").unwrap();\n    cmd.arg(\"info\")\n        .assert()\n        .success()\n        .stdout(predicate::str::contains(\"lua - Available\"));\n}\n\n#[test]\nfn test_repl_not_implemented() {\n    let mut cmd = Command::cargo_bin(\"llmspell\").unwrap();\n    cmd.arg(\"repl\")\n        .assert()\n        .failure()\n        .stderr(predicate::str::contains(\"REPL mode not implemented\"));\n}\n\n#[test]\nfn test_validate_missing_config() {\n    let mut cmd = Command::cargo_bin(\"llmspell\").unwrap();\n    cmd.arg(\"validate\")\n        .arg(\"nonexistent.toml\")\n        .assert()\n        .failure();\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-cli","tests","config_test.rs"],"content":"//! ABOUTME: Tests for configuration loading and validation\n//! ABOUTME: Verifies configuration discovery, parsing, and environment overrides\n\nuse llmspell_cli::config::{create_default_config, load_runtime_config, validate_config};\nuse serial_test::serial;\nuse std::env;\nuse std::fs;\nuse tempfile::tempdir;\n\n// Helper function to clean all LLMSPELL env vars\nfn clean_env_vars() {\n    env::remove_var(\"LLMSPELL_DEFAULT_ENGINE\");\n    env::remove_var(\"LLMSPELL_SCRIPT_TIMEOUT\");\n    env::remove_var(\"LLMSPELL_ENABLE_STREAMING\");\n    env::remove_var(\"LLMSPELL_ALLOW_FILE_ACCESS\");\n    env::remove_var(\"LLMSPELL_MAX_MEMORY_MB\");\n    env::remove_var(\"LLMSPELL_DEFAULT_PROVIDER\");\n    env::remove_var(\"LLMSPELL_ALLOW_NETWORK_ACCESS\");\n}\n\n#[tokio::test]\n#[serial]\nasync fn test_default_config() {\n    // Clean all env vars first\n    clean_env_vars();\n\n    // Load default configuration\n    let config = load_runtime_config(None).await.unwrap();\n\n    assert_eq!(config.default_engine, \"lua\");\n    assert!(config.runtime.enable_streaming);\n    assert_eq!(config.runtime.script_timeout_seconds, 300);\n    assert_eq!(config.runtime.security.max_memory_bytes, Some(50_000_000));\n}\n\n#[tokio::test]\nasync fn test_create_config_file() {\n    let dir = tempdir().unwrap();\n    let config_path = dir.path().join(\"test.toml\");\n\n    // Create default config\n    create_default_config(&config_path).await.unwrap();\n\n    // Verify file exists and is valid TOML\n    assert!(config_path.exists());\n    let content = fs::read_to_string(&config_path).unwrap();\n    assert!(content.contains(\"default_engine\"));\n    assert!(content.contains(\"lua\"));\n\n    // Load the created config\n    let config = load_runtime_config(Some(&config_path)).await.unwrap();\n    assert_eq!(config.default_engine, \"lua\");\n}\n\n#[tokio::test]\n#[serial]\nasync fn test_environment_overrides() {\n    // Clean first to ensure clean state\n    clean_env_vars();\n\n    // Set environment variables\n    env::set_var(\"LLMSPELL_DEFAULT_ENGINE\", \"javascript\");\n    env::set_var(\"LLMSPELL_SCRIPT_TIMEOUT\", \"600\");\n    env::set_var(\"LLMSPELL_ENABLE_STREAMING\", \"false\");\n    env::set_var(\"LLMSPELL_ALLOW_FILE_ACCESS\", \"true\");\n    env::set_var(\"LLMSPELL_MAX_MEMORY_MB\", \"100\");\n\n    // Load config with environment overrides\n    let config = load_runtime_config(None).await.unwrap();\n\n    assert_eq!(config.default_engine, \"javascript\");\n    assert_eq!(config.runtime.script_timeout_seconds, 600);\n    assert!(!config.runtime.enable_streaming);\n    assert!(config.runtime.security.allow_file_access);\n    assert_eq!(\n        config.runtime.security.max_memory_bytes,\n        Some(100 * 1024 * 1024)\n    );\n\n    // Clean up - use helper\n    clean_env_vars();\n}\n\n#[tokio::test]\n#[serial]\nasync fn test_config_discovery() {\n    clean_env_vars();\n    let dir = tempdir().unwrap();\n    let original_dir = env::current_dir().unwrap();\n\n    // Change to temp directory\n    env::set_current_dir(&dir).unwrap();\n\n    // Create config file in current directory\n    let config_path = dir.path().join(\"llmspell.toml\");\n    create_default_config(&config_path).await.unwrap();\n\n    // Should discover the config file\n    let config = load_runtime_config(None).await.unwrap();\n    assert_eq!(config.default_engine, \"lua\");\n\n    // Clean up\n    env::set_current_dir(original_dir).unwrap();\n}\n\n#[tokio::test]\nasync fn test_validate_config() {\n    let config = load_runtime_config(None).await.unwrap();\n\n    // Default config should be valid\n    validate_config(&config).unwrap();\n}\n\n#[tokio::test]\nasync fn test_invalid_config_validation() {\n    let mut config = load_runtime_config(None).await.unwrap();\n\n    // Make config invalid\n    config.default_engine = \"nonexistent\".to_string();\n\n    // Should fail validation\n    let result = validate_config(&config);\n    assert!(result.is_err());\n    assert!(result.unwrap_err().to_string().contains(\"not configured\"));\n}\n\n#[tokio::test]\nasync fn test_missing_config_file() {\n    let dir = tempdir().unwrap();\n    let nonexistent = dir.path().join(\"nonexistent.toml\");\n\n    // Should fail with clear error\n    let result = load_runtime_config(Some(&nonexistent)).await;\n    assert!(result.is_err());\n    assert!(result.unwrap_err().to_string().contains(\"not found\"));\n}\n\n#[tokio::test]\nasync fn test_malformed_config_file() {\n    let dir = tempdir().unwrap();\n    let config_path = dir.path().join(\"bad.toml\");\n\n    // Write invalid TOML\n    fs::write(&config_path, \"this is not valid toml!\").unwrap();\n\n    // Should fail with parse error\n    let result = load_runtime_config(Some(&config_path)).await;\n    assert!(result.is_err());\n    assert!(result.unwrap_err().to_string().contains(\"Failed to parse\"));\n}\n","traces":[{"line":11,"address":[],"length":0,"stats":{"Line":4}},{"line":12,"address":[],"length":0,"stats":{"Line":4}},{"line":13,"address":[],"length":0,"stats":{"Line":4}},{"line":14,"address":[],"length":0,"stats":{"Line":4}},{"line":15,"address":[],"length":0,"stats":{"Line":4}},{"line":16,"address":[],"length":0,"stats":{"Line":4}},{"line":17,"address":[],"length":0,"stats":{"Line":4}},{"line":18,"address":[],"length":0,"stats":{"Line":4}}],"covered":8,"coverable":8},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-cli","tests","streaming_test.rs"],"content":"//! ABOUTME: Tests for streaming output functionality\n//! ABOUTME: Validates progress indicators and Ctrl+C handling\n\nuse chrono::Utc;\nuse futures::stream;\nuse llmspell_bridge::engine::{ScriptMetadata, ScriptStream};\nuse llmspell_cli::{output::print_stream, OutputFormat};\nuse llmspell_core::types::{AgentChunk, ChunkContent, ChunkMetadata, ControlMessage};\n\n#[tokio::test]\nasync fn test_streaming_text_output() {\n    // Create a mock stream\n    let chunks = vec![\n        Ok(AgentChunk {\n            stream_id: \"test-stream\".to_string(),\n            chunk_index: 0,\n            content: ChunkContent::Control(ControlMessage::StreamStart {\n                expected_chunks: Some(3),\n                config: Default::default(),\n            }),\n            metadata: ChunkMetadata::default(),\n            timestamp: Utc::now(),\n        }),\n        Ok(AgentChunk {\n            stream_id: \"test-stream\".to_string(),\n            chunk_index: 1,\n            content: ChunkContent::Text(\"Hello, \".to_string()),\n            metadata: ChunkMetadata::default(),\n            timestamp: Utc::now(),\n        }),\n        Ok(AgentChunk {\n            stream_id: \"test-stream\".to_string(),\n            chunk_index: 2,\n            content: ChunkContent::Text(\"streaming world!\".to_string()),\n            metadata: ChunkMetadata {\n                is_final: true,\n                ..Default::default()\n            },\n            timestamp: Utc::now(),\n        }),\n    ];\n\n    let stream = Box::pin(stream::iter(chunks));\n    let mut script_stream = ScriptStream {\n        stream,\n        metadata: ScriptMetadata {\n            engine: \"test\".to_string(),\n            execution_time_ms: 0,\n            memory_usage_bytes: None,\n            warnings: vec![],\n        },\n    };\n\n    // Test text output\n    let result = print_stream(&mut script_stream, OutputFormat::Text).await;\n    assert!(result.is_ok());\n}\n\n#[tokio::test]\nasync fn test_streaming_json_output() {\n    // Create a mock stream with tool calls\n    let chunks = vec![\n        Ok(AgentChunk {\n            stream_id: \"test-stream\".to_string(),\n            chunk_index: 0,\n            content: ChunkContent::ToolCallProgress {\n                call_id: \"call-1\".to_string(),\n                tool_name: \"calculator\".to_string(),\n                partial_args: r#\"{\"expression\": \"2 +\"#.to_string(),\n            },\n            metadata: ChunkMetadata::default(),\n            timestamp: Utc::now(),\n        }),\n        Ok(AgentChunk {\n            stream_id: \"test-stream\".to_string(),\n            chunk_index: 1,\n            content: ChunkContent::ToolCallComplete {\n                call_id: \"call-1\".to_string(),\n                tool_name: \"calculator\".to_string(),\n                arguments: r#\"{\"expression\": \"2 + 2\"}\"#.to_string(),\n            },\n            metadata: ChunkMetadata::default(),\n            timestamp: Utc::now(),\n        }),\n    ];\n\n    let stream = Box::pin(stream::iter(chunks));\n    let mut script_stream = ScriptStream {\n        stream,\n        metadata: ScriptMetadata {\n            engine: \"test\".to_string(),\n            execution_time_ms: 0,\n            memory_usage_bytes: None,\n            warnings: vec![],\n        },\n    };\n\n    // Test JSON output\n    let result = print_stream(&mut script_stream, OutputFormat::Json).await;\n    assert!(result.is_ok());\n}\n\n#[tokio::test]\nasync fn test_streaming_with_media() {\n    // Create a mock stream with media content\n    let chunks = vec![\n        Ok(AgentChunk {\n            stream_id: \"test-stream\".to_string(),\n            chunk_index: 0,\n            content: ChunkContent::Text(\"Here's an image: \".to_string()),\n            metadata: ChunkMetadata::default(),\n            timestamp: Utc::now(),\n        }),\n        Ok(AgentChunk {\n            stream_id: \"test-stream\".to_string(),\n            chunk_index: 1,\n            content: ChunkContent::Media {\n                mime_type: \"image/png\".to_string(),\n                data: \"base64_encoded_image_data\".to_string(),\n                caption: Some(\"A beautiful sunset\".to_string()),\n            },\n            metadata: ChunkMetadata::default(),\n            timestamp: Utc::now(),\n        }),\n    ];\n\n    let stream = Box::pin(stream::iter(chunks));\n    let mut script_stream = ScriptStream {\n        stream,\n        metadata: ScriptMetadata {\n            engine: \"test\".to_string(),\n            execution_time_ms: 0,\n            memory_usage_bytes: None,\n            warnings: vec![],\n        },\n    };\n\n    // Test pretty output with media\n    let result = print_stream(&mut script_stream, OutputFormat::Pretty).await;\n    assert!(result.is_ok());\n}\n\n#[tokio::test]\nasync fn test_streaming_control_messages() {\n    // Create a mock stream with various control messages\n    let chunks = vec![\n        Ok(AgentChunk {\n            stream_id: \"test-stream\".to_string(),\n            chunk_index: 0,\n            content: ChunkContent::Control(ControlMessage::StreamStart {\n                expected_chunks: Some(5),\n                config: Default::default(),\n            }),\n            metadata: ChunkMetadata::default(),\n            timestamp: Utc::now(),\n        }),\n        Ok(AgentChunk {\n            stream_id: \"test-stream\".to_string(),\n            chunk_index: 1,\n            content: ChunkContent::Control(ControlMessage::Heartbeat),\n            metadata: ChunkMetadata::default(),\n            timestamp: Utc::now(),\n        }),\n        Ok(AgentChunk {\n            stream_id: \"test-stream\".to_string(),\n            chunk_index: 2,\n            content: ChunkContent::Text(\"Processing...\".to_string()),\n            metadata: ChunkMetadata::default(),\n            timestamp: Utc::now(),\n        }),\n        Ok(AgentChunk {\n            stream_id: \"test-stream\".to_string(),\n            chunk_index: 3,\n            content: ChunkContent::Control(ControlMessage::RateLimit {\n                remaining: 100,\n                reset_at: Utc::now() + chrono::Duration::minutes(5),\n            }),\n            metadata: ChunkMetadata::default(),\n            timestamp: Utc::now(),\n        }),\n        Ok(AgentChunk {\n            stream_id: \"test-stream\".to_string(),\n            chunk_index: 4,\n            content: ChunkContent::Control(ControlMessage::StreamEnd {\n                total_chunks: 5,\n                total_tokens: Some(150),\n                duration_ms: 1234,\n            }),\n            metadata: ChunkMetadata::default(),\n            timestamp: Utc::now(),\n        }),\n    ];\n\n    let stream = Box::pin(stream::iter(chunks));\n    let mut script_stream = ScriptStream {\n        stream,\n        metadata: ScriptMetadata {\n            engine: \"test\".to_string(),\n            execution_time_ms: 0,\n            memory_usage_bytes: None,\n            warnings: vec![],\n        },\n    };\n\n    // Test pretty output with control messages\n    let result = print_stream(&mut script_stream, OutputFormat::Pretty).await;\n    assert!(result.is_ok());\n}\n\n// This test would be for manual testing of Ctrl+C handling\n// It's commented out because it requires manual intervention\n/*\n#[tokio::test]\n#[ignore = \"Manual test - requires Ctrl+C interaction\"]\nasync fn test_streaming_interruption() {\n    // Create a slow stream that can be interrupted\n    let chunks = futures::stream::unfold(0, |state| async move {\n        if state < 100 {\n            sleep(Duration::from_millis(500)).await;\n            Some((\n                Ok(AgentChunk {\n                    stream_id: \"slow-stream\".to_string(),\n                    chunk_index: state,\n                    content: ChunkContent::Text(format!(\"Chunk {} \", state)),\n                    metadata: ChunkMetadata::default(),\n                    timestamp: Utc::now(),\n                }),\n                state + 1,\n            ))\n        } else {\n            None\n        }\n    });\n\n    let stream = Box::pin(chunks);\n    let mut script_stream = ScriptStream {\n        stream,\n        metadata: Default::default(),\n    };\n\n    println!(\"Press Ctrl+C to interrupt the stream...\");\n    let result = print_stream(&mut script_stream, OutputFormat::Pretty).await;\n    assert!(result.is_ok());\n}\n*/\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-config","src","lib.rs"],"content":"//! ABOUTME: llmspell-config implementation crate\n//! ABOUTME: Foundation stub for future implementation\n\n// Module stub - to be implemented in later phases\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-core","benches","core_benchmarks.rs"],"content":"//! Performance benchmarks for llmspell-core\n//!\n//! Uses criterion to measure performance of core operations\n\nuse criterion::{black_box, criterion_group, criterion_main, BenchmarkId, Criterion};\nuse llmspell_core::{\n    traits::{\n        agent::ConversationMessage,\n        workflow::{RetryPolicy, WorkflowStep},\n    },\n    types::{AgentInput, AgentOutput, ExecutionContext, OutputMetadata},\n    ComponentId, ComponentMetadata, LLMSpellError, Version,\n};\nuse std::time::Duration;\n\nfn bench_component_id_generation(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"ComponentId\");\n\n    // Benchmark generation from different name lengths\n    for name_len in [10, 50, 100, 500].iter() {\n        let name = \"a\".repeat(*name_len);\n        group.bench_with_input(BenchmarkId::new(\"from_name\", name_len), name_len, |b, _| {\n            b.iter(|| ComponentId::from_name(black_box(&name)));\n        });\n    }\n\n    // Benchmark new() vs from_name()\n    group.bench_function(\"new\", |b| b.iter(ComponentId::new));\n\n    group.finish();\n}\n\nfn bench_version_operations(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"Version\");\n\n    let v1 = Version::new(1, 2, 3);\n    let v2 = Version::new(1, 3, 0);\n    let v3 = Version::new(2, 0, 0);\n\n    group.bench_function(\"creation\", |b| {\n        b.iter(|| Version::new(black_box(1), black_box(2), black_box(3)))\n    });\n\n    group.bench_function(\"comparison\", |b| {\n        b.iter(|| {\n            let _ = black_box(&v1) < black_box(&v2);\n            let _ = black_box(&v2) < black_box(&v3);\n        })\n    });\n\n    group.bench_function(\"compatibility_check\", |b| {\n        b.iter(|| {\n            let _ = v1.is_compatible_with(black_box(&v2));\n            let _ = v1.is_compatible_with(black_box(&v3));\n        })\n    });\n\n    group.bench_function(\"to_string\", |b| b.iter(|| v1.to_string()));\n\n    group.finish();\n}\n\nfn bench_serialization(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"Serialization\");\n\n    // ComponentId serialization\n    let component_id = ComponentId::from_name(\"test-component\");\n    group.bench_function(\"ComponentId_serialize\", |b| {\n        b.iter(|| serde_json::to_string(black_box(&component_id)).unwrap())\n    });\n\n    group.bench_function(\"ComponentId_deserialize\", |b| {\n        let json = serde_json::to_string(&component_id).unwrap();\n        b.iter(|| {\n            let _: ComponentId = serde_json::from_str(black_box(&json)).unwrap();\n        })\n    });\n\n    // ComponentMetadata serialization\n    let metadata =\n        ComponentMetadata::new(\"test-component\".to_string(), \"A test component\".to_string());\n\n    group.bench_function(\"ComponentMetadata_serialize\", |b| {\n        b.iter(|| serde_json::to_string(black_box(&metadata)).unwrap())\n    });\n\n    group.bench_function(\"ComponentMetadata_deserialize\", |b| {\n        let json = serde_json::to_string(&metadata).unwrap();\n        b.iter(|| {\n            let _: ComponentMetadata = serde_json::from_str(black_box(&json)).unwrap();\n        })\n    });\n\n    // AgentInput with context\n    let context = ExecutionContext::new()\n        .with_data(\"key1\".to_string(), serde_json::json!(\"value1\"))\n        .with_data(\"key2\".to_string(), serde_json::json!(42))\n        .with_data(\"key3\".to_string(), serde_json::json!({\"nested\": \"value\"}));\n    let input = AgentInput::text(\"test prompt\").with_context(context);\n\n    group.bench_function(\"AgentInput_serialize\", |b| {\n        b.iter(|| serde_json::to_string(black_box(&input)).unwrap())\n    });\n\n    group.bench_function(\"AgentInput_deserialize\", |b| {\n        let json = serde_json::to_string(&input).unwrap();\n        b.iter(|| {\n            let _: AgentInput = serde_json::from_str(black_box(&json)).unwrap();\n        })\n    });\n\n    group.finish();\n}\n\nfn bench_agent_operations(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"Agent\");\n\n    // AgentInput creation and context manipulation\n    group.bench_function(\"AgentInput_creation\", |b| {\n        b.iter(|| AgentInput::text(black_box(\"test prompt\")))\n    });\n\n    group.bench_function(\"AgentInput_with_context\", |b| {\n        b.iter(|| {\n            let context = ExecutionContext::new()\n                .with_data(\"key1\".to_string(), serde_json::json!(\"value1\"))\n                .with_data(\"key2\".to_string(), serde_json::json!(42))\n                .with_data(\"key3\".to_string(), serde_json::json!(true));\n            AgentInput::text(\"test\").with_context(context)\n        })\n    });\n\n    let context = ExecutionContext::new()\n        .with_data(\"key1\".to_string(), serde_json::json!(\"value1\"))\n        .with_data(\"key2\".to_string(), serde_json::json!(42))\n        .with_data(\"key3\".to_string(), serde_json::json!(true));\n    let input = AgentInput::text(\"test\").with_context(context);\n\n    group.bench_function(\"AgentInput_get_context\", |b| {\n        b.iter(|| {\n            if let Some(ctx) = &input.context {\n                let _ = ctx.data.get(black_box(\"key1\"));\n                let _ = ctx.data.get(black_box(\"key2\"));\n                let _ = ctx.data.get(black_box(\"nonexistent\"));\n            }\n        })\n    });\n\n    // AgentOutput operations\n    group.bench_function(\"AgentOutput_creation\", |b| {\n        b.iter(|| AgentOutput::text(black_box(\"result\")))\n    });\n\n    group.bench_function(\"AgentOutput_with_metadata\", |b| {\n        b.iter(|| {\n            let mut metadata = OutputMetadata::default();\n            metadata.confidence = Some(0.95);\n            metadata.token_count = Some(150);\n            metadata.model = Some(\"gpt-4\".to_string());\n\n            AgentOutput::text(\"result\").with_metadata(metadata)\n        })\n    });\n\n    // ConversationMessage operations\n    group.bench_function(\"ConversationMessage_creation\", |b| {\n        b.iter(|| {\n            let _ = ConversationMessage::system(black_box(\"System prompt\".to_string()));\n            let _ = ConversationMessage::user(black_box(\"User message\".to_string()));\n            let _ = ConversationMessage::assistant(black_box(\"Assistant response\".to_string()));\n        })\n    });\n\n    group.finish();\n}\n\nfn bench_error_handling(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"Error\");\n\n    // Error creation\n    group.bench_function(\"create_validation_error\", |b| {\n        b.iter(|| LLMSpellError::Validation {\n            message: black_box(\"Invalid input\".to_string()),\n            field: Some(black_box(\"email\".to_string())),\n        })\n    });\n\n    group.bench_function(\"create_component_error\", |b| {\n        b.iter(|| LLMSpellError::Component {\n            message: black_box(\"Component failed\".to_string()),\n            source: None,\n        })\n    });\n\n    // Error property checks\n    let errors = vec![\n        LLMSpellError::Validation {\n            message: \"Invalid\".to_string(),\n            field: None,\n        },\n        LLMSpellError::Network {\n            message: \"Connection failed\".to_string(),\n            source: None,\n        },\n        LLMSpellError::Timeout {\n            message: \"Operation timed out\".to_string(),\n            duration_ms: Some(5000),\n        },\n    ];\n\n    group.bench_function(\"error_severity_check\", |b| {\n        b.iter(|| {\n            for err in &errors {\n                let _ = black_box(err.severity());\n            }\n        })\n    });\n\n    group.bench_function(\"error_retryability_check\", |b| {\n        b.iter(|| {\n            for err in &errors {\n                let _ = black_box(err.is_retryable());\n            }\n        })\n    });\n\n    group.bench_function(\"error_category_check\", |b| {\n        b.iter(|| {\n            for err in &errors {\n                let _ = black_box(err.category());\n            }\n        })\n    });\n\n    group.finish();\n}\n\nfn bench_workflow_operations(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"Workflow\");\n\n    let component_id = ComponentId::from_name(\"test-component\");\n\n    // WorkflowStep creation\n    group.bench_function(\"WorkflowStep_creation\", |b| {\n        b.iter(|| WorkflowStep::new(black_box(\"step-name\".to_string()), black_box(component_id)))\n    });\n\n    // WorkflowStep with dependencies\n    group.bench_function(\"WorkflowStep_with_dependencies\", |b| {\n        let dep1 = ComponentId::from_name(\"dep1\");\n        let dep2 = ComponentId::from_name(\"dep2\");\n        let dep3 = ComponentId::from_name(\"dep3\");\n\n        b.iter(|| {\n            WorkflowStep::new(\"step\".to_string(), component_id)\n                .with_dependency(black_box(dep1))\n                .with_dependency(black_box(dep2))\n                .with_dependency(black_box(dep3))\n                .with_retry(RetryPolicy::default())\n                .with_timeout(Duration::from_secs(30))\n        })\n    });\n\n    group.finish();\n}\n\nfn bench_memory_usage(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"Memory\");\n\n    // Measure allocation overhead for common types\n    group.bench_function(\"ComponentId_size\", |b| {\n        b.iter(|| {\n            let ids: Vec<ComponentId> = (0..1000)\n                .map(|i| ComponentId::from_name(&format!(\"component-{}\", i)))\n                .collect();\n            black_box(ids);\n        })\n    });\n\n    group.bench_function(\"AgentInput_with_large_context\", |b| {\n        b.iter(|| {\n            let mut context = ExecutionContext::new();\n            for i in 0..100 {\n                context = context.with_data(\n                    format!(\"key{}\", i),\n                    serde_json::json!({\"data\": \"x\".repeat(100)}),\n                );\n            }\n            let input = AgentInput::text(\"test\").with_context(context);\n            black_box(input);\n        })\n    });\n\n    group.finish();\n}\n\n// Concurrent access benchmarks\nfn bench_concurrent_operations(c: &mut Criterion) {\n    use std::sync::Arc;\n    use std::thread;\n\n    let mut group = c.benchmark_group(\"Concurrent\");\n\n    // ComponentId generation from multiple threads\n    group.bench_function(\"ComponentId_concurrent_generation\", |b| {\n        b.iter(|| {\n            let handles: Vec<_> = (0..4)\n                .map(|i| {\n                    thread::spawn(move || {\n                        for j in 0..25 {\n                            let _ = ComponentId::from_name(&format!(\"component-{}-{}\", i, j));\n                        }\n                    })\n                })\n                .collect();\n\n            for handle in handles {\n                handle.join().unwrap();\n            }\n        })\n    });\n\n    // Shared metadata access\n    group.bench_function(\"ComponentMetadata_shared_access\", |b| {\n        let metadata = Arc::new(ComponentMetadata::new(\n            \"shared\".to_string(),\n            \"Shared metadata\".to_string(),\n        ));\n\n        b.iter(|| {\n            let handles: Vec<_> = (0..4)\n                .map(|_| {\n                    let metadata_clone = Arc::clone(&metadata);\n                    thread::spawn(move || {\n                        for _ in 0..25 {\n                            let _ = black_box(&metadata_clone.name);\n                            let _ = black_box(&metadata_clone.version);\n                            let _ = black_box(metadata_clone.id);\n                        }\n                    })\n                })\n                .collect();\n\n            for handle in handles {\n                handle.join().unwrap();\n            }\n        })\n    });\n\n    group.finish();\n}\n\ncriterion_group!(\n    benches,\n    bench_component_id_generation,\n    bench_version_operations,\n    bench_serialization,\n    bench_agent_operations,\n    bench_error_handling,\n    bench_workflow_operations,\n    bench_memory_usage,\n    bench_concurrent_operations\n);\ncriterion_main!(benches);\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-core","src","error.rs"],"content":"//! ABOUTME: Error types and handling for rs-llmspell\n//! ABOUTME: Provides LLMSpellError enum and Result type alias\n\nuse thiserror::Error;\n\n/// Error severity levels.\n///\n/// Defines the severity of errors in the system, from informational to fatal.\n/// Used for error prioritization, alerting, and recovery strategies.\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::error::ErrorSeverity;\n///\n/// assert!(ErrorSeverity::Info < ErrorSeverity::Warning);\n/// assert!(ErrorSeverity::Error < ErrorSeverity::Critical);\n/// assert!(ErrorSeverity::Critical < ErrorSeverity::Fatal);\n/// ```\n#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord)]\npub enum ErrorSeverity {\n    /// Informational - can be ignored\n    Info,\n    /// Warning - should be addressed but not critical\n    Warning,\n    /// Error - normal error that can be recovered\n    Error,\n    /// Critical - severe error that may require intervention\n    Critical,\n    /// Fatal - unrecoverable error\n    Fatal,\n}\n\n/// Error category for classification.\n///\n/// Groups errors by their source or type for better error handling\n/// and monitoring. Categories help determine retry strategies and\n/// escalation paths.\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::error::ErrorCategory;\n///\n/// let category = ErrorCategory::Network;\n/// match category {\n///     ErrorCategory::Network => println!(\"Network issue - may be transient\"),\n///     ErrorCategory::Configuration => println!(\"Config error - needs fixing\"),\n///     ErrorCategory::Security => println!(\"Security issue - escalate immediately\"),\n///     _ => println!(\"Other error type\"),\n/// }\n/// ```\n#[derive(Debug, Clone, PartialEq, Eq)]\npub enum ErrorCategory {\n    /// Configuration-related errors\n    Configuration,\n    /// Network or provider errors\n    Network,\n    /// Resource errors (memory, disk, etc.)\n    Resource,\n    /// Security and permissions\n    Security,\n    /// Business logic errors\n    Logic,\n    /// External service errors\n    External,\n    /// Internal system errors\n    Internal,\n}\n\n/// Comprehensive error enum for all LLMSpell operations.\n///\n/// Central error type that encompasses all possible errors in the system.\n/// Each variant includes relevant context and may chain underlying errors.\n/// Provides methods for categorization, severity assessment, and retry logic.\n///\n/// # Error Handling Strategy\n///\n/// - **Retryable errors**: Network, timeout, and some storage errors\n/// - **Non-retryable errors**: Validation, security, and configuration errors\n/// - **Error chaining**: Use `with_source()` to preserve error context\n/// - **Structured logging**: All errors integrate with the logging system\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::{LLMSpellError, Result};\n/// use std::io;\n///\n/// // Create errors with context\n/// let validation_err = LLMSpellError::Validation {\n///     message: \"Invalid email format\".to_string(),\n///     field: Some(\"email\".to_string()),\n/// };\n///\n/// // Chain errors\n/// let io_error = io::Error::new(io::ErrorKind::NotFound, \"File not found\");\n/// let storage_err = LLMSpellError::Storage {\n///     message: \"Failed to read configuration\".to_string(),\n///     operation: Some(\"read\".to_string()),\n///     source: None,\n/// }.with_source(io_error);\n///\n/// // Check error properties\n/// assert!(!validation_err.is_retryable());\n/// assert!(storage_err.is_retryable());\n///\n/// // Use convenience macros\n/// use llmspell_core::{component_error, validation_error};\n///\n/// let comp_err = component_error!(\"Component initialization failed\");\n/// let val_err = validation_error!(\"Missing required field\", \"username\");\n/// ```\n#[derive(Debug, Error)]\npub enum LLMSpellError {\n    #[error(\"Component error: {message}\")]\n    Component {\n        message: String,\n        #[source]\n        source: Option<Box<dyn std::error::Error + Send + Sync>>,\n    },\n\n    #[error(\"Configuration error: {message}\")]\n    Configuration {\n        message: String,\n        #[source]\n        source: Option<Box<dyn std::error::Error + Send + Sync>>,\n    },\n\n    #[error(\"LLM provider error: {message}\")]\n    Provider {\n        message: String,\n        provider: Option<String>,\n        #[source]\n        source: Option<Box<dyn std::error::Error + Send + Sync>>,\n    },\n\n    #[error(\"Script execution error: {message}\")]\n    Script {\n        message: String,\n        language: Option<String>,\n        line: Option<usize>,\n        #[source]\n        source: Option<Box<dyn std::error::Error + Send + Sync>>,\n    },\n\n    #[error(\"Tool execution error: {message}\")]\n    Tool {\n        message: String,\n        tool_name: Option<String>,\n        #[source]\n        source: Option<Box<dyn std::error::Error + Send + Sync>>,\n    },\n\n    #[error(\"Workflow execution error: {message}\")]\n    Workflow {\n        message: String,\n        step: Option<String>,\n        #[source]\n        source: Option<Box<dyn std::error::Error + Send + Sync>>,\n    },\n\n    #[error(\"Storage error: {message}\")]\n    Storage {\n        message: String,\n        operation: Option<String>,\n        #[source]\n        source: Option<Box<dyn std::error::Error + Send + Sync>>,\n    },\n\n    #[error(\"Security violation: {message}\")]\n    Security {\n        message: String,\n        violation_type: Option<String>,\n    },\n\n    #[error(\"Validation error: {message}\")]\n    Validation {\n        message: String,\n        field: Option<String>,\n    },\n\n    #[error(\"Resource error: {message}\")]\n    Resource {\n        message: String,\n        resource_type: Option<String>,\n        #[source]\n        source: Option<Box<dyn std::error::Error + Send + Sync>>,\n    },\n\n    #[error(\"Timeout error: {message}\")]\n    Timeout {\n        message: String,\n        duration_ms: Option<u64>,\n    },\n\n    #[error(\"Network error: {message}\")]\n    Network {\n        message: String,\n        #[source]\n        source: Option<Box<dyn std::error::Error + Send + Sync>>,\n    },\n\n    #[error(\"Internal error: {message}\")]\n    Internal {\n        message: String,\n        #[source]\n        source: Option<Box<dyn std::error::Error + Send + Sync>>,\n    },\n}\n\nimpl LLMSpellError {\n    /// Get the error category\n    pub fn category(&self) -> ErrorCategory {\n        match self {\n            Self::Configuration { .. } => ErrorCategory::Configuration,\n            Self::Provider { .. } | Self::Network { .. } => ErrorCategory::Network,\n            Self::Resource { .. } | Self::Timeout { .. } => ErrorCategory::Resource,\n            Self::Security { .. } => ErrorCategory::Security,\n            Self::Validation { .. } | Self::Component { .. } => ErrorCategory::Logic,\n            Self::Tool { .. } | Self::Script { .. } | Self::Workflow { .. } => {\n                ErrorCategory::External\n            }\n            Self::Storage { .. } | Self::Internal { .. } => ErrorCategory::Internal,\n        }\n    }\n\n    /// Get the error severity\n    pub fn severity(&self) -> ErrorSeverity {\n        match self {\n            Self::Validation { .. } => ErrorSeverity::Warning,\n            Self::Configuration { .. } => ErrorSeverity::Error,\n            Self::Security { .. } => ErrorSeverity::Critical,\n            Self::Internal { .. } => ErrorSeverity::Fatal,\n            Self::Timeout { .. } => ErrorSeverity::Warning,\n            _ => ErrorSeverity::Error,\n        }\n    }\n\n    /// Check if the error is retryable\n    pub fn is_retryable(&self) -> bool {\n        match self {\n            Self::Network { .. } | Self::Timeout { .. } | Self::Provider { .. } => true,\n            Self::Resource { .. } => true,\n            Self::Storage { operation, .. } => {\n                // Some storage operations are retryable\n                operation\n                    .as_ref()\n                    .is_some_and(|op| op == \"read\" || op == \"write\" || op == \"lock\")\n            }\n            Self::Security { .. } | Self::Configuration { .. } | Self::Validation { .. } => false,\n            Self::Internal { .. } => false,\n            _ => false,\n        }\n    }\n\n    /// Get suggested retry delay in milliseconds\n    pub fn retry_delay_ms(&self) -> Option<u64> {\n        if !self.is_retryable() {\n            return None;\n        }\n\n        match self {\n            Self::Network { .. } => Some(1000), // 1 second\n            Self::Timeout { duration_ms, .. } => {\n                // Retry with double the timeout\n                duration_ms.map(|d| d * 2).or(Some(5000))\n            }\n            Self::Provider { .. } => Some(2000), // 2 seconds\n            Self::Resource { .. } => Some(500),  // 500ms\n            Self::Storage { .. } => Some(100),   // 100ms\n            _ => Some(1000),                     // Default 1 second\n        }\n    }\n\n    /// Chain with another error as the source\n    pub fn with_source<E>(mut self, source: E) -> Self\n    where\n        E: std::error::Error + Send + Sync + 'static,\n    {\n        match &mut self {\n            Self::Component { source: src, .. }\n            | Self::Configuration { source: src, .. }\n            | Self::Provider { source: src, .. }\n            | Self::Script { source: src, .. }\n            | Self::Tool { source: src, .. }\n            | Self::Workflow { source: src, .. }\n            | Self::Storage { source: src, .. }\n            | Self::Resource { source: src, .. }\n            | Self::Network { source: src, .. }\n            | Self::Internal { source: src, .. } => {\n                *src = Some(Box::new(source));\n            }\n            _ => {}\n        }\n        self\n    }\n}\n\n/// Convenience Result type alias\npub type Result<T> = std::result::Result<T, LLMSpellError>;\n\n// Common error conversions\nimpl From<std::io::Error> for LLMSpellError {\n    fn from(err: std::io::Error) -> Self {\n        LLMSpellError::Storage {\n            message: format!(\"IO error: {}\", err),\n            operation: None,\n            source: Some(Box::new(err)),\n        }\n    }\n}\n\nimpl From<serde_json::Error> for LLMSpellError {\n    fn from(err: serde_json::Error) -> Self {\n        LLMSpellError::Configuration {\n            message: format!(\"JSON serialization error: {}\", err),\n            source: Some(Box::new(err)),\n        }\n    }\n}\n\nimpl From<std::fmt::Error> for LLMSpellError {\n    fn from(err: std::fmt::Error) -> Self {\n        LLMSpellError::Internal {\n            message: format!(\"Formatting error: {}\", err),\n            source: Some(Box::new(err)),\n        }\n    }\n}\n\n// Error creation macros\n#[macro_export]\nmacro_rules! component_error {\n    ($msg:expr) => {\n        $crate::LLMSpellError::Component {\n            message: $msg.to_string(),\n            source: None,\n        }\n    };\n    ($msg:expr, $source:expr) => {\n        $crate::LLMSpellError::Component {\n            message: $msg.to_string(),\n            source: Some(Box::new($source)),\n        }\n    };\n}\n\n#[macro_export]\nmacro_rules! validation_error {\n    ($msg:expr) => {\n        $crate::LLMSpellError::Validation {\n            message: $msg.to_string(),\n            field: None,\n        }\n    };\n    ($msg:expr, $field:expr) => {\n        $crate::LLMSpellError::Validation {\n            message: $msg.to_string(),\n            field: Some($field.to_string()),\n        }\n    };\n}\n\n#[macro_export]\nmacro_rules! tool_error {\n    ($msg:expr) => {\n        $crate::LLMSpellError::Tool {\n            message: $msg.to_string(),\n            tool_name: None,\n            source: None,\n        }\n    };\n    ($msg:expr, $tool:expr) => {\n        $crate::LLMSpellError::Tool {\n            message: $msg.to_string(),\n            tool_name: Some($tool.to_string()),\n            source: None,\n        }\n    };\n}\n\n#[macro_export]\nmacro_rules! log_error {\n    ($error:expr) => {{\n        use tracing::error;\n        let err = &$error;\n        error!(\n            error = ?err,\n            category = ?err.category(),\n            severity = ?err.severity(),\n            retryable = err.is_retryable(),\n            \"Error occurred\"\n        );\n        err\n    }};\n    ($error:expr, $($field:tt)*) => {{\n        use tracing::error;\n        let err = &$error;\n        error!(\n            error = ?err,\n            category = ?err.category(),\n            severity = ?err.severity(),\n            retryable = err.is_retryable(),\n            $($field)*\n        );\n        err\n    }};\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_error_severity_ordering() {\n        assert!(ErrorSeverity::Info < ErrorSeverity::Warning);\n        assert!(ErrorSeverity::Warning < ErrorSeverity::Error);\n        assert!(ErrorSeverity::Error < ErrorSeverity::Critical);\n        assert!(ErrorSeverity::Critical < ErrorSeverity::Fatal);\n    }\n\n    #[test]\n    fn test_error_categorization() {\n        let config_err = LLMSpellError::Configuration {\n            message: \"Invalid config\".to_string(),\n            source: None,\n        };\n        assert_eq!(config_err.category(), ErrorCategory::Configuration);\n\n        let network_err = LLMSpellError::Network {\n            message: \"Connection failed\".to_string(),\n            source: None,\n        };\n        assert_eq!(network_err.category(), ErrorCategory::Network);\n\n        let security_err = LLMSpellError::Security {\n            message: \"Unauthorized\".to_string(),\n            violation_type: Some(\"auth\".to_string()),\n        };\n        assert_eq!(security_err.category(), ErrorCategory::Security);\n    }\n\n    #[test]\n    fn test_error_severity_mapping() {\n        let validation_err = LLMSpellError::Validation {\n            message: \"Invalid input\".to_string(),\n            field: Some(\"name\".to_string()),\n        };\n        assert_eq!(validation_err.severity(), ErrorSeverity::Warning);\n\n        let security_err = LLMSpellError::Security {\n            message: \"Access denied\".to_string(),\n            violation_type: None,\n        };\n        assert_eq!(security_err.severity(), ErrorSeverity::Critical);\n\n        let internal_err = LLMSpellError::Internal {\n            message: \"System failure\".to_string(),\n            source: None,\n        };\n        assert_eq!(internal_err.severity(), ErrorSeverity::Fatal);\n    }\n\n    #[test]\n    fn test_error_retryability() {\n        // Retryable errors\n        let network_err = LLMSpellError::Network {\n            message: \"Connection timeout\".to_string(),\n            source: None,\n        };\n        assert!(network_err.is_retryable());\n        assert_eq!(network_err.retry_delay_ms(), Some(1000));\n\n        let timeout_err = LLMSpellError::Timeout {\n            message: \"Operation timed out\".to_string(),\n            duration_ms: Some(5000),\n        };\n        assert!(timeout_err.is_retryable());\n        assert_eq!(timeout_err.retry_delay_ms(), Some(10000)); // Double the timeout\n\n        // Non-retryable errors\n        let validation_err = LLMSpellError::Validation {\n            message: \"Invalid format\".to_string(),\n            field: None,\n        };\n        assert!(!validation_err.is_retryable());\n        assert_eq!(validation_err.retry_delay_ms(), None);\n\n        let security_err = LLMSpellError::Security {\n            message: \"Forbidden\".to_string(),\n            violation_type: None,\n        };\n        assert!(!security_err.is_retryable());\n        assert_eq!(security_err.retry_delay_ms(), None);\n    }\n\n    #[test]\n    fn test_storage_error_retryability() {\n        let read_err = LLMSpellError::Storage {\n            message: \"Read failed\".to_string(),\n            operation: Some(\"read\".to_string()),\n            source: None,\n        };\n        assert!(read_err.is_retryable());\n\n        let delete_err = LLMSpellError::Storage {\n            message: \"Delete failed\".to_string(),\n            operation: Some(\"delete\".to_string()),\n            source: None,\n        };\n        assert!(!delete_err.is_retryable());\n    }\n\n    #[test]\n    fn test_error_chaining() {\n        use std::io;\n\n        let io_error = io::Error::new(io::ErrorKind::NotFound, \"File not found\");\n        let storage_err = LLMSpellError::Storage {\n            message: \"Failed to read file\".to_string(),\n            operation: Some(\"read\".to_string()),\n            source: None,\n        }\n        .with_source(io_error);\n\n        // Check that source is set\n        match storage_err {\n            LLMSpellError::Storage { source, .. } => {\n                assert!(source.is_some());\n            }\n            _ => panic!(\"Expected Storage error\"),\n        }\n    }\n\n    #[test]\n    fn test_error_display() {\n        let provider_err = LLMSpellError::Provider {\n            message: \"API rate limit exceeded\".to_string(),\n            provider: Some(\"OpenAI\".to_string()),\n            source: None,\n        };\n        let display = format!(\"{}\", provider_err);\n        assert!(display.contains(\"LLM provider error\"));\n        assert!(display.contains(\"API rate limit exceeded\"));\n    }\n\n    #[test]\n    fn test_error_macros() {\n        let comp_err = component_error!(\"Component failed\");\n        match comp_err {\n            LLMSpellError::Component { message, source } => {\n                assert_eq!(message, \"Component failed\");\n                assert!(source.is_none());\n            }\n            _ => panic!(\"Expected Component error\"),\n        }\n\n        let val_err = validation_error!(\"Invalid value\", \"username\");\n        match val_err {\n            LLMSpellError::Validation { message, field } => {\n                assert_eq!(message, \"Invalid value\");\n                assert_eq!(field, Some(\"username\".to_string()));\n            }\n            _ => panic!(\"Expected Validation error\"),\n        }\n\n        let tool_err = tool_error!(\"Execution failed\", \"FileReader\");\n        match tool_err {\n            LLMSpellError::Tool {\n                message, tool_name, ..\n            } => {\n                assert_eq!(message, \"Execution failed\");\n                assert_eq!(tool_name, Some(\"FileReader\".to_string()));\n            }\n            _ => panic!(\"Expected Tool error\"),\n        }\n    }\n\n    #[test]\n    fn test_script_error_with_details() {\n        let script_err = LLMSpellError::Script {\n            message: \"Syntax error\".to_string(),\n            language: Some(\"lua\".to_string()),\n            line: Some(42),\n            source: None,\n        };\n\n        match script_err {\n            LLMSpellError::Script { language, line, .. } => {\n                assert_eq!(language, Some(\"lua\".to_string()));\n                assert_eq!(line, Some(42));\n            }\n            _ => panic!(\"Expected Script error\"),\n        }\n    }\n\n    #[test]\n    fn test_workflow_error_with_step() {\n        let workflow_err = LLMSpellError::Workflow {\n            message: \"Step execution failed\".to_string(),\n            step: Some(\"data_processing\".to_string()),\n            source: None,\n        };\n\n        match workflow_err {\n            LLMSpellError::Workflow { step, .. } => {\n                assert_eq!(step, Some(\"data_processing\".to_string()));\n            }\n            _ => panic!(\"Expected Workflow error\"),\n        }\n    }\n\n    #[test]\n    fn test_error_serialization() {\n        // Test that errors can be converted to strings and back\n        let errors: Vec<LLMSpellError> = vec![\n            LLMSpellError::Component {\n                message: \"Test\".to_string(),\n                source: None,\n            },\n            LLMSpellError::Configuration {\n                message: \"Test\".to_string(),\n                source: None,\n            },\n            LLMSpellError::Provider {\n                message: \"Test\".to_string(),\n                provider: None,\n                source: None,\n            },\n            LLMSpellError::Security {\n                message: \"Test\".to_string(),\n                violation_type: None,\n            },\n        ];\n\n        for err in errors {\n            let err_string = err.to_string();\n            assert!(!err_string.is_empty());\n        }\n    }\n}\n","traces":[{"line":214,"address":[],"length":0,"stats":{"Line":23}},{"line":215,"address":[],"length":0,"stats":{"Line":23}},{"line":216,"address":[],"length":0,"stats":{"Line":1}},{"line":217,"address":[],"length":0,"stats":{"Line":1}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":1}},{"line":220,"address":[],"length":0,"stats":{"Line":20}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":23}},{"line":230,"address":[],"length":0,"stats":{"Line":23}},{"line":231,"address":[],"length":0,"stats":{"Line":1}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":1}},{"line":234,"address":[],"length":0,"stats":{"Line":1}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":20}},{"line":241,"address":[],"length":0,"stats":{"Line":24}},{"line":242,"address":[],"length":0,"stats":{"Line":24}},{"line":243,"address":[],"length":0,"stats":{"Line":10}},{"line":244,"address":[],"length":0,"stats":{"Line":2}},{"line":245,"address":[],"length":0,"stats":{"Line":6}},{"line":247,"address":[],"length":0,"stats":{"Line":6}},{"line":249,"address":[],"length":0,"stats":{"Line":24}},{"line":251,"address":[],"length":0,"stats":{"Line":6}},{"line":252,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":4}},{"line":259,"address":[],"length":0,"stats":{"Line":4}},{"line":260,"address":[],"length":0,"stats":{"Line":2}},{"line":263,"address":[],"length":0,"stats":{"Line":2}},{"line":264,"address":[],"length":0,"stats":{"Line":1}},{"line":265,"address":[],"length":0,"stats":{"Line":1}},{"line":267,"address":[],"length":0,"stats":{"Line":3}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":1}},{"line":281,"address":[],"length":0,"stats":{"Line":1}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":1}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":1}},{"line":292,"address":[],"length":0,"stats":{"Line":1}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":1}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":0}}],"covered":33,"coverable":62},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-core","src","lib.rs"],"content":"//! ABOUTME: Core traits, types, and infrastructure for rs-llmspell\n//! ABOUTME: Foundation layer providing BaseAgent, Agent, Tool, and Workflow traits\n//!\n//! # Overview\n//!\n//! `llmspell-core` is the foundational crate of the LLMSpell system, providing:\n//!\n//! - **Core Traits**: `BaseAgent`, `Agent`, `Tool`, and `Workflow` for component abstraction\n//! - **Type System**: `ComponentId`, `Version`, and `ComponentMetadata` for identification\n//! - **Error Handling**: Comprehensive error types with severity and retry logic\n//! - **Logging**: Structured logging with JSON and human-readable formats\n//!\n//! # Architecture\n//!\n//! The crate follows a trait-based architecture where all components implement\n//! `BaseAgent` as the foundation:\n//!\n//! ```text\n//! BaseAgent (foundation trait)\n//!     ├── Agent (LLM-powered components)\n//!     ├── Tool (functional components)  \n//!     └── Workflow (orchestration)\n//! ```\n//!\n//! # Getting Started\n//!\n//! ## Creating a Simple Agent\n//!\n//! ```\n//! use llmspell_core::{\n//!     ComponentMetadata, Result,\n//!     traits::{\n//!         base_agent::BaseAgent,\n//!         agent::{Agent, AgentConfig, ConversationMessage}\n//!     },\n//!     types::{AgentInput, AgentOutput, ExecutionContext}\n//! };\n//! use async_trait::async_trait;\n//!\n//! struct MyAgent {\n//!     metadata: ComponentMetadata,\n//!     config: AgentConfig,\n//! }\n//!\n//! impl MyAgent {\n//!     fn new(name: String) -> Self {\n//!         Self {\n//!             metadata: ComponentMetadata::new(name, \"My custom agent\".to_string()),\n//!             config: AgentConfig::default(),\n//!         }\n//!     }\n//! }\n//!\n//! #[async_trait]\n//! impl BaseAgent for MyAgent {\n//!     fn metadata(&self) -> &ComponentMetadata {\n//!         &self.metadata\n//!     }\n//!     \n//!     async fn execute(\n//!         &self,\n//!         input: AgentInput,\n//!         context: ExecutionContext,\n//!     ) -> Result<AgentOutput> {\n//!         // Your agent logic here\n//!         Ok(AgentOutput::text(format!(\"Processed: {}\", input.text)))\n//!     }\n//!     \n//!     async fn validate_input(&self, input: &AgentInput) -> Result<()> {\n//!         Ok(())\n//!     }\n//!     \n//!     async fn handle_error(&self, error: llmspell_core::LLMSpellError) -> Result<AgentOutput> {\n//!         Ok(AgentOutput::text(format!(\"Error: {}\", error)))\n//!     }\n//! }\n//! ```\n//!\n//! ## Error Handling\n//!\n//! ```\n//! use llmspell_core::{LLMSpellError, Result, component_error};\n//!\n//! fn process_data(data: &str) -> Result<String> {\n//!     if data.is_empty() {\n//!         return Err(LLMSpellError::Validation {\n//!             message: \"Data cannot be empty\".to_string(),\n//!             field: Some(\"data\".to_string()),\n//!         });\n//!     }\n//!     \n//!     // Or use convenience macros\n//!     if data.len() > 1000 {\n//!         return Err(component_error!(\"Data too large\"));\n//!     }\n//!     \n//!     Ok(data.to_uppercase())\n//! }\n//! ```\n//!\n//! ## Logging\n//!\n//! ```no_run\n//! use llmspell_core::logging::{init_from_env, info, debug};\n//!\n//! // Initialize logging\n//! init_from_env().expect(\"Failed to init logging\");\n//!\n//! // Use standard tracing macros\n//! info!(\"Application started\");\n//! debug!(user = \"alice\", \"Processing request\");\n//! ```\n\npub mod error;\npub mod logging;\npub mod types;\n\npub mod traits {\n    pub mod agent;\n    pub mod base_agent;\n    pub mod tool;\n    pub mod workflow;\n}\n\n// Re-export commonly used types\npub use error::{LLMSpellError, Result};\npub use traits::{agent::Agent, base_agent::BaseAgent, tool::Tool, workflow::Workflow};\npub use types::{ComponentId, ComponentMetadata, Version};\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-core","src","logging.rs"],"content":"//! ABOUTME: Structured logging infrastructure for rs-llmspell\n//! ABOUTME: Provides tracing setup with JSON formatting and runtime configuration\n\nuse tracing::Level;\nuse tracing_subscriber::{\n    fmt::{self, format::FmtSpan},\n    layer::SubscriberExt,\n    util::SubscriberInitExt,\n    EnvFilter, Layer,\n};\n\n/// Logging configuration for the LLMSpell system.\n///\n/// Controls various aspects of log output including format, level,\n/// and metadata inclusion. Supports both human-readable and JSON formats.\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::logging::{LoggingConfig, init_logging};\n/// use tracing::Level;\n///\n/// // Development configuration with pretty printing\n/// let dev_config = LoggingConfig::development();\n/// assert_eq!(dev_config.default_level, Level::DEBUG);\n/// assert!(!dev_config.json_format);\n///\n/// // Production configuration with JSON output\n/// let prod_config = LoggingConfig::production();\n/// assert!(prod_config.json_format);\n///\n/// // Custom configuration\n/// let custom_config = LoggingConfig {\n///     default_level: Level::WARN,\n///     json_format: true,\n///     with_timestamps: true,\n///     with_thread_names: false,\n///     with_thread_ids: false,\n///     with_file_lines: true,\n///     with_span_events: false,\n/// };\n/// ```\n#[derive(Debug, Clone)]\npub struct LoggingConfig {\n    /// Default log level\n    pub default_level: Level,\n    /// Whether to use JSON formatting\n    pub json_format: bool,\n    /// Whether to include timestamps\n    pub with_timestamps: bool,\n    /// Whether to include thread names\n    pub with_thread_names: bool,\n    /// Whether to include thread IDs\n    pub with_thread_ids: bool,\n    /// Whether to include file and line numbers\n    pub with_file_lines: bool,\n    /// Whether to include span events\n    pub with_span_events: bool,\n}\n\nimpl Default for LoggingConfig {\n    fn default() -> Self {\n        Self {\n            default_level: Level::INFO,\n            json_format: true,\n            with_timestamps: true,\n            with_thread_names: false,\n            with_thread_ids: false,\n            with_file_lines: true,\n            with_span_events: false,\n        }\n    }\n}\n\nimpl LoggingConfig {\n    /// Create a development configuration with human-readable output\n    pub fn development() -> Self {\n        Self {\n            default_level: Level::DEBUG,\n            json_format: false,\n            with_timestamps: true,\n            with_thread_names: true,\n            with_thread_ids: false,\n            with_file_lines: true,\n            with_span_events: true,\n        }\n    }\n\n    /// Create a production configuration with JSON output\n    pub fn production() -> Self {\n        Self::default()\n    }\n}\n\n/// Initialize logging with the given configuration.\n///\n/// Sets up the global tracing subscriber with the specified configuration.\n/// This function should be called once at application startup.\n///\n/// # Environment Variables\n///\n/// - `RUST_LOG`: Controls log filtering (e.g., \"debug\", \"llmspell=trace\")\n/// - `LLMSPELL_ENV`: Set to \"production\" for production config\n///\n/// # Examples\n///\n/// ```no_run\n/// use llmspell_core::logging::{LoggingConfig, init_logging};\n///\n/// // Initialize with default configuration\n/// init_logging(LoggingConfig::default()).expect(\"Failed to init logging\");\n///\n/// // Or initialize from environment\n/// use llmspell_core::logging::init_from_env;\n/// init_from_env().expect(\"Failed to init logging\");\n/// ```\npub fn init_logging(config: LoggingConfig) -> Result<(), Box<dyn std::error::Error>> {\n    // Create env filter with default level\n    let env_filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(config.default_level.to_string()));\n\n    // Configure format layer\n    let fmt_layer = if config.json_format {\n        fmt::layer()\n            .json()\n            .with_timer(fmt::time::UtcTime::rfc_3339())\n            .with_thread_names(config.with_thread_names)\n            .with_thread_ids(config.with_thread_ids)\n            .with_file(config.with_file_lines)\n            .with_line_number(config.with_file_lines)\n            .with_span_events(if config.with_span_events {\n                FmtSpan::FULL\n            } else {\n                FmtSpan::NONE\n            })\n            .boxed()\n    } else {\n        fmt::layer()\n            .pretty()\n            .with_timer(fmt::time::UtcTime::rfc_3339())\n            .with_thread_names(config.with_thread_names)\n            .with_thread_ids(config.with_thread_ids)\n            .with_file(config.with_file_lines)\n            .with_line_number(config.with_file_lines)\n            .with_span_events(if config.with_span_events {\n                FmtSpan::FULL\n            } else {\n                FmtSpan::NONE\n            })\n            .boxed()\n    };\n\n    // Build the subscriber\n    tracing_subscriber::registry()\n        .with(env_filter)\n        .with(fmt_layer)\n        .try_init()?;\n\n    Ok(())\n}\n\n/// Initialize logging from environment variables\npub fn init_from_env() -> Result<(), Box<dyn std::error::Error>> {\n    let config = if std::env::var(\"LLMSPELL_ENV\").as_deref() == Ok(\"production\") {\n        LoggingConfig::production()\n    } else {\n        LoggingConfig::development()\n    };\n\n    init_logging(config)\n}\n\n/// Update the global log filter at runtime\npub fn update_log_filter(filter: &str) -> Result<(), Box<dyn std::error::Error>> {\n    // This is a simplified version - in production you'd use reload handles\n    tracing::info!(\"Log filter update requested: {}\", filter);\n    Ok(())\n}\n\n// Re-export commonly used tracing macros\npub use tracing::{debug, error, info, instrument, span, trace, warn, Level as LogLevel};\n\n// Logging macros for components\n///\n/// These macros provide structured logging for component lifecycle events.\n/// They automatically capture component metadata and format it consistently.\n#[macro_export]\nmacro_rules! log_component_event {\n    ($component:expr, $event:expr) => {{\n        use tracing::info;\n        info!(\n            component_id = ?$component.metadata().id,\n            component_name = $component.metadata().name,\n            event = $event,\n            \"Component event\"\n        );\n    }};\n    ($component:expr, $event:expr, $($field:tt)*) => {{\n        use tracing::info;\n        info!(\n            component_id = ?$component.metadata().id,\n            component_name = $component.metadata().name,\n            event = $event,\n            $($field)*\n        );\n    }};\n}\n\n#[macro_export]\nmacro_rules! log_execution_start {\n    ($component:expr, $input:expr) => {{\n        use tracing::{info, instrument};\n        info!(\n            component_id = ?$component.metadata().id,\n            component_name = $component.metadata().name,\n            input = ?$input,\n            \"Execution started\"\n        );\n    }};\n}\n\n#[macro_export]\nmacro_rules! log_execution_end {\n    ($component:expr, $duration:expr, $success:expr) => {{\n        use tracing::info;\n        info!(\n            component_id = ?$component.metadata().id,\n            component_name = $component.metadata().name,\n            duration_ms = $duration.as_millis(),\n            success = $success,\n            \"Execution completed\"\n        );\n    }};\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_logging_config_default() {\n        let config = LoggingConfig::default();\n        assert_eq!(config.default_level, Level::INFO);\n        assert!(config.json_format);\n        assert!(config.with_timestamps);\n        assert!(!config.with_thread_names);\n    }\n\n    #[test]\n    fn test_logging_config_development() {\n        let config = LoggingConfig::development();\n        assert_eq!(config.default_level, Level::DEBUG);\n        assert!(!config.json_format);\n        assert!(config.with_timestamps);\n        assert!(config.with_thread_names);\n        assert!(config.with_span_events);\n    }\n\n    #[test]\n    fn test_logging_config_production() {\n        let config = LoggingConfig::production();\n        assert_eq!(config.default_level, Level::INFO);\n        assert!(config.json_format);\n        assert!(config.with_timestamps);\n        assert!(config.with_file_lines);\n    }\n\n    #[test]\n    fn test_logging_initialization() {\n        // We can't actually initialize logging in tests (it's global state)\n        // but we can verify the config builds correctly\n        let config = LoggingConfig::default();\n        assert!(config.json_format);\n    }\n}\n","traces":[{"line":62,"address":[],"length":0,"stats":{"Line":3}},{"line":77,"address":[],"length":0,"stats":{"Line":1}},{"line":90,"address":[],"length":0,"stats":{"Line":1}},{"line":91,"address":[],"length":0,"stats":{"Line":1}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}}],"covered":4,"coverable":38},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-core","src","traits","agent.rs"],"content":"//! ABOUTME: Agent trait for LLM-powered components\n//! ABOUTME: Extends BaseAgent with conversation management and LLM provider integration\n\nuse super::base_agent::BaseAgent;\nuse crate::Result;\nuse async_trait::async_trait;\nuse serde::{Deserialize, Serialize};\n\n/// Role in a conversation.\n///\n/// Defines the role of a message in a conversation history.\n/// Used for maintaining context in LLM interactions.\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::traits::agent::MessageRole;\n///\n/// assert_eq!(MessageRole::System.to_string(), \"system\");\n/// assert_eq!(MessageRole::User.to_string(), \"user\");\n/// assert_eq!(MessageRole::Assistant.to_string(), \"assistant\");\n/// ```\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]\npub enum MessageRole {\n    System,\n    User,\n    Assistant,\n}\n\nimpl std::fmt::Display for MessageRole {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            MessageRole::System => write!(f, \"system\"),\n            MessageRole::User => write!(f, \"user\"),\n            MessageRole::Assistant => write!(f, \"assistant\"),\n        }\n    }\n}\n\n/// Conversation message in an agent's history.\n///\n/// Represents a single message in a conversation, including the role,\n/// content, and timestamp. Used to maintain conversation context for agents.\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::traits::agent::{ConversationMessage, MessageRole};\n///\n/// // Create messages using convenience methods\n/// let system_msg = ConversationMessage::system(\"You are a helpful assistant\".to_string());\n/// let user_msg = ConversationMessage::user(\"Hello!\".to_string());\n/// let assistant_msg = ConversationMessage::assistant(\"Hi! How can I help?\".to_string());\n///\n/// assert_eq!(system_msg.role, MessageRole::System);\n/// assert_eq!(user_msg.role, MessageRole::User);\n/// assert_eq!(assistant_msg.role, MessageRole::Assistant);\n/// ```\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ConversationMessage {\n    pub role: MessageRole,\n    pub content: String,\n    pub timestamp: chrono::DateTime<chrono::Utc>,\n}\n\nimpl ConversationMessage {\n    /// Create a new conversation message\n    pub fn new(role: MessageRole, content: String) -> Self {\n        Self {\n            role,\n            content,\n            timestamp: chrono::Utc::now(),\n        }\n    }\n\n    /// Create a system message\n    pub fn system(content: String) -> Self {\n        Self::new(MessageRole::System, content)\n    }\n\n    /// Create a user message\n    pub fn user(content: String) -> Self {\n        Self::new(MessageRole::User, content)\n    }\n\n    /// Create an assistant message\n    pub fn assistant(content: String) -> Self {\n        Self::new(MessageRole::Assistant, content)\n    }\n}\n\n/// Configuration for LLM-powered agents.\n///\n/// Controls agent behavior including conversation management, generation parameters,\n/// and system prompts. All fields are optional to allow partial configuration.\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::traits::agent::AgentConfig;\n///\n/// let config = AgentConfig {\n///     max_conversation_length: Some(50),\n///     system_prompt: Some(\"You are a research assistant\".to_string()),\n///     temperature: Some(0.7),\n///     max_tokens: Some(1000),\n/// };\n///\n/// // Or use default configuration\n/// let default_config = AgentConfig::default();\n/// assert_eq!(default_config.max_conversation_length, Some(100));\n/// assert_eq!(default_config.temperature, Some(0.7));\n/// ```\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AgentConfig {\n    /// Maximum number of messages to retain in conversation history\n    pub max_conversation_length: Option<usize>,\n    /// System prompt for the agent\n    pub system_prompt: Option<String>,\n    /// Temperature setting for LLM generation\n    pub temperature: Option<f32>,\n    /// Maximum tokens to generate\n    pub max_tokens: Option<usize>,\n}\n\nimpl Default for AgentConfig {\n    fn default() -> Self {\n        Self {\n            max_conversation_length: Some(100),\n            system_prompt: None,\n            temperature: Some(0.7),\n            max_tokens: Some(2000),\n        }\n    }\n}\n\n/// Agent trait for LLM-powered components.\n///\n/// Extends `BaseAgent` with conversation management and LLM-specific functionality.\n/// Agents maintain conversation history, handle message trimming, and provide\n/// configuration for LLM generation parameters.\n///\n/// # Implementation Requirements\n///\n/// - Must maintain conversation history thread-safely\n/// - Should implement conversation trimming to respect max length\n/// - Configuration should be accessible but may be immutable\n/// - All conversation operations should be atomic\n///\n/// # Examples\n///\n/// ```ignore\n/// use llmspell_core::{\n///     ComponentMetadata, Result,\n///     traits::{\n///         base_agent::{BaseAgent, AgentInput, AgentOutput, ExecutionContext},\n///         agent::{Agent, AgentConfig, ConversationMessage, MessageRole}\n///     }\n/// };\n/// use async_trait::async_trait;\n///\n/// struct MyLLMAgent {\n///     metadata: ComponentMetadata,\n///     config: AgentConfig,\n///     conversation: Vec<ConversationMessage>,\n/// }\n///\n/// #[async_trait]\n/// impl Agent for MyLLMAgent {\n///     fn config(&self) -> &AgentConfig {\n///         &self.config\n///     }\n///     \n///     async fn get_conversation(&self) -> Result<Vec<ConversationMessage>> {\n///         Ok(self.conversation.clone())\n///     }\n///     \n///     async fn add_message(&mut self, message: ConversationMessage) -> Result<()> {\n///         self.conversation.push(message);\n///         // Trim if needed\n///         self.trim_conversation().await?;\n///         Ok(())\n///     }\n///     \n///     async fn clear_conversation(&mut self) -> Result<()> {\n///         self.conversation.clear();\n///         Ok(())\n///     }\n/// }\n///\n/// # impl BaseAgent for MyLLMAgent {\n/// #     fn metadata(&self) -> &ComponentMetadata { &self.metadata }\n/// #     async fn execute(&self, input: AgentInput, context: ExecutionContext) -> Result<AgentOutput> {\n/// #         Ok(AgentOutput::text(\"Response\".to_string()))\n/// #     }\n/// #     async fn validate_input(&self, input: &AgentInput) -> Result<()> { Ok(()) }\n/// #     async fn handle_error(&self, error: llmspell_core::LLMSpellError) -> Result<AgentOutput> {\n/// #         Ok(AgentOutput::text(\"Error\".to_string()))\n/// #     }\n/// # }\n/// ```\n#[async_trait]\npub trait Agent: BaseAgent {\n    /// Get agent configuration\n    fn config(&self) -> &AgentConfig;\n\n    /// Get conversation history\n    async fn get_conversation(&self) -> Result<Vec<ConversationMessage>>;\n\n    /// Add message to conversation\n    async fn add_message(&mut self, message: ConversationMessage) -> Result<()>;\n\n    /// Clear conversation history\n    async fn clear_conversation(&mut self) -> Result<()>;\n\n    /// Get the current conversation length\n    async fn conversation_length(&self) -> Result<usize> {\n        Ok(self.get_conversation().await?.len())\n    }\n\n    /// Trim conversation to configured max length\n    async fn trim_conversation(&mut self) -> Result<()> {\n        if let Some(max_len) = self.config().max_conversation_length {\n            let current_len = self.conversation_length().await?;\n            if current_len > max_len {\n                // Keep system messages and trim oldest user/assistant messages\n                let conversation = self.get_conversation().await?;\n                let system_messages: Vec<_> = conversation\n                    .iter()\n                    .filter(|msg| matches!(msg.role, MessageRole::System))\n                    .cloned()\n                    .collect();\n\n                let other_messages: Vec<_> = conversation\n                    .into_iter()\n                    .filter(|msg| !matches!(msg.role, MessageRole::System))\n                    .collect();\n\n                let skip_count = other_messages\n                    .len()\n                    .saturating_sub(max_len - system_messages.len());\n\n                self.clear_conversation().await?;\n\n                // Re-add system messages\n                for msg in system_messages {\n                    self.add_message(msg).await?;\n                }\n\n                // Add trimmed other messages\n                for msg in other_messages.into_iter().skip(skip_count) {\n                    self.add_message(msg).await?;\n                }\n            }\n        }\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::types::{AgentInput, AgentOutput, ExecutionContext};\n    use crate::ComponentMetadata;\n    use std::collections::VecDeque;\n\n    #[test]\n    fn test_message_role_display() {\n        assert_eq!(MessageRole::System.to_string(), \"system\");\n        assert_eq!(MessageRole::User.to_string(), \"user\");\n        assert_eq!(MessageRole::Assistant.to_string(), \"assistant\");\n    }\n\n    #[test]\n    fn test_conversation_message_creation() {\n        let content = \"Test message\".to_string();\n        let msg = ConversationMessage::new(MessageRole::User, content.clone());\n\n        assert_eq!(msg.role, MessageRole::User);\n        assert_eq!(msg.content, content);\n\n        // Test helper methods\n        let system_msg = ConversationMessage::system(\"System prompt\".to_string());\n        assert_eq!(system_msg.role, MessageRole::System);\n\n        let user_msg = ConversationMessage::user(\"User input\".to_string());\n        assert_eq!(user_msg.role, MessageRole::User);\n\n        let assistant_msg = ConversationMessage::assistant(\"Assistant response\".to_string());\n        assert_eq!(assistant_msg.role, MessageRole::Assistant);\n    }\n\n    #[test]\n    fn test_conversation_message_serialization() {\n        let msg = ConversationMessage::user(\"Test\".to_string());\n\n        let json = serde_json::to_string(&msg).unwrap();\n        let deserialized: ConversationMessage = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(msg.role, deserialized.role);\n        assert_eq!(msg.content, deserialized.content);\n    }\n\n    #[test]\n    fn test_agent_config_default() {\n        let config = AgentConfig::default();\n\n        assert_eq!(config.max_conversation_length, Some(100));\n        assert_eq!(config.system_prompt, None);\n        assert_eq!(config.temperature, Some(0.7));\n        assert_eq!(config.max_tokens, Some(2000));\n    }\n\n    #[test]\n    fn test_agent_config_serialization() {\n        let mut config = AgentConfig::default();\n        config.system_prompt = Some(\"You are a helpful assistant\".to_string());\n        config.temperature = Some(0.9);\n\n        let json = serde_json::to_string(&config).unwrap();\n        let deserialized: AgentConfig = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(config.system_prompt, deserialized.system_prompt);\n        assert_eq!(config.temperature, deserialized.temperature);\n    }\n\n    // Mock implementation for testing\n    struct MockLLMAgent {\n        metadata: ComponentMetadata,\n        config: AgentConfig,\n        conversation: VecDeque<ConversationMessage>,\n    }\n\n    impl MockLLMAgent {\n        fn new() -> Self {\n            let mut config = AgentConfig::default();\n            config.system_prompt = Some(\"You are a test assistant\".to_string());\n\n            Self {\n                metadata: ComponentMetadata::new(\n                    \"mock-llm-agent\".to_string(),\n                    \"A mock LLM agent for testing\".to_string(),\n                ),\n                config,\n                conversation: VecDeque::new(),\n            }\n        }\n    }\n\n    #[async_trait]\n    impl BaseAgent for MockLLMAgent {\n        fn metadata(&self) -> &ComponentMetadata {\n            &self.metadata\n        }\n\n        async fn execute(\n            &self,\n            input: AgentInput,\n            _context: ExecutionContext,\n        ) -> Result<AgentOutput> {\n            // Simple echo response\n            Ok(AgentOutput::text(format!(\"Response to: {}\", input.text)))\n        }\n\n        async fn validate_input(&self, input: &AgentInput) -> Result<()> {\n            if input.text.is_empty() {\n                return Err(crate::LLMSpellError::Validation {\n                    message: \"Prompt cannot be empty\".to_string(),\n                    field: Some(\"prompt\".to_string()),\n                });\n            }\n            Ok(())\n        }\n\n        async fn handle_error(&self, error: crate::LLMSpellError) -> Result<AgentOutput> {\n            Ok(AgentOutput::text(format!(\"Error: {}\", error)))\n        }\n    }\n\n    #[async_trait]\n    impl Agent for MockLLMAgent {\n        fn config(&self) -> &AgentConfig {\n            &self.config\n        }\n\n        async fn get_conversation(&self) -> Result<Vec<ConversationMessage>> {\n            Ok(self.conversation.iter().cloned().collect())\n        }\n\n        async fn add_message(&mut self, message: ConversationMessage) -> Result<()> {\n            self.conversation.push_back(message);\n            Ok(())\n        }\n\n        async fn clear_conversation(&mut self) -> Result<()> {\n            self.conversation.clear();\n            Ok(())\n        }\n    }\n\n    #[tokio::test]\n    async fn test_agent_conversation_management() {\n        let mut agent = MockLLMAgent::new();\n\n        // Test empty conversation\n        assert_eq!(agent.conversation_length().await.unwrap(), 0);\n\n        // Add messages\n        agent\n            .add_message(ConversationMessage::system(\"System prompt\".to_string()))\n            .await\n            .unwrap();\n        agent\n            .add_message(ConversationMessage::user(\"Hello\".to_string()))\n            .await\n            .unwrap();\n        agent\n            .add_message(ConversationMessage::assistant(\"Hi there!\".to_string()))\n            .await\n            .unwrap();\n\n        assert_eq!(agent.conversation_length().await.unwrap(), 3);\n\n        // Get conversation\n        let conversation = agent.get_conversation().await.unwrap();\n        assert_eq!(conversation.len(), 3);\n        assert_eq!(conversation[0].role, MessageRole::System);\n        assert_eq!(conversation[1].role, MessageRole::User);\n        assert_eq!(conversation[2].role, MessageRole::Assistant);\n\n        // Clear conversation\n        agent.clear_conversation().await.unwrap();\n        assert_eq!(agent.conversation_length().await.unwrap(), 0);\n    }\n\n    #[tokio::test]\n    async fn test_agent_conversation_trimming() {\n        let mut agent = MockLLMAgent::new();\n        agent.config.max_conversation_length = Some(5);\n\n        // Add system message\n        agent\n            .add_message(ConversationMessage::system(\"System prompt\".to_string()))\n            .await\n            .unwrap();\n\n        // Add more messages than max length\n        for i in 0..6 {\n            agent\n                .add_message(ConversationMessage::user(format!(\"Message {}\", i)))\n                .await\n                .unwrap();\n            agent\n                .add_message(ConversationMessage::assistant(format!(\"Response {}\", i)))\n                .await\n                .unwrap();\n        }\n\n        // Should have 13 messages (1 system + 12 others)\n        assert_eq!(agent.conversation_length().await.unwrap(), 13);\n\n        // Trim conversation\n        agent.trim_conversation().await.unwrap();\n\n        // Should keep system message and latest 4 messages\n        assert_eq!(agent.conversation_length().await.unwrap(), 5);\n\n        let conversation = agent.get_conversation().await.unwrap();\n        assert_eq!(conversation[0].role, MessageRole::System);\n        assert!(conversation[1].content.contains(\"Message 4\")); // Should keep latest messages\n    }\n\n    #[tokio::test]\n    async fn test_agent_config_usage() {\n        let agent = MockLLMAgent::new();\n\n        // Test config access\n        let config = agent.config();\n        assert_eq!(\n            config.system_prompt,\n            Some(\"You are a test assistant\".to_string())\n        );\n        assert_eq!(config.temperature, Some(0.7));\n        assert_eq!(config.max_tokens, Some(2000));\n    }\n}\n","traces":[{"line":31,"address":[],"length":0,"stats":{"Line":12}},{"line":32,"address":[],"length":0,"stats":{"Line":12}},{"line":33,"address":[],"length":0,"stats":{"Line":4}},{"line":34,"address":[],"length":0,"stats":{"Line":4}},{"line":35,"address":[],"length":0,"stats":{"Line":4}},{"line":68,"address":[],"length":0,"stats":{"Line":519}},{"line":72,"address":[],"length":0,"stats":{"Line":519}},{"line":77,"address":[],"length":0,"stats":{"Line":8}},{"line":78,"address":[],"length":0,"stats":{"Line":8}},{"line":82,"address":[],"length":0,"stats":{"Line":137}},{"line":83,"address":[],"length":0,"stats":{"Line":137}},{"line":87,"address":[],"length":0,"stats":{"Line":114}},{"line":88,"address":[],"length":0,"stats":{"Line":114}},{"line":127,"address":[],"length":0,"stats":{"Line":13}},{"line":129,"address":[],"length":0,"stats":{"Line":13}},{"line":131,"address":[],"length":0,"stats":{"Line":13}},{"line":132,"address":[],"length":0,"stats":{"Line":13}},{"line":217,"address":[],"length":0,"stats":{"Line":6}},{"line":218,"address":[],"length":0,"stats":{"Line":12}},{"line":222,"address":[],"length":0,"stats":{"Line":1}},{"line":223,"address":[],"length":0,"stats":{"Line":2}},{"line":224,"address":[],"length":0,"stats":{"Line":1}},{"line":225,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":2}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":13}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":25}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":241,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":3}},{"line":247,"address":[],"length":0,"stats":{"Line":1}},{"line":251,"address":[],"length":0,"stats":{"Line":5}},{"line":252,"address":[],"length":0,"stats":{"Line":4}},{"line":256,"address":[],"length":0,"stats":{"Line":1}}],"covered":30,"coverable":36},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-core","src","traits","base_agent.rs"],"content":"//! ABOUTME: BaseAgent trait - foundation for all components\n//! ABOUTME: Provides core functionality for agents, tools, and workflows\n\nuse crate::types::{AgentInput, AgentOutput, AgentStream, ExecutionContext, MediaType};\nuse crate::{ComponentMetadata, Result};\nuse async_trait::async_trait;\n\n/// Base trait for all components in the LLMSpell system.\n///\n/// This is the foundational trait that all agents, tools, and workflows must implement.\n/// It provides the core interface for component execution, validation, and error handling.\n///\n/// # Implementation Requirements\n///\n/// - Components must be `Send + Sync` for async execution\n/// - All methods should handle errors gracefully\n/// - Input validation should be thorough but not overly restrictive\n/// - Error handling should provide meaningful recovery options\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::{\n///     ComponentMetadata, Result, LLMSpellError,\n///     types::{AgentInput, AgentOutput, ExecutionContext},\n///     traits::base_agent::BaseAgent\n/// };\n/// use async_trait::async_trait;\n///\n/// struct MyAgent {\n///     metadata: ComponentMetadata,\n/// }\n///\n/// #[async_trait]\n/// impl BaseAgent for MyAgent {\n///     fn metadata(&self) -> &ComponentMetadata {\n///         &self.metadata\n///     }\n///     \n///     async fn execute(\n///         &self,\n///         input: AgentInput,\n///         context: ExecutionContext,\n///     ) -> Result<AgentOutput> {\n///         // Validate input first\n///         self.validate_input(&input).await?;\n///         \n///         // Process the input\n///         let result = format!(\"Processed: {}\", input.text);\n///         \n///         Ok(AgentOutput::text(result))\n///     }\n///     \n///     async fn validate_input(&self, input: &AgentInput) -> Result<()> {\n///         if input.text.is_empty() {\n///             return Err(LLMSpellError::Validation {\n///                 message: \"Text cannot be empty\".to_string(),\n///                 field: Some(\"text\".to_string()),\n///             });\n///         }\n///         Ok(())\n///     }\n///     \n///     async fn handle_error(&self, error: LLMSpellError) -> Result<AgentOutput> {\n///         Ok(AgentOutput::text(format!(\"Error handled: {}\", error)))\n///     }\n/// }\n/// ```\n#[async_trait]\npub trait BaseAgent: Send + Sync {\n    /// Get component metadata.\n    ///\n    /// Returns a reference to the component's metadata including its ID,\n    /// name, version, and description. This metadata is immutable and\n    /// identifies the component throughout its lifecycle.\n    fn metadata(&self) -> &ComponentMetadata;\n\n    /// Execute the component with given input.\n    ///\n    /// This is the main execution method for all components. It processes\n    /// the input according to the component's logic and returns the result.\n    ///\n    /// # Arguments\n    ///\n    /// * `input` - The input containing prompt and optional context data\n    /// * `context` - Execution context with session info and environment\n    ///\n    /// # Returns\n    ///\n    /// Returns `Ok(AgentOutput)` on success, or an error if execution fails.\n    /// The output contains the result content and optional metadata.\n    async fn execute(&self, input: AgentInput, context: ExecutionContext) -> Result<AgentOutput>;\n\n    /// Validate input before execution.\n    ///\n    /// Called before `execute()` to validate the input parameters.\n    /// Implementations should check for required fields, validate formats,\n    /// and ensure the input meets the component's requirements.\n    ///\n    /// # Arguments\n    ///\n    /// * `input` - The input to validate\n    ///\n    /// # Returns\n    ///\n    /// Returns `Ok(())` if validation passes, or a `Validation` error\n    /// with details about what failed.\n    async fn validate_input(&self, input: &AgentInput) -> Result<()>;\n\n    /// Handle execution errors.\n    ///\n    /// Provides a way for components to handle errors gracefully and\n    /// potentially recover or provide fallback responses. This method\n    /// is called when an error occurs during execution.\n    ///\n    /// # Arguments\n    ///\n    /// * `error` - The error that occurred\n    ///\n    /// # Returns\n    ///\n    /// Returns an `AgentOutput` with error information or a fallback response,\n    /// or propagates the error if it cannot be handled.\n    async fn handle_error(&self, error: crate::LLMSpellError) -> Result<AgentOutput>;\n\n    /// Execute the component with streaming output.\n    ///\n    /// This method provides streaming execution capabilities, allowing components\n    /// to emit partial results as they become available. This is especially useful\n    /// for LLM interactions where text can be generated incrementally.\n    ///\n    /// # Arguments\n    ///\n    /// * `input` - The input containing prompt and optional context data\n    /// * `context` - Execution context with session info and environment\n    ///\n    /// # Returns\n    ///\n    /// Returns a stream of `AgentChunk` items containing partial results,\n    /// or an error if streaming is not supported by this component.\n    ///\n    /// # Default Implementation\n    ///\n    /// The default implementation returns a NotImplemented error, indicating\n    /// that the component does not support streaming execution.\n    async fn stream_execute(\n        &self,\n        _input: AgentInput,\n        _context: ExecutionContext,\n    ) -> Result<AgentStream> {\n        Err(crate::LLMSpellError::Component {\n            message: \"Streaming execution not supported by this component\".to_string(),\n            source: None,\n        })\n    }\n\n    /// Check if this component supports streaming execution.\n    ///\n    /// Returns `true` if the component implements streaming via `stream_execute()`,\n    /// `false` otherwise. Components that support streaming should override this\n    /// method to return `true`.\n    ///\n    /// # Default Implementation\n    ///\n    /// Returns `false` by default, indicating no streaming support.\n    fn supports_streaming(&self) -> bool {\n        false\n    }\n\n    /// Check if this component supports multimodal content.\n    ///\n    /// Returns `true` if the component can process and generate content\n    /// beyond plain text (images, audio, video, binary), `false` otherwise.\n    ///\n    /// # Default Implementation\n    ///\n    /// Returns `false` by default, indicating text-only support.\n    fn supports_multimodal(&self) -> bool {\n        false\n    }\n\n    /// Get the media types supported by this component.\n    ///\n    /// Returns a vector of `MediaType` values indicating which types of\n    /// content this component can process in its input and/or generate\n    /// in its output.\n    ///\n    /// # Default Implementation\n    ///\n    /// Returns only `MediaType::Text` by default.\n    fn supported_media_types(&self) -> Vec<MediaType> {\n        vec![MediaType::Text]\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::types::{AgentInput, AgentOutput, ExecutionContext};\n\n    // Mock implementation for testing\n    struct MockAgent {\n        metadata: ComponentMetadata,\n    }\n\n    impl MockAgent {\n        fn new() -> Self {\n            Self {\n                metadata: ComponentMetadata::new(\n                    \"mock-agent\".to_string(),\n                    \"A mock agent for testing\".to_string(),\n                ),\n            }\n        }\n    }\n\n    #[async_trait]\n    impl BaseAgent for MockAgent {\n        fn metadata(&self) -> &ComponentMetadata {\n            &self.metadata\n        }\n\n        async fn execute(\n            &self,\n            input: AgentInput,\n            _context: ExecutionContext,\n        ) -> Result<AgentOutput> {\n            Ok(AgentOutput::text(format!(\"Processed: {}\", input.text)))\n        }\n\n        async fn validate_input(&self, input: &AgentInput) -> Result<()> {\n            if input.text.is_empty() {\n                return Err(crate::LLMSpellError::Validation {\n                    message: \"Text cannot be empty\".to_string(),\n                    field: Some(\"text\".to_string()),\n                });\n            }\n            Ok(())\n        }\n\n        async fn handle_error(&self, error: crate::LLMSpellError) -> Result<AgentOutput> {\n            Ok(AgentOutput::text(format!(\"Error handled: {}\", error)))\n        }\n    }\n\n    #[tokio::test]\n    async fn test_base_agent_implementation() {\n        let agent = MockAgent::new();\n\n        // Test metadata access\n        let metadata = agent.metadata();\n        assert_eq!(metadata.name, \"mock-agent\");\n        assert_eq!(metadata.description, \"A mock agent for testing\");\n\n        // Test successful execution\n        let input = AgentInput::text(\"test prompt\");\n        let context = ExecutionContext::new();\n        let result = agent.execute(input, context).await.unwrap();\n        assert_eq!(result.text, \"Processed: test prompt\");\n    }\n\n    #[tokio::test]\n    async fn test_base_agent_validation() {\n        let agent = MockAgent::new();\n\n        // Test valid input\n        let valid_input = AgentInput::text(\"valid prompt\");\n        assert!(agent.validate_input(&valid_input).await.is_ok());\n\n        // Test invalid input\n        let invalid_input = AgentInput::text(\"\");\n        let validation_result = agent.validate_input(&invalid_input).await;\n        assert!(validation_result.is_err());\n\n        if let Err(crate::LLMSpellError::Validation { message, .. }) = validation_result {\n            assert_eq!(message, \"Text cannot be empty\");\n        } else {\n            panic!(\"Expected validation error\");\n        }\n    }\n\n    #[tokio::test]\n    async fn test_base_agent_error_handling() {\n        let agent = MockAgent::new();\n\n        let error = crate::LLMSpellError::Component {\n            message: \"Test error\".to_string(),\n            source: None,\n        };\n\n        let result = agent.handle_error(error).await.unwrap();\n        assert!(result.text.contains(\"Error handled\"));\n        assert!(result.text.contains(\"Test error\"));\n    }\n\n    #[tokio::test]\n    async fn test_base_agent_streaming_default() {\n        let agent = MockAgent::new();\n\n        // Test that streaming is not supported by default\n        assert!(!agent.supports_streaming());\n\n        // Test that multimodal is not supported by default\n        assert!(!agent.supports_multimodal());\n\n        // Test that only text is supported by default\n        let supported_types = agent.supported_media_types();\n        assert_eq!(supported_types.len(), 1);\n        assert_eq!(supported_types[0], MediaType::Text);\n\n        // Test that stream_execute returns NotImplemented error\n        let input = AgentInput::text(\"test stream\");\n        let context = ExecutionContext::new();\n        let stream_result = agent.stream_execute(input, context).await;\n        assert!(stream_result.is_err());\n\n        if let Err(crate::LLMSpellError::Component { message, .. }) = stream_result {\n            assert!(message.contains(\"Streaming execution not supported\"));\n        } else {\n            panic!(\"Expected Component error\");\n        }\n    }\n}\n","traces":[{"line":151,"address":[],"length":0,"stats":{"Line":1}},{"line":152,"address":[],"length":0,"stats":{"Line":1}},{"line":153,"address":[],"length":0,"stats":{"Line":1}},{"line":166,"address":[],"length":0,"stats":{"Line":1}},{"line":167,"address":[],"length":0,"stats":{"Line":1}},{"line":178,"address":[],"length":0,"stats":{"Line":1}},{"line":179,"address":[],"length":0,"stats":{"Line":1}},{"line":191,"address":[],"length":0,"stats":{"Line":1}},{"line":192,"address":[],"length":0,"stats":{"Line":1}}],"covered":9,"coverable":9},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-core","src","traits","tool.rs"],"content":"//! ABOUTME: Tool trait for functional components with schema validation\n//! ABOUTME: Extends BaseAgent with parameter validation and tool categorization\n\nuse super::base_agent::BaseAgent;\nuse crate::{\n    types::{AgentInput, AgentStream},\n    Result,\n};\nuse async_trait::async_trait;\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n/// Tool category for organization and discovery.\n///\n/// Categorizes tools by their primary function to help with tool selection\n/// and organization. Custom categories can be created for specialized tools.\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::traits::tool::ToolCategory;\n///\n/// let category = ToolCategory::Filesystem;\n/// assert_eq!(category.to_string(), \"filesystem\");\n///\n/// // Custom category\n/// let custom = ToolCategory::Custom(\"ai-tools\".to_string());\n/// assert_eq!(custom.to_string(), \"ai-tools\");\n/// ```\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]\npub enum ToolCategory {\n    Filesystem,\n    Web,\n    Analysis,\n    Data,\n    System,\n    Utility,\n    Custom(String),\n}\n\nimpl std::fmt::Display for ToolCategory {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            ToolCategory::Filesystem => write!(f, \"filesystem\"),\n            ToolCategory::Web => write!(f, \"web\"),\n            ToolCategory::Analysis => write!(f, \"analysis\"),\n            ToolCategory::Data => write!(f, \"data\"),\n            ToolCategory::System => write!(f, \"system\"),\n            ToolCategory::Utility => write!(f, \"utility\"),\n            ToolCategory::Custom(name) => write!(f, \"{}\", name),\n        }\n    }\n}\n\n/// Security level for tools.\n///\n/// Defines the security requirements and permissions needed to execute a tool.\n/// Higher levels include permissions of lower levels (Privileged > Restricted > Safe).\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::traits::tool::SecurityLevel;\n///\n/// let user_level = SecurityLevel::Restricted;\n/// let tool_level = SecurityLevel::Safe;\n///\n/// // User with Restricted can run Safe tools\n/// assert!(user_level.allows(&tool_level));\n///\n/// // But Safe user cannot run Restricted tools\n/// assert!(!SecurityLevel::Safe.allows(&SecurityLevel::Restricted));\n/// ```\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, PartialOrd, Ord, Hash)]\npub enum SecurityLevel {\n    Safe,\n    Restricted,\n    Privileged,\n}\n\nimpl SecurityLevel {\n    /// Check if this security level allows execution at the given level\n    pub fn allows(&self, required: &SecurityLevel) -> bool {\n        self >= required\n    }\n}\n\n/// Security requirements for tool execution\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]\npub struct SecurityRequirements {\n    /// Required security level\n    pub level: SecurityLevel,\n    /// File system permissions (paths that can be accessed)\n    pub file_permissions: Vec<String>,\n    /// Network permissions (domains that can be accessed)\n    pub network_permissions: Vec<String>,\n    /// Environment variables that can be accessed\n    pub env_permissions: Vec<String>,\n    /// Custom security requirements\n    pub custom_requirements: HashMap<String, serde_json::Value>,\n}\n\nimpl Default for SecurityRequirements {\n    fn default() -> Self {\n        Self {\n            level: SecurityLevel::Safe,\n            file_permissions: Vec::new(),\n            network_permissions: Vec::new(),\n            env_permissions: Vec::new(),\n            custom_requirements: HashMap::new(),\n        }\n    }\n}\n\nimpl SecurityRequirements {\n    /// Create safe security requirements (no file/network access)\n    pub fn safe() -> Self {\n        Self::default()\n    }\n\n    /// Create restricted security requirements with limited access\n    pub fn restricted() -> Self {\n        Self {\n            level: SecurityLevel::Restricted,\n            ..Default::default()\n        }\n    }\n\n    /// Create privileged security requirements with full access\n    pub fn privileged() -> Self {\n        Self {\n            level: SecurityLevel::Privileged,\n            file_permissions: vec![\"*\".to_string()],\n            network_permissions: vec![\"*\".to_string()],\n            env_permissions: vec![\"*\".to_string()],\n            custom_requirements: HashMap::new(),\n        }\n    }\n\n    /// Add file permission\n    pub fn with_file_access(mut self, path: impl Into<String>) -> Self {\n        self.file_permissions.push(path.into());\n        self\n    }\n\n    /// Add network permission\n    pub fn with_network_access(mut self, domain: impl Into<String>) -> Self {\n        self.network_permissions.push(domain.into());\n        self\n    }\n\n    /// Add environment variable permission\n    pub fn with_env_access(mut self, var: impl Into<String>) -> Self {\n        self.env_permissions.push(var.into());\n        self\n    }\n}\n\n/// Resource limits for tool execution\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]\npub struct ResourceLimits {\n    /// Maximum memory usage in bytes\n    pub max_memory_bytes: Option<u64>,\n    /// Maximum CPU time in milliseconds\n    pub max_cpu_time_ms: Option<u64>,\n    /// Maximum network bandwidth in bytes per second\n    pub max_network_bps: Option<u64>,\n    /// Maximum file operations per second\n    pub max_file_ops_per_sec: Option<u32>,\n    /// Custom resource limits\n    pub custom_limits: HashMap<String, u64>,\n}\n\nimpl Default for ResourceLimits {\n    fn default() -> Self {\n        Self {\n            max_memory_bytes: Some(100 * 1024 * 1024), // 100MB default\n            max_cpu_time_ms: Some(30_000),             // 30 seconds default\n            max_network_bps: Some(10 * 1024 * 1024),   // 10MB/s default\n            max_file_ops_per_sec: Some(100),           // 100 ops/sec default\n            custom_limits: HashMap::new(),\n        }\n    }\n}\n\nimpl ResourceLimits {\n    /// Create unlimited resource limits (for privileged tools)\n    pub fn unlimited() -> Self {\n        Self {\n            max_memory_bytes: None,\n            max_cpu_time_ms: None,\n            max_network_bps: None,\n            max_file_ops_per_sec: None,\n            custom_limits: HashMap::new(),\n        }\n    }\n\n    /// Create strict resource limits (for safe tools)\n    pub fn strict() -> Self {\n        Self {\n            max_memory_bytes: Some(10 * 1024 * 1024), // 10MB\n            max_cpu_time_ms: Some(5_000),             // 5 seconds\n            max_network_bps: Some(1024 * 1024),       // 1MB/s\n            max_file_ops_per_sec: Some(10),           // 10 ops/sec\n            custom_limits: HashMap::new(),\n        }\n    }\n\n    /// Set memory limit\n    pub fn with_memory_limit(mut self, bytes: u64) -> Self {\n        self.max_memory_bytes = Some(bytes);\n        self\n    }\n\n    /// Set CPU time limit\n    pub fn with_cpu_limit(mut self, milliseconds: u64) -> Self {\n        self.max_cpu_time_ms = Some(milliseconds);\n        self\n    }\n\n    /// Set network bandwidth limit\n    pub fn with_network_limit(mut self, bytes_per_second: u64) -> Self {\n        self.max_network_bps = Some(bytes_per_second);\n        self\n    }\n}\n\n/// Parameter type information\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]\npub enum ParameterType {\n    String,\n    Number,\n    Boolean,\n    Array,\n    Object,\n    Null,\n}\n\n/// Tool parameter definition\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ParameterDef {\n    pub name: String,\n    pub param_type: ParameterType,\n    pub description: String,\n    pub required: bool,\n    pub default: Option<serde_json::Value>,\n}\n\n/// Tool schema for parameter validation.\n///\n/// Defines the structure and validation rules for tool parameters.\n/// Can be converted to JSON Schema format for integration with LLMs.\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::traits::tool::{ToolSchema, ParameterDef, ParameterType};\n/// use serde_json::json;\n///\n/// let schema = ToolSchema::new(\n///     \"search_files\".to_string(),\n///     \"Search for files by pattern\".to_string()\n/// )\n/// .with_parameter(ParameterDef {\n///     name: \"pattern\".to_string(),\n///     param_type: ParameterType::String,\n///     description: \"File pattern to search\".to_string(),\n///     required: true,\n///     default: None,\n/// })\n/// .with_parameter(ParameterDef {\n///     name: \"recursive\".to_string(),\n///     param_type: ParameterType::Boolean,\n///     description: \"Search recursively\".to_string(),\n///     required: false,\n///     default: Some(json!(true)),\n/// })\n/// .with_returns(ParameterType::Array);\n///\n/// // Get required parameters\n/// assert_eq!(schema.required_parameters(), vec![\"pattern\"]);\n///\n/// // Convert to JSON Schema\n/// let json_schema = schema.to_json_schema();\n/// assert_eq!(json_schema[\"type\"], \"object\");\n/// ```\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ToolSchema {\n    pub name: String,\n    pub description: String,\n    pub parameters: Vec<ParameterDef>,\n    pub returns: Option<ParameterType>,\n}\n\nimpl ToolSchema {\n    /// Create a new tool schema\n    pub fn new(name: String, description: String) -> Self {\n        Self {\n            name,\n            description,\n            parameters: Vec::new(),\n            returns: None,\n        }\n    }\n\n    /// Add a parameter to the schema\n    pub fn with_parameter(mut self, param: ParameterDef) -> Self {\n        self.parameters.push(param);\n        self\n    }\n\n    /// Set the return type\n    pub fn with_returns(mut self, returns: ParameterType) -> Self {\n        self.returns = Some(returns);\n        self\n    }\n\n    /// Get required parameter names\n    pub fn required_parameters(&self) -> Vec<String> {\n        self.parameters\n            .iter()\n            .filter(|p| p.required)\n            .map(|p| p.name.clone())\n            .collect()\n    }\n\n    /// Convert to JSON schema format\n    pub fn to_json_schema(&self) -> serde_json::Value {\n        let mut properties = serde_json::Map::new();\n\n        for param in &self.parameters {\n            let mut param_schema = serde_json::Map::new();\n            param_schema.insert(\n                \"type\".to_string(),\n                serde_json::Value::String(\n                    match param.param_type {\n                        ParameterType::String => \"string\",\n                        ParameterType::Number => \"number\",\n                        ParameterType::Boolean => \"boolean\",\n                        ParameterType::Array => \"array\",\n                        ParameterType::Object => \"object\",\n                        ParameterType::Null => \"null\",\n                    }\n                    .to_string(),\n                ),\n            );\n            param_schema.insert(\n                \"description\".to_string(),\n                serde_json::Value::String(param.description.clone()),\n            );\n\n            if let Some(default) = &param.default {\n                param_schema.insert(\"default\".to_string(), default.clone());\n            }\n\n            properties.insert(param.name.clone(), serde_json::Value::Object(param_schema));\n        }\n\n        serde_json::json!({\n            \"type\": \"object\",\n            \"properties\": properties,\n            \"required\": self.required_parameters()\n        })\n    }\n}\n\n/// Tool trait for functional components.\n///\n/// Extends `BaseAgent` to create tools - specialized components that perform\n/// specific functions with validated parameters. Tools have categories, security\n/// levels, and schemas that define their interfaces.\n///\n/// # Implementation Requirements\n///\n/// - Must provide accurate parameter schema\n/// - Should validate all parameters before execution\n/// - Security level should reflect actual requirements\n/// - Category should accurately describe tool function\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::{\n///     ComponentMetadata, Result, LLMSpellError,\n///     traits::{\n///         base_agent::BaseAgent,\n///         tool::{Tool, ToolCategory, SecurityLevel, ToolSchema, ParameterDef, ParameterType}\n///     },\n///     types::{AgentInput, AgentOutput, ExecutionContext}\n/// };\n/// use async_trait::async_trait;\n/// use serde_json::json;\n///\n/// struct FileSearchTool {\n///     metadata: ComponentMetadata,\n/// }\n///\n/// #[async_trait]\n/// impl Tool for FileSearchTool {\n///     fn category(&self) -> ToolCategory {\n///         ToolCategory::Filesystem\n///     }\n///     \n///     fn security_level(&self) -> SecurityLevel {\n///         SecurityLevel::Safe\n///     }\n///     \n///     fn schema(&self) -> ToolSchema {\n///         ToolSchema::new(\n///             \"file_search\".to_string(),\n///             \"Search for files\".to_string()\n///         )\n///         .with_parameter(ParameterDef {\n///             name: \"pattern\".to_string(),\n///             param_type: ParameterType::String,\n///             description: \"Search pattern\".to_string(),\n///             required: true,\n///             default: None,\n///         })\n///         .with_returns(ParameterType::Array)\n///     }\n/// }\n///\n/// #[async_trait]\n/// impl BaseAgent for FileSearchTool {\n///     fn metadata(&self) -> &ComponentMetadata {\n///         &self.metadata\n///     }\n///     \n///     async fn execute(\n///         &self,\n///         input: AgentInput,\n///         context: ExecutionContext,\n///     ) -> Result<AgentOutput> {\n///         // Get parameters from input context\n///         let params = input.parameters.get(\"parameters\")\n///             .ok_or_else(|| LLMSpellError::Validation {\n///                 message: \"Missing parameters\".to_string(),\n///                 field: Some(\"parameters\".to_string()),\n///             })?;\n///         \n///         // Validate parameters\n///         self.validate_parameters(params).await?;\n///         \n///         // Execute tool logic\n///         let pattern = params[\"pattern\"].as_str().unwrap();\n///         let results = json!([\"file1.txt\", \"file2.txt\"]);\n///         \n///         Ok(AgentOutput::text(results.to_string()))\n///     }\n///     \n///     async fn validate_input(&self, input: &AgentInput) -> Result<()> {\n///         Ok(())\n///     }\n///     \n///     async fn handle_error(&self, error: LLMSpellError) -> Result<AgentOutput> {\n///         Ok(AgentOutput::text(format!(\"Tool error: {}\", error)))\n///     }\n/// }\n/// ```\n#[async_trait]\npub trait Tool: BaseAgent {\n    /// Get tool category\n    fn category(&self) -> ToolCategory;\n\n    /// Get security level\n    fn security_level(&self) -> SecurityLevel;\n\n    /// Get parameter schema\n    fn schema(&self) -> ToolSchema;\n\n    /// Get security requirements for this tool\n    fn security_requirements(&self) -> SecurityRequirements {\n        SecurityRequirements {\n            level: self.security_level(),\n            ..Default::default()\n        }\n    }\n\n    /// Get resource limits for this tool\n    fn resource_limits(&self) -> ResourceLimits {\n        match self.security_level() {\n            SecurityLevel::Safe => ResourceLimits::strict(),\n            SecurityLevel::Restricted => ResourceLimits::default(),\n            SecurityLevel::Privileged => ResourceLimits::unlimited(),\n        }\n    }\n\n    /// Execute tool with streaming output\n    async fn stream_execute(\n        &self,\n        input: AgentInput,\n        context: crate::types::ExecutionContext,\n    ) -> Result<AgentStream> {\n        // Default implementation: execute normally and convert to a single chunk stream\n        let output = self.execute(input, context).await?;\n\n        // Convert AgentOutput to AgentChunk\n        let chunk = crate::types::AgentChunk {\n            stream_id: format!(\"tool-{}\", uuid::Uuid::new_v4()),\n            chunk_index: 0,\n            content: crate::types::ChunkContent::Text(output.text),\n            metadata: crate::types::ChunkMetadata {\n                is_final: true,\n                token_count: None,\n                model: None,\n                reasoning_step: None,\n            },\n            timestamp: chrono::Utc::now(),\n        };\n\n        // Create a simple stream with just the final chunk\n        use futures::stream;\n        let stream = stream::once(async move { Ok(chunk) });\n        Ok(Box::pin(stream))\n    }\n\n    /// Validate tool parameters\n    async fn validate_parameters(&self, params: &serde_json::Value) -> Result<()> {\n        // Basic validation implementation\n        let schema = self.schema();\n\n        // Check that params is an object\n        let params_map = params\n            .as_object()\n            .ok_or_else(|| crate::LLMSpellError::Validation {\n                message: \"Parameters must be an object\".to_string(),\n                field: Some(\"parameters\".to_string()),\n            })?;\n\n        // Check required parameters\n        for required in schema.required_parameters() {\n            if !params_map.contains_key(&required) {\n                return Err(crate::LLMSpellError::Validation {\n                    message: format!(\"Missing required parameter: {}\", required),\n                    field: Some(required.clone()),\n                });\n            }\n        }\n\n        // Check parameter types\n        for param_def in &schema.parameters {\n            if let Some(value) = params_map.get(&param_def.name) {\n                let valid_type = match param_def.param_type {\n                    ParameterType::String => value.is_string(),\n                    ParameterType::Number => value.is_number(),\n                    ParameterType::Boolean => value.is_boolean(),\n                    ParameterType::Array => value.is_array(),\n                    ParameterType::Object => value.is_object(),\n                    ParameterType::Null => value.is_null(),\n                };\n\n                if !valid_type {\n                    return Err(crate::LLMSpellError::Validation {\n                        message: format!(\n                            \"Invalid type for parameter '{}': expected {:?}\",\n                            param_def.name, param_def.param_type\n                        ),\n                        field: Some(param_def.name.clone()),\n                    });\n                }\n            }\n        }\n\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::types::{AgentInput, AgentOutput, ExecutionContext};\n    use crate::ComponentMetadata;\n\n    #[test]\n    fn test_tool_category_display() {\n        assert_eq!(ToolCategory::Filesystem.to_string(), \"filesystem\");\n        assert_eq!(ToolCategory::Web.to_string(), \"web\");\n        assert_eq!(ToolCategory::Custom(\"ai\".to_string()).to_string(), \"ai\");\n    }\n\n    #[test]\n    fn test_security_level_ordering() {\n        assert!(SecurityLevel::Safe < SecurityLevel::Restricted);\n        assert!(SecurityLevel::Restricted < SecurityLevel::Privileged);\n        assert!(SecurityLevel::Privileged.allows(&SecurityLevel::Safe));\n        assert!(!SecurityLevel::Safe.allows(&SecurityLevel::Privileged));\n    }\n\n    #[test]\n    fn test_parameter_def_creation() {\n        let param = ParameterDef {\n            name: \"input\".to_string(),\n            param_type: ParameterType::String,\n            description: \"Input text\".to_string(),\n            required: true,\n            default: None,\n        };\n\n        assert_eq!(param.name, \"input\");\n        assert!(param.required);\n        assert_eq!(param.param_type, ParameterType::String);\n    }\n\n    #[test]\n    fn test_tool_schema_builder() {\n        let schema = ToolSchema::new(\"test_tool\".to_string(), \"A test tool\".to_string())\n            .with_parameter(ParameterDef {\n                name: \"text\".to_string(),\n                param_type: ParameterType::String,\n                description: \"Input text\".to_string(),\n                required: true,\n                default: None,\n            })\n            .with_parameter(ParameterDef {\n                name: \"count\".to_string(),\n                param_type: ParameterType::Number,\n                description: \"Number of items\".to_string(),\n                required: false,\n                default: Some(serde_json::json!(1)),\n            })\n            .with_returns(ParameterType::String);\n\n        assert_eq!(schema.name, \"test_tool\");\n        assert_eq!(schema.parameters.len(), 2);\n        assert_eq!(schema.returns, Some(ParameterType::String));\n        assert_eq!(schema.required_parameters(), vec![\"text\"]);\n    }\n\n    #[test]\n    fn test_tool_schema_json_conversion() {\n        let schema =\n            ToolSchema::new(\"test\".to_string(), \"Test\".to_string()).with_parameter(ParameterDef {\n                name: \"input\".to_string(),\n                param_type: ParameterType::String,\n                description: \"Input parameter\".to_string(),\n                required: true,\n                default: None,\n            });\n\n        let json_schema = schema.to_json_schema();\n        assert_eq!(json_schema[\"type\"], \"object\");\n        assert_eq!(json_schema[\"required\"], serde_json::json!([\"input\"]));\n        assert_eq!(json_schema[\"properties\"][\"input\"][\"type\"], \"string\");\n    }\n\n    // Mock tool implementation for testing\n    struct MockTool {\n        metadata: ComponentMetadata,\n        category: ToolCategory,\n        security_level: SecurityLevel,\n        schema: ToolSchema,\n    }\n\n    impl MockTool {\n        fn new() -> Self {\n            let schema = ToolSchema::new(\n                \"mock_tool\".to_string(),\n                \"A mock tool for testing\".to_string(),\n            )\n            .with_parameter(ParameterDef {\n                name: \"text\".to_string(),\n                param_type: ParameterType::String,\n                description: \"Text to process\".to_string(),\n                required: true,\n                default: None,\n            })\n            .with_parameter(ParameterDef {\n                name: \"uppercase\".to_string(),\n                param_type: ParameterType::Boolean,\n                description: \"Convert to uppercase\".to_string(),\n                required: false,\n                default: Some(serde_json::json!(false)),\n            })\n            .with_returns(ParameterType::String);\n\n            Self {\n                metadata: ComponentMetadata::new(\n                    \"mock-tool\".to_string(),\n                    \"A mock tool for testing\".to_string(),\n                ),\n                category: ToolCategory::Utility,\n                security_level: SecurityLevel::Safe,\n                schema,\n            }\n        }\n    }\n\n    #[async_trait]\n    impl BaseAgent for MockTool {\n        fn metadata(&self) -> &ComponentMetadata {\n            &self.metadata\n        }\n\n        async fn execute(\n            &self,\n            input: AgentInput,\n            _context: ExecutionContext,\n        ) -> Result<AgentOutput> {\n            // Parse parameters from input context\n            let params = input.parameters.get(\"parameters\").ok_or_else(|| {\n                crate::LLMSpellError::Validation {\n                    message: \"Missing parameters in input\".to_string(),\n                    field: Some(\"parameters\".to_string()),\n                }\n            })?;\n\n            // Validate parameters\n            self.validate_parameters(params).await?;\n\n            // Execute tool logic\n            let text = params[\"text\"].as_str().unwrap();\n            let uppercase = params\n                .get(\"uppercase\")\n                .and_then(|v| v.as_bool())\n                .unwrap_or(false);\n\n            let result = if uppercase {\n                text.to_uppercase()\n            } else {\n                text.to_string()\n            };\n\n            Ok(AgentOutput::text(result))\n        }\n\n        async fn validate_input(&self, input: &AgentInput) -> Result<()> {\n            if input.text.is_empty() {\n                return Err(crate::LLMSpellError::Validation {\n                    message: \"Input prompt cannot be empty\".to_string(),\n                    field: Some(\"prompt\".to_string()),\n                });\n            }\n            Ok(())\n        }\n\n        async fn handle_error(&self, error: crate::LLMSpellError) -> Result<AgentOutput> {\n            Ok(AgentOutput::text(format!(\"Tool error: {}\", error)))\n        }\n    }\n\n    #[async_trait]\n    impl Tool for MockTool {\n        fn category(&self) -> ToolCategory {\n            self.category.clone()\n        }\n\n        fn security_level(&self) -> SecurityLevel {\n            self.security_level.clone()\n        }\n\n        fn schema(&self) -> ToolSchema {\n            self.schema.clone()\n        }\n    }\n\n    #[tokio::test]\n    async fn test_tool_parameter_validation() {\n        let tool = MockTool::new();\n\n        // Valid parameters\n        let valid_params = serde_json::json!({\n            \"text\": \"hello\",\n            \"uppercase\": true\n        });\n        assert!(tool.validate_parameters(&valid_params).await.is_ok());\n\n        // Missing required parameter\n        let missing_params = serde_json::json!({\n            \"uppercase\": true\n        });\n        let result = tool.validate_parameters(&missing_params).await;\n        assert!(result.is_err());\n        assert!(result\n            .unwrap_err()\n            .to_string()\n            .contains(\"Missing required parameter\"));\n\n        // Wrong parameter type\n        let wrong_type = serde_json::json!({\n            \"text\": 123,\n            \"uppercase\": true\n        });\n        let result = tool.validate_parameters(&wrong_type).await;\n        assert!(result.is_err());\n        assert!(result.unwrap_err().to_string().contains(\"Invalid type\"));\n\n        // Non-object parameters\n        let non_object = serde_json::json!(\"not an object\");\n        let result = tool.validate_parameters(&non_object).await;\n        assert!(result.is_err());\n        assert!(result\n            .unwrap_err()\n            .to_string()\n            .contains(\"must be an object\"));\n    }\n\n    #[tokio::test]\n    async fn test_tool_execution() {\n        let tool = MockTool::new();\n\n        // Test with uppercase = false\n        let input = AgentInput::text(\"process text\".to_string()).with_parameter(\n            \"parameters\".to_string(),\n            serde_json::json!({\n                \"text\": \"hello world\",\n                \"uppercase\": false\n            }),\n        );\n        let context = ExecutionContext::with_conversation(\"session\".to_string());\n\n        let result = tool.execute(input, context).await.unwrap();\n        assert_eq!(result.text, \"hello world\");\n\n        // Test with uppercase = true\n        let input = AgentInput::text(\"process text\".to_string()).with_parameter(\n            \"parameters\".to_string(),\n            serde_json::json!({\n                \"text\": \"hello world\",\n                \"uppercase\": true\n            }),\n        );\n        let context = ExecutionContext::with_conversation(\"session\".to_string());\n\n        let result = tool.execute(input, context).await.unwrap();\n        assert_eq!(result.text, \"HELLO WORLD\");\n    }\n\n    #[test]\n    fn test_tool_metadata() {\n        let tool = MockTool::new();\n\n        assert_eq!(tool.category(), ToolCategory::Utility);\n        assert_eq!(tool.security_level(), SecurityLevel::Safe);\n        assert_eq!(tool.schema().name, \"mock_tool\");\n        assert_eq!(tool.metadata().name, \"mock-tool\");\n    }\n}\n","traces":[{"line":42,"address":[],"length":0,"stats":{"Line":13}},{"line":43,"address":[],"length":0,"stats":{"Line":13}},{"line":44,"address":[],"length":0,"stats":{"Line":2}},{"line":45,"address":[],"length":0,"stats":{"Line":2}},{"line":46,"address":[],"length":0,"stats":{"Line":1}},{"line":47,"address":[],"length":0,"stats":{"Line":1}},{"line":48,"address":[],"length":0,"stats":{"Line":1}},{"line":49,"address":[],"length":0,"stats":{"Line":1}},{"line":50,"address":[],"length":0,"stats":{"Line":5}},{"line":83,"address":[],"length":0,"stats":{"Line":16}},{"line":84,"address":[],"length":0,"stats":{"Line":16}},{"line":104,"address":[],"length":0,"stats":{"Line":45}},{"line":107,"address":[],"length":0,"stats":{"Line":45}},{"line":108,"address":[],"length":0,"stats":{"Line":45}},{"line":109,"address":[],"length":0,"stats":{"Line":45}},{"line":110,"address":[],"length":0,"stats":{"Line":45}},{"line":117,"address":[],"length":0,"stats":{"Line":25}},{"line":118,"address":[],"length":0,"stats":{"Line":25}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":1}},{"line":133,"address":[],"length":0,"stats":{"Line":1}},{"line":134,"address":[],"length":0,"stats":{"Line":1}},{"line":135,"address":[],"length":0,"stats":{"Line":1}},{"line":136,"address":[],"length":0,"stats":{"Line":1}},{"line":141,"address":[],"length":0,"stats":{"Line":8}},{"line":142,"address":[],"length":0,"stats":{"Line":8}},{"line":143,"address":[],"length":0,"stats":{"Line":8}},{"line":147,"address":[],"length":0,"stats":{"Line":27}},{"line":148,"address":[],"length":0,"stats":{"Line":27}},{"line":149,"address":[],"length":0,"stats":{"Line":27}},{"line":153,"address":[],"length":0,"stats":{"Line":11}},{"line":154,"address":[],"length":0,"stats":{"Line":11}},{"line":155,"address":[],"length":0,"stats":{"Line":11}},{"line":175,"address":[],"length":0,"stats":{"Line":4}},{"line":177,"address":[],"length":0,"stats":{"Line":4}},{"line":178,"address":[],"length":0,"stats":{"Line":4}},{"line":179,"address":[],"length":0,"stats":{"Line":4}},{"line":180,"address":[],"length":0,"stats":{"Line":4}},{"line":181,"address":[],"length":0,"stats":{"Line":4}},{"line":188,"address":[],"length":0,"stats":{"Line":3}},{"line":194,"address":[],"length":0,"stats":{"Line":3}},{"line":199,"address":[],"length":0,"stats":{"Line":27}},{"line":201,"address":[],"length":0,"stats":{"Line":27}},{"line":202,"address":[],"length":0,"stats":{"Line":27}},{"line":203,"address":[],"length":0,"stats":{"Line":27}},{"line":204,"address":[],"length":0,"stats":{"Line":27}},{"line":205,"address":[],"length":0,"stats":{"Line":27}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":2}},{"line":217,"address":[],"length":0,"stats":{"Line":2}},{"line":218,"address":[],"length":0,"stats":{"Line":2}},{"line":222,"address":[],"length":0,"stats":{"Line":3}},{"line":223,"address":[],"length":0,"stats":{"Line":3}},{"line":224,"address":[],"length":0,"stats":{"Line":3}},{"line":297,"address":[],"length":0,"stats":{"Line":36}},{"line":301,"address":[],"length":0,"stats":{"Line":36}},{"line":307,"address":[],"length":0,"stats":{"Line":52}},{"line":308,"address":[],"length":0,"stats":{"Line":52}},{"line":309,"address":[],"length":0,"stats":{"Line":52}},{"line":313,"address":[],"length":0,"stats":{"Line":31}},{"line":314,"address":[],"length":0,"stats":{"Line":31}},{"line":315,"address":[],"length":0,"stats":{"Line":31}},{"line":319,"address":[],"length":0,"stats":{"Line":11}},{"line":320,"address":[],"length":0,"stats":{"Line":11}},{"line":322,"address":[],"length":0,"stats":{"Line":53}},{"line":323,"address":[],"length":0,"stats":{"Line":37}},{"line":328,"address":[],"length":0,"stats":{"Line":1}},{"line":329,"address":[],"length":0,"stats":{"Line":1}},{"line":331,"address":[],"length":0,"stats":{"Line":3}},{"line":337,"address":[],"length":0,"stats":{"Line":1}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":359,"address":[],"length":0,"stats":{"Line":1}},{"line":360,"address":[],"length":0,"stats":{"Line":1}},{"line":361,"address":[],"length":0,"stats":{"Line":1}},{"line":362,"address":[],"length":0,"stats":{"Line":1}},{"line":473,"address":[],"length":0,"stats":{"Line":20}},{"line":475,"address":[],"length":0,"stats":{"Line":20}},{"line":481,"address":[],"length":0,"stats":{"Line":10}},{"line":482,"address":[],"length":0,"stats":{"Line":10}},{"line":483,"address":[],"length":0,"stats":{"Line":6}},{"line":484,"address":[],"length":0,"stats":{"Line":2}},{"line":485,"address":[],"length":0,"stats":{"Line":2}},{"line":496,"address":[],"length":0,"stats":{"Line":0}},{"line":500,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":0}},{"line":503,"address":[],"length":0,"stats":{"Line":0}},{"line":509,"address":[],"length":0,"stats":{"Line":0}},{"line":514,"address":[],"length":0,"stats":{"Line":0}},{"line":515,"address":[],"length":0,"stats":{"Line":0}},{"line":519,"address":[],"length":0,"stats":{"Line":6}},{"line":521,"address":[],"length":0,"stats":{"Line":6}},{"line":524,"address":[],"length":0,"stats":{"Line":11}},{"line":526,"address":[],"length":0,"stats":{"Line":7}},{"line":527,"address":[],"length":0,"stats":{"Line":1}},{"line":528,"address":[],"length":0,"stats":{"Line":1}},{"line":532,"address":[],"length":0,"stats":{"Line":5}},{"line":533,"address":[],"length":0,"stats":{"Line":5}},{"line":534,"address":[],"length":0,"stats":{"Line":1}},{"line":535,"address":[],"length":0,"stats":{"Line":1}},{"line":536,"address":[],"length":0,"stats":{"Line":1}},{"line":542,"address":[],"length":0,"stats":{"Line":17}},{"line":543,"address":[],"length":0,"stats":{"Line":14}},{"line":544,"address":[],"length":0,"stats":{"Line":0}},{"line":545,"address":[],"length":0,"stats":{"Line":4}},{"line":546,"address":[],"length":0,"stats":{"Line":0}},{"line":547,"address":[],"length":0,"stats":{"Line":3}},{"line":548,"address":[],"length":0,"stats":{"Line":0}},{"line":549,"address":[],"length":0,"stats":{"Line":0}},{"line":550,"address":[],"length":0,"stats":{"Line":0}},{"line":553,"address":[],"length":0,"stats":{"Line":0}},{"line":554,"address":[],"length":0,"stats":{"Line":1}},{"line":555,"address":[],"length":0,"stats":{"Line":1}},{"line":556,"address":[],"length":0,"stats":{"Line":1}},{"line":557,"address":[],"length":0,"stats":{"Line":1}},{"line":559,"address":[],"length":0,"stats":{"Line":1}},{"line":565,"address":[],"length":0,"stats":{"Line":3}}],"covered":100,"coverable":123},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-core","src","traits","workflow.rs"],"content":"//! ABOUTME: Workflow trait for orchestration components\n//! ABOUTME: Extends BaseAgent with step management and execution planning\n\nuse super::base_agent::BaseAgent;\nuse crate::types::AgentOutput;\nuse crate::{ComponentId, Result};\nuse async_trait::async_trait;\nuse serde::{Deserialize, Serialize};\nuse std::collections::{HashMap, HashSet};\nuse std::time::Duration;\n\n/// Workflow step definition.\n///\n/// Represents a single step in a workflow, including its dependencies,\n/// retry policies, and timeout configuration. Steps are executed in\n/// topological order based on their dependencies.\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::{ComponentId, traits::workflow::{WorkflowStep, RetryPolicy}};\n/// use std::time::Duration;\n///\n/// let step1_id = ComponentId::new();\n/// let step2_id = ComponentId::new();\n/// let agent_id = ComponentId::new();\n///\n/// let step = WorkflowStep::new(\"analyze_data\".to_string(), agent_id)\n///     .with_dependency(step1_id)\n///     .with_dependency(step2_id)\n///     .with_retry(RetryPolicy::default())\n///     .with_timeout(Duration::from_secs(300));\n///\n/// assert_eq!(step.name, \"analyze_data\");\n/// assert_eq!(step.dependencies.len(), 2);\n/// ```\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct WorkflowStep {\n    pub id: ComponentId,\n    pub name: String,\n    pub component_id: ComponentId,\n    pub dependencies: Vec<ComponentId>,\n    pub retry_policy: Option<RetryPolicy>,\n    pub timeout: Option<Duration>,\n}\n\nimpl WorkflowStep {\n    /// Create a new workflow step\n    pub fn new(name: String, component_id: ComponentId) -> Self {\n        Self {\n            id: ComponentId::new(),\n            name,\n            component_id,\n            dependencies: Vec::new(),\n            retry_policy: None,\n            timeout: None,\n        }\n    }\n\n    /// Add a dependency\n    pub fn with_dependency(mut self, dep: ComponentId) -> Self {\n        self.dependencies.push(dep);\n        self\n    }\n\n    /// Set retry policy\n    pub fn with_retry(mut self, policy: RetryPolicy) -> Self {\n        self.retry_policy = Some(policy);\n        self\n    }\n\n    /// Set timeout\n    pub fn with_timeout(mut self, timeout: Duration) -> Self {\n        self.timeout = Some(timeout);\n        self\n    }\n}\n\n/// Retry policy for workflow steps.\n///\n/// Defines how failed steps should be retried, including the number of attempts,\n/// backoff strategy, and delay between retries.\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::traits::workflow::RetryPolicy;\n///\n/// let policy = RetryPolicy {\n///     max_attempts: 5,\n///     backoff_seconds: 2,\n///     exponential_backoff: true,\n/// };\n///\n/// // Default policy\n/// let default = RetryPolicy::default();\n/// assert_eq!(default.max_attempts, 3);\n/// assert!(default.exponential_backoff);\n/// ```\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct RetryPolicy {\n    pub max_attempts: u32,\n    pub backoff_seconds: u32,\n    pub exponential_backoff: bool,\n}\n\nimpl Default for RetryPolicy {\n    fn default() -> Self {\n        Self {\n            max_attempts: 3,\n            backoff_seconds: 1,\n            exponential_backoff: true,\n        }\n    }\n}\n\n/// Step execution result\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct StepResult {\n    pub step_id: ComponentId,\n    pub output: AgentOutput,\n    pub duration: Duration,\n    pub success: bool,\n    pub error: Option<String>,\n    pub retry_count: u32,\n}\n\nimpl StepResult {\n    /// Create a successful result\n    pub fn success(step_id: ComponentId, output: AgentOutput, duration: Duration) -> Self {\n        Self {\n            step_id,\n            output,\n            duration,\n            success: true,\n            error: None,\n            retry_count: 0,\n        }\n    }\n\n    /// Create a failed result\n    pub fn failure(\n        step_id: ComponentId,\n        error: String,\n        duration: Duration,\n        retry_count: u32,\n    ) -> Self {\n        Self {\n            step_id,\n            output: AgentOutput::text(String::new()),\n            duration,\n            success: false,\n            error: Some(error),\n            retry_count,\n        }\n    }\n}\n\n/// Workflow execution status\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]\npub enum WorkflowStatus {\n    Pending,\n    Running,\n    Completed,\n    Failed,\n    Cancelled,\n}\n\n/// Workflow configuration.\n///\n/// Controls workflow execution behavior including parallelism limits,\n/// error handling strategy, and global timeouts.\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::traits::workflow::WorkflowConfig;\n/// use std::time::Duration;\n///\n/// let config = WorkflowConfig {\n///     max_parallel: Some(4),\n///     continue_on_error: true,\n///     timeout: Some(Duration::from_secs(3600)),\n/// };\n///\n/// // Default configuration\n/// let default = WorkflowConfig::default();\n/// assert_eq!(default.max_parallel, None); // No limit\n/// assert!(!default.continue_on_error); // Stop on error\n/// ```\n#[derive(Debug, Clone, Serialize, Deserialize, Default)]\npub struct WorkflowConfig {\n    /// Maximum parallel executions\n    pub max_parallel: Option<usize>,\n    /// Continue on step failure\n    pub continue_on_error: bool,\n    /// Global timeout for workflow\n    pub timeout: Option<Duration>,\n}\n\n/// Workflow trait for orchestration components.\n///\n/// Extends `BaseAgent` to create workflows that orchestrate multiple components.\n/// Workflows manage step execution order, handle dependencies, and coordinate\n/// parallel execution while respecting configuration limits.\n///\n/// # Key Features\n///\n/// - **Dependency Management**: Steps execute in topological order\n/// - **Parallel Execution**: Multiple independent steps can run concurrently\n/// - **Error Handling**: Configurable continue-on-error behavior\n/// - **Retry Logic**: Per-step retry policies with backoff\n/// - **Circular Dependency Detection**: Validates workflow before execution\n///\n/// # Implementation Requirements\n///\n/// - Must detect circular dependencies during validation\n/// - Should respect max_parallel configuration\n/// - Must maintain step execution results\n/// - Should handle step failures according to configuration\n///\n/// # Examples\n///\n/// ```ignore\n/// use llmspell_core::{\n///     ComponentId, ComponentMetadata, Result,\n///     types::{AgentInput, AgentOutput, ExecutionContext},\n///     traits::{\n///         base_agent::BaseAgent,\n///         workflow::{Workflow, WorkflowConfig, WorkflowStep, WorkflowStatus, StepResult}\n///     }\n/// };\n/// use async_trait::async_trait;\n///\n/// struct DataPipeline {\n///     metadata: ComponentMetadata,\n///     config: WorkflowConfig,\n///     steps: Vec<WorkflowStep>,\n///     status: WorkflowStatus,\n///     results: Vec<StepResult>,\n/// }\n///\n/// #[async_trait]\n/// impl Workflow for DataPipeline {\n///     fn config(&self) -> &WorkflowConfig {\n///         &self.config\n///     }\n///     \n///     async fn add_step(&mut self, step: WorkflowStep) -> Result<()> {\n///         // Validate no circular dependencies\n///         self.steps.push(step);\n///         self.validate().await?;\n///         Ok(())\n///     }\n///     \n///     async fn remove_step(&mut self, step_id: ComponentId) -> Result<()> {\n///         self.steps.retain(|s| s.id != step_id);\n///         Ok(())\n///     }\n///     \n///     async fn get_steps(&self) -> Result<Vec<WorkflowStep>> {\n///         Ok(self.steps.clone())\n///     }\n///     \n///     async fn status(&self) -> Result<WorkflowStatus> {\n///         Ok(self.status.clone())\n///     }\n///     \n///     async fn get_results(&self) -> Result<Vec<StepResult>> {\n///         Ok(self.results.clone())\n///     }\n/// }\n///\n/// # impl BaseAgent for DataPipeline {\n/// #     fn metadata(&self) -> &ComponentMetadata { &self.metadata }\n/// #     async fn execute(&self, input: AgentInput, context: ExecutionContext) -> Result<AgentOutput> {\n/// #         Ok(AgentOutput::text(\"Workflow complete\"))\n/// #     }\n/// #     async fn validate_input(&self, input: &AgentInput) -> Result<()> { Ok(()) }\n/// #     async fn handle_error(&self, error: llmspell_core::LLMSpellError) -> Result<AgentOutput> {\n/// #         Ok(AgentOutput::text(\"Error\"))\n/// #     }\n/// # }\n/// ```\n#[async_trait]\npub trait Workflow: BaseAgent {\n    /// Get workflow configuration\n    fn config(&self) -> &WorkflowConfig;\n\n    /// Add step to workflow\n    async fn add_step(&mut self, step: WorkflowStep) -> Result<()>;\n\n    /// Remove step from workflow\n    async fn remove_step(&mut self, step_id: ComponentId) -> Result<()>;\n\n    /// Get all steps\n    async fn get_steps(&self) -> Result<Vec<WorkflowStep>>;\n\n    /// Get execution plan (topologically sorted)\n    async fn plan_execution(&self) -> Result<Vec<WorkflowStep>> {\n        let steps = self.get_steps().await?;\n\n        // Build dependency graph\n        let mut graph: HashMap<ComponentId, HashSet<ComponentId>> = HashMap::new();\n        let mut in_degree: HashMap<ComponentId, usize> = HashMap::new();\n\n        for step in &steps {\n            graph.entry(step.id).or_default();\n            in_degree.entry(step.id).or_insert(0);\n\n            for dep in &step.dependencies {\n                graph.entry(*dep).or_default().insert(step.id);\n                *in_degree.entry(step.id).or_default() += 1;\n            }\n        }\n\n        // Topological sort using Kahn's algorithm\n        let mut queue: Vec<ComponentId> = in_degree\n            .iter()\n            .filter(|(_, &degree)| degree == 0)\n            .map(|(id, _)| *id)\n            .collect();\n\n        let mut sorted = Vec::new();\n\n        while let Some(node) = queue.pop() {\n            if let Some(step) = steps.iter().find(|s| s.id == node) {\n                sorted.push(step.clone());\n            }\n\n            if let Some(neighbors) = graph.get(&node) {\n                for neighbor in neighbors {\n                    if let Some(degree) = in_degree.get_mut(neighbor) {\n                        *degree -= 1;\n                        if *degree == 0 {\n                            queue.push(*neighbor);\n                        }\n                    }\n                }\n            }\n        }\n\n        // Check for cycles\n        if sorted.len() != steps.len() {\n            return Err(crate::LLMSpellError::Workflow {\n                message: \"Workflow contains circular dependencies\".to_string(),\n                step: None,\n                source: None,\n            });\n        }\n\n        Ok(sorted)\n    }\n\n    /// Get workflow status\n    async fn status(&self) -> Result<WorkflowStatus>;\n\n    /// Get step results\n    async fn get_results(&self) -> Result<Vec<StepResult>>;\n\n    /// Get result for specific step\n    async fn get_step_result(&self, step_id: ComponentId) -> Result<Option<StepResult>> {\n        let results = self.get_results().await?;\n        Ok(results.into_iter().find(|r| r.step_id == step_id))\n    }\n\n    /// Check if workflow can execute (no cycles, all dependencies valid)\n    async fn validate(&self) -> Result<()> {\n        // Check all dependencies exist first\n        let steps = self.get_steps().await?;\n        let step_ids: HashSet<ComponentId> = steps.iter().map(|s| s.id).collect();\n\n        for step in &steps {\n            for dep in &step.dependencies {\n                if !step_ids.contains(dep) {\n                    return Err(crate::LLMSpellError::Workflow {\n                        message: format!(\"Step '{}' has invalid dependency: {:?}\", step.name, dep),\n                        step: Some(step.name.clone()),\n                        source: None,\n                    });\n                }\n            }\n        }\n\n        // Then check for cycles - plan execution will fail if there are cycles\n        self.plan_execution().await?;\n\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::types::{AgentInput, ExecutionContext};\n    use crate::ComponentMetadata;\n    use std::sync::Arc;\n    use tokio::sync::Mutex;\n\n    #[test]\n    fn test_workflow_step_builder() {\n        let component_id = ComponentId::new();\n        let dep_id = ComponentId::new();\n\n        let step = WorkflowStep::new(\"test_step\".to_string(), component_id)\n            .with_dependency(dep_id)\n            .with_retry(RetryPolicy::default())\n            .with_timeout(Duration::from_secs(30));\n\n        assert_eq!(step.name, \"test_step\");\n        assert_eq!(step.component_id, component_id);\n        assert_eq!(step.dependencies.len(), 1);\n        assert_eq!(step.dependencies[0], dep_id);\n        assert!(step.retry_policy.is_some());\n        assert_eq!(step.timeout, Some(Duration::from_secs(30)));\n    }\n\n    #[test]\n    fn test_retry_policy_default() {\n        let policy = RetryPolicy::default();\n        assert_eq!(policy.max_attempts, 3);\n        assert_eq!(policy.backoff_seconds, 1);\n        assert!(policy.exponential_backoff);\n    }\n\n    #[test]\n    fn test_step_result_creation() {\n        let step_id = ComponentId::new();\n        let output = AgentOutput::text(\"Success\");\n        let duration = Duration::from_secs(1);\n\n        // Test success result\n        let success = StepResult::success(step_id, output.clone(), duration);\n        assert!(success.success);\n        assert_eq!(success.error, None);\n        assert_eq!(success.retry_count, 0);\n\n        // Test failure result\n        let failure = StepResult::failure(step_id, \"Error occurred\".to_string(), duration, 2);\n        assert!(!failure.success);\n        assert_eq!(failure.error, Some(\"Error occurred\".to_string()));\n        assert_eq!(failure.retry_count, 2);\n    }\n\n    #[test]\n    fn test_workflow_config_default() {\n        let config = WorkflowConfig::default();\n        assert_eq!(config.max_parallel, None);\n        assert!(!config.continue_on_error);\n        assert_eq!(config.timeout, None);\n    }\n\n    // Mock workflow implementation\n    struct MockWorkflow {\n        metadata: ComponentMetadata,\n        config: WorkflowConfig,\n        steps: Arc<Mutex<Vec<WorkflowStep>>>,\n        status: Arc<Mutex<WorkflowStatus>>,\n        results: Arc<Mutex<Vec<StepResult>>>,\n    }\n\n    impl MockWorkflow {\n        fn new() -> Self {\n            Self {\n                metadata: ComponentMetadata::new(\n                    \"mock-workflow\".to_string(),\n                    \"A mock workflow for testing\".to_string(),\n                ),\n                config: WorkflowConfig::default(),\n                steps: Arc::new(Mutex::new(Vec::new())),\n                status: Arc::new(Mutex::new(WorkflowStatus::Pending)),\n                results: Arc::new(Mutex::new(Vec::new())),\n            }\n        }\n    }\n\n    #[async_trait]\n    impl BaseAgent for MockWorkflow {\n        fn metadata(&self) -> &ComponentMetadata {\n            &self.metadata\n        }\n\n        async fn execute(\n            &self,\n            _input: AgentInput,\n            _context: ExecutionContext,\n        ) -> Result<AgentOutput> {\n            // Execute workflow\n            *self.status.lock().await = WorkflowStatus::Running;\n\n            // Simulate execution\n            let steps = self.steps.lock().await.clone();\n            for step in steps {\n                let result = StepResult::success(\n                    step.id,\n                    AgentOutput::text(format!(\"Executed {}\", step.name)),\n                    Duration::from_secs(1),\n                );\n                self.results.lock().await.push(result);\n            }\n\n            *self.status.lock().await = WorkflowStatus::Completed;\n            Ok(AgentOutput::text(\"Workflow completed\"))\n        }\n\n        async fn validate_input(&self, input: &AgentInput) -> Result<()> {\n            if input.text.is_empty() {\n                return Err(crate::LLMSpellError::Validation {\n                    message: \"Input text cannot be empty\".to_string(),\n                    field: Some(\"text\".to_string()),\n                });\n            }\n            Ok(())\n        }\n\n        async fn handle_error(&self, error: crate::LLMSpellError) -> Result<AgentOutput> {\n            *self.status.lock().await = WorkflowStatus::Failed;\n            Ok(AgentOutput::text(format!(\"Workflow error: {}\", error)))\n        }\n    }\n\n    #[async_trait]\n    impl Workflow for MockWorkflow {\n        fn config(&self) -> &WorkflowConfig {\n            &self.config\n        }\n\n        async fn add_step(&mut self, step: WorkflowStep) -> Result<()> {\n            self.steps.lock().await.push(step);\n            Ok(())\n        }\n\n        async fn remove_step(&mut self, step_id: ComponentId) -> Result<()> {\n            let mut steps = self.steps.lock().await;\n            steps.retain(|s| s.id != step_id);\n            Ok(())\n        }\n\n        async fn get_steps(&self) -> Result<Vec<WorkflowStep>> {\n            Ok(self.steps.lock().await.clone())\n        }\n\n        async fn status(&self) -> Result<WorkflowStatus> {\n            Ok(self.status.lock().await.clone())\n        }\n\n        async fn get_results(&self) -> Result<Vec<StepResult>> {\n            Ok(self.results.lock().await.clone())\n        }\n    }\n\n    #[tokio::test]\n    async fn test_workflow_step_management() {\n        let mut workflow = MockWorkflow::new();\n\n        // Add steps\n        let step1 = WorkflowStep::new(\"step1\".to_string(), ComponentId::new());\n        let step2 =\n            WorkflowStep::new(\"step2\".to_string(), ComponentId::new()).with_dependency(step1.id);\n\n        workflow.add_step(step1.clone()).await.unwrap();\n        workflow.add_step(step2.clone()).await.unwrap();\n\n        let steps = workflow.get_steps().await.unwrap();\n        assert_eq!(steps.len(), 2);\n\n        // Remove step\n        workflow.remove_step(step1.id).await.unwrap();\n        let steps = workflow.get_steps().await.unwrap();\n        assert_eq!(steps.len(), 1);\n        assert_eq!(steps[0].id, step2.id);\n    }\n\n    #[tokio::test]\n    async fn test_workflow_execution_planning() {\n        let mut workflow = MockWorkflow::new();\n\n        // Create steps with dependencies: step1 -> step2 -> step3\n        let step1 = WorkflowStep::new(\"step1\".to_string(), ComponentId::new());\n        let step2 =\n            WorkflowStep::new(\"step2\".to_string(), ComponentId::new()).with_dependency(step1.id);\n        let step3 =\n            WorkflowStep::new(\"step3\".to_string(), ComponentId::new()).with_dependency(step2.id);\n\n        workflow.add_step(step3.clone()).await.unwrap();\n        workflow.add_step(step1.clone()).await.unwrap();\n        workflow.add_step(step2.clone()).await.unwrap();\n\n        // Plan execution should order them correctly\n        let plan = workflow.plan_execution().await.unwrap();\n        assert_eq!(plan.len(), 3);\n        assert_eq!(plan[0].id, step1.id);\n        assert_eq!(plan[1].id, step2.id);\n        assert_eq!(plan[2].id, step3.id);\n    }\n\n    #[tokio::test]\n    async fn test_workflow_circular_dependency_detection() {\n        let mut workflow = MockWorkflow::new();\n\n        // Create circular dependency: step1 -> step2 -> step1\n        let step1 = WorkflowStep::new(\"step1\".to_string(), ComponentId::new());\n        let step2 =\n            WorkflowStep::new(\"step2\".to_string(), ComponentId::new()).with_dependency(step1.id);\n        let step1_circular = WorkflowStep {\n            dependencies: vec![step2.id],\n            ..step1.clone()\n        };\n\n        workflow.add_step(step1_circular).await.unwrap();\n        workflow.add_step(step2).await.unwrap();\n\n        // Planning should fail\n        let result = workflow.plan_execution().await;\n        assert!(result.is_err());\n        assert!(result.unwrap_err().to_string().contains(\"circular\"));\n    }\n\n    #[tokio::test]\n    async fn test_workflow_validation() {\n        let mut workflow = MockWorkflow::new();\n\n        // Valid workflow\n        let step1 = WorkflowStep::new(\"step1\".to_string(), ComponentId::new());\n        let step2 =\n            WorkflowStep::new(\"step2\".to_string(), ComponentId::new()).with_dependency(step1.id);\n\n        workflow.add_step(step1).await.unwrap();\n        workflow.add_step(step2).await.unwrap();\n\n        assert!(workflow.validate().await.is_ok());\n\n        // Invalid workflow with missing dependency\n        let invalid_dep = ComponentId::new();\n        let step3 =\n            WorkflowStep::new(\"step3\".to_string(), ComponentId::new()).with_dependency(invalid_dep);\n\n        workflow.add_step(step3).await.unwrap();\n\n        let result = workflow.validate().await;\n        assert!(result.is_err());\n        let error_msg = result.unwrap_err().to_string();\n        assert!(\n            error_msg.contains(\"invalid dependency\"),\n            \"Error message was: {}\",\n            error_msg\n        );\n    }\n\n    #[tokio::test]\n    async fn test_workflow_execution_and_results() {\n        let workflow = MockWorkflow::new();\n\n        // Add steps\n        let step1 = WorkflowStep::new(\"step1\".to_string(), ComponentId::new());\n        let mut workflow_mut = workflow;\n        workflow_mut.add_step(step1.clone()).await.unwrap();\n        let workflow = workflow_mut;\n\n        // Execute workflow\n        let input = AgentInput::text(\"Execute workflow\");\n        let context = ExecutionContext::with_conversation(\"session\".to_string());\n\n        let output = workflow.execute(input, context).await.unwrap();\n        assert_eq!(output.text, \"Workflow completed\");\n\n        // Check status and results\n        assert_eq!(workflow.status().await.unwrap(), WorkflowStatus::Completed);\n\n        let results = workflow.get_results().await.unwrap();\n        assert_eq!(results.len(), 1);\n        assert!(results[0].success);\n\n        // Get specific step result\n        let step_result = workflow.get_step_result(step1.id).await.unwrap();\n        assert!(step_result.is_some());\n    }\n}\n","traces":[{"line":49,"address":[],"length":0,"stats":{"Line":528}},{"line":51,"address":[],"length":0,"stats":{"Line":528}},{"line":54,"address":[],"length":0,"stats":{"Line":528}},{"line":61,"address":[],"length":0,"stats":{"Line":526}},{"line":62,"address":[],"length":0,"stats":{"Line":526}},{"line":63,"address":[],"length":0,"stats":{"Line":526}},{"line":67,"address":[],"length":0,"stats":{"Line":2}},{"line":68,"address":[],"length":0,"stats":{"Line":2}},{"line":69,"address":[],"length":0,"stats":{"Line":2}},{"line":73,"address":[],"length":0,"stats":{"Line":2}},{"line":74,"address":[],"length":0,"stats":{"Line":2}},{"line":75,"address":[],"length":0,"stats":{"Line":2}},{"line":108,"address":[],"length":0,"stats":{"Line":6}},{"line":130,"address":[],"length":0,"stats":{"Line":3}},{"line":142,"address":[],"length":0,"stats":{"Line":2}},{"line":150,"address":[],"length":0,"stats":{"Line":2}},{"line":153,"address":[],"length":0,"stats":{"Line":2}},{"line":300,"address":[],"length":0,"stats":{"Line":3}},{"line":301,"address":[],"length":0,"stats":{"Line":6}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":17}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":17}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":7}},{"line":321,"address":[],"length":0,"stats":{"Line":2}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":13}},{"line":327,"address":[],"length":0,"stats":{"Line":14}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":5}},{"line":332,"address":[],"length":0,"stats":{"Line":11}},{"line":333,"address":[],"length":0,"stats":{"Line":3}},{"line":334,"address":[],"length":0,"stats":{"Line":0}},{"line":335,"address":[],"length":0,"stats":{"Line":3}},{"line":336,"address":[],"length":0,"stats":{"Line":3}},{"line":344,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":1}},{"line":346,"address":[],"length":0,"stats":{"Line":1}},{"line":347,"address":[],"length":0,"stats":{"Line":1}},{"line":348,"address":[],"length":0,"stats":{"Line":1}},{"line":352,"address":[],"length":0,"stats":{"Line":2}},{"line":362,"address":[],"length":0,"stats":{"Line":1}},{"line":363,"address":[],"length":0,"stats":{"Line":2}},{"line":364,"address":[],"length":0,"stats":{"Line":1}},{"line":368,"address":[],"length":0,"stats":{"Line":2}},{"line":370,"address":[],"length":0,"stats":{"Line":4}},{"line":371,"address":[],"length":0,"stats":{"Line":5}},{"line":373,"address":[],"length":0,"stats":{"Line":11}},{"line":374,"address":[],"length":0,"stats":{"Line":10}},{"line":375,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":1}},{"line":377,"address":[],"length":0,"stats":{"Line":1}},{"line":378,"address":[],"length":0,"stats":{"Line":1}},{"line":379,"address":[],"length":0,"stats":{"Line":1}},{"line":386,"address":[],"length":0,"stats":{"Line":1}},{"line":388,"address":[],"length":0,"stats":{"Line":1}}],"covered":49,"coverable":61},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-core","src","types","agent_io.rs"],"content":"//! ABOUTME: Agent input/output types with multimodal support\n//! ABOUTME: Provides AgentInput, AgentOutput, and related types for agent communication\n\nuse super::{ComponentId, MediaContent, MediaType};\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\nuse std::collections::HashMap;\nuse std::fmt;\n\n/// Execution context for agent operations\n#[derive(Debug, Clone, Default, Serialize, Deserialize)]\npub struct ExecutionContext {\n    /// Current conversation ID\n    pub conversation_id: Option<String>,\n    /// User ID if applicable\n    pub user_id: Option<String>,\n    /// Session ID for tracking\n    pub session_id: Option<String>,\n    /// Additional context data\n    pub data: HashMap<String, Value>,\n}\n\nimpl ExecutionContext {\n    /// Create a new empty execution context\n    pub fn new() -> Self {\n        Self::default()\n    }\n\n    /// Create with conversation ID\n    pub fn with_conversation(conversation_id: String) -> Self {\n        Self {\n            conversation_id: Some(conversation_id),\n            ..Default::default()\n        }\n    }\n\n    /// Add a data field\n    pub fn with_data(mut self, key: String, value: Value) -> Self {\n        self.data.insert(key, value);\n        self\n    }\n}\n\n/// Represents a tool call made during agent execution\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ToolCall {\n    /// ID of the tool being called\n    pub tool_id: String,\n    /// Tool name for display\n    pub tool_name: String,\n    /// Input parameters for the tool\n    pub parameters: HashMap<String, Value>,\n    /// Result of the tool call (if completed)\n    pub result: Option<ToolOutput>,\n}\n\n/// Output from a tool execution\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ToolOutput {\n    /// Success status\n    pub success: bool,\n    /// Output data\n    pub data: Value,\n    /// Error message if failed\n    pub error: Option<String>,\n    /// Execution time in milliseconds\n    pub execution_time_ms: Option<u64>,\n}\n\n/// Metadata about agent output\n#[derive(Debug, Clone, Default, Serialize, Deserialize)]\npub struct OutputMetadata {\n    /// Model used for generation\n    pub model: Option<String>,\n    /// Number of tokens used\n    pub token_count: Option<u32>,\n    /// Execution time in milliseconds\n    pub execution_time_ms: Option<u64>,\n    /// Confidence score (0.0 to 1.0)\n    pub confidence: Option<f32>,\n    /// Additional metadata\n    pub extra: HashMap<String, Value>,\n}\n\n/// Enhanced agent input with multimodal support\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AgentInput {\n    /// Text prompt or instruction\n    pub text: String,\n    /// Optional media content\n    pub media: Vec<MediaContent>,\n    /// Context from previous interactions\n    pub context: Option<ExecutionContext>,\n    /// Parameters for execution\n    pub parameters: HashMap<String, Value>,\n    /// Preferred output modalities\n    pub output_modalities: Vec<MediaType>,\n}\n\nimpl AgentInput {\n    /// Create a text-only input\n    pub fn text(text: impl Into<String>) -> Self {\n        Self {\n            text: text.into(),\n            media: vec![],\n            context: None,\n            parameters: HashMap::new(),\n            output_modalities: vec![MediaType::Text],\n        }\n    }\n\n    /// Add media content to the input\n    pub fn with_media(mut self, media: MediaContent) -> Self {\n        self.media.push(media);\n        self\n    }\n\n    /// Add multiple media items\n    pub fn with_media_vec(mut self, media: Vec<MediaContent>) -> Self {\n        self.media.extend(media);\n        self\n    }\n\n    /// Set the execution context\n    pub fn with_context(mut self, context: ExecutionContext) -> Self {\n        self.context = Some(context);\n        self\n    }\n\n    /// Add a parameter\n    pub fn with_parameter(mut self, key: impl Into<String>, value: impl Into<Value>) -> Self {\n        self.parameters.insert(key.into(), value.into());\n        self\n    }\n\n    /// Set output modalities\n    pub fn with_output_modalities(mut self, modalities: Vec<MediaType>) -> Self {\n        self.output_modalities = modalities;\n        self\n    }\n\n    /// Create a builder for more complex inputs\n    pub fn builder() -> AgentInputBuilder {\n        AgentInputBuilder::new()\n    }\n\n    /// Check if input has media content\n    pub fn has_media(&self) -> bool {\n        !self.media.is_empty()\n    }\n\n    /// Get media of a specific type\n    pub fn get_media_by_type(&self, media_type: MediaType) -> Vec<&MediaContent> {\n        self.media\n            .iter()\n            .filter(|m| m.media_type() == media_type)\n            .collect()\n    }\n}\n\nimpl fmt::Display for AgentInput {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(\n            f,\n            \"AgentInput {{ text: \\\"{}\\\", media: {} items\",\n            if self.text.len() > 50 {\n                format!(\"{}...\", &self.text[..50])\n            } else {\n                self.text.clone()\n            },\n            self.media.len()\n        )?;\n        if !self.parameters.is_empty() {\n            write!(f, \", parameters: {} items\", self.parameters.len())?;\n        }\n        write!(f, \" }}\")\n    }\n}\n\n/// Builder for AgentInput\npub struct AgentInputBuilder {\n    text: String,\n    media: Vec<MediaContent>,\n    context: Option<ExecutionContext>,\n    parameters: HashMap<String, Value>,\n    output_modalities: Vec<MediaType>,\n}\n\nimpl AgentInputBuilder {\n    /// Create a new builder\n    pub fn new() -> Self {\n        Self {\n            text: String::new(),\n            media: vec![],\n            context: None,\n            parameters: HashMap::new(),\n            output_modalities: vec![MediaType::Text],\n        }\n    }\n\n    /// Set the text\n    pub fn text(mut self, text: impl Into<String>) -> Self {\n        self.text = text.into();\n        self\n    }\n\n    /// Add media content\n    pub fn add_media(mut self, media: MediaContent) -> Self {\n        self.media.push(media);\n        self\n    }\n\n    /// Set the context\n    pub fn context(mut self, context: ExecutionContext) -> Self {\n        self.context = Some(context);\n        self\n    }\n\n    /// Add a parameter\n    pub fn parameter(mut self, key: impl Into<String>, value: impl Into<Value>) -> Self {\n        self.parameters.insert(key.into(), value.into());\n        self\n    }\n\n    /// Set output modalities\n    pub fn output_modalities(mut self, modalities: Vec<MediaType>) -> Self {\n        self.output_modalities = modalities;\n        self\n    }\n\n    /// Build the AgentInput\n    pub fn build(self) -> AgentInput {\n        AgentInput {\n            text: self.text,\n            media: self.media,\n            context: self.context,\n            parameters: self.parameters,\n            output_modalities: self.output_modalities,\n        }\n    }\n}\n\nimpl Default for AgentInputBuilder {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n/// Enhanced agent output with multimodal support\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AgentOutput {\n    /// Primary text response\n    pub text: String,\n    /// Generated or processed media\n    pub media: Vec<MediaContent>,\n    /// Tool calls made during execution\n    pub tool_calls: Vec<ToolCall>,\n    /// Metadata about the execution\n    pub metadata: OutputMetadata,\n    /// Next agent to transfer to (if any)\n    pub transfer_to: Option<ComponentId>,\n}\n\nimpl AgentOutput {\n    /// Create a text-only output\n    pub fn text(text: impl Into<String>) -> Self {\n        Self {\n            text: text.into(),\n            media: vec![],\n            tool_calls: vec![],\n            metadata: OutputMetadata::default(),\n            transfer_to: None,\n        }\n    }\n\n    /// Add media content to the output\n    pub fn with_media(mut self, media: MediaContent) -> Self {\n        self.media.push(media);\n        self\n    }\n\n    /// Add a tool call\n    pub fn with_tool_call(mut self, tool_call: ToolCall) -> Self {\n        self.tool_calls.push(tool_call);\n        self\n    }\n\n    /// Set metadata\n    pub fn with_metadata(mut self, metadata: OutputMetadata) -> Self {\n        self.metadata = metadata;\n        self\n    }\n\n    /// Set transfer target\n    pub fn with_transfer(mut self, agent_id: ComponentId) -> Self {\n        self.transfer_to = Some(agent_id);\n        self\n    }\n\n    /// Create a builder for more complex outputs\n    pub fn builder() -> AgentOutputBuilder {\n        AgentOutputBuilder::new()\n    }\n\n    /// Check if output has media content\n    pub fn has_media(&self) -> bool {\n        !self.media.is_empty()\n    }\n\n    /// Check if output has tool calls\n    pub fn has_tool_calls(&self) -> bool {\n        !self.tool_calls.is_empty()\n    }\n\n    /// Check if this is a transfer response\n    pub fn is_transfer(&self) -> bool {\n        self.transfer_to.is_some()\n    }\n}\n\nimpl fmt::Display for AgentOutput {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(\n            f,\n            \"AgentOutput {{ text: \\\"{}\\\", media: {} items\",\n            if self.text.len() > 50 {\n                format!(\"{}...\", &self.text[..50])\n            } else {\n                self.text.clone()\n            },\n            self.media.len()\n        )?;\n        if !self.tool_calls.is_empty() {\n            write!(f, \", tool_calls: {} items\", self.tool_calls.len())?;\n        }\n        if let Some(ref agent_id) = self.transfer_to {\n            write!(f, \", transfer_to: {}\", agent_id)?;\n        }\n        write!(f, \" }}\")\n    }\n}\n\n/// Builder for AgentOutput\npub struct AgentOutputBuilder {\n    text: String,\n    media: Vec<MediaContent>,\n    tool_calls: Vec<ToolCall>,\n    metadata: OutputMetadata,\n    transfer_to: Option<ComponentId>,\n}\n\nimpl AgentOutputBuilder {\n    /// Create a new builder\n    pub fn new() -> Self {\n        Self {\n            text: String::new(),\n            media: vec![],\n            tool_calls: vec![],\n            metadata: OutputMetadata::default(),\n            transfer_to: None,\n        }\n    }\n\n    /// Set the text\n    pub fn text(mut self, text: impl Into<String>) -> Self {\n        self.text = text.into();\n        self\n    }\n\n    /// Add media content\n    pub fn add_media(mut self, media: MediaContent) -> Self {\n        self.media.push(media);\n        self\n    }\n\n    /// Add a tool call\n    pub fn add_tool_call(mut self, tool_call: ToolCall) -> Self {\n        self.tool_calls.push(tool_call);\n        self\n    }\n\n    /// Set metadata\n    pub fn metadata(mut self, metadata: OutputMetadata) -> Self {\n        self.metadata = metadata;\n        self\n    }\n\n    /// Set transfer target\n    pub fn transfer_to(mut self, agent_id: ComponentId) -> Self {\n        self.transfer_to = Some(agent_id);\n        self\n    }\n\n    /// Build the AgentOutput\n    pub fn build(self) -> AgentOutput {\n        AgentOutput {\n            text: self.text,\n            media: self.media,\n            tool_calls: self.tool_calls,\n            metadata: self.metadata,\n            transfer_to: self.transfer_to,\n        }\n    }\n}\n\nimpl Default for AgentOutputBuilder {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_agent_input_text_constructor() {\n        let input = AgentInput::text(\"Hello, world!\");\n        assert_eq!(input.text, \"Hello, world!\");\n        assert!(input.media.is_empty());\n        assert!(input.context.is_none());\n        assert!(input.parameters.is_empty());\n        assert_eq!(input.output_modalities, vec![MediaType::Text]);\n    }\n\n    #[test]\n    fn test_agent_input_builder() {\n        let context = ExecutionContext::new()\n            .with_data(\"key\".to_string(), Value::String(\"value\".to_string()));\n\n        let input = AgentInput::builder()\n            .text(\"Test prompt\")\n            .context(context)\n            .parameter(\"temperature\", 0.7)\n            .parameter(\"max_tokens\", 100)\n            .output_modalities(vec![MediaType::Text, MediaType::Image])\n            .build();\n\n        assert_eq!(input.text, \"Test prompt\");\n        assert!(input.context.is_some());\n        assert_eq!(input.parameters.len(), 2);\n        assert_eq!(input.parameters[\"temperature\"], 0.7);\n        assert_eq!(input.parameters[\"max_tokens\"], 100);\n        assert_eq!(input.output_modalities.len(), 2);\n    }\n\n    #[test]\n    fn test_agent_input_with_media() {\n        let media = MediaContent::Text(\"Additional context\".to_string());\n        let input = AgentInput::text(\"Main prompt\").with_media(media);\n\n        assert_eq!(input.text, \"Main prompt\");\n        assert_eq!(input.media.len(), 1);\n        assert!(input.has_media());\n    }\n\n    #[test]\n    fn test_agent_output_text_constructor() {\n        let output = AgentOutput::text(\"Response text\");\n        assert_eq!(output.text, \"Response text\");\n        assert!(output.media.is_empty());\n        assert!(output.tool_calls.is_empty());\n        assert!(output.transfer_to.is_none());\n    }\n\n    #[test]\n    fn test_agent_output_builder() {\n        let tool_call = ToolCall {\n            tool_id: \"tool-123\".to_string(),\n            tool_name: \"Calculator\".to_string(),\n            parameters: HashMap::new(),\n            result: None,\n        };\n\n        let mut metadata = OutputMetadata::default();\n        metadata.model = Some(\"gpt-4\".to_string());\n        metadata.token_count = Some(150);\n\n        let output = AgentOutput::builder()\n            .text(\"Calculated result\")\n            .add_tool_call(tool_call)\n            .metadata(metadata)\n            .build();\n\n        assert_eq!(output.text, \"Calculated result\");\n        assert_eq!(output.tool_calls.len(), 1);\n        assert_eq!(output.tool_calls[0].tool_name, \"Calculator\");\n        assert_eq!(output.metadata.model, Some(\"gpt-4\".to_string()));\n        assert_eq!(output.metadata.token_count, Some(150));\n    }\n\n    #[test]\n    fn test_agent_output_with_transfer() {\n        let agent_id = ComponentId::from_name(\"next-agent\");\n        let output = AgentOutput::text(\"Transferring to specialist\").with_transfer(agent_id);\n\n        assert!(output.is_transfer());\n        assert_eq!(output.transfer_to, Some(agent_id));\n    }\n\n    #[test]\n    fn test_execution_context() {\n        let context = ExecutionContext::with_conversation(\"conv-123\".to_string())\n            .with_data(\"user_name\".to_string(), Value::String(\"Alice\".to_string()))\n            .with_data(\n                \"session_type\".to_string(),\n                Value::String(\"chat\".to_string()),\n            );\n\n        assert_eq!(context.conversation_id, Some(\"conv-123\".to_string()));\n        assert_eq!(context.data.len(), 2);\n        assert_eq!(context.data[\"user_name\"], \"Alice\");\n    }\n\n    #[test]\n    fn test_tool_output() {\n        let output = ToolOutput {\n            success: true,\n            data: serde_json::json!({\"result\": 42}),\n            error: None,\n            execution_time_ms: Some(25),\n        };\n\n        assert!(output.success);\n        assert_eq!(output.data[\"result\"], 42);\n        assert!(output.error.is_none());\n        assert_eq!(output.execution_time_ms, Some(25));\n    }\n\n    #[test]\n    fn test_serialization() {\n        let input = AgentInput::text(\"Test\").with_parameter(\"key\", \"value\");\n        let json = serde_json::to_string(&input).unwrap();\n        let deserialized: AgentInput = serde_json::from_str(&json).unwrap();\n        assert_eq!(input.text, deserialized.text);\n        assert_eq!(input.parameters, deserialized.parameters);\n\n        let output = AgentOutput::text(\"Response\");\n        let json = serde_json::to_string(&output).unwrap();\n        let deserialized: AgentOutput = serde_json::from_str(&json).unwrap();\n        assert_eq!(output.text, deserialized.text);\n    }\n\n    #[test]\n    fn test_display_formatting() {\n        let input = AgentInput::text(\"This is a very long prompt that should be truncated in the display output for readability\");\n        let display = format!(\"{}\", input);\n        assert!(display.contains(\"...\"));\n        assert!(display.contains(\"AgentInput\"));\n\n        let output = AgentOutput::text(\"This is a very long response that should be truncated in the display output for readability\");\n        let display = format!(\"{}\", output);\n        assert!(display.contains(\"...\"));\n        assert!(display.contains(\"AgentOutput\"));\n    }\n}\n","traces":[{"line":25,"address":[],"length":0,"stats":{"Line":3}},{"line":26,"address":[],"length":0,"stats":{"Line":3}},{"line":30,"address":[],"length":0,"stats":{"Line":748}},{"line":32,"address":[],"length":0,"stats":{"Line":748}},{"line":38,"address":[],"length":0,"stats":{"Line":643}},{"line":39,"address":[],"length":0,"stats":{"Line":643}},{"line":40,"address":[],"length":0,"stats":{"Line":643}},{"line":102,"address":[],"length":0,"stats":{"Line":921}},{"line":104,"address":[],"length":0,"stats":{"Line":921}},{"line":105,"address":[],"length":0,"stats":{"Line":921}},{"line":107,"address":[],"length":0,"stats":{"Line":921}},{"line":108,"address":[],"length":0,"stats":{"Line":921}},{"line":113,"address":[],"length":0,"stats":{"Line":1}},{"line":114,"address":[],"length":0,"stats":{"Line":1}},{"line":115,"address":[],"length":0,"stats":{"Line":1}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":1708}},{"line":132,"address":[],"length":0,"stats":{"Line":1708}},{"line":133,"address":[],"length":0,"stats":{"Line":1708}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":1}},{"line":144,"address":[],"length":0,"stats":{"Line":1}},{"line":148,"address":[],"length":0,"stats":{"Line":1}},{"line":149,"address":[],"length":0,"stats":{"Line":1}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":1}},{"line":163,"address":[],"length":0,"stats":{"Line":1}},{"line":164,"address":[],"length":0,"stats":{"Line":1}},{"line":166,"address":[],"length":0,"stats":{"Line":1}},{"line":167,"address":[],"length":0,"stats":{"Line":1}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":1}},{"line":173,"address":[],"length":0,"stats":{"Line":1}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":1}},{"line":191,"address":[],"length":0,"stats":{"Line":1}},{"line":193,"address":[],"length":0,"stats":{"Line":1}},{"line":194,"address":[],"length":0,"stats":{"Line":1}},{"line":196,"address":[],"length":0,"stats":{"Line":1}},{"line":197,"address":[],"length":0,"stats":{"Line":1}},{"line":202,"address":[],"length":0,"stats":{"Line":1}},{"line":203,"address":[],"length":0,"stats":{"Line":1}},{"line":204,"address":[],"length":0,"stats":{"Line":1}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":1}},{"line":215,"address":[],"length":0,"stats":{"Line":1}},{"line":216,"address":[],"length":0,"stats":{"Line":1}},{"line":220,"address":[],"length":0,"stats":{"Line":2}},{"line":221,"address":[],"length":0,"stats":{"Line":2}},{"line":222,"address":[],"length":0,"stats":{"Line":2}},{"line":226,"address":[],"length":0,"stats":{"Line":1}},{"line":227,"address":[],"length":0,"stats":{"Line":1}},{"line":228,"address":[],"length":0,"stats":{"Line":1}},{"line":232,"address":[],"length":0,"stats":{"Line":1}},{"line":234,"address":[],"length":0,"stats":{"Line":1}},{"line":235,"address":[],"length":0,"stats":{"Line":1}},{"line":236,"address":[],"length":0,"stats":{"Line":1}},{"line":237,"address":[],"length":0,"stats":{"Line":1}},{"line":238,"address":[],"length":0,"stats":{"Line":1}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":788}},{"line":268,"address":[],"length":0,"stats":{"Line":788}},{"line":269,"address":[],"length":0,"stats":{"Line":788}},{"line":270,"address":[],"length":0,"stats":{"Line":788}},{"line":271,"address":[],"length":0,"stats":{"Line":788}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":560}},{"line":290,"address":[],"length":0,"stats":{"Line":560}},{"line":291,"address":[],"length":0,"stats":{"Line":560}},{"line":295,"address":[],"length":0,"stats":{"Line":1}},{"line":296,"address":[],"length":0,"stats":{"Line":1}},{"line":297,"address":[],"length":0,"stats":{"Line":1}},{"line":301,"address":[],"length":0,"stats":{"Line":1}},{"line":302,"address":[],"length":0,"stats":{"Line":1}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":1}},{"line":317,"address":[],"length":0,"stats":{"Line":1}},{"line":322,"address":[],"length":0,"stats":{"Line":1}},{"line":323,"address":[],"length":0,"stats":{"Line":1}},{"line":324,"address":[],"length":0,"stats":{"Line":1}},{"line":326,"address":[],"length":0,"stats":{"Line":1}},{"line":327,"address":[],"length":0,"stats":{"Line":1}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":1}},{"line":333,"address":[],"length":0,"stats":{"Line":1}},{"line":334,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":1}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":1}},{"line":354,"address":[],"length":0,"stats":{"Line":1}},{"line":356,"address":[],"length":0,"stats":{"Line":1}},{"line":357,"address":[],"length":0,"stats":{"Line":1}},{"line":358,"address":[],"length":0,"stats":{"Line":1}},{"line":359,"address":[],"length":0,"stats":{"Line":1}},{"line":365,"address":[],"length":0,"stats":{"Line":1}},{"line":366,"address":[],"length":0,"stats":{"Line":1}},{"line":367,"address":[],"length":0,"stats":{"Line":1}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":373,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":1}},{"line":378,"address":[],"length":0,"stats":{"Line":1}},{"line":379,"address":[],"length":0,"stats":{"Line":1}},{"line":383,"address":[],"length":0,"stats":{"Line":1}},{"line":384,"address":[],"length":0,"stats":{"Line":1}},{"line":385,"address":[],"length":0,"stats":{"Line":1}},{"line":389,"address":[],"length":0,"stats":{"Line":0}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":391,"address":[],"length":0,"stats":{"Line":0}},{"line":395,"address":[],"length":0,"stats":{"Line":1}},{"line":397,"address":[],"length":0,"stats":{"Line":1}},{"line":398,"address":[],"length":0,"stats":{"Line":1}},{"line":399,"address":[],"length":0,"stats":{"Line":1}},{"line":400,"address":[],"length":0,"stats":{"Line":1}},{"line":401,"address":[],"length":0,"stats":{"Line":1}},{"line":407,"address":[],"length":0,"stats":{"Line":0}},{"line":408,"address":[],"length":0,"stats":{"Line":0}}],"covered":97,"coverable":137},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-core","src","types","media.rs"],"content":"//! ABOUTME: Multimodal content types for text, image, audio, video, and binary data\n//! ABOUTME: Provides MediaContent enum, format types, metadata structures, and validation helpers\n\nuse serde::{Deserialize, Serialize};\nuse std::fmt;\n\n/// Maximum file size limits for different media types (in bytes)\npub const MAX_IMAGE_SIZE: usize = 100 * 1024 * 1024; // 100MB\npub const MAX_AUDIO_SIZE: usize = 500 * 1024 * 1024; // 500MB\npub const MAX_VIDEO_SIZE: usize = 5 * 1024 * 1024 * 1024; // 5GB\npub const MAX_BINARY_SIZE: usize = 1024 * 1024 * 1024; // 1GB\n\n/// Multimodal content that can be processed by agents\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::types::{MediaContent, ImageFormat, ImageMetadata, ColorSpace};\n///\n/// // Text content\n/// let text = MediaContent::Text(\"Hello world\".to_string());\n///\n/// // Image content with metadata\n/// let image = MediaContent::Image {\n///     data: vec![0xFF, 0xD8, 0xFF], // JPEG header\n///     format: ImageFormat::Jpeg,\n///     metadata: ImageMetadata {\n///         width: 1920,\n///         height: 1080,\n///         color_space: ColorSpace::RGB,\n///         has_transparency: false,\n///         dpi: Some(72),\n///     },\n/// };\n/// ```\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\n#[serde(tag = \"type\", rename_all = \"snake_case\")]\npub enum MediaContent {\n    /// Plain text content\n    Text(String),\n\n    /// Image data with format and metadata\n    Image {\n        /// Raw image bytes\n        data: Vec<u8>,\n        /// Image format\n        format: ImageFormat,\n        /// Image metadata\n        metadata: ImageMetadata,\n    },\n\n    /// Audio data with format and metadata\n    Audio {\n        /// Raw audio bytes\n        data: Vec<u8>,\n        /// Audio format\n        format: AudioFormat,\n        /// Audio metadata\n        metadata: AudioMetadata,\n    },\n\n    /// Video data with format and metadata\n    Video {\n        /// Raw video bytes\n        data: Vec<u8>,\n        /// Video format\n        format: VideoFormat,\n        /// Video metadata\n        metadata: VideoMetadata,\n    },\n\n    /// Generic binary data\n    Binary {\n        /// Raw binary bytes\n        data: Vec<u8>,\n        /// MIME type if known\n        mime_type: Option<String>,\n        /// Original filename if available\n        filename: Option<String>,\n    },\n}\n\n/// Supported image formats\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]\n#[serde(rename_all = \"snake_case\")]\npub enum ImageFormat {\n    /// PNG format\n    Png,\n    /// JPEG format\n    Jpeg,\n    /// WebP format\n    Webp,\n    /// GIF format\n    Gif,\n    /// SVG format\n    Svg,\n    /// TIFF format\n    Tiff,\n}\n\n/// Supported audio formats\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]\n#[serde(rename_all = \"snake_case\")]\npub enum AudioFormat {\n    /// MP3 format\n    Mp3,\n    /// WAV format\n    Wav,\n    /// FLAC format\n    Flac,\n    /// OGG format\n    Ogg,\n    /// M4A format\n    M4a,\n}\n\n/// Supported video formats\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]\n#[serde(rename_all = \"snake_case\")]\npub enum VideoFormat {\n    /// MP4 format\n    Mp4,\n    /// WebM format\n    Webm,\n    /// AVI format\n    Avi,\n    /// MOV format\n    Mov,\n    /// MKV format\n    Mkv,\n}\n\n/// Color space information for images\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]\n#[serde(rename_all = \"snake_case\")]\npub enum ColorSpace {\n    /// RGB color space\n    RGB,\n    /// RGBA color space (with alpha)\n    RGBA,\n    /// Grayscale\n    Grayscale,\n    /// CMYK color space\n    CMYK,\n}\n\n/// Metadata for image content\n#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]\npub struct ImageMetadata {\n    /// Image width in pixels\n    pub width: u32,\n    /// Image height in pixels\n    pub height: u32,\n    /// Color space\n    pub color_space: ColorSpace,\n    /// Whether image has transparency\n    pub has_transparency: bool,\n    /// Dots per inch (if available)\n    pub dpi: Option<u32>,\n}\n\n/// Metadata for audio content\n#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]\npub struct AudioMetadata {\n    /// Duration in milliseconds\n    pub duration_ms: u64,\n    /// Sample rate in Hz\n    pub sample_rate: u32,\n    /// Number of channels (1 = mono, 2 = stereo, etc.)\n    pub channels: u8,\n    /// Bitrate in bits per second\n    pub bitrate: Option<u32>,\n}\n\n/// Metadata for video content\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\npub struct VideoMetadata {\n    /// Duration in milliseconds\n    pub duration_ms: u64,\n    /// Video width in pixels\n    pub width: u32,\n    /// Video height in pixels\n    pub height: u32,\n    /// Frames per second\n    pub fps: f32,\n    /// Video codec name\n    pub codec: Option<String>,\n}\n\n/// Media types for capability detection\n///\n/// Used to indicate which media types an agent or tool can handle.\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::types::MediaType;\n///\n/// let supported_types = vec![\n///     MediaType::Text,\n///     MediaType::Image,\n/// ];\n///\n/// // Check if audio is supported\n/// if supported_types.contains(&MediaType::Audio) {\n///     println!(\"Audio processing available\");\n/// }\n/// ```\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]\n#[serde(rename_all = \"snake_case\")]\npub enum MediaType {\n    /// Text content\n    Text,\n    /// Image content\n    Image,\n    /// Audio content\n    Audio,\n    /// Video content\n    Video,\n    /// Binary content\n    Binary,\n}\n\n// Display implementations\n\nimpl fmt::Display for MediaContent {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            MediaContent::Text(text) => {\n                write!(f, \"Text({} chars)\", text.len())\n            }\n            MediaContent::Image {\n                format, metadata, ..\n            } => {\n                write!(\n                    f,\n                    \"Image({:?}, {}x{})\",\n                    format, metadata.width, metadata.height\n                )\n            }\n            MediaContent::Audio {\n                format, metadata, ..\n            } => {\n                write!(f, \"Audio({:?}, {}ms)\", format, metadata.duration_ms)\n            }\n            MediaContent::Video {\n                format, metadata, ..\n            } => {\n                write!(\n                    f,\n                    \"Video({:?}, {}x{}, {}ms)\",\n                    format, metadata.width, metadata.height, metadata.duration_ms\n                )\n            }\n            MediaContent::Binary {\n                mime_type,\n                filename,\n                data,\n            } => {\n                write!(f, \"Binary({} bytes\", data.len())?;\n                if let Some(mime) = mime_type {\n                    write!(f, \", {}\", mime)?;\n                }\n                if let Some(name) = filename {\n                    write!(f, \", {}\", name)?;\n                }\n                write!(f, \")\")\n            }\n        }\n    }\n}\n\nimpl fmt::Display for ImageFormat {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            ImageFormat::Png => write!(f, \"PNG\"),\n            ImageFormat::Jpeg => write!(f, \"JPEG\"),\n            ImageFormat::Webp => write!(f, \"WebP\"),\n            ImageFormat::Gif => write!(f, \"GIF\"),\n            ImageFormat::Svg => write!(f, \"SVG\"),\n            ImageFormat::Tiff => write!(f, \"TIFF\"),\n        }\n    }\n}\n\nimpl fmt::Display for AudioFormat {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            AudioFormat::Mp3 => write!(f, \"MP3\"),\n            AudioFormat::Wav => write!(f, \"WAV\"),\n            AudioFormat::Flac => write!(f, \"FLAC\"),\n            AudioFormat::Ogg => write!(f, \"OGG\"),\n            AudioFormat::M4a => write!(f, \"M4A\"),\n        }\n    }\n}\n\nimpl fmt::Display for VideoFormat {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            VideoFormat::Mp4 => write!(f, \"MP4\"),\n            VideoFormat::Webm => write!(f, \"WebM\"),\n            VideoFormat::Avi => write!(f, \"AVI\"),\n            VideoFormat::Mov => write!(f, \"MOV\"),\n            VideoFormat::Mkv => write!(f, \"MKV\"),\n        }\n    }\n}\n\nimpl fmt::Display for ColorSpace {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            ColorSpace::RGB => write!(f, \"RGB\"),\n            ColorSpace::RGBA => write!(f, \"RGBA\"),\n            ColorSpace::Grayscale => write!(f, \"Grayscale\"),\n            ColorSpace::CMYK => write!(f, \"CMYK\"),\n        }\n    }\n}\n\nimpl fmt::Display for MediaType {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            MediaType::Text => write!(f, \"Text\"),\n            MediaType::Image => write!(f, \"Image\"),\n            MediaType::Audio => write!(f, \"Audio\"),\n            MediaType::Video => write!(f, \"Video\"),\n            MediaType::Binary => write!(f, \"Binary\"),\n        }\n    }\n}\n\n// Helper implementations\n\nimpl MediaContent {\n    /// Get the size of the content in bytes\n    pub fn size_bytes(&self) -> usize {\n        match self {\n            MediaContent::Text(text) => text.len(),\n            MediaContent::Image { data, .. } => data.len(),\n            MediaContent::Audio { data, .. } => data.len(),\n            MediaContent::Video { data, .. } => data.len(),\n            MediaContent::Binary { data, .. } => data.len(),\n        }\n    }\n\n    /// Get the media type of this content\n    pub fn media_type(&self) -> MediaType {\n        match self {\n            MediaContent::Text(_) => MediaType::Text,\n            MediaContent::Image { .. } => MediaType::Image,\n            MediaContent::Audio { .. } => MediaType::Audio,\n            MediaContent::Video { .. } => MediaType::Video,\n            MediaContent::Binary { .. } => MediaType::Binary,\n        }\n    }\n\n    /// Validate size constraints\n    pub fn validate_size(&self) -> Result<(), String> {\n        let size = self.size_bytes();\n        let (max_size, type_name) = match self {\n            MediaContent::Text(_) => return Ok(()), // No size limit for text\n            MediaContent::Image { .. } => (MAX_IMAGE_SIZE, \"image\"),\n            MediaContent::Audio { .. } => (MAX_AUDIO_SIZE, \"audio\"),\n            MediaContent::Video { .. } => (MAX_VIDEO_SIZE, \"video\"),\n            MediaContent::Binary { .. } => (MAX_BINARY_SIZE, \"binary\"),\n        };\n\n        if size > max_size {\n            Err(format!(\n                \"{} size {} bytes exceeds maximum {} bytes\",\n                type_name, size, max_size\n            ))\n        } else {\n            Ok(())\n        }\n    }\n}\n\nimpl ImageFormat {\n    /// Get MIME type for the image format\n    pub fn mime_type(&self) -> &'static str {\n        match self {\n            ImageFormat::Png => \"image/png\",\n            ImageFormat::Jpeg => \"image/jpeg\",\n            ImageFormat::Webp => \"image/webp\",\n            ImageFormat::Gif => \"image/gif\",\n            ImageFormat::Svg => \"image/svg+xml\",\n            ImageFormat::Tiff => \"image/tiff\",\n        }\n    }\n\n    /// Get common file extensions for the format\n    pub fn extensions(&self) -> &'static [&'static str] {\n        match self {\n            ImageFormat::Png => &[\"png\"],\n            ImageFormat::Jpeg => &[\"jpg\", \"jpeg\"],\n            ImageFormat::Webp => &[\"webp\"],\n            ImageFormat::Gif => &[\"gif\"],\n            ImageFormat::Svg => &[\"svg\"],\n            ImageFormat::Tiff => &[\"tif\", \"tiff\"],\n        }\n    }\n}\n\nimpl AudioFormat {\n    /// Get MIME type for the audio format\n    pub fn mime_type(&self) -> &'static str {\n        match self {\n            AudioFormat::Mp3 => \"audio/mpeg\",\n            AudioFormat::Wav => \"audio/wav\",\n            AudioFormat::Flac => \"audio/flac\",\n            AudioFormat::Ogg => \"audio/ogg\",\n            AudioFormat::M4a => \"audio/mp4\",\n        }\n    }\n\n    /// Get common file extensions for the format\n    pub fn extensions(&self) -> &'static [&'static str] {\n        match self {\n            AudioFormat::Mp3 => &[\"mp3\"],\n            AudioFormat::Wav => &[\"wav\"],\n            AudioFormat::Flac => &[\"flac\"],\n            AudioFormat::Ogg => &[\"ogg\", \"oga\"],\n            AudioFormat::M4a => &[\"m4a\"],\n        }\n    }\n}\n\nimpl VideoFormat {\n    /// Get MIME type for the video format\n    pub fn mime_type(&self) -> &'static str {\n        match self {\n            VideoFormat::Mp4 => \"video/mp4\",\n            VideoFormat::Webm => \"video/webm\",\n            VideoFormat::Avi => \"video/x-msvideo\",\n            VideoFormat::Mov => \"video/quicktime\",\n            VideoFormat::Mkv => \"video/x-matroska\",\n        }\n    }\n\n    /// Get common file extensions for the format\n    pub fn extensions(&self) -> &'static [&'static str] {\n        match self {\n            VideoFormat::Mp4 => &[\"mp4\"],\n            VideoFormat::Webm => &[\"webm\"],\n            VideoFormat::Avi => &[\"avi\"],\n            VideoFormat::Mov => &[\"mov\"],\n            VideoFormat::Mkv => &[\"mkv\"],\n        }\n    }\n}\n\n// Type conversion utilities\n\nimpl TryFrom<&str> for ImageFormat {\n    type Error = String;\n\n    fn try_from(ext: &str) -> Result<Self, Self::Error> {\n        match ext.to_lowercase().as_str() {\n            \"png\" => Ok(ImageFormat::Png),\n            \"jpg\" | \"jpeg\" => Ok(ImageFormat::Jpeg),\n            \"webp\" => Ok(ImageFormat::Webp),\n            \"gif\" => Ok(ImageFormat::Gif),\n            \"svg\" => Ok(ImageFormat::Svg),\n            \"tif\" | \"tiff\" => Ok(ImageFormat::Tiff),\n            _ => Err(format!(\"Unknown image format: {}\", ext)),\n        }\n    }\n}\n\nimpl TryFrom<&str> for AudioFormat {\n    type Error = String;\n\n    fn try_from(ext: &str) -> Result<Self, Self::Error> {\n        match ext.to_lowercase().as_str() {\n            \"mp3\" => Ok(AudioFormat::Mp3),\n            \"wav\" => Ok(AudioFormat::Wav),\n            \"flac\" => Ok(AudioFormat::Flac),\n            \"ogg\" | \"oga\" => Ok(AudioFormat::Ogg),\n            \"m4a\" => Ok(AudioFormat::M4a),\n            _ => Err(format!(\"Unknown audio format: {}\", ext)),\n        }\n    }\n}\n\nimpl TryFrom<&str> for VideoFormat {\n    type Error = String;\n\n    fn try_from(ext: &str) -> Result<Self, Self::Error> {\n        match ext.to_lowercase().as_str() {\n            \"mp4\" => Ok(VideoFormat::Mp4),\n            \"webm\" => Ok(VideoFormat::Webm),\n            \"avi\" => Ok(VideoFormat::Avi),\n            \"mov\" => Ok(VideoFormat::Mov),\n            \"mkv\" => Ok(VideoFormat::Mkv),\n            _ => Err(format!(\"Unknown video format: {}\", ext)),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_media_content_text() {\n        let content = MediaContent::Text(\"Hello, world!\".to_string());\n        assert_eq!(content.size_bytes(), 13);\n        assert_eq!(content.media_type(), MediaType::Text);\n        assert!(content.validate_size().is_ok());\n        assert_eq!(format!(\"{}\", content), \"Text(13 chars)\");\n    }\n\n    #[test]\n    fn test_media_content_image() {\n        let content = MediaContent::Image {\n            data: vec![0xFF, 0xD8, 0xFF],\n            format: ImageFormat::Jpeg,\n            metadata: ImageMetadata {\n                width: 1920,\n                height: 1080,\n                color_space: ColorSpace::RGB,\n                has_transparency: false,\n                dpi: Some(72),\n            },\n        };\n\n        assert_eq!(content.size_bytes(), 3);\n        assert_eq!(content.media_type(), MediaType::Image);\n        assert!(content.validate_size().is_ok());\n        assert_eq!(format!(\"{}\", content), \"Image(Jpeg, 1920x1080)\");\n    }\n\n    #[test]\n    fn test_media_content_audio() {\n        let content = MediaContent::Audio {\n            data: vec![0x00; 1024],\n            format: AudioFormat::Mp3,\n            metadata: AudioMetadata {\n                duration_ms: 180000,\n                sample_rate: 44100,\n                channels: 2,\n                bitrate: Some(320000),\n            },\n        };\n\n        assert_eq!(content.size_bytes(), 1024);\n        assert_eq!(content.media_type(), MediaType::Audio);\n        assert!(content.validate_size().is_ok());\n        assert_eq!(format!(\"{}\", content), \"Audio(Mp3, 180000ms)\");\n    }\n\n    #[test]\n    fn test_media_content_video() {\n        let content = MediaContent::Video {\n            data: vec![0x00; 2048],\n            format: VideoFormat::Mp4,\n            metadata: VideoMetadata {\n                duration_ms: 60000,\n                width: 1920,\n                height: 1080,\n                fps: 30.0,\n                codec: Some(\"h264\".to_string()),\n            },\n        };\n\n        assert_eq!(content.size_bytes(), 2048);\n        assert_eq!(content.media_type(), MediaType::Video);\n        assert!(content.validate_size().is_ok());\n        assert_eq!(format!(\"{}\", content), \"Video(Mp4, 1920x1080, 60000ms)\");\n    }\n\n    #[test]\n    fn test_media_content_binary() {\n        let content = MediaContent::Binary {\n            data: vec![0x00; 512],\n            mime_type: Some(\"application/pdf\".to_string()),\n            filename: Some(\"document.pdf\".to_string()),\n        };\n\n        assert_eq!(content.size_bytes(), 512);\n        assert_eq!(content.media_type(), MediaType::Binary);\n        assert!(content.validate_size().is_ok());\n        assert_eq!(\n            format!(\"{}\", content),\n            \"Binary(512 bytes, application/pdf, document.pdf)\"\n        );\n    }\n\n    #[test]\n    fn test_size_validation() {\n        // Test oversized image\n        let oversized_image = MediaContent::Image {\n            data: vec![0x00; MAX_IMAGE_SIZE + 1],\n            format: ImageFormat::Png,\n            metadata: ImageMetadata {\n                width: 10000,\n                height: 10000,\n                color_space: ColorSpace::RGBA,\n                has_transparency: true,\n                dpi: None,\n            },\n        };\n\n        assert!(oversized_image.validate_size().is_err());\n    }\n\n    #[test]\n    fn test_image_format_conversions() {\n        assert_eq!(ImageFormat::try_from(\"png\").unwrap(), ImageFormat::Png);\n        assert_eq!(ImageFormat::try_from(\"JPG\").unwrap(), ImageFormat::Jpeg);\n        assert_eq!(ImageFormat::try_from(\"jpeg\").unwrap(), ImageFormat::Jpeg);\n        assert!(ImageFormat::try_from(\"unknown\").is_err());\n\n        assert_eq!(ImageFormat::Png.mime_type(), \"image/png\");\n        assert_eq!(ImageFormat::Jpeg.extensions(), &[\"jpg\", \"jpeg\"]);\n    }\n\n    #[test]\n    fn test_audio_format_conversions() {\n        assert_eq!(AudioFormat::try_from(\"mp3\").unwrap(), AudioFormat::Mp3);\n        assert_eq!(AudioFormat::try_from(\"WAV\").unwrap(), AudioFormat::Wav);\n        assert!(AudioFormat::try_from(\"unknown\").is_err());\n\n        assert_eq!(AudioFormat::Mp3.mime_type(), \"audio/mpeg\");\n        assert_eq!(AudioFormat::Ogg.extensions(), &[\"ogg\", \"oga\"]);\n    }\n\n    #[test]\n    fn test_video_format_conversions() {\n        assert_eq!(VideoFormat::try_from(\"mp4\").unwrap(), VideoFormat::Mp4);\n        assert_eq!(VideoFormat::try_from(\"WEBM\").unwrap(), VideoFormat::Webm);\n        assert!(VideoFormat::try_from(\"unknown\").is_err());\n\n        assert_eq!(VideoFormat::Mp4.mime_type(), \"video/mp4\");\n        assert_eq!(VideoFormat::Mkv.extensions(), &[\"mkv\"]);\n    }\n\n    #[test]\n    fn test_display_implementations() {\n        assert_eq!(format!(\"{}\", ImageFormat::Png), \"PNG\");\n        assert_eq!(format!(\"{}\", AudioFormat::Mp3), \"MP3\");\n        assert_eq!(format!(\"{}\", VideoFormat::Mp4), \"MP4\");\n        assert_eq!(format!(\"{}\", ColorSpace::RGB), \"RGB\");\n        assert_eq!(format!(\"{}\", MediaType::Image), \"Image\");\n    }\n\n    #[test]\n    fn test_serialization() {\n        let metadata = ImageMetadata {\n            width: 1920,\n            height: 1080,\n            color_space: ColorSpace::RGB,\n            has_transparency: false,\n            dpi: Some(72),\n        };\n\n        let json = serde_json::to_string(&metadata).unwrap();\n        let deserialized: ImageMetadata = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(metadata, deserialized);\n    }\n\n    #[test]\n    fn test_media_content_serialization() {\n        let content = MediaContent::Image {\n            data: vec![0xFF, 0xD8],\n            format: ImageFormat::Jpeg,\n            metadata: ImageMetadata {\n                width: 800,\n                height: 600,\n                color_space: ColorSpace::RGB,\n                has_transparency: false,\n                dpi: None,\n            },\n        };\n\n        let json = serde_json::to_string(&content).unwrap();\n        let deserialized: MediaContent = serde_json::from_str(&json).unwrap();\n\n        match deserialized {\n            MediaContent::Image {\n                format, metadata, ..\n            } => {\n                assert_eq!(format, ImageFormat::Jpeg);\n                assert_eq!(metadata.width, 800);\n                assert_eq!(metadata.height, 600);\n            }\n            _ => panic!(\"Expected image content\"),\n        }\n    }\n}\n","traces":[{"line":227,"address":[],"length":0,"stats":{"Line":5}},{"line":228,"address":[],"length":0,"stats":{"Line":5}},{"line":229,"address":[],"length":0,"stats":{"Line":1}},{"line":230,"address":[],"length":0,"stats":{"Line":1}},{"line":233,"address":[],"length":0,"stats":{"Line":1}},{"line":234,"address":[],"length":0,"stats":{"Line":1}},{"line":235,"address":[],"length":0,"stats":{"Line":1}},{"line":236,"address":[],"length":0,"stats":{"Line":1}},{"line":238,"address":[],"length":0,"stats":{"Line":1}},{"line":242,"address":[],"length":0,"stats":{"Line":1}},{"line":243,"address":[],"length":0,"stats":{"Line":1}},{"line":244,"address":[],"length":0,"stats":{"Line":1}},{"line":247,"address":[],"length":0,"stats":{"Line":1}},{"line":248,"address":[],"length":0,"stats":{"Line":1}},{"line":249,"address":[],"length":0,"stats":{"Line":1}},{"line":250,"address":[],"length":0,"stats":{"Line":1}},{"line":252,"address":[],"length":0,"stats":{"Line":1}},{"line":256,"address":[],"length":0,"stats":{"Line":1}},{"line":257,"address":[],"length":0,"stats":{"Line":1}},{"line":258,"address":[],"length":0,"stats":{"Line":1}},{"line":259,"address":[],"length":0,"stats":{"Line":1}},{"line":260,"address":[],"length":0,"stats":{"Line":1}},{"line":261,"address":[],"length":0,"stats":{"Line":2}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":2}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":1}},{"line":274,"address":[],"length":0,"stats":{"Line":1}},{"line":275,"address":[],"length":0,"stats":{"Line":1}},{"line":276,"address":[],"length":0,"stats":{"Line":1}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":1}},{"line":288,"address":[],"length":0,"stats":{"Line":1}},{"line":289,"address":[],"length":0,"stats":{"Line":1}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":1}},{"line":300,"address":[],"length":0,"stats":{"Line":1}},{"line":301,"address":[],"length":0,"stats":{"Line":1}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":1}},{"line":312,"address":[],"length":0,"stats":{"Line":1}},{"line":313,"address":[],"length":0,"stats":{"Line":1}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":1}},{"line":323,"address":[],"length":0,"stats":{"Line":1}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":325,"address":[],"length":0,"stats":{"Line":1}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":11}},{"line":338,"address":[],"length":0,"stats":{"Line":11}},{"line":339,"address":[],"length":0,"stats":{"Line":2}},{"line":340,"address":[],"length":0,"stats":{"Line":3}},{"line":341,"address":[],"length":0,"stats":{"Line":2}},{"line":342,"address":[],"length":0,"stats":{"Line":2}},{"line":343,"address":[],"length":0,"stats":{"Line":2}},{"line":348,"address":[],"length":0,"stats":{"Line":5}},{"line":349,"address":[],"length":0,"stats":{"Line":5}},{"line":350,"address":[],"length":0,"stats":{"Line":1}},{"line":351,"address":[],"length":0,"stats":{"Line":1}},{"line":352,"address":[],"length":0,"stats":{"Line":1}},{"line":353,"address":[],"length":0,"stats":{"Line":1}},{"line":354,"address":[],"length":0,"stats":{"Line":1}},{"line":359,"address":[],"length":0,"stats":{"Line":6}},{"line":360,"address":[],"length":0,"stats":{"Line":6}},{"line":361,"address":[],"length":0,"stats":{"Line":11}},{"line":362,"address":[],"length":0,"stats":{"Line":1}},{"line":363,"address":[],"length":0,"stats":{"Line":2}},{"line":364,"address":[],"length":0,"stats":{"Line":1}},{"line":365,"address":[],"length":0,"stats":{"Line":1}},{"line":366,"address":[],"length":0,"stats":{"Line":1}},{"line":370,"address":[],"length":0,"stats":{"Line":1}},{"line":371,"address":[],"length":0,"stats":{"Line":1}},{"line":372,"address":[],"length":0,"stats":{"Line":1}},{"line":375,"address":[],"length":0,"stats":{"Line":4}},{"line":382,"address":[],"length":0,"stats":{"Line":1}},{"line":383,"address":[],"length":0,"stats":{"Line":1}},{"line":384,"address":[],"length":0,"stats":{"Line":1}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":386,"address":[],"length":0,"stats":{"Line":0}},{"line":387,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":389,"address":[],"length":0,"stats":{"Line":0}},{"line":394,"address":[],"length":0,"stats":{"Line":1}},{"line":395,"address":[],"length":0,"stats":{"Line":1}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":397,"address":[],"length":0,"stats":{"Line":1}},{"line":398,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":400,"address":[],"length":0,"stats":{"Line":0}},{"line":401,"address":[],"length":0,"stats":{"Line":0}},{"line":408,"address":[],"length":0,"stats":{"Line":1}},{"line":409,"address":[],"length":0,"stats":{"Line":1}},{"line":410,"address":[],"length":0,"stats":{"Line":1}},{"line":411,"address":[],"length":0,"stats":{"Line":0}},{"line":412,"address":[],"length":0,"stats":{"Line":0}},{"line":413,"address":[],"length":0,"stats":{"Line":0}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":419,"address":[],"length":0,"stats":{"Line":1}},{"line":420,"address":[],"length":0,"stats":{"Line":1}},{"line":421,"address":[],"length":0,"stats":{"Line":0}},{"line":422,"address":[],"length":0,"stats":{"Line":0}},{"line":423,"address":[],"length":0,"stats":{"Line":0}},{"line":424,"address":[],"length":0,"stats":{"Line":1}},{"line":425,"address":[],"length":0,"stats":{"Line":0}},{"line":432,"address":[],"length":0,"stats":{"Line":1}},{"line":433,"address":[],"length":0,"stats":{"Line":1}},{"line":434,"address":[],"length":0,"stats":{"Line":1}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":443,"address":[],"length":0,"stats":{"Line":1}},{"line":444,"address":[],"length":0,"stats":{"Line":1}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":446,"address":[],"length":0,"stats":{"Line":0}},{"line":447,"address":[],"length":0,"stats":{"Line":0}},{"line":448,"address":[],"length":0,"stats":{"Line":0}},{"line":449,"address":[],"length":0,"stats":{"Line":1}},{"line":459,"address":[],"length":0,"stats":{"Line":4}},{"line":460,"address":[],"length":0,"stats":{"Line":4}},{"line":461,"address":[],"length":0,"stats":{"Line":5}},{"line":462,"address":[],"length":0,"stats":{"Line":7}},{"line":463,"address":[],"length":0,"stats":{"Line":1}},{"line":464,"address":[],"length":0,"stats":{"Line":1}},{"line":465,"address":[],"length":0,"stats":{"Line":1}},{"line":466,"address":[],"length":0,"stats":{"Line":2}},{"line":467,"address":[],"length":0,"stats":{"Line":1}},{"line":475,"address":[],"length":0,"stats":{"Line":3}},{"line":476,"address":[],"length":0,"stats":{"Line":3}},{"line":477,"address":[],"length":0,"stats":{"Line":4}},{"line":478,"address":[],"length":0,"stats":{"Line":3}},{"line":479,"address":[],"length":0,"stats":{"Line":1}},{"line":480,"address":[],"length":0,"stats":{"Line":2}},{"line":481,"address":[],"length":0,"stats":{"Line":1}},{"line":482,"address":[],"length":0,"stats":{"Line":1}},{"line":490,"address":[],"length":0,"stats":{"Line":3}},{"line":491,"address":[],"length":0,"stats":{"Line":3}},{"line":492,"address":[],"length":0,"stats":{"Line":4}},{"line":493,"address":[],"length":0,"stats":{"Line":3}},{"line":494,"address":[],"length":0,"stats":{"Line":1}},{"line":495,"address":[],"length":0,"stats":{"Line":1}},{"line":496,"address":[],"length":0,"stats":{"Line":1}},{"line":497,"address":[],"length":0,"stats":{"Line":1}}],"covered":109,"coverable":157},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-core","src","types","mod.rs"],"content":"//! ABOUTME: Core types and foundational data structures\n//! ABOUTME: Provides ComponentId, Version, ComponentMetadata and streaming types\n\nmod agent_io;\nmod media;\nmod streaming;\n\npub use agent_io::{\n    AgentInput, AgentInputBuilder, AgentOutput, AgentOutputBuilder, ExecutionContext,\n    OutputMetadata, ToolCall, ToolOutput,\n};\npub use media::{\n    AudioFormat, AudioMetadata, ColorSpace, ImageFormat, ImageMetadata, MediaContent, MediaType,\n    VideoFormat, VideoMetadata, MAX_AUDIO_SIZE, MAX_BINARY_SIZE, MAX_IMAGE_SIZE, MAX_VIDEO_SIZE,\n};\npub use streaming::{\n    AgentChunk, AgentStream, ChunkContent, ChunkMetadata, ControlMessage, ReasoningStep,\n};\n\nuse serde::{Deserialize, Serialize};\nuse std::fmt;\nuse uuid::Uuid;\n\n/// Unique identifier for components in the LLMSpell system.\n///\n/// `ComponentId` uses UUID v4 for random generation and UUID v5 for deterministic\n/// generation from names. This allows both unique random IDs and reproducible IDs\n/// for named components.\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::ComponentId;\n///\n/// // Create a random ID\n/// let id1 = ComponentId::new();\n/// let id2 = ComponentId::new();\n/// assert_ne!(id1, id2);\n///\n/// // Create deterministic ID from name\n/// let id3 = ComponentId::from_name(\"my-agent\");\n/// let id4 = ComponentId::from_name(\"my-agent\");\n/// assert_eq!(id3, id4);\n/// ```\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]\npub struct ComponentId(Uuid);\n\nimpl ComponentId {\n    /// Generate a new random ComponentId\n    pub fn new() -> Self {\n        Self(Uuid::new_v4())\n    }\n\n    /// Create ComponentId from name (deterministic)\n    pub fn from_name(name: &str) -> Self {\n        let namespace = Uuid::NAMESPACE_DNS;\n        Self(Uuid::new_v5(&namespace, name.as_bytes()))\n    }\n\n    /// Get inner UUID\n    pub fn uuid(&self) -> Uuid {\n        self.0\n    }\n}\n\nimpl fmt::Display for ComponentId {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"{}\", self.0)\n    }\n}\n\nimpl Default for ComponentId {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n/// Semantic version information for components.\n///\n/// Follows semantic versioning specification (major.minor.patch).\n/// Used to track component versions and check compatibility.\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::Version;\n///\n/// let v1 = Version::new(1, 0, 0);\n/// let v2 = Version::new(1, 1, 0);\n///\n/// // Check compatibility (same major version)\n/// assert!(v1.is_compatible_with(&v2));\n///\n/// // Check if newer\n/// assert!(v2.is_newer_than(&v1));\n///\n/// // Display version\n/// assert_eq!(v1.to_string(), \"1.0.0\");\n/// ```\n#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord, Serialize, Deserialize)]\npub struct Version {\n    pub major: u32,\n    pub minor: u32,\n    pub patch: u32,\n}\n\nimpl Version {\n    pub fn new(major: u32, minor: u32, patch: u32) -> Self {\n        Self {\n            major,\n            minor,\n            patch,\n        }\n    }\n\n    /// Check if this version is compatible with another (same major version)\n    pub fn is_compatible_with(&self, other: &Version) -> bool {\n        self.major == other.major\n    }\n\n    /// Check if this version is newer than another\n    pub fn is_newer_than(&self, other: &Version) -> bool {\n        self > other\n    }\n}\n\nimpl fmt::Display for Version {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"{}.{}.{}\", self.major, self.minor, self.patch)\n    }\n}\n\n/// Metadata for components in the LLMSpell system.\n///\n/// Contains essential information about a component including its ID, name,\n/// version, description, and timestamps. This metadata is used throughout\n/// the system for component identification and management.\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::{ComponentMetadata, Version};\n///\n/// let mut metadata = ComponentMetadata::new(\n///     \"research-agent\".to_string(),\n///     \"An agent for conducting research\".to_string(),\n/// );\n///\n/// // Update version\n/// metadata.update_version(Version::new(1, 1, 0));\n///\n/// assert_eq!(metadata.name, \"research-agent\");\n/// assert_eq!(metadata.version, Version::new(1, 1, 0));\n/// ```\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ComponentMetadata {\n    pub id: ComponentId,\n    pub name: String,\n    pub version: Version,\n    pub description: String,\n    pub created_at: chrono::DateTime<chrono::Utc>,\n    pub updated_at: chrono::DateTime<chrono::Utc>,\n}\n\nimpl ComponentMetadata {\n    pub fn new(name: String, description: String) -> Self {\n        let now = chrono::Utc::now();\n        Self {\n            id: ComponentId::from_name(&name),\n            name,\n            version: Version::new(0, 1, 0),\n            description,\n            created_at: now,\n            updated_at: now,\n        }\n    }\n\n    /// Update the version and updated_at timestamp\n    pub fn update_version(&mut self, version: Version) {\n        self.version = version;\n        self.updated_at = chrono::Utc::now();\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_component_id_generation() {\n        let id1 = ComponentId::new();\n        let id2 = ComponentId::new();\n\n        // Each new ID should be unique\n        assert_ne!(id1, id2);\n        assert_ne!(id1.uuid(), id2.uuid());\n    }\n\n    #[test]\n    fn test_component_id_from_name_deterministic() {\n        let name = \"test-component\";\n        let id1 = ComponentId::from_name(name);\n        let id2 = ComponentId::from_name(name);\n\n        // Same name should generate same ID\n        assert_eq!(id1, id2);\n        assert_eq!(id1.uuid(), id2.uuid());\n    }\n\n    #[test]\n    fn test_component_id_from_different_names() {\n        let id1 = ComponentId::from_name(\"component-a\");\n        let id2 = ComponentId::from_name(\"component-b\");\n\n        // Different names should generate different IDs\n        assert_ne!(id1, id2);\n    }\n\n    #[test]\n    fn test_component_id_display() {\n        let id = ComponentId::from_name(\"test\");\n        let display_str = format!(\"{}\", id);\n\n        // Should display as UUID string\n        assert!(display_str.len() == 36); // UUID string length\n        assert!(display_str.contains('-')); // UUID format\n    }\n\n    #[test]\n    fn test_component_id_serialization() {\n        let id = ComponentId::from_name(\"test\");\n\n        // Test JSON serialization roundtrip\n        let json = serde_json::to_string(&id).unwrap();\n        let deserialized: ComponentId = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(id, deserialized);\n    }\n\n    #[test]\n    fn test_version_creation() {\n        let version = Version::new(1, 2, 3);\n\n        assert_eq!(version.major, 1);\n        assert_eq!(version.minor, 2);\n        assert_eq!(version.patch, 3);\n    }\n\n    #[test]\n    fn test_version_comparison() {\n        let v1_0_0 = Version::new(1, 0, 0);\n        let v1_1_0 = Version::new(1, 1, 0);\n        let v1_1_1 = Version::new(1, 1, 1);\n        let v2_0_0 = Version::new(2, 0, 0);\n\n        // Test ordering\n        assert!(v1_0_0 < v1_1_0);\n        assert!(v1_1_0 < v1_1_1);\n        assert!(v1_1_1 < v2_0_0);\n\n        // Test newer_than\n        assert!(v1_1_0.is_newer_than(&v1_0_0));\n        assert!(v2_0_0.is_newer_than(&v1_1_1));\n        assert!(!v1_0_0.is_newer_than(&v1_1_0));\n    }\n\n    #[test]\n    fn test_version_compatibility() {\n        let v1_0_0 = Version::new(1, 0, 0);\n        let v1_1_0 = Version::new(1, 1, 0);\n        let v2_0_0 = Version::new(2, 0, 0);\n\n        // Same major version should be compatible\n        assert!(v1_0_0.is_compatible_with(&v1_1_0));\n        assert!(v1_1_0.is_compatible_with(&v1_0_0));\n\n        // Different major version should not be compatible\n        assert!(!v1_0_0.is_compatible_with(&v2_0_0));\n        assert!(!v2_0_0.is_compatible_with(&v1_0_0));\n    }\n\n    #[test]\n    fn test_version_display() {\n        let version = Version::new(1, 2, 3);\n        assert_eq!(format!(\"{}\", version), \"1.2.3\");\n    }\n\n    #[test]\n    fn test_version_serialization() {\n        let version = Version::new(1, 2, 3);\n\n        // Test JSON serialization roundtrip\n        let json = serde_json::to_string(&version).unwrap();\n        let deserialized: Version = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(version, deserialized);\n    }\n\n    #[test]\n    fn test_component_metadata_creation() {\n        let name = \"test-component\".to_string();\n        let description = \"A test component\".to_string();\n\n        let metadata = ComponentMetadata::new(name.clone(), description.clone());\n\n        assert_eq!(metadata.name, name);\n        assert_eq!(metadata.description, description);\n        assert_eq!(metadata.version, Version::new(0, 1, 0));\n        assert_eq!(metadata.id, ComponentId::from_name(&name));\n\n        // Timestamps should be recent\n        let now = chrono::Utc::now();\n        let duration = now - metadata.created_at;\n        assert!(duration.num_seconds() < 5); // Created within last 5 seconds\n    }\n\n    #[test]\n    fn test_component_metadata_version_update() {\n        let mut metadata = ComponentMetadata::new(\"test\".to_string(), \"test component\".to_string());\n\n        let original_updated_at = metadata.updated_at;\n\n        // Small delay to ensure timestamp difference\n        std::thread::sleep(std::time::Duration::from_millis(1));\n\n        let new_version = Version::new(1, 0, 0);\n        metadata.update_version(new_version.clone());\n\n        assert_eq!(metadata.version, new_version);\n        assert!(metadata.updated_at > original_updated_at);\n    }\n\n    #[test]\n    fn test_component_metadata_serialization() {\n        let metadata = ComponentMetadata::new(\"test\".to_string(), \"test component\".to_string());\n\n        // Test JSON serialization roundtrip\n        let json = serde_json::to_string(&metadata).unwrap();\n        let deserialized: ComponentMetadata = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(metadata.id, deserialized.id);\n        assert_eq!(metadata.name, deserialized.name);\n        assert_eq!(metadata.version, deserialized.version);\n        assert_eq!(metadata.description, deserialized.description);\n    }\n}\n","traces":[{"line":50,"address":[],"length":0,"stats":{"Line":1063}},{"line":51,"address":[],"length":0,"stats":{"Line":1063}},{"line":55,"address":[],"length":0,"stats":{"Line":8206}},{"line":56,"address":[],"length":0,"stats":{"Line":8206}},{"line":57,"address":[],"length":0,"stats":{"Line":8206}},{"line":61,"address":[],"length":0,"stats":{"Line":4}},{"line":62,"address":[],"length":0,"stats":{"Line":4}},{"line":67,"address":[],"length":0,"stats":{"Line":1}},{"line":68,"address":[],"length":0,"stats":{"Line":1}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":4278}},{"line":117,"address":[],"length":0,"stats":{"Line":1560}},{"line":118,"address":[],"length":0,"stats":{"Line":1560}},{"line":122,"address":[],"length":0,"stats":{"Line":3}},{"line":123,"address":[],"length":0,"stats":{"Line":3}},{"line":128,"address":[],"length":0,"stats":{"Line":1059}},{"line":129,"address":[],"length":0,"stats":{"Line":1059}},{"line":166,"address":[],"length":0,"stats":{"Line":636}},{"line":167,"address":[],"length":0,"stats":{"Line":636}},{"line":169,"address":[],"length":0,"stats":{"Line":636}},{"line":171,"address":[],"length":0,"stats":{"Line":636}},{"line":179,"address":[],"length":0,"stats":{"Line":517}},{"line":180,"address":[],"length":0,"stats":{"Line":517}},{"line":181,"address":[],"length":0,"stats":{"Line":517}}],"covered":23,"coverable":25},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-core","src","types","streaming.rs"],"content":"//! ABOUTME: Streaming types for agent responses and chunk-based communication\n//! ABOUTME: Provides AgentStream, AgentChunk, and related types for streaming LLM interactions\n\nuse crate::error::LLMSpellError;\nuse chrono::{DateTime, Utc};\nuse futures::Stream;\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\nuse std::fmt;\nuse std::pin::Pin;\n\n/// Type alias for a stream of agent chunks.\n///\n/// This stream is pinned and boxed to allow for dynamic dispatch across\n/// different stream implementations. Each item in the stream is a Result\n/// containing either an AgentChunk or an error.\n///\n/// # Examples\n///\n/// ```no_run\n/// use llmspell_core::types::{AgentStream, AgentChunk, ChunkContent};\n/// use futures::stream;\n///\n/// fn create_text_stream() -> AgentStream {\n///     Box::pin(stream::iter(vec![\n///         Ok(AgentChunk {\n///             stream_id: \"stream-1\".to_string(),\n///             chunk_index: 0,\n///             content: ChunkContent::Text(\"Hello, \".to_string()),\n///             metadata: Default::default(),\n///             timestamp: chrono::Utc::now(),\n///         }),\n///         Ok(AgentChunk {\n///             stream_id: \"stream-1\".to_string(),\n///             chunk_index: 1,\n///             content: ChunkContent::Text(\"world!\".to_string()),\n///             metadata: Default::default(),\n///             timestamp: chrono::Utc::now(),\n///         }),\n///     ]))\n/// }\n/// ```\npub type AgentStream = Pin<Box<dyn Stream<Item = Result<AgentChunk, LLMSpellError>> + Send>>;\n\n/// Represents a single chunk in a streaming agent response.\n///\n/// Each chunk contains a piece of content (text, tool call, etc.) along with\n/// metadata about its position in the stream and various properties.\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_core::types::{AgentChunk, ChunkContent, ChunkMetadata};\n///\n/// let chunk = AgentChunk {\n///     stream_id: \"conversation-123\".to_string(),\n///     chunk_index: 0,\n///     content: ChunkContent::Text(\"The answer is\".to_string()),\n///     metadata: ChunkMetadata {\n///         is_final: false,\n///         token_count: Some(3),\n///         model: Some(\"gpt-4\".to_string()),\n///         reasoning_step: None,\n///     },\n///     timestamp: chrono::Utc::now(),\n/// };\n/// ```\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub struct AgentChunk {\n    /// Unique identifier for this stream\n    pub stream_id: String,\n\n    /// Sequential index of this chunk in the stream\n    pub chunk_index: usize,\n\n    /// The actual content of this chunk\n    pub content: ChunkContent,\n\n    /// Metadata about this chunk\n    pub metadata: ChunkMetadata,\n\n    /// Timestamp when this chunk was created\n    pub timestamp: DateTime<Utc>,\n}\n\nimpl fmt::Display for AgentChunk {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(\n            f,\n            \"AgentChunk[{}/{}]: {}\",\n            self.stream_id, self.chunk_index, self.content\n        )\n    }\n}\n\n/// Content types that can appear in agent chunks.\n///\n/// Different variants represent different kinds of streaming content,\n/// from simple text to complex tool calls and media.\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(tag = \"type\", content = \"data\")]\npub enum ChunkContent {\n    /// Plain text content\n    Text(String),\n\n    /// Partial tool call in progress\n    ToolCallProgress {\n        /// Tool call ID\n        call_id: String,\n        /// Tool name being called\n        tool_name: String,\n        /// Partial arguments being built\n        partial_args: String,\n    },\n\n    /// Complete tool call ready for execution\n    ToolCallComplete {\n        /// Tool call ID\n        call_id: String,\n        /// Tool name to execute\n        tool_name: String,\n        /// Complete arguments as JSON string\n        arguments: String,\n    },\n\n    /// Media content (images, audio, etc.)\n    Media {\n        /// MIME type of the media\n        mime_type: String,\n        /// Base64 encoded data or URL\n        data: String,\n        /// Optional caption or description\n        caption: Option<String>,\n    },\n\n    /// Control messages for stream management\n    Control(ControlMessage),\n}\n\nimpl fmt::Display for ChunkContent {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            ChunkContent::Text(text) => write!(f, \"Text: {}\", text),\n            ChunkContent::ToolCallProgress { tool_name, .. } => {\n                write!(f, \"ToolCallProgress: {}\", tool_name)\n            }\n            ChunkContent::ToolCallComplete { tool_name, .. } => {\n                write!(f, \"ToolCallComplete: {}\", tool_name)\n            }\n            ChunkContent::Media {\n                mime_type, caption, ..\n            } => {\n                write!(\n                    f,\n                    \"Media[{}]{}\",\n                    mime_type,\n                    caption\n                        .as_ref()\n                        .map(|c| format!(\": {}\", c))\n                        .unwrap_or_default()\n                )\n            }\n            ChunkContent::Control(msg) => write!(f, \"Control: {}\", msg),\n        }\n    }\n}\n\n/// Metadata associated with each chunk.\n///\n/// Provides additional context about the chunk such as whether it's\n/// the final chunk, token counts, model information, etc.\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Default)]\npub struct ChunkMetadata {\n    /// Whether this is the final chunk in the stream\n    pub is_final: bool,\n\n    /// Number of tokens in this chunk (if available)\n    pub token_count: Option<usize>,\n\n    /// Model that generated this chunk\n    pub model: Option<String>,\n\n    /// If this chunk is part of a reasoning step\n    pub reasoning_step: Option<ReasoningStep>,\n}\n\nimpl fmt::Display for ChunkMetadata {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let mut parts = vec![];\n\n        if self.is_final {\n            parts.push(\"final\".to_string());\n        }\n\n        if let Some(count) = self.token_count {\n            parts.push(format!(\"{} tokens\", count));\n        }\n\n        if let Some(model) = &self.model {\n            parts.push(format!(\"model={}\", model));\n        }\n\n        if let Some(step) = &self.reasoning_step {\n            parts.push(format!(\"step={}\", step.step_type));\n        }\n\n        write!(f, \"Metadata[{}]\", parts.join(\", \"))\n    }\n}\n\n/// Information about reasoning steps in the agent's thought process.\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub struct ReasoningStep {\n    /// Type of reasoning step\n    pub step_type: String,\n\n    /// Step number in sequence\n    pub step_number: usize,\n\n    /// Additional properties for this step\n    pub properties: HashMap<String, String>,\n}\n\n/// Control messages for stream management.\n///\n/// These messages control the flow of the stream and provide\n/// status updates about the streaming process.\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub enum ControlMessage {\n    /// Stream has started\n    StreamStart {\n        /// Expected total chunks (if known)\n        expected_chunks: Option<usize>,\n        /// Stream configuration\n        config: HashMap<String, String>,\n    },\n\n    /// Stream has ended normally\n    StreamEnd {\n        /// Total chunks sent\n        total_chunks: usize,\n        /// Total tokens used\n        total_tokens: Option<usize>,\n        /// Duration in milliseconds\n        duration_ms: u64,\n    },\n\n    /// Stream was cancelled\n    StreamCancelled {\n        /// Reason for cancellation\n        reason: String,\n    },\n\n    /// Heartbeat to keep connection alive\n    Heartbeat,\n\n    /// Rate limit information\n    RateLimit {\n        /// Requests remaining\n        remaining: usize,\n        /// Reset time\n        reset_at: DateTime<Utc>,\n    },\n\n    /// Custom control message\n    Custom {\n        /// Message type\n        message_type: String,\n        /// Message payload\n        payload: HashMap<String, String>,\n    },\n}\n\nimpl fmt::Display for ControlMessage {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            ControlMessage::StreamStart {\n                expected_chunks, ..\n            } => {\n                write!(\n                    f,\n                    \"StreamStart{}\",\n                    expected_chunks\n                        .map(|n| format!(\" (expecting {} chunks)\", n))\n                        .unwrap_or_default()\n                )\n            }\n            ControlMessage::StreamEnd {\n                total_chunks,\n                duration_ms,\n                ..\n            } => {\n                write!(\n                    f,\n                    \"StreamEnd ({} chunks in {}ms)\",\n                    total_chunks, duration_ms\n                )\n            }\n            ControlMessage::StreamCancelled { reason } => {\n                write!(f, \"StreamCancelled: {}\", reason)\n            }\n            ControlMessage::Heartbeat => write!(f, \"Heartbeat\"),\n            ControlMessage::RateLimit { remaining, .. } => {\n                write!(f, \"RateLimit ({} remaining)\", remaining)\n            }\n            ControlMessage::Custom { message_type, .. } => {\n                write!(f, \"Custom[{}]\", message_type)\n            }\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_agent_chunk_serialization() {\n        let chunk = AgentChunk {\n            stream_id: \"test-stream\".to_string(),\n            chunk_index: 0,\n            content: ChunkContent::Text(\"Hello\".to_string()),\n            metadata: ChunkMetadata::default(),\n            timestamp: Utc::now(),\n        };\n\n        let json = serde_json::to_string(&chunk).unwrap();\n        let deserialized: AgentChunk = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(chunk.stream_id, deserialized.stream_id);\n        assert_eq!(chunk.chunk_index, deserialized.chunk_index);\n        assert_eq!(chunk.content, deserialized.content);\n        assert_eq!(chunk.metadata, deserialized.metadata);\n    }\n\n    #[test]\n    fn test_chunk_content_variants_serialization() {\n        let test_cases = vec![\n            ChunkContent::Text(\"Hello world\".to_string()),\n            ChunkContent::ToolCallProgress {\n                call_id: \"call-123\".to_string(),\n                tool_name: \"search\".to_string(),\n                partial_args: r#\"{\"query\": \"rust\"#.to_string(),\n            },\n            ChunkContent::ToolCallComplete {\n                call_id: \"call-456\".to_string(),\n                tool_name: \"calculator\".to_string(),\n                arguments: r#\"{\"expression\": \"2 + 2\"}\"#.to_string(),\n            },\n            ChunkContent::Media {\n                mime_type: \"image/png\".to_string(),\n                data: \"base64data\".to_string(),\n                caption: Some(\"A test image\".to_string()),\n            },\n            ChunkContent::Control(ControlMessage::Heartbeat),\n        ];\n\n        for content in test_cases {\n            let json = serde_json::to_string(&content).unwrap();\n            let deserialized: ChunkContent = serde_json::from_str(&json).unwrap();\n            assert_eq!(content, deserialized);\n        }\n    }\n\n    #[test]\n    fn test_chunk_metadata_serialization() {\n        let metadata = ChunkMetadata {\n            is_final: true,\n            token_count: Some(42),\n            model: Some(\"gpt-4\".to_string()),\n            reasoning_step: Some(ReasoningStep {\n                step_type: \"analysis\".to_string(),\n                step_number: 1,\n                properties: HashMap::from([(\"depth\".to_string(), \"3\".to_string())]),\n            }),\n        };\n\n        let json = serde_json::to_string(&metadata).unwrap();\n        let deserialized: ChunkMetadata = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(metadata, deserialized);\n    }\n\n    #[test]\n    fn test_control_message_variants_serialization() {\n        let test_cases = vec![\n            ControlMessage::StreamStart {\n                expected_chunks: Some(10),\n                config: HashMap::from([(\"mode\".to_string(), \"fast\".to_string())]),\n            },\n            ControlMessage::StreamEnd {\n                total_chunks: 5,\n                total_tokens: Some(100),\n                duration_ms: 1500,\n            },\n            ControlMessage::StreamCancelled {\n                reason: \"User interrupted\".to_string(),\n            },\n            ControlMessage::Heartbeat,\n            ControlMessage::RateLimit {\n                remaining: 50,\n                reset_at: Utc::now(),\n            },\n            ControlMessage::Custom {\n                message_type: \"debug\".to_string(),\n                payload: HashMap::from([(\"level\".to_string(), \"info\".to_string())]),\n            },\n        ];\n\n        for message in test_cases {\n            let json = serde_json::to_string(&message).unwrap();\n            let deserialized: ControlMessage = serde_json::from_str(&json).unwrap();\n            assert_eq!(message, deserialized);\n        }\n    }\n\n    #[test]\n    fn test_display_implementations() {\n        let chunk = AgentChunk {\n            stream_id: \"stream-1\".to_string(),\n            chunk_index: 5,\n            content: ChunkContent::Text(\"Hello\".to_string()),\n            metadata: ChunkMetadata::default(),\n            timestamp: Utc::now(),\n        };\n\n        assert_eq!(format!(\"{}\", chunk), \"AgentChunk[stream-1/5]: Text: Hello\");\n\n        let metadata = ChunkMetadata {\n            is_final: true,\n            token_count: Some(10),\n            model: Some(\"gpt-4\".to_string()),\n            reasoning_step: None,\n        };\n\n        assert_eq!(\n            format!(\"{}\", metadata),\n            \"Metadata[final, 10 tokens, model=gpt-4]\"\n        );\n\n        let control = ControlMessage::StreamEnd {\n            total_chunks: 20,\n            total_tokens: Some(500),\n            duration_ms: 2000,\n        };\n\n        assert_eq!(format!(\"{}\", control), \"StreamEnd (20 chunks in 2000ms)\");\n    }\n\n    #[test]\n    fn test_default_chunk_metadata() {\n        let metadata = ChunkMetadata::default();\n\n        assert!(!metadata.is_final);\n        assert!(metadata.token_count.is_none());\n        assert!(metadata.model.is_none());\n        assert!(metadata.reasoning_step.is_none());\n    }\n}\n","traces":[{"line":87,"address":[],"length":0,"stats":{"Line":1}},{"line":88,"address":[],"length":0,"stats":{"Line":1}},{"line":89,"address":[],"length":0,"stats":{"Line":1}},{"line":91,"address":[],"length":0,"stats":{"Line":1}},{"line":141,"address":[],"length":0,"stats":{"Line":1}},{"line":142,"address":[],"length":0,"stats":{"Line":1}},{"line":143,"address":[],"length":0,"stats":{"Line":1}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":1}},{"line":189,"address":[],"length":0,"stats":{"Line":1}},{"line":191,"address":[],"length":0,"stats":{"Line":2}},{"line":192,"address":[],"length":0,"stats":{"Line":1}},{"line":195,"address":[],"length":0,"stats":{"Line":2}},{"line":199,"address":[],"length":0,"stats":{"Line":2}},{"line":203,"address":[],"length":0,"stats":{"Line":1}},{"line":207,"address":[],"length":0,"stats":{"Line":1}},{"line":275,"address":[],"length":0,"stats":{"Line":1}},{"line":276,"address":[],"length":0,"stats":{"Line":1}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":1}},{"line":290,"address":[],"length":0,"stats":{"Line":1}},{"line":291,"address":[],"length":0,"stats":{"Line":1}},{"line":292,"address":[],"length":0,"stats":{"Line":1}},{"line":293,"address":[],"length":0,"stats":{"Line":1}},{"line":294,"address":[],"length":0,"stats":{"Line":1}},{"line":296,"address":[],"length":0,"stats":{"Line":1}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}}],"covered":24,"coverable":51},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-core","tests","concurrency_tests.rs"],"content":"//! Concurrency and thread-safety tests for llmspell-core\n//!\n//! These tests verify that components work correctly under concurrent access\n\nuse async_trait::async_trait;\nuse llmspell_core::{\n    traits::{\n        agent::{Agent, AgentConfig, ConversationMessage},\n        base_agent::BaseAgent,\n    },\n    types::{AgentInput, AgentOutput, ExecutionContext},\n    ComponentId, ComponentMetadata, Result,\n};\nuse std::sync::{\n    atomic::{AtomicUsize, Ordering},\n    Arc, Mutex,\n};\nuse tokio::sync::RwLock;\n\n/// Thread-safe agent implementation\nstruct ConcurrentAgent {\n    metadata: ComponentMetadata,\n    config: AgentConfig,\n    conversation: Arc<RwLock<Vec<ConversationMessage>>>,\n    execution_count: Arc<AtomicUsize>,\n}\n\nimpl ConcurrentAgent {\n    fn new(name: &str) -> Self {\n        Self {\n            metadata: ComponentMetadata::new(\n                name.to_string(),\n                format!(\"Concurrent agent: {}\", name),\n            ),\n            config: AgentConfig::default(),\n            conversation: Arc::new(RwLock::new(Vec::new())),\n            execution_count: Arc::new(AtomicUsize::new(0)),\n        }\n    }\n\n    fn get_execution_count(&self) -> usize {\n        self.execution_count.load(Ordering::SeqCst)\n    }\n}\n\n#[async_trait]\nimpl BaseAgent for ConcurrentAgent {\n    fn metadata(&self) -> &ComponentMetadata {\n        &self.metadata\n    }\n\n    async fn execute(&self, input: AgentInput, _context: ExecutionContext) -> Result<AgentOutput> {\n        // Increment execution count atomically\n        let count = self.execution_count.fetch_add(1, Ordering::SeqCst) + 1;\n\n        // Add to conversation with write lock\n        {\n            let mut conv = self.conversation.write().await;\n            conv.push(ConversationMessage::user(input.text.clone()));\n            conv.push(ConversationMessage::assistant(format!(\n                \"Response #{}\",\n                count\n            )));\n        }\n\n        // Simulate some work\n        tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;\n\n        Ok(AgentOutput::text(format!(\"Execution #{}\", count)))\n    }\n\n    async fn validate_input(&self, input: &AgentInput) -> Result<()> {\n        if input.text.is_empty() {\n            return Err(llmspell_core::LLMSpellError::Validation {\n                message: \"Empty prompt\".to_string(),\n                field: Some(\"prompt\".to_string()),\n            });\n        }\n        Ok(())\n    }\n\n    async fn handle_error(&self, error: llmspell_core::LLMSpellError) -> Result<AgentOutput> {\n        Ok(AgentOutput::text(format!(\"Error: {}\", error)))\n    }\n}\n\n#[async_trait]\nimpl Agent for ConcurrentAgent {\n    fn config(&self) -> &AgentConfig {\n        &self.config\n    }\n\n    async fn get_conversation(&self) -> Result<Vec<ConversationMessage>> {\n        let conv = self.conversation.read().await;\n        Ok(conv.clone())\n    }\n\n    async fn add_message(&mut self, message: ConversationMessage) -> Result<()> {\n        let mut conv = self.conversation.write().await;\n        conv.push(message);\n        Ok(())\n    }\n\n    async fn clear_conversation(&mut self) -> Result<()> {\n        let mut conv = self.conversation.write().await;\n        conv.clear();\n        Ok(())\n    }\n}\n\n#[tokio::test]\nasync fn test_concurrent_agent_execution() {\n    let agent = Arc::new(ConcurrentAgent::new(\"concurrent-test\"));\n    let num_tasks = 100;\n\n    // Spawn multiple concurrent tasks\n    let mut handles = Vec::new();\n    for i in 0..num_tasks {\n        let agent_clone = Arc::clone(&agent);\n        let handle = tokio::spawn(async move {\n            let input = AgentInput::text(format!(\"Request {}\", i));\n            let context = ExecutionContext::with_conversation(format!(\"session-{}\", i));\n            agent_clone.execute(input, context).await\n        });\n        handles.push(handle);\n    }\n\n    // Wait for all tasks to complete\n    let mut results = Vec::new();\n    for handle in handles {\n        let result = handle.await.unwrap();\n        results.push(result);\n    }\n\n    // Verify all executions completed\n    assert_eq!(results.len(), num_tasks);\n    for result in &results {\n        assert!(result.is_ok());\n    }\n\n    // Verify execution count\n    assert_eq!(agent.get_execution_count(), num_tasks);\n\n    // Verify conversation has correct number of messages\n    let conv = agent.get_conversation().await.unwrap();\n    assert_eq!(conv.len(), num_tasks * 2); // User + Assistant messages\n}\n\n#[tokio::test]\nasync fn test_component_id_thread_safety() {\n    let num_threads = 50;\n    let names = Arc::new(Mutex::new(Vec::new()));\n\n    // Generate unique names in parallel\n    let mut handles = Vec::new();\n    for i in 0..num_threads {\n        let names_clone = Arc::clone(&names);\n        let handle = std::thread::spawn(move || {\n            let name = format!(\"component-{}\", i);\n            let id = ComponentId::from_name(&name);\n            names_clone.lock().unwrap().push((name, id));\n        });\n        handles.push(handle);\n    }\n\n    // Wait for all threads\n    for handle in handles {\n        handle.join().unwrap();\n    }\n\n    // Verify deterministic ID generation\n    let names_vec = names.lock().unwrap();\n    for (name, id) in names_vec.iter() {\n        let id2 = ComponentId::from_name(name);\n        assert_eq!(*id, id2, \"ComponentId generation should be deterministic\");\n    }\n}\n\n#[tokio::test]\nasync fn test_concurrent_conversation_modifications() {\n    let agent = Arc::new(RwLock::new(ConcurrentAgent::new(\"conversation-test\")));\n\n    // Concurrent readers\n    let mut read_handles = Vec::new();\n    for i in 0..10 {\n        let agent_clone = Arc::clone(&agent);\n        let handle = tokio::spawn(async move {\n            tokio::time::sleep(tokio::time::Duration::from_millis(i * 5)).await;\n            let agent = agent_clone.read().await;\n            agent.get_conversation().await\n        });\n        read_handles.push(handle);\n    }\n\n    // Concurrent writer\n    let agent_clone = Arc::clone(&agent);\n    let write_handle = tokio::spawn(async move {\n        for i in 0..20 {\n            tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;\n            let mut agent = agent_clone.write().await;\n            agent\n                .add_message(ConversationMessage::user(format!(\"Message {}\", i)))\n                .await\n                .unwrap();\n        }\n    });\n\n    // Wait for all operations\n    for handle in read_handles {\n        let _ = handle.await.unwrap();\n    }\n    write_handle.await.unwrap();\n\n    // Verify final state\n    let agent = agent.read().await;\n    let conv = agent.get_conversation().await.unwrap();\n    assert_eq!(conv.len(), 20);\n}\n\n#[tokio::test]\nasync fn test_metadata_immutability() {\n    // ComponentMetadata should be safely shareable\n    let metadata = Arc::new(ComponentMetadata::new(\n        \"shared-component\".to_string(),\n        \"A shared component\".to_string(),\n    ));\n\n    let mut handles = Vec::new();\n    for _ in 0..10 {\n        let metadata_clone = Arc::clone(&metadata);\n        let handle = tokio::spawn(async move {\n            // Multiple readers accessing metadata concurrently\n            assert_eq!(metadata_clone.name, \"shared-component\");\n            assert_eq!(metadata_clone.description, \"A shared component\");\n            // Serialize to ensure thread safety\n            let _ = serde_json::to_string(&*metadata_clone).unwrap();\n        });\n        handles.push(handle);\n    }\n\n    for handle in handles {\n        handle.await.unwrap();\n    }\n}\n\n#[tokio::test]\nasync fn test_execution_context_concurrent_access() {\n    let context = Arc::new({\n        let mut context = ExecutionContext::with_conversation(\"shared-session\".to_string());\n        context.user_id = Some(\"user-123\".to_string());\n        context\n            .with_data(\"KEY1\".to_string(), serde_json::json!(\"value1\"))\n            .with_data(\"KEY2\".to_string(), serde_json::json!(\"value2\"))\n    });\n\n    let mut handles = Vec::new();\n    for i in 0..20 {\n        let context_clone = Arc::clone(&context);\n        let handle = tokio::spawn(async move {\n            // Concurrent reads\n            assert_eq!(\n                context_clone.conversation_id,\n                Some(\"shared-session\".to_string())\n            );\n            assert_eq!(context_clone.user_id, Some(\"user-123\".to_string()));\n\n            // Access data variables\n            if i % 2 == 0 {\n                assert_eq!(\n                    context_clone.data.get(\"KEY1\"),\n                    Some(&serde_json::json!(\"value1\"))\n                );\n            } else {\n                assert_eq!(\n                    context_clone.data.get(\"KEY2\"),\n                    Some(&serde_json::json!(\"value2\"))\n                );\n            }\n        });\n        handles.push(handle);\n    }\n\n    for handle in handles {\n        handle.await.unwrap();\n    }\n}\n\n#[test]\nfn test_error_thread_safety() {\n    use std::thread;\n\n    // Errors should be Send + Sync\n    let error = Arc::new(llmspell_core::LLMSpellError::Component {\n        message: \"Shared error\".to_string(),\n        source: None,\n    });\n\n    let mut handles = Vec::new();\n    for _ in 0..10 {\n        let error_clone = Arc::clone(&error);\n        let handle = thread::spawn(move || {\n            // Access error from multiple threads\n            assert!(error_clone.to_string().contains(\"Shared error\"));\n            assert_eq!(\n                error_clone.severity(),\n                llmspell_core::error::ErrorSeverity::Error\n            );\n            assert_eq!(\n                error_clone.category(),\n                llmspell_core::error::ErrorCategory::Logic\n            );\n        });\n        handles.push(handle);\n    }\n\n    for handle in handles {\n        handle.join().unwrap();\n    }\n}\n","traces":[{"line":29,"address":[],"length":0,"stats":{"Line":2}},{"line":31,"address":[],"length":0,"stats":{"Line":2}},{"line":35,"address":[],"length":0,"stats":{"Line":2}},{"line":36,"address":[],"length":0,"stats":{"Line":2}},{"line":37,"address":[],"length":0,"stats":{"Line":2}},{"line":41,"address":[],"length":0,"stats":{"Line":1}},{"line":42,"address":[],"length":0,"stats":{"Line":1}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":100}},{"line":54,"address":[],"length":0,"stats":{"Line":100}},{"line":58,"address":[],"length":0,"stats":{"Line":200}},{"line":59,"address":[],"length":0,"stats":{"Line":100}},{"line":60,"address":[],"length":0,"stats":{"Line":100}},{"line":61,"address":[],"length":0,"stats":{"Line":100}},{"line":62,"address":[],"length":0,"stats":{"Line":100}},{"line":67,"address":[],"length":0,"stats":{"Line":100}},{"line":69,"address":[],"length":0,"stats":{"Line":100}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":12}},{"line":94,"address":[],"length":0,"stats":{"Line":24}},{"line":95,"address":[],"length":0,"stats":{"Line":12}},{"line":98,"address":[],"length":0,"stats":{"Line":20}},{"line":99,"address":[],"length":0,"stats":{"Line":40}},{"line":100,"address":[],"length":0,"stats":{"Line":20}},{"line":101,"address":[],"length":0,"stats":{"Line":20}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}}],"covered":23,"coverable":39},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-core","tests","edge_cases.rs"],"content":"//! Edge case tests for llmspell-core\n//!\n//! These tests verify behavior in boundary conditions and unusual scenarios\n\nuse llmspell_core::{\n    traits::{\n        agent::{ConversationMessage, MessageRole},\n        tool::{ParameterType, SecurityLevel, ToolCategory},\n    },\n    types::{AgentInput, AgentOutput},\n    ComponentId, LLMSpellError, Version,\n};\n\n#[test]\nfn test_component_id_edge_cases() {\n    // Empty string should still produce valid ID\n    let id1 = ComponentId::from_name(\"\");\n    let id2 = ComponentId::from_name(\"\");\n    assert_eq!(id1, id2);\n\n    // Very long strings\n    let long_name = \"a\".repeat(10000);\n    let id = ComponentId::from_name(&long_name);\n    let id2 = ComponentId::from_name(&long_name);\n    assert_eq!(id, id2);\n\n    // Unicode characters\n    let unicode_name = \"🚀🎯💡 Special-Characters_123 ñáéíóú\";\n    let id = ComponentId::from_name(unicode_name);\n    let id2 = ComponentId::from_name(unicode_name);\n    assert_eq!(id, id2);\n\n    // Whitespace variations should produce different IDs\n    let id1 = ComponentId::from_name(\"test\");\n    let id2 = ComponentId::from_name(\" test\");\n    let id3 = ComponentId::from_name(\"test \");\n    let id4 = ComponentId::from_name(\" test \");\n    assert_ne!(id1, id2);\n    assert_ne!(id1, id3);\n    assert_ne!(id1, id4);\n}\n\n#[test]\nfn test_version_edge_cases() {\n    // Maximum values\n    let v = Version {\n        major: u32::MAX,\n        minor: u32::MAX,\n        patch: u32::MAX,\n    };\n    assert_eq!(\n        v.to_string(),\n        format!(\"{}.{}.{}\", u32::MAX, u32::MAX, u32::MAX)\n    );\n\n    // Ordering edge cases\n    let v1 = Version {\n        major: 1,\n        minor: 0,\n        patch: 0,\n    };\n    let v2 = Version {\n        major: 1,\n        minor: 0,\n        patch: 1,\n    };\n    let v3 = Version {\n        major: 1,\n        minor: 1,\n        patch: 0,\n    };\n    let v4 = Version {\n        major: 2,\n        minor: 0,\n        patch: 0,\n    };\n\n    assert!(v1 < v2);\n    assert!(v2 < v3);\n    assert!(v3 < v4);\n\n    // Compatibility edge cases\n    assert!(v1.is_compatible_with(&v2)); // Patch difference\n    assert!(v1.is_compatible_with(&v3)); // Minor difference\n    assert!(!v1.is_compatible_with(&v4)); // Major difference\n\n    // Zero version\n    let v0 = Version {\n        major: 0,\n        minor: 0,\n        patch: 0,\n    };\n    assert_eq!(v0.to_string(), \"0.0.0\");\n    assert!(v0.is_compatible_with(&v0));\n}\n\n#[test]\nfn test_error_edge_cases() {\n    // Very long error messages\n    let long_message = \"e\".repeat(10000);\n    let err = LLMSpellError::Component {\n        message: long_message.clone(),\n        source: None,\n    };\n    assert!(err.to_string().contains(&long_message[..100])); // Should contain at least start\n\n    // Nested error sources\n    let io_err = std::io::Error::new(std::io::ErrorKind::NotFound, \"file not found\");\n    let err1 = LLMSpellError::Storage {\n        message: \"Storage failed\".to_string(),\n        operation: Some(\"read\".to_string()),\n        source: Some(Box::new(io_err)),\n    };\n\n    let err2 = LLMSpellError::Component {\n        message: \"Component failed\".to_string(),\n        source: Some(Box::new(err1)),\n    };\n\n    // Should be able to chain through errors\n    assert!(err2.to_string().contains(\"Component failed\"));\n\n    // Empty optional fields\n    let err = LLMSpellError::Validation {\n        message: \"Validation failed\".to_string(),\n        field: None,\n    };\n    assert!(err.to_string().contains(\"Validation failed\"));\n}\n\n#[test]\nfn test_agent_input_edge_cases() {\n    // Empty prompt\n    let input = AgentInput::text(\"\".to_string());\n    assert_eq!(input.text, \"\");\n    assert!(input.parameters.is_empty());\n\n    // Very large context\n    let mut input = AgentInput::text(\"test\".to_string());\n    for i in 0..1000 {\n        input = input.with_parameter(format!(\"key{}\", i), serde_json::json!(i));\n    }\n    assert_eq!(input.parameters.len(), 1000);\n\n    // Overwriting parameter values\n    let input = AgentInput::text(\"test\".to_string())\n        .with_parameter(\"key\".to_string(), serde_json::json!(\"value1\"))\n        .with_parameter(\"key\".to_string(), serde_json::json!(\"value2\"));\n    assert_eq!(\n        input.parameters.get(\"key\"),\n        Some(&serde_json::json!(\"value2\"))\n    );\n\n    // Null and complex values in parameters\n    let input = AgentInput::text(\"test\".to_string())\n        .with_parameter(\"null\".to_string(), serde_json::json!(null))\n        .with_parameter(\"array\".to_string(), serde_json::json!([1, 2, 3]))\n        .with_parameter(\n            \"object\".to_string(),\n            serde_json::json!({\"nested\": {\"deep\": \"value\"}}),\n        );\n\n    assert_eq!(input.parameters.get(\"null\"), Some(&serde_json::json!(null)));\n    assert_eq!(\n        input.parameters.get(\"array\"),\n        Some(&serde_json::json!([1, 2, 3]))\n    );\n}\n\n#[test]\nfn test_agent_output_edge_cases() {\n    // Empty content\n    let output = AgentOutput::text(\"\".to_string());\n    assert_eq!(output.text, \"\");\n    assert!(output.metadata.extra.is_empty());\n\n    // Unicode content\n    let output = AgentOutput::text(\"Hello 世界 🌍\".to_string());\n    assert_eq!(output.text, \"Hello 世界 🌍\");\n\n    // Very large metadata\n    let mut output = AgentOutput::text(\"result\".to_string());\n    let mut metadata = llmspell_core::types::OutputMetadata::default();\n    for i in 0..1000 {\n        metadata\n            .extra\n            .insert(format!(\"key{}\", i), serde_json::json!(i));\n    }\n    output = output.with_metadata(metadata);\n    assert_eq!(output.metadata.extra.len(), 1000);\n\n    // Overwriting metadata\n    let mut metadata1 = llmspell_core::types::OutputMetadata::default();\n    metadata1\n        .extra\n        .insert(\"key\".to_string(), serde_json::json!(1));\n    let mut metadata2 = llmspell_core::types::OutputMetadata::default();\n    metadata2\n        .extra\n        .insert(\"key\".to_string(), serde_json::json!(2));\n    let output = AgentOutput::text(\"test\".to_string())\n        .with_metadata(metadata1)\n        .with_metadata(metadata2);\n    assert_eq!(\n        output.metadata.extra.get(\"key\"),\n        Some(&serde_json::json!(2))\n    );\n}\n\n#[test]\nfn test_conversation_message_edge_cases() {\n    // Empty content\n    let msg = ConversationMessage::new(MessageRole::User, \"\".to_string());\n    assert_eq!(msg.content, \"\");\n\n    // Very long content\n    let long_content = \"x\".repeat(100000);\n    let msg = ConversationMessage::new(MessageRole::Assistant, long_content.clone());\n    assert_eq!(msg.content, long_content);\n\n    // Unicode content\n    let msg = ConversationMessage::new(MessageRole::System, \"システムメッセージ 🤖\".to_string());\n    assert_eq!(msg.content, \"システムメッセージ 🤖\");\n\n    // Timestamp ordering\n    let msg1 = ConversationMessage::user(\"first\".to_string());\n    std::thread::sleep(std::time::Duration::from_millis(10));\n    let msg2 = ConversationMessage::user(\"second\".to_string());\n    assert!(msg2.timestamp > msg1.timestamp);\n}\n\n#[test]\nfn test_tool_category_edge_cases() {\n    // Custom categories with special characters\n    let category = ToolCategory::Custom(\"My-Special_Category 123!\".to_string());\n    assert_eq!(category.to_string(), \"My-Special_Category 123!\");\n\n    // Empty custom category\n    let category = ToolCategory::Custom(\"\".to_string());\n    assert_eq!(category.to_string(), \"\");\n\n    // Very long custom category\n    let long_name = \"category\".repeat(1000);\n    let category = ToolCategory::Custom(long_name.clone());\n    assert_eq!(category.to_string(), long_name);\n}\n\n#[test]\nfn test_security_level_edge_cases() {\n    // Ordering tests\n    assert!(SecurityLevel::Safe < SecurityLevel::Restricted);\n    assert!(SecurityLevel::Restricted < SecurityLevel::Privileged);\n    assert!(SecurityLevel::Safe < SecurityLevel::Privileged);\n\n    // allows() method edge cases\n    assert!(SecurityLevel::Privileged.allows(&SecurityLevel::Safe));\n    assert!(SecurityLevel::Privileged.allows(&SecurityLevel::Restricted));\n    assert!(SecurityLevel::Privileged.allows(&SecurityLevel::Privileged));\n\n    assert!(SecurityLevel::Restricted.allows(&SecurityLevel::Safe));\n    assert!(SecurityLevel::Restricted.allows(&SecurityLevel::Restricted));\n    assert!(!SecurityLevel::Restricted.allows(&SecurityLevel::Privileged));\n\n    assert!(SecurityLevel::Safe.allows(&SecurityLevel::Safe));\n    assert!(!SecurityLevel::Safe.allows(&SecurityLevel::Restricted));\n    assert!(!SecurityLevel::Safe.allows(&SecurityLevel::Privileged));\n}\n\n#[test]\nfn test_parameter_type_equality() {\n    // Ensure all parameter types are distinct\n    let types = [\n        ParameterType::String,\n        ParameterType::Number,\n        ParameterType::Boolean,\n        ParameterType::Array,\n        ParameterType::Object,\n        ParameterType::Null,\n    ];\n\n    for (i, t1) in types.iter().enumerate() {\n        for (j, t2) in types.iter().enumerate() {\n            if i == j {\n                assert_eq!(t1, t2);\n            } else {\n                assert_ne!(t1, t2);\n            }\n        }\n    }\n}\n\n#[test]\nfn test_message_role_display_consistency() {\n    // Ensure display strings are consistent\n    assert_eq!(MessageRole::System.to_string(), \"system\");\n    assert_eq!(MessageRole::User.to_string(), \"user\");\n    assert_eq!(MessageRole::Assistant.to_string(), \"assistant\");\n\n    // Case sensitivity\n    assert_ne!(MessageRole::System.to_string(), \"System\");\n    assert_ne!(MessageRole::User.to_string(), \"USER\");\n    assert_ne!(MessageRole::Assistant.to_string(), \"ASSISTANT\");\n}\n\n#[test]\nfn test_error_retryability_edge_cases() {\n    // Network errors should always be retryable\n    let err = LLMSpellError::Network {\n        message: \"Connection refused\".to_string(),\n        source: None,\n    };\n    assert!(err.is_retryable());\n\n    // Timeout errors should always be retryable\n    let err = LLMSpellError::Timeout {\n        message: \"Operation timed out\".to_string(),\n        duration_ms: Some(30000),\n    };\n    assert!(err.is_retryable());\n\n    // Provider errors should be retryable\n    let err = LLMSpellError::Provider {\n        message: \"Rate limit exceeded\".to_string(),\n        provider: Some(\"openai\".to_string()),\n        source: None,\n    };\n    assert!(err.is_retryable());\n\n    // Resource errors should be retryable\n    let err = LLMSpellError::Resource {\n        message: \"Memory limit exceeded\".to_string(),\n        resource_type: Some(\"memory\".to_string()),\n        source: None,\n    };\n    assert!(err.is_retryable());\n\n    // Storage errors depend on operation\n    let err = LLMSpellError::Storage {\n        message: \"Database error\".to_string(),\n        operation: Some(\"read\".to_string()),\n        source: None,\n    };\n    assert!(err.is_retryable());\n\n    let err = LLMSpellError::Storage {\n        message: \"Database error\".to_string(),\n        operation: Some(\"delete\".to_string()),\n        source: None,\n    };\n    assert!(!err.is_retryable());\n\n    // Validation errors should not be retryable\n    let err = LLMSpellError::Validation {\n        message: \"Invalid input\".to_string(),\n        field: Some(\"email\".to_string()),\n    };\n    assert!(!err.is_retryable());\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-core","tests","integration_tests.rs"],"content":"//! Integration tests for llmspell-core\n//!\n//! These tests verify that different components work together correctly\n\nuse async_trait::async_trait;\nuse llmspell_core::{\n    traits::{\n        agent::{Agent, AgentConfig, ConversationMessage, MessageRole},\n        base_agent::BaseAgent,\n        tool::{ParameterDef, ParameterType, SecurityLevel, Tool, ToolCategory, ToolSchema},\n    },\n    types::{AgentInput, AgentOutput, ExecutionContext},\n    ComponentMetadata, LLMSpellError, Result, Version,\n};\nuse std::sync::{Arc, Mutex};\n\n/// Test agent that maintains conversation state\nstruct TestAgent {\n    metadata: ComponentMetadata,\n    config: AgentConfig,\n    conversation: Arc<Mutex<Vec<ConversationMessage>>>,\n    execution_count: Arc<Mutex<usize>>,\n}\n\nimpl TestAgent {\n    fn new(name: &str) -> Self {\n        Self {\n            metadata: ComponentMetadata::new(name.to_string(), format!(\"Test agent: {}\", name)),\n            config: AgentConfig::default(),\n            conversation: Arc::new(Mutex::new(Vec::new())),\n            execution_count: Arc::new(Mutex::new(0)),\n        }\n    }\n}\n\n#[async_trait]\nimpl BaseAgent for TestAgent {\n    fn metadata(&self) -> &ComponentMetadata {\n        &self.metadata\n    }\n\n    async fn execute(&self, input: AgentInput, _context: ExecutionContext) -> Result<AgentOutput> {\n        // Validate input first\n        self.validate_input(&input).await?;\n\n        *self.execution_count.lock().unwrap() += 1;\n\n        // Add to conversation\n        let mut conv = self.conversation.lock().unwrap();\n        conv.push(ConversationMessage::user(input.text.clone()));\n\n        let response = format!(\"Processed: {}\", input.text);\n        conv.push(ConversationMessage::assistant(response.clone()));\n\n        let mut metadata = llmspell_core::types::OutputMetadata::default();\n        metadata.extra.insert(\n            \"execution_count\".to_string(),\n            serde_json::json!(*self.execution_count.lock().unwrap()),\n        );\n        Ok(AgentOutput::text(response).with_metadata(metadata))\n    }\n\n    async fn validate_input(&self, input: &AgentInput) -> Result<()> {\n        if input.text.is_empty() {\n            return Err(LLMSpellError::Validation {\n                message: \"Prompt cannot be empty\".to_string(),\n                field: Some(\"prompt\".to_string()),\n            });\n        }\n        Ok(())\n    }\n\n    async fn handle_error(&self, error: LLMSpellError) -> Result<AgentOutput> {\n        Ok(AgentOutput::text(format!(\"Error handled: {}\", error)))\n    }\n}\n\n#[async_trait]\nimpl Agent for TestAgent {\n    fn config(&self) -> &AgentConfig {\n        &self.config\n    }\n\n    async fn get_conversation(&self) -> Result<Vec<ConversationMessage>> {\n        Ok(self.conversation.lock().unwrap().clone())\n    }\n\n    async fn add_message(&mut self, message: ConversationMessage) -> Result<()> {\n        self.conversation.lock().unwrap().push(message);\n        Ok(())\n    }\n\n    async fn clear_conversation(&mut self) -> Result<()> {\n        self.conversation.lock().unwrap().clear();\n        Ok(())\n    }\n}\n\n/// Test tool that performs string transformations\nstruct TestTool {\n    metadata: ComponentMetadata,\n    invocation_count: Arc<Mutex<usize>>,\n}\n\nimpl TestTool {\n    fn new(name: &str) -> Self {\n        Self {\n            metadata: ComponentMetadata::new(name.to_string(), format!(\"Test tool: {}\", name)),\n            invocation_count: Arc::new(Mutex::new(0)),\n        }\n    }\n}\n\n#[async_trait]\nimpl BaseAgent for TestTool {\n    fn metadata(&self) -> &ComponentMetadata {\n        &self.metadata\n    }\n\n    async fn execute(&self, input: AgentInput, _context: ExecutionContext) -> Result<AgentOutput> {\n        *self.invocation_count.lock().unwrap() += 1;\n\n        // Parse parameters from input parameters\n        let params = input\n            .parameters\n            .get(\"params\")\n            .ok_or_else(|| LLMSpellError::Validation {\n                message: \"Missing params in parameters\".to_string(),\n                field: Some(\"params\".to_string()),\n            })?;\n\n        let text = params.get(\"text\").and_then(|v| v.as_str()).ok_or_else(|| {\n            LLMSpellError::Validation {\n                message: \"Missing text parameter\".to_string(),\n                field: Some(\"text\".to_string()),\n            }\n        })?;\n\n        let operation = params\n            .get(\"operation\")\n            .and_then(|v| v.as_str())\n            .unwrap_or(\"uppercase\");\n\n        let result = match operation {\n            \"uppercase\" => text.to_uppercase(),\n            \"lowercase\" => text.to_lowercase(),\n            \"reverse\" => text.chars().rev().collect(),\n            _ => text.to_string(),\n        };\n\n        Ok(AgentOutput::text(result))\n    }\n\n    async fn validate_input(&self, _input: &AgentInput) -> Result<()> {\n        Ok(())\n    }\n\n    async fn handle_error(&self, error: LLMSpellError) -> Result<AgentOutput> {\n        Ok(AgentOutput::text(format!(\"Tool error: {}\", error)))\n    }\n}\n\n#[async_trait]\nimpl Tool for TestTool {\n    fn category(&self) -> ToolCategory {\n        ToolCategory::Utility\n    }\n\n    fn security_level(&self) -> SecurityLevel {\n        SecurityLevel::Safe\n    }\n\n    fn schema(&self) -> ToolSchema {\n        ToolSchema::new(\n            \"string_transform\".to_string(),\n            \"Transform strings in various ways\".to_string(),\n        )\n        .with_parameter(ParameterDef {\n            name: \"text\".to_string(),\n            param_type: ParameterType::String,\n            description: \"Text to transform\".to_string(),\n            required: true,\n            default: None,\n        })\n        .with_parameter(ParameterDef {\n            name: \"operation\".to_string(),\n            param_type: ParameterType::String,\n            description: \"Operation: uppercase, lowercase, reverse\".to_string(),\n            required: false,\n            default: Some(serde_json::json!(\"uppercase\")),\n        })\n    }\n\n    async fn validate_parameters(&self, params: &serde_json::Value) -> Result<()> {\n        if !params.is_object() {\n            return Err(LLMSpellError::Validation {\n                message: \"Parameters must be an object\".to_string(),\n                field: None,\n            });\n        }\n\n        if !params.get(\"text\").is_some() {\n            return Err(LLMSpellError::Validation {\n                message: \"Missing required parameter: text\".to_string(),\n                field: Some(\"text\".to_string()),\n            });\n        }\n\n        Ok(())\n    }\n}\n\n#[tokio::test]\nasync fn test_agent_conversation_flow() {\n    let mut agent = TestAgent::new(\"conversational-agent\");\n\n    // Test empty conversation\n    let conv = agent.get_conversation().await.unwrap();\n    assert_eq!(conv.len(), 0);\n\n    // Execute with input\n    let input = AgentInput::text(\"Hello, agent!\".to_string());\n    let context = ExecutionContext::with_conversation(\"test-session\".to_string());\n\n    let output = agent.execute(input, context).await.unwrap();\n    assert_eq!(output.text, \"Processed: Hello, agent!\");\n\n    // Check conversation was updated\n    let conv = agent.get_conversation().await.unwrap();\n    assert_eq!(conv.len(), 2);\n    assert_eq!(conv[0].role, MessageRole::User);\n    assert_eq!(conv[0].content, \"Hello, agent!\");\n    assert_eq!(conv[1].role, MessageRole::Assistant);\n    assert_eq!(conv[1].content, \"Processed: Hello, agent!\");\n\n    // Check execution count in metadata\n    let count = output.metadata.extra.get(\"execution_count\").unwrap();\n    assert_eq!(count, &serde_json::json!(1));\n\n    // Add system message\n    agent\n        .add_message(ConversationMessage::system(\n            \"You are a helpful assistant\".to_string(),\n        ))\n        .await\n        .unwrap();\n    let conv = agent.get_conversation().await.unwrap();\n    assert_eq!(conv.len(), 3);\n\n    // Clear conversation\n    agent.clear_conversation().await.unwrap();\n    let conv = agent.get_conversation().await.unwrap();\n    assert_eq!(conv.len(), 0);\n}\n\n#[tokio::test]\nasync fn test_tool_execution_and_validation() {\n    let tool = TestTool::new(\"string-tool\");\n\n    // Test schema\n    let schema = tool.schema();\n    assert_eq!(schema.name, \"string_transform\");\n    assert_eq!(schema.parameters.len(), 2);\n    assert_eq!(schema.required_parameters(), vec![\"text\"]);\n\n    // Test parameter validation\n    let valid_params = serde_json::json!({\n        \"text\": \"hello world\",\n        \"operation\": \"uppercase\"\n    });\n    assert!(tool.validate_parameters(&valid_params).await.is_ok());\n\n    let invalid_params = serde_json::json!({\n        \"operation\": \"uppercase\"\n    });\n    let err = tool.validate_parameters(&invalid_params).await.unwrap_err();\n    assert!(err.to_string().contains(\"Missing required parameter\"));\n\n    // Test execution\n    let input = AgentInput::text(\"transform\".to_string())\n        .with_parameter(\"params\".to_string(), valid_params);\n    let context = ExecutionContext::with_conversation(\"test-session\".to_string());\n\n    let output = tool.execute(input, context).await.unwrap();\n    assert_eq!(output.text, \"HELLO WORLD\");\n\n    // Test different operations\n    let params = serde_json::json!({\n        \"text\": \"HELLO\",\n        \"operation\": \"lowercase\"\n    });\n    let input =\n        AgentInput::text(\"transform\".to_string()).with_parameter(\"params\".to_string(), params);\n    let output = tool\n        .execute(\n            input,\n            ExecutionContext::with_conversation(\"test\".to_string()),\n        )\n        .await\n        .unwrap();\n    assert_eq!(output.text, \"hello\");\n\n    // Test reverse\n    let params = serde_json::json!({\n        \"text\": \"hello\",\n        \"operation\": \"reverse\"\n    });\n    let input =\n        AgentInput::text(\"transform\".to_string()).with_parameter(\"params\".to_string(), params);\n    let output = tool\n        .execute(\n            input,\n            ExecutionContext::with_conversation(\"test\".to_string()),\n        )\n        .await\n        .unwrap();\n    assert_eq!(output.text, \"olleh\");\n}\n\n#[tokio::test]\nasync fn test_error_handling_flow() {\n    let agent = TestAgent::new(\"error-test-agent\");\n\n    // Test validation error\n    let input = AgentInput::text(\"\".to_string());\n    let context = ExecutionContext::with_conversation(\"test\".to_string());\n\n    let result = agent.execute(input, context).await;\n    assert!(result.is_err());\n\n    let err = result.unwrap_err();\n    match &err {\n        LLMSpellError::Validation { field, .. } => {\n            assert_eq!(*field, Some(\"prompt\".to_string()));\n        }\n        _ => panic!(\"Expected validation error\"),\n    }\n\n    // Test error handling\n    let handled = agent.handle_error(err).await.unwrap();\n    assert!(handled.text.contains(\"Error handled\"));\n}\n\n#[tokio::test]\nasync fn test_component_metadata_updates() {\n    let mut metadata =\n        ComponentMetadata::new(\"test-component\".to_string(), \"A test component\".to_string());\n\n    // Initial version\n    assert_eq!(metadata.version, Version::new(0, 1, 0));\n\n    // Update version\n    metadata.update_version(Version::new(1, 0, 0));\n    assert_eq!(metadata.version, Version::new(1, 0, 0));\n\n    // Check timestamps\n    assert!(metadata.updated_at >= metadata.created_at);\n\n    // Test serialization\n    let json = serde_json::to_string(&metadata).unwrap();\n    let deserialized: ComponentMetadata = serde_json::from_str(&json).unwrap();\n    assert_eq!(metadata.id, deserialized.id);\n    assert_eq!(metadata.name, deserialized.name);\n}\n\n#[tokio::test]\nasync fn test_execution_context_environment() {\n    let mut context = ExecutionContext::with_conversation(\"test-session\".to_string());\n    context.user_id = Some(\"user-123\".to_string());\n    let context = context\n        .with_data(\"LOG_LEVEL\".to_string(), serde_json::json!(\"debug\"))\n        .with_data(\"ENV\".to_string(), serde_json::json!(\"test\"));\n\n    assert_eq!(context.conversation_id, Some(\"test-session\".to_string()));\n    assert_eq!(context.user_id, Some(\"user-123\".to_string()));\n    assert_eq!(\n        context.data.get(\"LOG_LEVEL\"),\n        Some(&serde_json::json!(\"debug\"))\n    );\n    assert_eq!(context.data.get(\"ENV\"), Some(&serde_json::json!(\"test\")));\n    assert_eq!(context.data.get(\"MISSING\"), None);\n}\n\n#[tokio::test]\nasync fn test_agent_input_context_manipulation() {\n    let input = AgentInput::text(\"test prompt\".to_string())\n        .with_parameter(\"key1\".to_string(), serde_json::json!(\"value1\"))\n        .with_parameter(\"key2\".to_string(), serde_json::json!(42))\n        .with_parameter(\n            \"nested\".to_string(),\n            serde_json::json!({\n                \"inner\": \"value\",\n                \"count\": 10\n            }),\n        );\n\n    assert_eq!(input.text, \"test prompt\");\n    assert_eq!(\n        input.parameters.get(\"key1\"),\n        Some(&serde_json::json!(\"value1\"))\n    );\n    assert_eq!(input.parameters.get(\"key2\"), Some(&serde_json::json!(42)));\n\n    let nested = input.parameters.get(\"nested\").unwrap();\n    assert_eq!(nested.get(\"inner\"), Some(&serde_json::json!(\"value\")));\n    assert_eq!(nested.get(\"count\"), Some(&serde_json::json!(10)));\n}\n\n#[tokio::test]\nasync fn test_agent_output_metadata() {\n    let mut metadata = llmspell_core::types::OutputMetadata::default();\n    metadata.confidence = Some(0.95);\n    metadata.token_count = Some(100);\n    metadata.model = Some(\"gpt-4\".to_string());\n    let output = AgentOutput::text(\"result\".to_string()).with_metadata(metadata);\n\n    assert_eq!(output.text, \"result\");\n    assert_eq!(output.metadata.confidence, Some(0.95));\n    assert_eq!(output.metadata.token_count, Some(100));\n    assert_eq!(output.metadata.model, Some(\"gpt-4\".to_string()));\n    assert_eq!(output.metadata.extra.get(\"missing\"), None);\n}\n","traces":[{"line":26,"address":[],"length":0,"stats":{"Line":2}},{"line":28,"address":[],"length":0,"stats":{"Line":2}},{"line":29,"address":[],"length":0,"stats":{"Line":2}},{"line":30,"address":[],"length":0,"stats":{"Line":2}},{"line":31,"address":[],"length":0,"stats":{"Line":2}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":2}},{"line":44,"address":[],"length":0,"stats":{"Line":3}},{"line":46,"address":[],"length":0,"stats":{"Line":1}},{"line":49,"address":[],"length":0,"stats":{"Line":1}},{"line":50,"address":[],"length":0,"stats":{"Line":1}},{"line":52,"address":[],"length":0,"stats":{"Line":1}},{"line":53,"address":[],"length":0,"stats":{"Line":1}},{"line":55,"address":[],"length":0,"stats":{"Line":1}},{"line":56,"address":[],"length":0,"stats":{"Line":1}},{"line":57,"address":[],"length":0,"stats":{"Line":1}},{"line":58,"address":[],"length":0,"stats":{"Line":1}},{"line":60,"address":[],"length":0,"stats":{"Line":1}},{"line":63,"address":[],"length":0,"stats":{"Line":2}},{"line":64,"address":[],"length":0,"stats":{"Line":2}},{"line":65,"address":[],"length":0,"stats":{"Line":1}},{"line":66,"address":[],"length":0,"stats":{"Line":1}},{"line":67,"address":[],"length":0,"stats":{"Line":1}},{"line":70,"address":[],"length":0,"stats":{"Line":1}},{"line":73,"address":[],"length":0,"stats":{"Line":1}},{"line":74,"address":[],"length":0,"stats":{"Line":1}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":4}},{"line":85,"address":[],"length":0,"stats":{"Line":4}},{"line":88,"address":[],"length":0,"stats":{"Line":1}},{"line":89,"address":[],"length":0,"stats":{"Line":1}},{"line":90,"address":[],"length":0,"stats":{"Line":1}},{"line":93,"address":[],"length":0,"stats":{"Line":1}},{"line":94,"address":[],"length":0,"stats":{"Line":1}},{"line":95,"address":[],"length":0,"stats":{"Line":1}},{"line":106,"address":[],"length":0,"stats":{"Line":1}},{"line":108,"address":[],"length":0,"stats":{"Line":1}},{"line":109,"address":[],"length":0,"stats":{"Line":1}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":3}},{"line":121,"address":[],"length":0,"stats":{"Line":3}},{"line":124,"address":[],"length":0,"stats":{"Line":6}},{"line":125,"address":[],"length":0,"stats":{"Line":3}},{"line":127,"address":[],"length":0,"stats":{"Line":3}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":6}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":3}},{"line":145,"address":[],"length":0,"stats":{"Line":1}},{"line":146,"address":[],"length":0,"stats":{"Line":3}},{"line":147,"address":[],"length":0,"stats":{"Line":2}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":1}},{"line":175,"address":[],"length":0,"stats":{"Line":1}},{"line":176,"address":[],"length":0,"stats":{"Line":1}},{"line":178,"address":[],"length":0,"stats":{"Line":1}},{"line":179,"address":[],"length":0,"stats":{"Line":1}},{"line":180,"address":[],"length":0,"stats":{"Line":1}},{"line":181,"address":[],"length":0,"stats":{"Line":1}},{"line":182,"address":[],"length":0,"stats":{"Line":1}},{"line":183,"address":[],"length":0,"stats":{"Line":1}},{"line":185,"address":[],"length":0,"stats":{"Line":1}},{"line":186,"address":[],"length":0,"stats":{"Line":1}},{"line":187,"address":[],"length":0,"stats":{"Line":1}},{"line":188,"address":[],"length":0,"stats":{"Line":1}},{"line":189,"address":[],"length":0,"stats":{"Line":1}},{"line":190,"address":[],"length":0,"stats":{"Line":1}},{"line":194,"address":[],"length":0,"stats":{"Line":2}},{"line":195,"address":[],"length":0,"stats":{"Line":2}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":2}},{"line":203,"address":[],"length":0,"stats":{"Line":1}},{"line":204,"address":[],"length":0,"stats":{"Line":1}},{"line":205,"address":[],"length":0,"stats":{"Line":1}},{"line":209,"address":[],"length":0,"stats":{"Line":1}}],"covered":68,"coverable":91},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-core","tests","property_tests.rs"],"content":"//! Property-based tests for llmspell-core\n//!\n//! These tests use proptest to verify invariants and properties\n//! that should hold for all possible inputs\n\nuse llmspell_core::{\n    traits::{\n        agent::{AgentConfig, ConversationMessage, MessageRole},\n        workflow::{RetryPolicy, WorkflowStep},\n    },\n    types::{AgentInput, AgentOutput, ExecutionContext},\n    ComponentId, ComponentMetadata, Version,\n};\nuse proptest::prelude::*;\n\n// Strategy for generating ComponentIds\nprop_compose! {\n    fn arb_component_name()(name in \"[a-zA-Z][a-zA-Z0-9-_]{0,63}\") -> String {\n        name\n    }\n}\n\n// Strategy for generating Versions\nprop_compose! {\n    fn arb_version()(\n        major in 0u32..100,\n        minor in 0u32..100,\n        patch in 0u32..100\n    ) -> Version {\n        Version::new(major, minor, patch)\n    }\n}\n\n// Strategy for generating AgentInput\nprop_compose! {\n    fn arb_agent_input()(\n        prompt in prop::string::string_regex(\"[a-zA-Z0-9 .,!?-]{1,1000}\").unwrap(),\n        context_keys in prop::collection::vec(\n            prop::string::string_regex(\"[a-zA-Z][a-zA-Z0-9_]{0,31}\").unwrap(),\n            0..5\n        ),\n        context_values in prop::collection::vec(\n            prop_oneof![\n                Just(serde_json::json!(null)),\n                prop::num::i64::ANY.prop_map(|n| serde_json::json!(n)),\n                prop::string::string_regex(\"[a-zA-Z0-9 ]{0,50}\").unwrap().prop_map(|s| serde_json::json!(s)),\n                prop::bool::ANY.prop_map(|b| serde_json::json!(b)),\n            ],\n            0..5\n        )\n    ) -> AgentInput {\n        let mut input = AgentInput::text(prompt);\n        for (key, value) in context_keys.into_iter().zip(context_values.into_iter()) {\n            input = input.with_parameter(key, value);\n        }\n        input\n    }\n}\n\n// Strategy for generating MessageRole\nfn arb_message_role() -> impl Strategy<Value = MessageRole> {\n    prop_oneof![\n        Just(MessageRole::System),\n        Just(MessageRole::User),\n        Just(MessageRole::Assistant),\n    ]\n}\n\n// Strategy for generating ConversationMessage\nprop_compose! {\n    fn arb_conversation_message()(\n        role in arb_message_role(),\n        content in prop::string::string_regex(\"[a-zA-Z0-9 .,!?-]{1,1000}\").unwrap()\n    ) -> ConversationMessage {\n        ConversationMessage::new(role, content)\n    }\n}\n\n// Strategy for generating RetryPolicy\nprop_compose! {\n    fn arb_retry_policy()(\n        max_attempts in 1u32..10,\n        backoff_seconds in 1u32..60,\n        exponential_backoff in any::<bool>()\n    ) -> RetryPolicy {\n        RetryPolicy {\n            max_attempts,\n            backoff_seconds,\n            exponential_backoff,\n        }\n    }\n}\n\nproptest! {\n    #[test]\n    fn test_component_id_deterministic(name in arb_component_name()) {\n        // Property: Same name always produces same ComponentId\n        let id1 = ComponentId::from_name(&name);\n        let id2 = ComponentId::from_name(&name);\n        prop_assert_eq!(id1, id2);\n    }\n\n    #[test]\n    fn test_component_id_different_names(\n        name1 in arb_component_name(),\n        name2 in arb_component_name()\n    ) {\n        // Property: Different names produce different ComponentIds\n        prop_assume!(name1 != name2);\n        let id1 = ComponentId::from_name(&name1);\n        let id2 = ComponentId::from_name(&name2);\n        prop_assert_ne!(id1, id2);\n    }\n\n    #[test]\n    fn test_component_id_serialization_roundtrip(name in arb_component_name()) {\n        // Property: ComponentId survives serialization/deserialization\n        let id = ComponentId::from_name(&name);\n        let json = serde_json::to_string(&id).unwrap();\n        let deserialized: ComponentId = serde_json::from_str(&json).unwrap();\n        prop_assert_eq!(id, deserialized);\n    }\n\n    #[test]\n    fn test_version_ordering_properties(v1 in arb_version(), v2 in arb_version()) {\n        // Property: Version ordering is transitive\n        if v1 < v2 {\n            prop_assert!(!(v2 < v1)); // Antisymmetry\n        }\n        if v1 == v2 {\n            prop_assert!(v1.is_compatible_with(&v2));\n            prop_assert!(v2.is_compatible_with(&v1));\n        }\n    }\n\n    #[test]\n    fn test_version_compatibility_properties(v in arb_version()) {\n        // Property: A version is always compatible with itself\n        prop_assert!(v.is_compatible_with(&v));\n\n        // Property: Versions with same major are compatible\n        let v2 = Version::new(v.major, v.minor + 1, v.patch);\n        prop_assert!(v.is_compatible_with(&v2));\n\n        // Property: Versions with different major are not compatible\n        let v3 = Version::new(v.major + 1, v.minor, v.patch);\n        prop_assert!(!v.is_compatible_with(&v3));\n    }\n\n    #[test]\n    fn test_version_serialization_roundtrip(v in arb_version()) {\n        // Property: Version survives serialization/deserialization\n        let json = serde_json::to_string(&v).unwrap();\n        let deserialized: Version = serde_json::from_str(&json).unwrap();\n        prop_assert_eq!(v.major, deserialized.major);\n        prop_assert_eq!(v.minor, deserialized.minor);\n        prop_assert_eq!(v.patch, deserialized.patch);\n        prop_assert_eq!(v.to_string(), deserialized.to_string());\n    }\n\n    #[test]\n    fn test_agent_input_context_preservation(input in arb_agent_input()) {\n        // Property: Parameter values are preserved\n        for (key, value) in &input.parameters {\n            prop_assert_eq!(input.parameters.get(key), Some(value));\n        }\n\n        // Property: Non-existent keys return None\n        prop_assert_eq!(input.parameters.get(\"non_existent_key_xyz\"), None);\n    }\n\n    #[test]\n    fn test_agent_input_serialization_roundtrip(input in arb_agent_input()) {\n        // Property: AgentInput survives serialization/deserialization\n        let json = serde_json::to_string(&input).unwrap();\n        let deserialized: AgentInput = serde_json::from_str(&json).unwrap();\n        prop_assert_eq!(input.text, deserialized.text);\n        prop_assert_eq!(input.parameters, deserialized.parameters);\n    }\n\n    #[test]\n    fn test_agent_output_metadata_preservation(\n        content in prop::string::string_regex(\"[a-zA-Z0-9 ]{1,100}\").unwrap(),\n        metadata_keys in prop::collection::vec(\n            prop::string::string_regex(\"[a-zA-Z][a-zA-Z0-9_]{0,31}\").unwrap(),\n            0..5\n        ),\n        metadata_values in prop::collection::vec(\n            prop_oneof![\n                Just(serde_json::json!(null)),\n                prop::num::i64::ANY.prop_map(|n| serde_json::json!(n)),\n                prop::string::string_regex(\"[a-zA-Z0-9 ]{0,50}\").unwrap().prop_map(|s| serde_json::json!(s)),\n                prop::bool::ANY.prop_map(|b| serde_json::json!(b)),\n            ],\n            0..5\n        )\n    ) {\n        // Property: Metadata values are preserved\n        let mut metadata = llmspell_core::types::OutputMetadata::default();\n        for (key, value) in metadata_keys.iter().zip(metadata_values.iter()) {\n            metadata.extra.insert(key.clone(), value.clone());\n        }\n        let output = AgentOutput::text(content).with_metadata(metadata);\n        for (key, value) in metadata_keys.into_iter().zip(metadata_values.into_iter()) {\n            prop_assert_eq!(output.metadata.extra.get(&key), Some(&value));\n        }\n    }\n\n    #[test]\n    fn test_conversation_message_properties(msg in arb_conversation_message()) {\n        // Property: Message fields are preserved\n        let cloned = msg.clone();\n        prop_assert_eq!(msg.role, cloned.role);\n        prop_assert_eq!(msg.content, cloned.content);\n\n        // Property: Timestamp is set and reasonable\n        let now = chrono::Utc::now();\n        let diff = now - msg.timestamp;\n        prop_assert!(diff.num_seconds() >= 0);\n        prop_assert!(diff.num_seconds() < 60); // Should be created within last minute\n    }\n\n    #[test]\n    fn test_execution_context_environment_properties(\n        session_id in prop::string::string_regex(\"[a-zA-Z0-9-]{1,50}\").unwrap(),\n        user_id in prop::option::of(prop::string::string_regex(\"[a-zA-Z0-9-]{1,50}\").unwrap()),\n        env_keys in prop::collection::vec(\n            prop::string::string_regex(\"[A-Z_]{1,20}\").unwrap(),\n            0..5\n        ),\n        env_values in prop::collection::vec(\n            prop::string::string_regex(\"[a-zA-Z0-9-]{1,50}\").unwrap(),\n            0..5\n        )\n    ) {\n        // Property: Context preserves all fields\n        let mut context = ExecutionContext::with_conversation(session_id.clone());\n\n        if let Some(uid) = user_id.clone() {\n            context.user_id = Some(uid);\n        }\n\n        for (key, value) in env_keys.into_iter().zip(env_values.into_iter()) {\n            let json_value = serde_json::json!(value.clone());\n            context = context.with_data(key.clone(), json_value.clone());\n            prop_assert_eq!(context.data.get(&key), Some(&json_value));\n        }\n\n        prop_assert_eq!(context.conversation_id, Some(session_id));\n        prop_assert_eq!(context.user_id, user_id);\n    }\n\n    #[test]\n    fn test_retry_policy_properties(policy in arb_retry_policy()) {\n        // Property: All fields are preserved\n        let cloned = policy.clone();\n        prop_assert_eq!(policy.max_attempts, cloned.max_attempts);\n        prop_assert_eq!(policy.backoff_seconds, cloned.backoff_seconds);\n        prop_assert_eq!(policy.exponential_backoff, cloned.exponential_backoff);\n\n        // Property: Serialization roundtrip\n        let json = serde_json::to_string(&policy).unwrap();\n        let deserialized: RetryPolicy = serde_json::from_str(&json).unwrap();\n        prop_assert_eq!(policy.max_attempts, deserialized.max_attempts);\n    }\n\n    #[test]\n    fn test_component_metadata_timestamp_ordering(\n        name in arb_component_name(),\n        description in prop::string::string_regex(\"[a-zA-Z0-9 ]{1,100}\").unwrap()\n    ) {\n        // Property: created_at <= updated_at\n        let metadata = ComponentMetadata::new(name, description);\n        prop_assert!(metadata.created_at <= metadata.updated_at);\n\n        // Property: After version update, updated_at changes\n        let mut metadata_mut = metadata.clone();\n        std::thread::sleep(std::time::Duration::from_millis(10));\n        metadata_mut.update_version(Version::new(1, 0, 0));\n        prop_assert!(metadata_mut.updated_at > metadata.updated_at);\n    }\n\n    #[test]\n    fn test_agent_config_optional_fields(\n        max_conversation_length in prop::option::of(1usize..1000),\n        system_prompt in prop::option::of(prop::string::string_regex(\"[a-zA-Z0-9 ]{1,100}\").unwrap()),\n        temperature in prop::option::of(0.0f32..2.0),\n        max_tokens in prop::option::of(1usize..10000)\n    ) {\n        // Property: Optional fields are preserved correctly\n        let config = AgentConfig {\n            max_conversation_length,\n            system_prompt: system_prompt.clone(),\n            temperature,\n            max_tokens,\n        };\n\n        // Serialization roundtrip\n        let json = serde_json::to_string(&config).unwrap();\n        let deserialized: AgentConfig = serde_json::from_str(&json).unwrap();\n\n        prop_assert_eq!(config.max_conversation_length, deserialized.max_conversation_length);\n        prop_assert_eq!(config.system_prompt, deserialized.system_prompt);\n        prop_assert_eq!(config.temperature, deserialized.temperature);\n        prop_assert_eq!(config.max_tokens, deserialized.max_tokens);\n    }\n}\n\n// Additional complex property tests\nproptest! {\n    #[test]\n    fn test_workflow_step_dependency_properties(\n        name in arb_component_name(),\n        component_id in arb_component_name().prop_map(|n| ComponentId::from_name(&n)),\n        dep_count in 0usize..5\n    ) {\n        // Generate random dependencies\n        let deps: Vec<ComponentId> = (0..dep_count)\n            .map(|i| ComponentId::from_name(&format!(\"dep-{}\", i)))\n            .collect();\n\n        // Build workflow step\n        let mut step = WorkflowStep::new(name, component_id);\n        for dep in &deps {\n            step = step.with_dependency(*dep);\n        }\n\n        // Property: All dependencies are preserved\n        prop_assert_eq!(step.dependencies.len(), deps.len());\n        for dep in deps {\n            prop_assert!(step.dependencies.contains(&dep));\n        }\n    }\n\n    #[test]\n    fn test_error_severity_ordering_transitivity(\n        errors in prop::collection::vec(\n            prop_oneof![\n                Just(llmspell_core::error::ErrorSeverity::Info),\n                Just(llmspell_core::error::ErrorSeverity::Warning),\n                Just(llmspell_core::error::ErrorSeverity::Error),\n                Just(llmspell_core::error::ErrorSeverity::Critical),\n                Just(llmspell_core::error::ErrorSeverity::Fatal),\n            ],\n            3..=3\n        )\n    ) {\n        // Property: If a < b and b < c, then a < c (transitivity)\n        let (a, b, c) = (errors[0].clone(), errors[1].clone(), errors[2].clone());\n        if a < b && b < c {\n            prop_assert!(a < c);\n        }\n\n        // Property: Exactly one of a < b, a == b, or a > b is true\n        let less = a < b;\n        let equal = a == b;\n        let greater = a > b;\n        prop_assert_eq!((less as i32) + (equal as i32) + (greater as i32), 1);\n    }\n}\n\n#[cfg(test)]\nmod regression_tests {\n    use super::*;\n\n    #[test]\n    fn test_empty_string_component_id() {\n        // Regression test: empty strings should produce valid IDs\n        let id1 = ComponentId::from_name(\"\");\n        let id2 = ComponentId::from_name(\"\");\n        assert_eq!(id1, id2);\n    }\n\n    #[test]\n    fn test_unicode_component_names() {\n        // Regression test: unicode should work in component names\n        let names = vec![\n            \"компонент\",\n            \"组件\",\n            \"コンポーネント\",\n            \"🚀-rocket\",\n            \"café-component\",\n        ];\n\n        for name in names {\n            let id1 = ComponentId::from_name(name);\n            let id2 = ComponentId::from_name(name);\n            assert_eq!(id1, id2);\n        }\n    }\n\n    #[test]\n    fn test_very_large_version_numbers() {\n        // Regression test: large version numbers\n        let v = Version::new(u32::MAX, u32::MAX, u32::MAX);\n        let json = serde_json::to_string(&v).unwrap();\n        let deserialized: Version = serde_json::from_str(&json).unwrap();\n        assert_eq!(v, deserialized);\n    }\n}\n","traces":[{"line":45,"address":[],"length":0,"stats":{"Line":268}},{"line":46,"address":[],"length":0,"stats":{"Line":274}},{"line":47,"address":[],"length":0,"stats":{"Line":273}},{"line":61,"address":[],"length":0,"stats":{"Line":1}},{"line":62,"address":[],"length":0,"stats":{"Line":1}},{"line":63,"address":[],"length":0,"stats":{"Line":1}},{"line":64,"address":[],"length":0,"stats":{"Line":1}},{"line":65,"address":[],"length":0,"stats":{"Line":1}},{"line":191,"address":[],"length":0,"stats":{"Line":153}},{"line":192,"address":[],"length":0,"stats":{"Line":163}},{"line":193,"address":[],"length":0,"stats":{"Line":119}},{"line":314,"address":[],"length":0,"stats":{"Line":256}},{"line":319,"address":[],"length":0,"stats":{"Line":518}}],"covered":13,"coverable":13},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-core","tests","serialization_tests.rs"],"content":"//! Serialization and deserialization tests\n//!\n//! These tests verify that all types can be correctly serialized and deserialized\n\nuse llmspell_core::{\n    traits::{\n        agent::{AgentConfig, ConversationMessage, MessageRole},\n        tool::{ParameterDef, ParameterType, SecurityLevel, ToolCategory, ToolSchema},\n        workflow::{RetryPolicy, StepResult, WorkflowStatus, WorkflowStep},\n    },\n    types::{AgentInput, AgentOutput, ExecutionContext},\n    ComponentId, ComponentMetadata, Version,\n};\n\n#[test]\nfn test_component_id_json_roundtrip() {\n    let id = ComponentId::from_name(\"test-component\");\n\n    let json = serde_json::to_string(&id).unwrap();\n    let deserialized: ComponentId = serde_json::from_str(&json).unwrap();\n\n    assert_eq!(id, deserialized);\n}\n\n#[test]\nfn test_version_json_roundtrip() {\n    let version = Version::new(1, 2, 3);\n\n    let json = serde_json::to_string(&version).unwrap();\n    let deserialized: Version = serde_json::from_str(&json).unwrap();\n\n    assert_eq!(version, deserialized);\n    assert_eq!(deserialized.major, 1);\n    assert_eq!(deserialized.minor, 2);\n    assert_eq!(deserialized.patch, 3);\n}\n\n#[test]\nfn test_component_metadata_json_roundtrip() {\n    let metadata = ComponentMetadata::new(\n        \"test-component\".to_string(),\n        \"Test component description\".to_string(),\n    );\n\n    let json = serde_json::to_string(&metadata).unwrap();\n    let deserialized: ComponentMetadata = serde_json::from_str(&json).unwrap();\n\n    assert_eq!(metadata.id, deserialized.id);\n    assert_eq!(metadata.name, deserialized.name);\n    assert_eq!(metadata.description, deserialized.description);\n    assert_eq!(metadata.version, deserialized.version);\n}\n\n#[test]\nfn test_agent_input_json_roundtrip() {\n    let input = AgentInput::text(\"test prompt\".to_string())\n        .with_parameter(\"key1\".to_string(), serde_json::json!(\"value1\"))\n        .with_parameter(\"key2\".to_string(), serde_json::json!(42))\n        .with_parameter(\n            \"nested\".to_string(),\n            serde_json::json!({\n                \"inner\": \"value\",\n                \"count\": 10\n            }),\n        );\n\n    let json = serde_json::to_string(&input).unwrap();\n    let deserialized: AgentInput = serde_json::from_str(&json).unwrap();\n\n    assert_eq!(input.text, deserialized.text);\n    assert_eq!(input.parameters, deserialized.parameters);\n}\n\n#[test]\nfn test_agent_output_json_roundtrip() {\n    let mut metadata = llmspell_core::types::OutputMetadata::default();\n    metadata.confidence = Some(0.95);\n    metadata.token_count = Some(150);\n    metadata.model = Some(\"gpt-4\".to_string());\n    let output = AgentOutput::text(\"result content\".to_string()).with_metadata(metadata);\n\n    let json = serde_json::to_string(&output).unwrap();\n    let deserialized: AgentOutput = serde_json::from_str(&json).unwrap();\n\n    assert_eq!(output.text, deserialized.text);\n    assert_eq!(output.metadata.confidence, deserialized.metadata.confidence);\n    assert_eq!(\n        output.metadata.token_count,\n        deserialized.metadata.token_count\n    );\n    assert_eq!(output.metadata.model, deserialized.metadata.model);\n}\n\n#[test]\nfn test_execution_context_json_roundtrip() {\n    let mut context = ExecutionContext::with_conversation(\"session-123\".to_string());\n    context.user_id = Some(\"user-456\".to_string());\n    let context = context.with_data(\"ENV_VAR\".to_string(), serde_json::json!(\"value\"));\n\n    let json = serde_json::to_string(&context).unwrap();\n    let deserialized: ExecutionContext = serde_json::from_str(&json).unwrap();\n\n    assert_eq!(context.conversation_id, deserialized.conversation_id);\n    assert_eq!(context.user_id, deserialized.user_id);\n    assert_eq!(context.data, deserialized.data);\n}\n\n#[test]\nfn test_conversation_message_json_roundtrip() {\n    let messages = vec![\n        ConversationMessage::system(\"System prompt\".to_string()),\n        ConversationMessage::user(\"User message\".to_string()),\n        ConversationMessage::assistant(\"Assistant response\".to_string()),\n    ];\n\n    for msg in messages {\n        let json = serde_json::to_string(&msg).unwrap();\n        let deserialized: ConversationMessage = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(msg.role, deserialized.role);\n        assert_eq!(msg.content, deserialized.content);\n        // Timestamps might differ slightly, so we just check they exist\n        assert!(deserialized.timestamp.timestamp() > 0);\n    }\n}\n\n#[test]\nfn test_message_role_json_roundtrip() {\n    let roles = vec![\n        MessageRole::System,\n        MessageRole::User,\n        MessageRole::Assistant,\n    ];\n\n    for role in roles {\n        let json = serde_json::to_string(&role).unwrap();\n        let deserialized: MessageRole = serde_json::from_str(&json).unwrap();\n        assert_eq!(role, deserialized);\n    }\n}\n\n#[test]\nfn test_agent_config_json_roundtrip() {\n    let config = AgentConfig {\n        max_conversation_length: Some(100),\n        system_prompt: Some(\"You are helpful\".to_string()),\n        temperature: Some(0.7),\n        max_tokens: Some(2000),\n    };\n\n    let json = serde_json::to_string(&config).unwrap();\n    let deserialized: AgentConfig = serde_json::from_str(&json).unwrap();\n\n    assert_eq!(\n        config.max_conversation_length,\n        deserialized.max_conversation_length\n    );\n    assert_eq!(config.system_prompt, deserialized.system_prompt);\n    assert_eq!(config.temperature, deserialized.temperature);\n    assert_eq!(config.max_tokens, deserialized.max_tokens);\n}\n\n#[test]\nfn test_tool_schema_json_roundtrip() {\n    let schema = ToolSchema::new(\"test_tool\".to_string(), \"A test tool\".to_string())\n        .with_parameter(ParameterDef {\n            name: \"param1\".to_string(),\n            param_type: ParameterType::String,\n            description: \"First parameter\".to_string(),\n            required: true,\n            default: None,\n        })\n        .with_parameter(ParameterDef {\n            name: \"param2\".to_string(),\n            param_type: ParameterType::Number,\n            description: \"Second parameter\".to_string(),\n            required: false,\n            default: Some(serde_json::json!(42)),\n        });\n\n    let json = serde_json::to_string(&schema).unwrap();\n    let deserialized: ToolSchema = serde_json::from_str(&json).unwrap();\n\n    assert_eq!(schema.name, deserialized.name);\n    assert_eq!(schema.description, deserialized.description);\n    assert_eq!(schema.parameters.len(), deserialized.parameters.len());\n}\n\n#[test]\nfn test_tool_category_json_roundtrip() {\n    let categories = vec![\n        ToolCategory::Filesystem,\n        ToolCategory::Web,\n        ToolCategory::Analysis,\n        ToolCategory::Data,\n        ToolCategory::System,\n        ToolCategory::Utility,\n        ToolCategory::Custom(\"MyCategory\".to_string()),\n    ];\n\n    for category in categories {\n        let json = serde_json::to_string(&category).unwrap();\n        let deserialized: ToolCategory = serde_json::from_str(&json).unwrap();\n        assert_eq!(category, deserialized);\n    }\n}\n\n#[test]\nfn test_security_level_json_roundtrip() {\n    let levels = vec![\n        SecurityLevel::Safe,\n        SecurityLevel::Restricted,\n        SecurityLevel::Privileged,\n    ];\n\n    for level in levels {\n        let json = serde_json::to_string(&level).unwrap();\n        let deserialized: SecurityLevel = serde_json::from_str(&json).unwrap();\n        assert_eq!(level, deserialized);\n    }\n}\n\n#[test]\nfn test_parameter_type_json_roundtrip() {\n    let types = vec![\n        ParameterType::String,\n        ParameterType::Number,\n        ParameterType::Boolean,\n        ParameterType::Array,\n        ParameterType::Object,\n        ParameterType::Null,\n    ];\n\n    for param_type in types {\n        let json = serde_json::to_string(&param_type).unwrap();\n        let deserialized: ParameterType = serde_json::from_str(&json).unwrap();\n        assert_eq!(param_type, deserialized);\n    }\n}\n\n#[test]\nfn test_workflow_step_json_roundtrip() {\n    let component_id = ComponentId::from_name(\"process-component\");\n    let dep_id = ComponentId::from_name(\"init-component\");\n\n    let step = WorkflowStep::new(\"process_data\".to_string(), component_id)\n        .with_dependency(dep_id)\n        .with_retry(RetryPolicy::default())\n        .with_timeout(std::time::Duration::from_secs(300));\n\n    let json = serde_json::to_string(&step).unwrap();\n    let deserialized: WorkflowStep = serde_json::from_str(&json).unwrap();\n\n    assert_eq!(step.id, deserialized.id);\n    assert_eq!(step.name, deserialized.name);\n    assert_eq!(step.component_id, deserialized.component_id);\n    assert_eq!(step.dependencies, deserialized.dependencies);\n}\n\n#[test]\nfn test_step_result_json_roundtrip() {\n    let step_id = ComponentId::from_name(\"test-step\");\n    let mut metadata = llmspell_core::types::OutputMetadata::default();\n    metadata\n        .extra\n        .insert(\"records\".to_string(), serde_json::json!(100));\n    let output = AgentOutput::text(\"Completed successfully\".to_string()).with_metadata(metadata);\n\n    let success_result = StepResult::success(step_id, output, std::time::Duration::from_secs(1));\n\n    let json = serde_json::to_string(&success_result).unwrap();\n    let deserialized: StepResult = serde_json::from_str(&json).unwrap();\n\n    assert_eq!(success_result.success, deserialized.success);\n    assert_eq!(success_result.step_id, deserialized.step_id);\n    assert!(deserialized.error.is_none());\n\n    let error_result = StepResult::failure(\n        step_id,\n        \"Processing failed\".to_string(),\n        std::time::Duration::from_secs(1),\n        2,\n    );\n\n    let json = serde_json::to_string(&error_result).unwrap();\n    let deserialized: StepResult = serde_json::from_str(&json).unwrap();\n\n    assert!(!deserialized.success);\n    assert_eq!(deserialized.error, Some(\"Processing failed\".to_string()));\n    assert_eq!(deserialized.retry_count, 2);\n}\n\n#[test]\nfn test_workflow_status_json_roundtrip() {\n    let statuses = vec![\n        WorkflowStatus::Pending,\n        WorkflowStatus::Running,\n        WorkflowStatus::Completed,\n        WorkflowStatus::Failed,\n        WorkflowStatus::Cancelled,\n    ];\n\n    for status in statuses {\n        let json = serde_json::to_string(&status).unwrap();\n        let deserialized: WorkflowStatus = serde_json::from_str(&json).unwrap();\n        assert_eq!(status, deserialized);\n    }\n}\n\n#[test]\nfn test_retry_policy_json_roundtrip() {\n    let policies = vec![\n        RetryPolicy::default(),\n        RetryPolicy {\n            max_attempts: 5,\n            backoff_seconds: 2,\n            exponential_backoff: false,\n        },\n        RetryPolicy {\n            max_attempts: 10,\n            backoff_seconds: 5,\n            exponential_backoff: true,\n        },\n    ];\n\n    for policy in policies {\n        let json = serde_json::to_string(&policy).unwrap();\n        let deserialized: RetryPolicy = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(policy.max_attempts, deserialized.max_attempts);\n        assert_eq!(policy.backoff_seconds, deserialized.backoff_seconds);\n        assert_eq!(policy.exponential_backoff, deserialized.exponential_backoff);\n    }\n}\n\n#[test]\nfn test_complex_nested_serialization() {\n    // Test deeply nested structures\n    let input = AgentInput::text(\"complex test\".to_string()).with_parameter(\n        \"nested\".to_string(),\n        serde_json::json!({\n            \"level1\": {\n                \"level2\": {\n                    \"level3\": {\n                        \"data\": [1, 2, 3],\n                        \"flag\": true,\n                        \"value\": null\n                    }\n                }\n            }\n        }),\n    );\n\n    let json = serde_json::to_string(&input).unwrap();\n    let deserialized: AgentInput = serde_json::from_str(&json).unwrap();\n\n    let nested = deserialized.parameters.get(\"nested\").unwrap();\n    let level3 = &nested[\"level1\"][\"level2\"][\"level3\"];\n    assert_eq!(level3[\"data\"], serde_json::json!([1, 2, 3]));\n    assert_eq!(level3[\"flag\"], serde_json::json!(true));\n    assert_eq!(level3[\"value\"], serde_json::json!(null));\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-core","tests","trait_tests.rs"],"content":"//! Unit tests for trait behavior using mocks\n//!\n//! These tests verify the expected behavior of trait methods\n\nuse llmspell_core::{\n    traits::{\n        agent::{Agent, AgentConfig, ConversationMessage, MessageRole},\n        base_agent::BaseAgent,\n        tool::{ParameterDef, ParameterType, SecurityLevel, Tool, ToolCategory, ToolSchema},\n        workflow::{RetryPolicy, Workflow, WorkflowStatus, WorkflowStep},\n    },\n    types::{AgentInput, AgentOutput, ExecutionContext},\n    ComponentId, LLMSpellError,\n};\nuse llmspell_testing::mocks::*;\nuse mockall::predicate::*;\n\n#[tokio::test]\nasync fn test_base_agent_mock_behavior() {\n    let mut mock = MockBaseAgent::new();\n\n    // Note: We can't mock metadata() as it returns a reference\n    // Instead we'll just test the other methods\n\n    mock.expect_validate_input()\n        .with(always())\n        .times(1)\n        .returning(|_| Ok(()));\n\n    mock.expect_execute()\n        .with(always(), always())\n        .times(1)\n        .returning(|input, _| Ok(AgentOutput::text(format!(\"Mocked: {}\", input.text))));\n\n    // Test the mock\n    let input = AgentInput::text(\"test input\");\n    let context = ExecutionContext::with_conversation(\"test-session\".to_string());\n\n    assert!(mock.validate_input(&input).await.is_ok());\n    let result = mock.execute(input, context).await.unwrap();\n    assert_eq!(result.text, \"Mocked: test input\");\n}\n\n#[tokio::test]\nasync fn test_agent_mock_conversation_management() {\n    let mut mock = MockAgent::new();\n\n    // Setup conversation expectations\n    let messages = vec![\n        ConversationMessage::user(\"Hello\".to_string()),\n        ConversationMessage::assistant(\"Hi there!\".to_string()),\n    ];\n\n    mock.expect_get_conversation()\n        .times(1)\n        .returning(move || Ok(messages.clone()));\n\n    mock.expect_add_message()\n        .withf(|msg| msg.role == MessageRole::System && msg.content == \"System prompt\")\n        .times(1)\n        .returning(|_| Ok(()));\n\n    mock.expect_clear_conversation()\n        .times(1)\n        .returning(|| Ok(()));\n\n    // Test conversation methods\n    let conv = mock.get_conversation().await.unwrap();\n    assert_eq!(conv.len(), 2);\n    assert_eq!(conv[0].content, \"Hello\");\n\n    mock.add_message(ConversationMessage::system(\"System prompt\".to_string()))\n        .await\n        .unwrap();\n    mock.clear_conversation().await.unwrap();\n}\n\n#[tokio::test]\nasync fn test_tool_mock_schema_validation() {\n    let mut mock = MockTool::new();\n\n    // Setup schema\n    let schema = ToolSchema::new(\"test_tool\".to_string(), \"A test tool\".to_string())\n        .with_parameter(ParameterDef {\n            name: \"input\".to_string(),\n            param_type: ParameterType::String,\n            description: \"Input parameter\".to_string(),\n            required: true,\n            default: None,\n        });\n\n    mock.expect_schema()\n        .times(1)\n        .returning(move || schema.clone());\n\n    mock.expect_validate_parameters()\n        .with(eq(serde_json::json!({\"input\": \"test\"})))\n        .times(1)\n        .returning(|_| Ok(()));\n\n    mock.expect_validate_parameters()\n        .with(eq(serde_json::json!({})))\n        .times(1)\n        .returning(|_| {\n            Err(LLMSpellError::Validation {\n                message: \"Missing required parameter: input\".to_string(),\n                field: Some(\"input\".to_string()),\n            })\n        });\n\n    // Test schema and validation\n    let tool_schema = mock.schema();\n    assert_eq!(tool_schema.name, \"test_tool\");\n    assert_eq!(tool_schema.required_parameters(), vec![\"input\"]);\n\n    assert!(mock\n        .validate_parameters(&serde_json::json!({\"input\": \"test\"}))\n        .await\n        .is_ok());\n    assert!(mock\n        .validate_parameters(&serde_json::json!({}))\n        .await\n        .is_err());\n}\n\n#[tokio::test]\nasync fn test_workflow_mock_step_execution() {\n    let mut mock = MockWorkflow::new();\n\n    // Setup workflow steps\n    let component_id1 = ComponentId::from_name(\"component1\");\n    let component_id2 = ComponentId::from_name(\"component2\");\n    let component_id3 = ComponentId::from_name(\"component3\");\n\n    let steps = vec![\n        WorkflowStep::new(\"step1\".to_string(), component_id1),\n        WorkflowStep::new(\"step2\".to_string(), component_id2),\n        WorkflowStep::new(\"step3\".to_string(), component_id3),\n    ];\n\n    let steps_for_mock = steps.clone();\n    let steps_for_test = steps.clone();\n\n    mock.expect_add_step()\n        .with(always())\n        .times(3)\n        .returning(|_| Ok(()));\n\n    mock.expect_get_steps()\n        .times(1)\n        .returning(move || Ok(steps_for_mock.clone()));\n\n    mock.expect_status()\n        .times(1)\n        .returning(|| Ok(WorkflowStatus::Running));\n\n    // Test workflow execution\n    for step in &steps_for_test {\n        mock.add_step(step.clone()).await.unwrap();\n    }\n\n    let workflow_steps = mock.get_steps().await.unwrap();\n    assert_eq!(workflow_steps.len(), 3);\n\n    let status = mock.status().await.unwrap();\n    assert_eq!(status, WorkflowStatus::Running);\n}\n\n#[test]\nfn test_tool_category_enum_variants() {\n    // Test all category variants\n    let categories = vec![\n        ToolCategory::Filesystem,\n        ToolCategory::Web,\n        ToolCategory::Analysis,\n        ToolCategory::Data,\n        ToolCategory::System,\n        ToolCategory::Utility,\n        ToolCategory::Custom(\"MyCategory\".to_string()),\n    ];\n\n    for category in categories {\n        // Ensure Display trait works\n        let _ = category.to_string();\n\n        // Ensure Clone works\n        let _ = category.clone();\n    }\n}\n\n#[test]\nfn test_security_level_ordering() {\n    assert!(SecurityLevel::Safe < SecurityLevel::Restricted);\n    assert!(SecurityLevel::Restricted < SecurityLevel::Privileged);\n\n    // Test allows method\n    assert!(SecurityLevel::Privileged.allows(&SecurityLevel::Safe));\n    assert!(SecurityLevel::Privileged.allows(&SecurityLevel::Restricted));\n    assert!(SecurityLevel::Privileged.allows(&SecurityLevel::Privileged));\n\n    assert!(!SecurityLevel::Safe.allows(&SecurityLevel::Restricted));\n    assert!(!SecurityLevel::Safe.allows(&SecurityLevel::Privileged));\n}\n\n#[test]\nfn test_message_role_variants() {\n    let roles = vec![\n        MessageRole::System,\n        MessageRole::User,\n        MessageRole::Assistant,\n    ];\n\n    for role in roles {\n        // Test Display\n        let _ = role.to_string();\n\n        // Test Clone\n        let _ = role.clone();\n\n        // Test PartialEq\n        assert_eq!(role, role);\n    }\n}\n\n#[test]\nfn test_workflow_status_transitions() {\n    // Test all status variants\n    let statuses = vec![\n        WorkflowStatus::Pending,\n        WorkflowStatus::Running,\n        WorkflowStatus::Completed,\n        WorkflowStatus::Failed,\n        WorkflowStatus::Cancelled,\n    ];\n\n    for status in statuses {\n        // Ensure Display works\n        let _ = format!(\"{:?}\", status);\n\n        // Ensure Clone works\n        let _ = status.clone();\n    }\n}\n\n#[test]\nfn test_retry_policy_configuration() {\n    let default_policy = RetryPolicy::default();\n    assert_eq!(default_policy.max_attempts, 3);\n    assert_eq!(default_policy.backoff_seconds, 1);\n    assert!(default_policy.exponential_backoff);\n\n    let custom_policy = RetryPolicy {\n        max_attempts: 5,\n        backoff_seconds: 2,\n        exponential_backoff: false,\n    };\n    assert_eq!(custom_policy.max_attempts, 5);\n    assert_eq!(custom_policy.backoff_seconds, 2);\n    assert!(!custom_policy.exponential_backoff);\n}\n\n#[test]\nfn test_execution_context_builder() {\n    let mut context = ExecutionContext::with_conversation(\"test-session\".to_string());\n    context.user_id = Some(\"user-123\".to_string());\n    let context = context\n        .with_data(\"KEY1\".to_string(), serde_json::json!(\"value1\"))\n        .with_data(\"KEY2\".to_string(), serde_json::json!(\"value2\"));\n\n    assert_eq!(context.conversation_id, Some(\"test-session\".to_string()));\n    assert_eq!(context.user_id, Some(\"user-123\".to_string()));\n    assert_eq!(context.data.get(\"KEY1\"), Some(&serde_json::json!(\"value1\")));\n    assert_eq!(context.data.get(\"KEY2\"), Some(&serde_json::json!(\"value2\")));\n    assert_eq!(context.data.get(\"KEY3\"), None);\n}\n\n#[test]\nfn test_agent_config_defaults() {\n    let config = AgentConfig::default();\n\n    // Verify default values are sensible\n    assert_eq!(config.max_tokens, Some(2000));\n    assert_eq!(config.temperature, Some(0.7));\n    assert_eq!(config.max_conversation_length, Some(100));\n    assert_eq!(config.system_prompt, None);\n}\n\n#[test]\nfn test_parameter_type_variants() {\n    let types = vec![\n        ParameterType::String,\n        ParameterType::Number,\n        ParameterType::Boolean,\n        ParameterType::Array,\n        ParameterType::Object,\n        ParameterType::Null,\n    ];\n\n    // Ensure all variants work\n    for param_type in types {\n        let _ = format!(\"{:?}\", param_type);\n        let _ = param_type.clone();\n    }\n}\n\n#[test]\nfn test_conversation_message_creation() {\n    let user_msg = ConversationMessage::user(\"Hello\".to_string());\n    assert_eq!(user_msg.role, MessageRole::User);\n    assert_eq!(user_msg.content, \"Hello\");\n\n    let assistant_msg = ConversationMessage::assistant(\"Hi there!\".to_string());\n    assert_eq!(assistant_msg.role, MessageRole::Assistant);\n    assert_eq!(assistant_msg.content, \"Hi there!\");\n\n    let system_msg = ConversationMessage::system(\"You are helpful\".to_string());\n    assert_eq!(system_msg.role, MessageRole::System);\n    assert_eq!(system_msg.content, \"You are helpful\");\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-core","tests","types_tests.rs"],"content":"//! Unit tests for core types\n//!\n//! These tests verify behavior of ComponentId, Version, and ComponentMetadata\n\nuse llmspell_core::{ComponentId, ComponentMetadata, Version};\nuse std::collections::HashSet;\nuse std::thread;\nuse std::time::Duration;\n\n#[test]\nfn test_component_id_deterministic() {\n    // Same name should always produce same ID\n    let name = \"test-component\";\n    let id1 = ComponentId::from_name(name);\n    let id2 = ComponentId::from_name(name);\n    assert_eq!(id1, id2);\n}\n\n#[test]\nfn test_component_id_uniqueness() {\n    // Different names should produce different IDs\n    let id1 = ComponentId::from_name(\"component-1\");\n    let id2 = ComponentId::from_name(\"component-2\");\n    assert_ne!(id1, id2);\n}\n\n#[test]\nfn test_component_id_thread_safety() {\n    // ComponentId generation should be thread-safe\n    let handles: Vec<_> = (0..10)\n        .map(|i| thread::spawn(move || ComponentId::from_name(&format!(\"thread-{}\", i))))\n        .collect();\n\n    let ids: HashSet<ComponentId> = handles.into_iter().map(|h| h.join().unwrap()).collect();\n\n    assert_eq!(ids.len(), 10);\n}\n\n#[test]\nfn test_version_comparison() {\n    let v1 = Version::new(1, 0, 0);\n    let v2 = Version::new(1, 0, 1);\n    let v3 = Version::new(1, 1, 0);\n    let v4 = Version::new(2, 0, 0);\n\n    assert!(v1 < v2);\n    assert!(v2 < v3);\n    assert!(v3 < v4);\n    assert!(v1 < v4);\n}\n\n#[test]\nfn test_version_equality() {\n    let v1 = Version::new(1, 2, 3);\n    let v2 = Version::new(1, 2, 3);\n    let v3 = Version::new(1, 2, 4);\n\n    assert_eq!(v1, v2);\n    assert_ne!(v1, v3);\n}\n\n#[test]\nfn test_version_compatibility() {\n    let v1 = Version::new(1, 0, 0);\n    let v2 = Version::new(1, 0, 1);\n    let v3 = Version::new(1, 1, 0);\n    let v4 = Version::new(2, 0, 0);\n\n    // Same major version is compatible\n    assert!(v1.is_compatible_with(&v2));\n    assert!(v1.is_compatible_with(&v3));\n    assert!(v2.is_compatible_with(&v3));\n\n    // Different major version is not compatible\n    assert!(!v1.is_compatible_with(&v4));\n    assert!(!v2.is_compatible_with(&v4));\n    assert!(!v3.is_compatible_with(&v4));\n}\n\n#[test]\nfn test_version_display() {\n    let v = Version::new(1, 2, 3);\n    assert_eq!(v.to_string(), \"1.2.3\");\n\n    let v0 = Version::new(0, 0, 0);\n    assert_eq!(v0.to_string(), \"0.0.0\");\n\n    let v_max = Version::new(u32::MAX, u32::MAX, u32::MAX);\n    assert_eq!(\n        v_max.to_string(),\n        format!(\"{}.{}.{}\", u32::MAX, u32::MAX, u32::MAX)\n    );\n}\n\n#[test]\nfn test_component_metadata_creation() {\n    let metadata =\n        ComponentMetadata::new(\"test-component\".to_string(), \"A test component\".to_string());\n\n    assert_eq!(metadata.name, \"test-component\");\n    assert_eq!(metadata.description, \"A test component\");\n    assert_eq!(metadata.version, Version::new(0, 1, 0));\n}\n\n#[test]\nfn test_component_metadata_update_version() {\n    let mut metadata = ComponentMetadata::new(\"test\".to_string(), \"Test component\".to_string());\n\n    let original_updated_at = metadata.updated_at;\n\n    // Sleep briefly to ensure timestamp changes\n    thread::sleep(Duration::from_millis(10));\n\n    metadata.update_version(Version::new(1, 0, 0));\n\n    assert_eq!(metadata.version, Version::new(1, 0, 0));\n    assert!(metadata.updated_at > original_updated_at);\n}\n\n#[test]\nfn test_component_metadata_serialization() {\n    let metadata = ComponentMetadata::new(\n        \"serialization-test\".to_string(),\n        \"Test serialization\".to_string(),\n    );\n\n    // Serialize\n    let json = serde_json::to_string(&metadata).unwrap();\n\n    // Deserialize\n    let deserialized: ComponentMetadata = serde_json::from_str(&json).unwrap();\n\n    assert_eq!(metadata.id, deserialized.id);\n    assert_eq!(metadata.name, deserialized.name);\n    assert_eq!(metadata.description, deserialized.description);\n    assert_eq!(metadata.version, deserialized.version);\n}\n\n#[test]\nfn test_component_metadata_timestamps() {\n    let metadata = ComponentMetadata::new(\n        \"timestamp-test\".to_string(),\n        \"Component to test timestamps\".to_string(),\n    );\n\n    // Check that timestamps are set\n    assert!(metadata.created_at <= metadata.updated_at);\n\n    // Both should be recent (within last second)\n    let now = chrono::Utc::now();\n    let diff = now - metadata.created_at;\n    assert!(diff.num_seconds() < 1);\n}\n\n#[test]\nfn test_component_id_serialization() {\n    let id = ComponentId::from_name(\"serialization-test\");\n\n    // Serialize\n    let json = serde_json::to_string(&id).unwrap();\n\n    // Deserialize\n    let deserialized: ComponentId = serde_json::from_str(&json).unwrap();\n\n    assert_eq!(id, deserialized);\n}\n\n#[test]\nfn test_version_serialization() {\n    let version = Version::new(1, 2, 3);\n\n    // Serialize\n    let json = serde_json::to_string(&version).unwrap();\n\n    // Deserialize\n    let deserialized: Version = serde_json::from_str(&json).unwrap();\n\n    assert_eq!(version, deserialized);\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-hooks","src","lib.rs"],"content":"//! ABOUTME: llmspell-hooks implementation crate\n//! ABOUTME: Foundation stub for future implementation\n\n// Module stub - to be implemented in later phases\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-providers","src","abstraction.rs"],"content":"//! ABOUTME: Provider abstraction layer defining capabilities and management interfaces\n//! ABOUTME: Enables provider-agnostic LLM integration with capability detection\n\nuse async_trait::async_trait;\nuse llmspell_core::{\n    error::LLMSpellError,\n    types::{AgentInput, AgentOutput, AgentStream},\n};\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\nuse crate::ModelSpecifier;\n\n/// Capabilities that a provider might support\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Default)]\npub struct ProviderCapabilities {\n    /// Whether the provider supports streaming responses\n    pub supports_streaming: bool,\n\n    /// Whether the provider supports multimodal content (images, audio, etc.)\n    pub supports_multimodal: bool,\n\n    /// Maximum context window size in tokens\n    pub max_context_tokens: Option<usize>,\n\n    /// Maximum output tokens\n    pub max_output_tokens: Option<usize>,\n\n    /// Supported model names\n    pub available_models: Vec<String>,\n\n    /// Provider-specific features\n    pub custom_features: HashMap<String, serde_json::Value>,\n}\n\n/// Configuration for a provider instance\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ProviderConfig {\n    /// Provider name (e.g., \"openai\", \"anthropic\", \"local\")\n    pub name: String,\n\n    /// API endpoint URL (if applicable)\n    pub endpoint: Option<String>,\n\n    /// API key or authentication token\n    pub api_key: Option<String>,\n\n    /// Model to use\n    pub model: String,\n\n    /// Request timeout in seconds\n    pub timeout_secs: Option<u64>,\n\n    /// Maximum retries for failed requests\n    pub max_retries: Option<u32>,\n\n    /// Provider-specific configuration\n    pub custom_config: HashMap<String, serde_json::Value>,\n}\n\nimpl ProviderConfig {\n    /// Create a new provider configuration\n    pub fn new(name: impl Into<String>, model: impl Into<String>) -> Self {\n        Self {\n            name: name.into(),\n            model: model.into(),\n            endpoint: None,\n            api_key: None,\n            timeout_secs: Some(30),\n            max_retries: Some(3),\n            custom_config: HashMap::new(),\n        }\n    }\n\n    /// Load configuration from environment variables\n    pub fn from_env(name: &str) -> Result<Self, LLMSpellError> {\n        let env_prefix = format!(\"LLMSPELL_{}_\", name.to_uppercase());\n\n        let api_key = std::env::var(format!(\"{}API_KEY\", env_prefix)).ok();\n        let endpoint = std::env::var(format!(\"{}ENDPOINT\", env_prefix)).ok();\n        let model =\n            std::env::var(format!(\"{}MODEL\", env_prefix)).unwrap_or_else(|_| \"default\".to_string());\n\n        Ok(Self {\n            name: name.to_string(),\n            endpoint,\n            api_key,\n            model,\n            timeout_secs: std::env::var(format!(\"{}TIMEOUT\", env_prefix))\n                .ok()\n                .and_then(|s| s.parse().ok()),\n            max_retries: std::env::var(format!(\"{}MAX_RETRIES\", env_prefix))\n                .ok()\n                .and_then(|s| s.parse().ok()),\n            custom_config: HashMap::new(),\n        })\n    }\n}\n\n/// Trait for LLM provider implementations\n#[async_trait]\npub trait ProviderInstance: Send + Sync {\n    /// Get the provider's capabilities\n    fn capabilities(&self) -> &ProviderCapabilities;\n\n    /// Execute a completion request\n    async fn complete(&self, input: &AgentInput) -> Result<AgentOutput, LLMSpellError>;\n\n    /// Execute a streaming completion request\n    async fn complete_streaming(&self, _input: &AgentInput) -> Result<AgentStream, LLMSpellError> {\n        // Default implementation returns NotImplemented error\n        Err(LLMSpellError::Provider {\n            message: \"Streaming not implemented for this provider\".to_string(),\n            provider: Some(self.name().to_string()),\n            source: None,\n        })\n    }\n\n    /// Validate the provider configuration and connectivity\n    async fn validate(&self) -> Result<(), LLMSpellError>;\n\n    /// Get provider name\n    fn name(&self) -> &str;\n\n    /// Get current model\n    fn model(&self) -> &str;\n}\n\n/// Factory function type for creating provider instances\npub type ProviderFactory =\n    Box<dyn Fn(ProviderConfig) -> Result<Box<dyn ProviderInstance>, LLMSpellError> + Send + Sync>;\n\n/// Type alias for provider instance storage\npub type ProviderInstanceMap = HashMap<String, Arc<Box<dyn ProviderInstance>>>;\n\n/// Provider registry for managing available providers\npub struct ProviderRegistry {\n    factories: HashMap<String, ProviderFactory>,\n}\n\nimpl ProviderRegistry {\n    /// Create a new provider registry\n    pub fn new() -> Self {\n        Self {\n            factories: HashMap::new(),\n        }\n    }\n\n    /// Register a provider factory\n    pub fn register<F>(&mut self, name: impl Into<String>, factory: F)\n    where\n        F: Fn(ProviderConfig) -> Result<Box<dyn ProviderInstance>, LLMSpellError>\n            + Send\n            + Sync\n            + 'static,\n    {\n        self.factories.insert(name.into(), Box::new(factory));\n    }\n\n    /// Create a provider instance\n    pub fn create(\n        &self,\n        config: ProviderConfig,\n    ) -> Result<Box<dyn ProviderInstance>, LLMSpellError> {\n        let factory =\n            self.factories\n                .get(&config.name)\n                .ok_or_else(|| LLMSpellError::Configuration {\n                    message: format!(\"Unknown provider: {}\", config.name),\n                    source: None,\n                })?;\n\n        factory(config)\n    }\n\n    /// Get list of registered provider names\n    pub fn available_providers(&self) -> Vec<&str> {\n        self.factories.keys().map(|s| s.as_str()).collect()\n    }\n}\n\nimpl Default for ProviderRegistry {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n/// Provider manager for handling multiple provider instances\npub struct ProviderManager {\n    registry: Arc<RwLock<ProviderRegistry>>,\n    instances: Arc<RwLock<ProviderInstanceMap>>,\n    default_provider: Arc<RwLock<Option<String>>>,\n}\n\nimpl ProviderManager {\n    /// Create a new provider manager\n    pub fn new() -> Self {\n        Self {\n            registry: Arc::new(RwLock::new(ProviderRegistry::new())),\n            instances: Arc::new(RwLock::new(HashMap::new())),\n            default_provider: Arc::new(RwLock::new(None)),\n        }\n    }\n\n    /// Register a provider factory\n    pub async fn register_provider<F>(&self, name: impl Into<String>, factory: F)\n    where\n        F: Fn(ProviderConfig) -> Result<Box<dyn ProviderInstance>, LLMSpellError>\n            + Send\n            + Sync\n            + 'static,\n    {\n        let mut registry = self.registry.write().await;\n        registry.register(name, factory);\n    }\n\n    /// Initialize a provider instance\n    pub async fn init_provider(&self, config: ProviderConfig) -> Result<(), LLMSpellError> {\n        let instance_name = format!(\"{}:{}\", config.name, config.model);\n\n        let registry = self.registry.read().await;\n        let provider = registry.create(config)?;\n\n        // Validate the provider\n        provider.validate().await?;\n\n        let mut instances = self.instances.write().await;\n        instances.insert(instance_name.clone(), Arc::new(provider));\n\n        // Set as default if it's the first provider\n        let mut default = self.default_provider.write().await;\n        if default.is_none() {\n            *default = Some(instance_name);\n        }\n\n        Ok(())\n    }\n\n    /// Get a provider instance\n    pub async fn get_provider(\n        &self,\n        name: Option<&str>,\n    ) -> Result<Arc<Box<dyn ProviderInstance>>, LLMSpellError> {\n        let instances = self.instances.read().await;\n        let default = self.default_provider.read().await;\n\n        let provider_name = if let Some(name) = name {\n            name.to_string()\n        } else {\n            default\n                .as_ref()\n                .ok_or_else(|| LLMSpellError::Configuration {\n                    message: \"No default provider configured\".to_string(),\n                    source: None,\n                })?\n                .clone()\n        };\n\n        instances\n            .get(&provider_name)\n            .cloned()\n            .ok_or_else(|| LLMSpellError::Configuration {\n                message: format!(\"Provider not found: {}\", provider_name),\n                source: None,\n            })\n    }\n\n    /// Create and initialize a provider from a ModelSpecifier\n    ///\n    /// This method handles the core functionality for Task 2.1.2:\n    /// - Parses the ModelSpecifier to determine provider and model\n    /// - Applies base URL overrides if specified\n    /// - Creates provider configuration with proper fallbacks\n    /// - Initializes the provider and makes it available\n    ///\n    /// # Arguments\n    /// * `spec` - ModelSpecifier containing provider/model information\n    /// * `base_url_override` - Optional base URL to override default endpoints\n    /// * `api_key` - Optional API key (falls back to environment variables)\n    ///\n    /// # Returns\n    /// Returns the initialized provider instance\n    ///\n    /// # Examples\n    /// ```no_run\n    /// # use llmspell_providers::{ProviderManager, ModelSpecifier};\n    /// # #[tokio::main]\n    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {\n    /// let manager = ProviderManager::new();\n    ///\n    /// // Basic usage with provider/model syntax\n    /// let spec = ModelSpecifier::parse(\"openai/gpt-4\")?;\n    /// let provider = manager.create_agent_from_spec(spec, None, None).await?;\n    ///\n    /// // With base URL override\n    /// let spec = ModelSpecifier::parse(\"openai/gpt-4\")?;\n    /// let provider = manager.create_agent_from_spec(\n    ///     spec,\n    ///     Some(\"https://api.custom.com/v1\"),\n    ///     Some(\"custom-api-key\")\n    /// ).await?;\n    /// # Ok(())\n    /// # }\n    /// ```\n    pub async fn create_agent_from_spec(\n        &self,\n        spec: ModelSpecifier,\n        base_url_override: Option<&str>,\n        api_key: Option<&str>,\n    ) -> Result<Arc<Box<dyn ProviderInstance>>, LLMSpellError> {\n        // Determine the provider name\n        let provider_name = match &spec.provider {\n            Some(provider) => provider.clone(),\n            None => {\n                // If no provider specified, try to use default\n                let default = self.default_provider.read().await;\n                if let Some(default_provider) = default.as_ref() {\n                    // Extract provider name from \"provider:model\" format\n                    if let Some(colon_pos) = default_provider.find(':') {\n                        default_provider[..colon_pos].to_string()\n                    } else {\n                        return Err(LLMSpellError::Configuration {\n                            message:\n                                \"No provider specified and no valid default provider available\"\n                                    .to_string(),\n                            source: None,\n                        });\n                    }\n                } else {\n                    return Err(LLMSpellError::Configuration {\n                        message: \"No provider specified and no default provider configured\"\n                            .to_string(),\n                        source: None,\n                    });\n                }\n            }\n        };\n\n        // Create provider configuration\n        let mut config = ProviderConfig::new(&provider_name, &spec.model);\n\n        // Apply base URL override with precedence:\n        // 1. Function parameter (highest priority)\n        // 2. ModelSpecifier base_url\n        // 3. Default provider endpoint (lowest priority)\n        if let Some(base_url) = base_url_override {\n            config.endpoint = Some(base_url.to_string());\n        } else if let Some(base_url) = &spec.base_url {\n            config.endpoint = Some(base_url.clone());\n        }\n\n        // Set API key with fallback to environment variables\n        if let Some(api_key) = api_key {\n            config.api_key = Some(api_key.to_string());\n        } else {\n            // Try to load from environment\n            if let Ok(env_config) = ProviderConfig::from_env(&provider_name) {\n                if config.api_key.is_none() {\n                    config.api_key = env_config.api_key;\n                }\n                if config.endpoint.is_none() {\n                    config.endpoint = env_config.endpoint;\n                }\n            }\n        }\n\n        // Create a unique instance name\n        let instance_name = format!(\"{}:{}\", provider_name, spec.model);\n\n        // Check if we already have this instance\n        {\n            let instances = self.instances.read().await;\n            if let Some(existing) = instances.get(&instance_name) {\n                return Ok(existing.clone());\n            }\n        }\n\n        // Create the provider instance\n        let registry = self.registry.read().await;\n        let provider = registry.create(config)?;\n\n        // Validate the provider\n        provider.validate().await?;\n\n        // Store the instance\n        let provider_arc = Arc::new(provider);\n        let mut instances = self.instances.write().await;\n        instances.insert(instance_name, provider_arc.clone());\n\n        Ok(provider_arc)\n    }\n\n    /// Get the default provider instance\n    pub async fn get_default_provider(\n        &self,\n    ) -> Result<Arc<Box<dyn ProviderInstance>>, LLMSpellError> {\n        self.get_provider(None).await\n    }\n\n    /// Set the default provider\n    pub async fn set_default_provider(&self, name: impl Into<String>) -> Result<(), LLMSpellError> {\n        let name = name.into();\n        let instances = self.instances.read().await;\n\n        if !instances.contains_key(&name) {\n            return Err(LLMSpellError::Configuration {\n                message: format!(\"Cannot set default: provider '{}' not initialized\", name),\n                source: None,\n            });\n        }\n\n        let mut default = self.default_provider.write().await;\n        *default = Some(name);\n        Ok(())\n    }\n\n    /// Query capabilities of a provider\n    pub async fn query_capabilities(\n        &self,\n        name: Option<&str>,\n    ) -> Result<ProviderCapabilities, LLMSpellError> {\n        let instances = self.instances.read().await;\n        let default = self.default_provider.read().await;\n\n        let provider_name = if let Some(name) = name {\n            name.to_string()\n        } else {\n            default\n                .as_ref()\n                .ok_or_else(|| LLMSpellError::Configuration {\n                    message: \"No default provider configured\".to_string(),\n                    source: None,\n                })?\n                .clone()\n        };\n\n        instances\n            .get(&provider_name)\n            .ok_or_else(|| LLMSpellError::Configuration {\n                message: format!(\"Provider not found: {}\", provider_name),\n                source: None,\n            })\n            .map(|p| p.capabilities().clone())\n    }\n\n    /// List all initialized providers\n    pub async fn list_providers(&self) -> Vec<String> {\n        let instances = self.instances.read().await;\n        instances.keys().cloned().collect()\n    }\n\n    /// List all available provider types\n    pub async fn available_provider_types(&self) -> Vec<String> {\n        let registry = self.registry.read().await;\n        registry\n            .available_providers()\n            .into_iter()\n            .map(|s| s.to_string())\n            .collect()\n    }\n}\n\nimpl Default for ProviderManager {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_provider_capabilities_default() {\n        let caps = ProviderCapabilities::default();\n        assert!(!caps.supports_streaming);\n        assert!(!caps.supports_multimodal);\n        assert!(caps.max_context_tokens.is_none());\n        assert!(caps.available_models.is_empty());\n    }\n\n    #[test]\n    fn test_provider_config_creation() {\n        let config = ProviderConfig::new(\"openai\", \"gpt-4\");\n        assert_eq!(config.name, \"openai\");\n        assert_eq!(config.model, \"gpt-4\");\n        assert_eq!(config.timeout_secs, Some(30));\n        assert_eq!(config.max_retries, Some(3));\n    }\n\n    #[test]\n    fn test_provider_registry() {\n        let mut registry = ProviderRegistry::new();\n\n        // Register a mock factory\n        registry.register(\"mock\", |_config| {\n            Err(LLMSpellError::Provider {\n                message: \"Mock provider\".to_string(),\n                provider: Some(\"mock\".to_string()),\n                source: None,\n            })\n        });\n\n        assert_eq!(registry.available_providers(), vec![\"mock\"]);\n    }\n\n    #[tokio::test]\n    async fn test_provider_manager_initialization() {\n        let manager = ProviderManager::new();\n\n        // Register a mock provider\n        manager\n            .register_provider(\"mock\", |_config| {\n                Err(LLMSpellError::Provider {\n                    message: \"Mock provider\".to_string(),\n                    provider: Some(\"mock\".to_string()),\n                    source: None,\n                })\n            })\n            .await;\n\n        let types = manager.available_provider_types().await;\n        assert!(types.contains(&\"mock\".to_string()));\n    }\n\n    #[tokio::test]\n    async fn test_create_agent_from_spec_no_provider() {\n        use crate::ModelSpecifier;\n\n        let manager = ProviderManager::new();\n        let spec = ModelSpecifier::parse(\"gpt-4\").unwrap();\n\n        // Should fail when no provider specified and no default\n        let result = manager.create_agent_from_spec(spec, None, None).await;\n        assert!(result.is_err());\n\n        if let Err(LLMSpellError::Configuration { message, .. }) = result {\n            assert!(message.contains(\"No provider specified\"));\n        }\n    }\n\n    #[tokio::test]\n    async fn test_create_agent_from_spec_unknown_provider() {\n        use crate::ModelSpecifier;\n\n        let manager = ProviderManager::new();\n        let spec = ModelSpecifier::parse(\"unknown/model\").unwrap();\n\n        // Should fail when provider not registered\n        let result = manager.create_agent_from_spec(spec, None, None).await;\n        assert!(result.is_err());\n\n        if let Err(LLMSpellError::Configuration { message, .. }) = result {\n            assert!(message.contains(\"Unknown provider\"));\n        }\n    }\n\n    #[tokio::test]\n    async fn test_model_specifier_base_url_precedence() {\n        use crate::ModelSpecifier;\n\n        let manager = ProviderManager::new();\n\n        // Register a mock provider that tracks configuration\n        manager\n            .register_provider(\"test\", |config| {\n                // Verify base URL is set correctly\n                assert_eq!(config.endpoint, Some(\"https://override.com\".to_string()));\n                Err(LLMSpellError::Provider {\n                    message: \"Test validation\".to_string(),\n                    provider: Some(\"test\".to_string()),\n                    source: None,\n                })\n            })\n            .await;\n\n        let spec =\n            ModelSpecifier::parse_with_base_url(\"test/model\", Some(\"https://spec.com\")).unwrap();\n\n        // Override parameter should take precedence over spec base_url\n        let result = manager\n            .create_agent_from_spec(spec, Some(\"https://override.com\"), None)\n            .await;\n\n        // Should fail at validation (expected for our mock)\n        assert!(result.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_model_specifier_provider_extraction() {\n        use crate::ModelSpecifier;\n\n        // Test different provider/model formats\n        let spec1 = ModelSpecifier::parse(\"openai/gpt-4\").unwrap();\n        assert_eq!(spec1.provider, Some(\"openai\".to_string()));\n        assert_eq!(spec1.model, \"gpt-4\");\n\n        let spec2 = ModelSpecifier::parse(\"openrouter/deepseek/model\").unwrap();\n        assert_eq!(spec2.provider, Some(\"openrouter/deepseek\".to_string()));\n        assert_eq!(spec2.model, \"model\");\n\n        let spec3 = ModelSpecifier::parse(\"claude-3\").unwrap();\n        assert_eq!(spec3.provider, None);\n        assert_eq!(spec3.model, \"claude-3\");\n    }\n}\n","traces":[{"line":65,"address":[],"length":0,"stats":{"Line":14}},{"line":67,"address":[],"length":0,"stats":{"Line":14}},{"line":68,"address":[],"length":0,"stats":{"Line":14}},{"line":71,"address":[],"length":0,"stats":{"Line":14}},{"line":72,"address":[],"length":0,"stats":{"Line":14}},{"line":73,"address":[],"length":0,"stats":{"Line":14}},{"line":78,"address":[],"length":0,"stats":{"Line":2}},{"line":79,"address":[],"length":0,"stats":{"Line":2}},{"line":81,"address":[],"length":0,"stats":{"Line":2}},{"line":82,"address":[],"length":0,"stats":{"Line":2}},{"line":83,"address":[],"length":0,"stats":{"Line":2}},{"line":84,"address":[],"length":0,"stats":{"Line":6}},{"line":86,"address":[],"length":0,"stats":{"Line":2}},{"line":87,"address":[],"length":0,"stats":{"Line":2}},{"line":88,"address":[],"length":0,"stats":{"Line":2}},{"line":89,"address":[],"length":0,"stats":{"Line":2}},{"line":90,"address":[],"length":0,"stats":{"Line":2}},{"line":91,"address":[],"length":0,"stats":{"Line":2}},{"line":92,"address":[],"length":0,"stats":{"Line":2}},{"line":93,"address":[],"length":0,"stats":{"Line":4}},{"line":94,"address":[],"length":0,"stats":{"Line":2}},{"line":95,"address":[],"length":0,"stats":{"Line":2}},{"line":96,"address":[],"length":0,"stats":{"Line":4}},{"line":97,"address":[],"length":0,"stats":{"Line":2}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":134}},{"line":147,"address":[],"length":0,"stats":{"Line":134}},{"line":152,"address":[],"length":0,"stats":{"Line":69}},{"line":159,"address":[],"length":0,"stats":{"Line":69}},{"line":163,"address":[],"length":0,"stats":{"Line":8}},{"line":167,"address":[],"length":0,"stats":{"Line":5}},{"line":168,"address":[],"length":0,"stats":{"Line":8}},{"line":169,"address":[],"length":0,"stats":{"Line":8}},{"line":170,"address":[],"length":0,"stats":{"Line":11}},{"line":171,"address":[],"length":0,"stats":{"Line":3}},{"line":172,"address":[],"length":0,"stats":{"Line":3}},{"line":179,"address":[],"length":0,"stats":{"Line":2}},{"line":180,"address":[],"length":0,"stats":{"Line":6}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":133}},{"line":201,"address":[],"length":0,"stats":{"Line":133}},{"line":202,"address":[],"length":0,"stats":{"Line":133}},{"line":203,"address":[],"length":0,"stats":{"Line":133}},{"line":208,"address":[],"length":0,"stats":{"Line":68}},{"line":215,"address":[],"length":0,"stats":{"Line":136}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":9}},{"line":221,"address":[],"length":0,"stats":{"Line":3}},{"line":223,"address":[],"length":0,"stats":{"Line":6}},{"line":224,"address":[],"length":0,"stats":{"Line":6}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":8}},{"line":246,"address":[],"length":0,"stats":{"Line":14}},{"line":247,"address":[],"length":0,"stats":{"Line":14}},{"line":249,"address":[],"length":0,"stats":{"Line":11}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":5}},{"line":254,"address":[],"length":0,"stats":{"Line":10}},{"line":255,"address":[],"length":0,"stats":{"Line":5}},{"line":256,"address":[],"length":0,"stats":{"Line":5}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":2}},{"line":265,"address":[],"length":0,"stats":{"Line":2}},{"line":266,"address":[],"length":0,"stats":{"Line":2}},{"line":307,"address":[],"length":0,"stats":{"Line":3}},{"line":314,"address":[],"length":0,"stats":{"Line":5}},{"line":315,"address":[],"length":0,"stats":{"Line":2}},{"line":318,"address":[],"length":0,"stats":{"Line":2}},{"line":319,"address":[],"length":0,"stats":{"Line":1}},{"line":321,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":325,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":1}},{"line":333,"address":[],"length":0,"stats":{"Line":1}},{"line":334,"address":[],"length":0,"stats":{"Line":1}},{"line":335,"address":[],"length":0,"stats":{"Line":1}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":1}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":1}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":359,"address":[],"length":0,"stats":{"Line":4}},{"line":360,"address":[],"length":0,"stats":{"Line":2}},{"line":361,"address":[],"length":0,"stats":{"Line":2}},{"line":363,"address":[],"length":0,"stats":{"Line":1}},{"line":364,"address":[],"length":0,"stats":{"Line":1}},{"line":370,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":2}},{"line":375,"address":[],"length":0,"stats":{"Line":2}},{"line":376,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":4}},{"line":382,"address":[],"length":0,"stats":{"Line":4}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":389,"address":[],"length":0,"stats":{"Line":0}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":403,"address":[],"length":0,"stats":{"Line":0}},{"line":404,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":407,"address":[],"length":0,"stats":{"Line":0}},{"line":408,"address":[],"length":0,"stats":{"Line":0}},{"line":409,"address":[],"length":0,"stats":{"Line":0}},{"line":410,"address":[],"length":0,"stats":{"Line":0}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":415,"address":[],"length":0,"stats":{"Line":0}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":420,"address":[],"length":0,"stats":{"Line":0}},{"line":424,"address":[],"length":0,"stats":{"Line":0}},{"line":425,"address":[],"length":0,"stats":{"Line":0}},{"line":427,"address":[],"length":0,"stats":{"Line":0}},{"line":428,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":432,"address":[],"length":0,"stats":{"Line":0}},{"line":433,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":441,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":449,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":0}},{"line":451,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":2}},{"line":456,"address":[],"length":0,"stats":{"Line":2}},{"line":457,"address":[],"length":0,"stats":{"Line":0}},{"line":460,"address":[],"length":0,"stats":{"Line":1}},{"line":466,"address":[],"length":0,"stats":{"Line":0}},{"line":467,"address":[],"length":0,"stats":{"Line":0}}],"covered":81,"coverable":151},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-providers","src","lib.rs"],"content":"//! ABOUTME: llmspell-providers implementation crate\n//! ABOUTME: Provider abstraction layer and LLM provider implementations\n\npub mod abstraction;\npub mod model_specifier;\npub mod rig;\n\n// Re-export main types\npub use abstraction::{\n    ProviderCapabilities, ProviderConfig, ProviderInstance, ProviderManager, ProviderRegistry,\n};\npub use model_specifier::ModelSpecifier;\n\n// Re-export provider factories\npub use rig::create_rig_provider;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-providers","src","model_specifier.rs"],"content":"//! ABOUTME: ModelSpecifier for parsing provider/model syntax\n//! ABOUTME: Handles \"provider/model\", \"model\", and base URL override parsing\n\nuse llmspell_core::error::LLMSpellError;\nuse serde::{Deserialize, Serialize};\nuse std::str::FromStr;\n\n/// Specification for a model with optional provider and base URL\n#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]\npub struct ModelSpecifier {\n    /// The provider name (e.g., \"openai\", \"anthropic\")\n    pub provider: Option<String>,\n    /// The model name (e.g., \"gpt-4\", \"claude-3-sonnet\")\n    pub model: String,\n    /// Optional base URL override\n    pub base_url: Option<String>,\n}\n\nimpl ModelSpecifier {\n    /// Create a new ModelSpecifier with just a model name\n    pub fn new(model: impl Into<String>) -> Self {\n        Self {\n            provider: None,\n            model: model.into(),\n            base_url: None,\n        }\n    }\n\n    /// Create a new ModelSpecifier with provider and model\n    pub fn with_provider(provider: impl Into<String>, model: impl Into<String>) -> Self {\n        Self {\n            provider: Some(provider.into()),\n            model: model.into(),\n            base_url: None,\n        }\n    }\n\n    /// Create a new ModelSpecifier with provider, model, and base URL\n    pub fn with_base_url(\n        provider: impl Into<String>,\n        model: impl Into<String>,\n        base_url: impl Into<String>,\n    ) -> Self {\n        Self {\n            provider: Some(provider.into()),\n            model: model.into(),\n            base_url: Some(base_url.into()),\n        }\n    }\n\n    /// Parse a model specification string\n    ///\n    /// Supported formats:\n    /// - \"model\" -> ModelSpecifier { provider: None, model: \"model\", base_url: None }\n    /// - \"provider/model\" -> ModelSpecifier { provider: Some(\"provider\"), model: \"model\", base_url: None }\n    /// - \"provider/subprovider/model\" -> ModelSpecifier { provider: Some(\"provider/subprovider\"), model: \"model\", base_url: None }\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// # use llmspell_providers::ModelSpecifier;\n    /// let spec = ModelSpecifier::parse(\"gpt-4\").unwrap();\n    /// assert_eq!(spec.model, \"gpt-4\");\n    /// assert_eq!(spec.provider, None);\n    ///\n    /// let spec = ModelSpecifier::parse(\"openai/gpt-4\").unwrap();\n    /// assert_eq!(spec.model, \"gpt-4\");\n    /// assert_eq!(spec.provider, Some(\"openai\".to_string()));\n    ///\n    /// let spec = ModelSpecifier::parse(\"openrouter/deepseek/model\").unwrap();\n    /// assert_eq!(spec.model, \"model\");\n    /// assert_eq!(spec.provider, Some(\"openrouter/deepseek\".to_string()));\n    /// ```\n    pub fn parse(spec: &str) -> Result<Self, LLMSpellError> {\n        let spec = spec.trim();\n\n        if spec.is_empty() {\n            return Err(LLMSpellError::Configuration {\n                message: \"Model specification cannot be empty\".to_string(),\n                source: None,\n            });\n        }\n\n        // Split by '/' and handle different cases\n        let parts: Vec<&str> = spec.split('/').collect();\n\n        match parts.len() {\n            1 => {\n                // Just a model name\n                Ok(Self::new(parts[0]))\n            }\n            2 => {\n                // provider/model\n                Ok(Self::with_provider(parts[0], parts[1]))\n            }\n            n if n > 2 => {\n                // provider/subprovider/.../model\n                // Join all parts except the last as provider\n                let provider = parts[..n - 1].join(\"/\");\n                let model = parts[n - 1];\n                Ok(Self::with_provider(provider, model))\n            }\n            _ => {\n                // This shouldn't happen with split, but handle gracefully\n                Err(LLMSpellError::Configuration {\n                    message: format!(\"Invalid model specification format: '{}'\", spec),\n                    source: None,\n                })\n            }\n        }\n    }\n\n    /// Parse a model specification with an optional base URL override\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// # use llmspell_providers::ModelSpecifier;\n    /// let spec = ModelSpecifier::parse_with_base_url(\n    ///     \"openai/gpt-4\",\n    ///     Some(\"https://api.custom.com/v1\")\n    /// ).unwrap();\n    /// assert_eq!(spec.model, \"gpt-4\");\n    /// assert_eq!(spec.provider, Some(\"openai\".to_string()));\n    /// assert_eq!(spec.base_url, Some(\"https://api.custom.com/v1\".to_string()));\n    /// ```\n    pub fn parse_with_base_url(spec: &str, base_url: Option<&str>) -> Result<Self, LLMSpellError> {\n        let mut model_spec = Self::parse(spec)?;\n        model_spec.base_url = base_url.map(|url| url.to_string());\n        Ok(model_spec)\n    }\n\n    /// Get the provider name, or return a default\n    pub fn provider_or_default<'a>(&'a self, default: &'a str) -> &'a str {\n        self.provider.as_deref().unwrap_or(default)\n    }\n\n    /// Check if this specifier has a provider\n    pub fn has_provider(&self) -> bool {\n        self.provider.is_some()\n    }\n\n    /// Check if this specifier has a base URL override\n    pub fn has_base_url(&self) -> bool {\n        self.base_url.is_some()\n    }\n}\n\nimpl std::fmt::Display for ModelSpecifier {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match &self.provider {\n            Some(provider) => write!(f, \"{}/{}\", provider, self.model),\n            None => write!(f, \"{}\", self.model),\n        }\n    }\n}\n\nimpl FromStr for ModelSpecifier {\n    type Err = LLMSpellError;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        Self::parse(s)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_parse_model_only() {\n        let spec = ModelSpecifier::parse(\"gpt-4\").unwrap();\n        assert_eq!(spec.model, \"gpt-4\");\n        assert_eq!(spec.provider, None);\n        assert_eq!(spec.base_url, None);\n        assert!(!spec.has_provider());\n        assert!(!spec.has_base_url());\n    }\n\n    #[test]\n    fn test_parse_provider_model() {\n        let spec = ModelSpecifier::parse(\"openai/gpt-4\").unwrap();\n        assert_eq!(spec.model, \"gpt-4\");\n        assert_eq!(spec.provider, Some(\"openai\".to_string()));\n        assert_eq!(spec.base_url, None);\n        assert!(spec.has_provider());\n        assert!(!spec.has_base_url());\n    }\n\n    #[test]\n    fn test_parse_nested_provider() {\n        let spec = ModelSpecifier::parse(\"openrouter/deepseek/model\").unwrap();\n        assert_eq!(spec.model, \"model\");\n        assert_eq!(spec.provider, Some(\"openrouter/deepseek\".to_string()));\n        assert_eq!(spec.base_url, None);\n        assert!(spec.has_provider());\n    }\n\n    #[test]\n    fn test_parse_deeply_nested() {\n        let spec = ModelSpecifier::parse(\"a/b/c/d/model\").unwrap();\n        assert_eq!(spec.model, \"model\");\n        assert_eq!(spec.provider, Some(\"a/b/c/d\".to_string()));\n    }\n\n    #[test]\n    fn test_parse_empty_string() {\n        let result = ModelSpecifier::parse(\"\");\n        assert!(result.is_err());\n        if let Err(LLMSpellError::Configuration { message, .. }) = result {\n            assert!(message.contains(\"empty\"));\n        }\n    }\n\n    #[test]\n    fn test_parse_whitespace_only() {\n        let result = ModelSpecifier::parse(\"   \");\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_parse_with_base_url() {\n        let spec =\n            ModelSpecifier::parse_with_base_url(\"openai/gpt-4\", Some(\"https://api.custom.com/v1\"))\n                .unwrap();\n\n        assert_eq!(spec.model, \"gpt-4\");\n        assert_eq!(spec.provider, Some(\"openai\".to_string()));\n        assert_eq!(spec.base_url, Some(\"https://api.custom.com/v1\".to_string()));\n        assert!(spec.has_base_url());\n    }\n\n    #[test]\n    fn test_parse_with_base_url_none() {\n        let spec = ModelSpecifier::parse_with_base_url(\"openai/gpt-4\", None).unwrap();\n        assert_eq!(spec.base_url, None);\n        assert!(!spec.has_base_url());\n    }\n\n    #[test]\n    fn test_constructor_methods() {\n        let spec1 = ModelSpecifier::new(\"gpt-4\");\n        assert_eq!(spec1.model, \"gpt-4\");\n        assert_eq!(spec1.provider, None);\n\n        let spec2 = ModelSpecifier::with_provider(\"openai\", \"gpt-4\");\n        assert_eq!(spec2.model, \"gpt-4\");\n        assert_eq!(spec2.provider, Some(\"openai\".to_string()));\n\n        let spec3 = ModelSpecifier::with_base_url(\"openai\", \"gpt-4\", \"https://api.custom.com\");\n        assert_eq!(spec3.model, \"gpt-4\");\n        assert_eq!(spec3.provider, Some(\"openai\".to_string()));\n        assert_eq!(spec3.base_url, Some(\"https://api.custom.com\".to_string()));\n    }\n\n    #[test]\n    fn test_provider_or_default() {\n        let spec1 = ModelSpecifier::new(\"gpt-4\");\n        assert_eq!(spec1.provider_or_default(\"default\"), \"default\");\n\n        let spec2 = ModelSpecifier::with_provider(\"openai\", \"gpt-4\");\n        assert_eq!(spec2.provider_or_default(\"default\"), \"openai\");\n    }\n\n    #[test]\n    fn test_to_string() {\n        let spec1 = ModelSpecifier::new(\"gpt-4\");\n        assert_eq!(spec1.to_string(), \"gpt-4\");\n\n        let spec2 = ModelSpecifier::with_provider(\"openai\", \"gpt-4\");\n        assert_eq!(spec2.to_string(), \"openai/gpt-4\");\n\n        let spec3 = ModelSpecifier::parse(\"openrouter/deepseek/model\").unwrap();\n        assert_eq!(spec3.to_string(), \"openrouter/deepseek/model\");\n    }\n\n    #[test]\n    fn test_display_trait() {\n        let spec = ModelSpecifier::with_provider(\"openai\", \"gpt-4\");\n        assert_eq!(format!(\"{}\", spec), \"openai/gpt-4\");\n    }\n\n    #[test]\n    fn test_from_str_trait() {\n        let spec: ModelSpecifier = \"openai/gpt-4\".parse().unwrap();\n        assert_eq!(spec.model, \"gpt-4\");\n        assert_eq!(spec.provider, Some(\"openai\".to_string()));\n    }\n\n    #[test]\n    fn test_serde_serialization() {\n        let spec = ModelSpecifier::with_base_url(\"openai\", \"gpt-4\", \"https://api.custom.com\");\n\n        // Test serialization\n        let serialized = serde_json::to_string(&spec).unwrap();\n\n        // Test deserialization\n        let deserialized: ModelSpecifier = serde_json::from_str(&serialized).unwrap();\n        assert_eq!(spec, deserialized);\n    }\n\n    #[test]\n    fn test_edge_cases() {\n        // Test with special characters in model names\n        let spec = ModelSpecifier::parse(\"openai/gpt-4-turbo-preview\").unwrap();\n        assert_eq!(spec.model, \"gpt-4-turbo-preview\");\n\n        // Test with numbers and hyphens\n        let spec = ModelSpecifier::parse(\"anthropic/claude-3-opus-20240229\").unwrap();\n        assert_eq!(spec.model, \"claude-3-opus-20240229\");\n        assert_eq!(spec.provider, Some(\"anthropic\".to_string()));\n    }\n\n    #[test]\n    fn test_clone_and_eq() {\n        let spec1 = ModelSpecifier::with_provider(\"openai\", \"gpt-4\");\n        let spec2 = spec1.clone();\n        assert_eq!(spec1, spec2);\n\n        let spec3 = ModelSpecifier::with_provider(\"anthropic\", \"claude-3\");\n        assert_ne!(spec1, spec3);\n    }\n}\n","traces":[{"line":21,"address":[],"length":0,"stats":{"Line":6}},{"line":24,"address":[],"length":0,"stats":{"Line":6}},{"line":30,"address":[],"length":0,"stats":{"Line":19}},{"line":32,"address":[],"length":0,"stats":{"Line":19}},{"line":33,"address":[],"length":0,"stats":{"Line":19}},{"line":39,"address":[],"length":0,"stats":{"Line":2}},{"line":45,"address":[],"length":0,"stats":{"Line":2}},{"line":46,"address":[],"length":0,"stats":{"Line":2}},{"line":47,"address":[],"length":0,"stats":{"Line":2}},{"line":74,"address":[],"length":0,"stats":{"Line":18}},{"line":75,"address":[],"length":0,"stats":{"Line":18}},{"line":77,"address":[],"length":0,"stats":{"Line":18}},{"line":78,"address":[],"length":0,"stats":{"Line":2}},{"line":79,"address":[],"length":0,"stats":{"Line":2}},{"line":80,"address":[],"length":0,"stats":{"Line":2}},{"line":85,"address":[],"length":0,"stats":{"Line":16}},{"line":87,"address":[],"length":0,"stats":{"Line":16}},{"line":90,"address":[],"length":0,"stats":{"Line":3}},{"line":94,"address":[],"length":0,"stats":{"Line":9}},{"line":96,"address":[],"length":0,"stats":{"Line":12}},{"line":99,"address":[],"length":0,"stats":{"Line":4}},{"line":100,"address":[],"length":0,"stats":{"Line":4}},{"line":101,"address":[],"length":0,"stats":{"Line":4}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":3}},{"line":128,"address":[],"length":0,"stats":{"Line":6}},{"line":129,"address":[],"length":0,"stats":{"Line":2}},{"line":134,"address":[],"length":0,"stats":{"Line":2}},{"line":135,"address":[],"length":0,"stats":{"Line":2}},{"line":139,"address":[],"length":0,"stats":{"Line":3}},{"line":140,"address":[],"length":0,"stats":{"Line":3}},{"line":144,"address":[],"length":0,"stats":{"Line":4}},{"line":145,"address":[],"length":0,"stats":{"Line":4}},{"line":150,"address":[],"length":0,"stats":{"Line":4}},{"line":151,"address":[],"length":0,"stats":{"Line":4}},{"line":152,"address":[],"length":0,"stats":{"Line":3}},{"line":153,"address":[],"length":0,"stats":{"Line":1}},{"line":161,"address":[],"length":0,"stats":{"Line":1}},{"line":162,"address":[],"length":0,"stats":{"Line":1}}],"covered":38,"coverable":41},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-providers","src","rig.rs"],"content":"//! ABOUTME: Rig provider implementation for LLM completions\n//! ABOUTME: Wraps the rig-core crate to provide LLM capabilities\n\nuse crate::abstraction::{ProviderCapabilities, ProviderConfig, ProviderInstance};\nuse async_trait::async_trait;\nuse llmspell_core::{\n    error::LLMSpellError,\n    types::{AgentInput, AgentOutput, AgentStream},\n};\nuse rig::{completion::CompletionModel, providers};\nuse serde_json::json;\n\n/// Enum to hold different provider models\nenum RigModel {\n    OpenAI(providers::openai::CompletionModel),\n    Anthropic(providers::anthropic::completion::CompletionModel),\n    Cohere(providers::cohere::CompletionModel),\n}\n\n/// Rig provider implementation\npub struct RigProvider {\n    config: ProviderConfig,\n    capabilities: ProviderCapabilities,\n    model: RigModel,\n}\n\nimpl RigProvider {\n    /// Create a new Rig provider instance\n    pub fn new(config: ProviderConfig) -> Result<Self, LLMSpellError> {\n        // Create the appropriate model based on provider name\n        let model = match config.name.as_str() {\n            \"openai\" => {\n                let api_key =\n                    config\n                        .api_key\n                        .as_ref()\n                        .ok_or_else(|| LLMSpellError::Configuration {\n                            message: \"OpenAI API key required\".to_string(),\n                            source: None,\n                        })?;\n\n                let client = providers::openai::Client::new(api_key);\n                let model = client.completion_model(&config.model);\n                RigModel::OpenAI(model)\n            }\n            \"anthropic\" => {\n                let api_key =\n                    config\n                        .api_key\n                        .as_ref()\n                        .ok_or_else(|| LLMSpellError::Configuration {\n                            message: \"Anthropic API key required\".to_string(),\n                            source: None,\n                        })?;\n\n                // Anthropic client requires more parameters\n                let base_url = config\n                    .endpoint\n                    .as_deref()\n                    .unwrap_or(\"https://api.anthropic.com\");\n                let version = \"2023-06-01\"; // Default API version\n\n                let client = providers::anthropic::Client::new(api_key, base_url, None, version);\n                let model = client.completion_model(&config.model);\n                RigModel::Anthropic(model)\n            }\n            \"cohere\" => {\n                let api_key =\n                    config\n                        .api_key\n                        .as_ref()\n                        .ok_or_else(|| LLMSpellError::Configuration {\n                            message: \"Cohere API key required\".to_string(),\n                            source: None,\n                        })?;\n\n                let client = providers::cohere::Client::new(api_key);\n                let model = client.completion_model(&config.model);\n                RigModel::Cohere(model)\n            }\n            _ => {\n                return Err(LLMSpellError::Configuration {\n                    message: format!(\"Unsupported provider: {}\", config.name),\n                    source: None,\n                });\n            }\n        };\n\n        // Set capabilities based on provider and model\n        let capabilities = ProviderCapabilities {\n            supports_streaming: false, // Rig doesn't expose streaming yet\n            supports_multimodal: matches!(config.name.as_str(), \"openai\" | \"anthropic\"),\n            max_context_tokens: Some(match config.name.as_str() {\n                \"openai\" => match config.model.as_str() {\n                    \"gpt-4\" | \"gpt-4-turbo\" => 128000,\n                    \"gpt-3.5-turbo\" => 16384,\n                    _ => 8192,\n                },\n                \"anthropic\" => match config.model.as_str() {\n                    \"claude-3-opus\" | \"claude-3-sonnet\" => 200000,\n                    \"claude-2.1\" => 100000,\n                    _ => 100000,\n                },\n                \"cohere\" => 4096,\n                _ => 4096,\n            }),\n            max_output_tokens: Some(4096),\n            available_models: vec![config.model.clone()],\n            custom_features: Default::default(),\n        };\n\n        Ok(Self {\n            config,\n            capabilities,\n            model,\n        })\n    }\n\n    async fn execute_completion(&self, prompt: String) -> Result<String, LLMSpellError> {\n        match &self.model {\n            RigModel::OpenAI(model) => model\n                .completion_request(&prompt)\n                .send()\n                .await\n                .map_err(|e| LLMSpellError::Provider {\n                    message: format!(\"OpenAI completion failed: {}\", e),\n                    provider: Some(self.config.name.clone()),\n                    source: None,\n                })\n                .and_then(|response| match response.choice {\n                    rig::completion::ModelChoice::Message(text) => Ok(text),\n                    rig::completion::ModelChoice::ToolCall(name, _params) => {\n                        Err(LLMSpellError::Provider {\n                            message: format!(\"Unexpected tool call response: {}\", name),\n                            provider: Some(self.config.name.clone()),\n                            source: None,\n                        })\n                    }\n                }),\n            RigModel::Anthropic(model) => model\n                .completion_request(&prompt)\n                .send()\n                .await\n                .map_err(|e| LLMSpellError::Provider {\n                    message: format!(\"Anthropic completion failed: {}\", e),\n                    provider: Some(self.config.name.clone()),\n                    source: None,\n                })\n                .and_then(|response| match response.choice {\n                    rig::completion::ModelChoice::Message(text) => Ok(text),\n                    rig::completion::ModelChoice::ToolCall(name, _params) => {\n                        Err(LLMSpellError::Provider {\n                            message: format!(\"Unexpected tool call response: {}\", name),\n                            provider: Some(self.config.name.clone()),\n                            source: None,\n                        })\n                    }\n                }),\n            RigModel::Cohere(model) => model\n                .completion_request(&prompt)\n                .send()\n                .await\n                .map_err(|e| LLMSpellError::Provider {\n                    message: format!(\"Cohere completion failed: {}\", e),\n                    provider: Some(self.config.name.clone()),\n                    source: None,\n                })\n                .and_then(|response| match response.choice {\n                    rig::completion::ModelChoice::Message(text) => Ok(text),\n                    rig::completion::ModelChoice::ToolCall(name, _params) => {\n                        Err(LLMSpellError::Provider {\n                            message: format!(\"Unexpected tool call response: {}\", name),\n                            provider: Some(self.config.name.clone()),\n                            source: None,\n                        })\n                    }\n                }),\n        }\n    }\n}\n\n#[async_trait]\nimpl ProviderInstance for RigProvider {\n    fn capabilities(&self) -> &ProviderCapabilities {\n        &self.capabilities\n    }\n\n    async fn complete(&self, input: &AgentInput) -> Result<AgentOutput, LLMSpellError> {\n        // Build the prompt\n        let mut prompt = input.text.clone();\n\n        // Add context if available\n        if let Some(context) = &input.context {\n            // Add context data as prefix\n            if !context.data.is_empty() {\n                let context_text = context\n                    .data\n                    .iter()\n                    .map(|(k, v)| format!(\"{}: {}\", k, v))\n                    .collect::<Vec<_>>()\n                    .join(\"\\n\");\n\n                prompt = format!(\"{}\\n\\n{}\", context_text, prompt);\n            }\n        }\n\n        // TODO: In a real implementation, we would handle parameters like max_tokens, temperature, etc.\n        // For now, we'll use defaults since Rig's simple completion API doesn't expose these\n\n        // Execute the completion\n        let output_text = self.execute_completion(prompt).await?;\n\n        // Build the output\n        let mut output = AgentOutput::text(output_text);\n\n        // Add provider metadata\n        output.metadata.model = Some(self.config.model.clone());\n        output\n            .metadata\n            .extra\n            .insert(\"provider\".to_string(), json!(self.config.name));\n\n        // Note: Rig's simple completion API doesn't return usage information\n        // In a real implementation, we might need to use more advanced APIs\n\n        Ok(output)\n    }\n\n    async fn complete_streaming(&self, _input: &AgentInput) -> Result<AgentStream, LLMSpellError> {\n        // Rig doesn't expose streaming yet, use default implementation\n        Err(LLMSpellError::Provider {\n            message: \"Streaming not yet supported in Rig provider\".to_string(),\n            provider: Some(self.name().to_string()),\n            source: None,\n        })\n    }\n\n    async fn validate(&self) -> Result<(), LLMSpellError> {\n        // Try a simple completion to validate the configuration\n        let test_input = AgentInput::text(\"Say 'test'\");\n\n        match self.complete(&test_input).await {\n            Ok(_) => Ok(()),\n            Err(e) => Err(LLMSpellError::Configuration {\n                message: format!(\"Provider validation failed: {}\", e),\n                source: Some(Box::new(e)),\n            }),\n        }\n    }\n\n    fn name(&self) -> &str {\n        &self.config.name\n    }\n\n    fn model(&self) -> &str {\n        &self.config.model\n    }\n}\n\n/// Factory function for creating Rig providers\npub fn create_rig_provider(\n    config: ProviderConfig,\n) -> Result<Box<dyn ProviderInstance>, LLMSpellError> {\n    Ok(Box::new(RigProvider::new(config)?))\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_rig_provider_capabilities() {\n        let config = ProviderConfig::new(\"openai\", \"gpt-4\");\n\n        // Note: This will fail without API key, but we can test the error handling\n        match RigProvider::new(config) {\n            Err(LLMSpellError::Configuration { message, .. }) => {\n                assert!(message.contains(\"API key required\"));\n            }\n            _ => panic!(\"Expected configuration error\"),\n        }\n    }\n\n    #[test]\n    fn test_unsupported_provider() {\n        let config = ProviderConfig::new(\"unsupported\", \"model\");\n\n        match RigProvider::new(config) {\n            Err(LLMSpellError::Configuration { message, .. }) => {\n                assert!(message.contains(\"Unsupported provider\"));\n            }\n            _ => panic!(\"Expected configuration error\"),\n        }\n    }\n\n    #[test]\n    fn test_provider_capabilities_settings() {\n        let mut config = ProviderConfig::new(\"openai\", \"gpt-4\");\n        config.api_key = Some(\"test-key\".to_string());\n\n        // Create provider and check capabilities\n        if let Ok(provider) = RigProvider::new(config) {\n            let caps = provider.capabilities();\n            assert!(!caps.supports_streaming); // Rig doesn't support streaming yet\n            assert!(caps.supports_multimodal); // OpenAI supports multimodal\n            assert_eq!(caps.max_context_tokens, Some(128000)); // GPT-4 context size\n            assert_eq!(caps.max_output_tokens, Some(4096));\n            assert_eq!(caps.available_models, vec![\"gpt-4\"]);\n        }\n    }\n\n    #[test]\n    fn test_anthropic_capabilities() {\n        let mut config = ProviderConfig::new(\"anthropic\", \"claude-3-opus\");\n        config.api_key = Some(\"test-key\".to_string());\n\n        if let Ok(provider) = RigProvider::new(config) {\n            let caps = provider.capabilities();\n            assert!(caps.supports_multimodal); // Anthropic supports multimodal\n            assert_eq!(caps.max_context_tokens, Some(200000)); // Claude 3 Opus context size\n        }\n    }\n\n    #[test]\n    fn test_cohere_capabilities() {\n        let mut config = ProviderConfig::new(\"cohere\", \"command\");\n        config.api_key = Some(\"test-key\".to_string());\n\n        if let Ok(provider) = RigProvider::new(config) {\n            let caps = provider.capabilities();\n            assert!(!caps.supports_multimodal); // Cohere doesn't support multimodal\n            assert_eq!(caps.max_context_tokens, Some(4096)); // Cohere context size\n        }\n    }\n}\n","traces":[{"line":29,"address":[],"length":0,"stats":{"Line":9}},{"line":31,"address":[],"length":0,"stats":{"Line":12}},{"line":32,"address":[],"length":0,"stats":{"Line":9}},{"line":33,"address":[],"length":0,"stats":{"Line":1}},{"line":34,"address":[],"length":0,"stats":{"Line":2}},{"line":35,"address":[],"length":0,"stats":{"Line":2}},{"line":37,"address":[],"length":0,"stats":{"Line":3}},{"line":38,"address":[],"length":0,"stats":{"Line":1}},{"line":39,"address":[],"length":0,"stats":{"Line":1}},{"line":46,"address":[],"length":0,"stats":{"Line":7}},{"line":47,"address":[],"length":0,"stats":{"Line":1}},{"line":48,"address":[],"length":0,"stats":{"Line":1}},{"line":49,"address":[],"length":0,"stats":{"Line":1}},{"line":51,"address":[],"length":0,"stats":{"Line":1}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":6}},{"line":68,"address":[],"length":0,"stats":{"Line":1}},{"line":69,"address":[],"length":0,"stats":{"Line":1}},{"line":70,"address":[],"length":0,"stats":{"Line":1}},{"line":72,"address":[],"length":0,"stats":{"Line":1}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":5}},{"line":83,"address":[],"length":0,"stats":{"Line":5}},{"line":84,"address":[],"length":0,"stats":{"Line":5}},{"line":92,"address":[],"length":0,"stats":{"Line":4}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":3}},{"line":185,"address":[],"length":0,"stats":{"Line":3}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":221,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":4}},{"line":264,"address":[],"length":0,"stats":{"Line":8}}],"covered":27,"coverable":107},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-security","src","lib.rs"],"content":"//! ABOUTME: llmspell-security implementation crate\n//! ABOUTME: Security sandbox for safe tool execution with file, network, and resource controls\n\npub mod sandbox;\n\n// Re-export main types\npub use sandbox::{\n    FileSandbox, IntegratedSandbox, NetworkSandbox, ResourceMonitor, SandboxContext,\n    SandboxViolation,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-security","src","sandbox","file_sandbox.rs"],"content":"//! ABOUTME: File system access control sandbox\n//! ABOUTME: Restricts file operations to allowed paths with path traversal protection\n\nuse super::{SandboxContext, SandboxViolation};\nuse llmspell_core::{error::LLMSpellError, Result};\nuse std::fs;\nuse std::path::{Path, PathBuf};\nuse tokio::fs as async_fs;\nuse tracing::{debug, warn};\n\n/// File sandbox for controlling file system access\npub struct FileSandbox {\n    context: SandboxContext,\n    violations: Vec<SandboxViolation>,\n}\n\nimpl FileSandbox {\n    /// Create a new file sandbox\n    pub fn new(context: SandboxContext) -> Result<Self> {\n        Ok(Self {\n            context,\n            violations: Vec::new(),\n        })\n    }\n\n    /// Check if a path is safe (no path traversal, within allowed paths)\n    pub fn validate_path(&self, path: &Path) -> Result<PathBuf> {\n        // Normalize the path to prevent path traversal\n        let normalized = self.normalize_path(path)?;\n\n        // Check if the path is within allowed directories\n        if !self.context.is_path_allowed(&normalized) {\n            let violation = SandboxViolation::FileAccess {\n                path: normalized.to_string_lossy().to_string(),\n                operation: \"access\".to_string(),\n                reason: \"Path not in allowed list\".to_string(),\n            };\n            warn!(\"File access violation: {}\", violation);\n            return Err(LLMSpellError::Security {\n                message: violation.to_string(),\n                violation_type: Some(\"file_access\".to_string()),\n            });\n        }\n\n        debug!(\"Path validation successful: {:?}\", normalized);\n        Ok(normalized)\n    }\n\n    /// Normalize path to prevent traversal attacks\n    fn normalize_path(&self, path: &Path) -> Result<PathBuf> {\n        // Convert to absolute path\n        let absolute = if path.is_absolute() {\n            path.to_path_buf()\n        } else {\n            PathBuf::from(&self.context.working_directory).join(path)\n        };\n\n        // Manually resolve .. and . components for security validation\n        let mut components = Vec::new();\n        for component in absolute.components() {\n            match component {\n                std::path::Component::Normal(name) => {\n                    components.push(name);\n                }\n                std::path::Component::ParentDir => {\n                    if components.is_empty() {\n                        return Err(LLMSpellError::Security {\n                            message: \"Path traversal detected: cannot go above root\".to_string(),\n                            violation_type: Some(\"path_traversal\".to_string()),\n                        });\n                    }\n                    components.pop();\n                }\n                std::path::Component::CurDir => {\n                    // Ignore current directory references\n                }\n                std::path::Component::RootDir | std::path::Component::Prefix(_) => {\n                    // Keep root and prefix components\n                    components.clear();\n                    if let std::path::Component::Prefix(_) = component {\n                        components.push(component.as_os_str());\n                    }\n                }\n            }\n        }\n\n        // Reconstruct the normalized path\n        let mut normalized = PathBuf::new();\n        normalized.push(\"/\"); // Start with root\n        for component in components {\n            normalized.push(component);\n        }\n\n        // Final check for any remaining traversal patterns\n        let path_str = normalized.to_string_lossy();\n        if path_str.contains(\"..\") || path_str.contains(\"./\") {\n            return Err(LLMSpellError::Security {\n                message: \"Path traversal pattern detected\".to_string(),\n                violation_type: Some(\"path_traversal\".to_string()),\n            });\n        }\n\n        Ok(normalized)\n    }\n\n    /// Safe file read operation\n    pub async fn read_file(&mut self, path: &Path) -> Result<Vec<u8>> {\n        let safe_path = self.validate_path(path)?;\n\n        debug!(\"Reading file: {:?}\", safe_path);\n\n        async_fs::read(&safe_path).await.map_err(|e| {\n            let violation = SandboxViolation::FileAccess {\n                path: safe_path.to_string_lossy().to_string(),\n                operation: \"read\".to_string(),\n                reason: format!(\"IO error: {}\", e),\n            };\n            self.violations.push(violation.clone());\n            LLMSpellError::Security {\n                message: violation.to_string(),\n                violation_type: Some(\"file_read\".to_string()),\n            }\n        })\n    }\n\n    /// Safe file write operation\n    pub async fn write_file(&mut self, path: &Path, contents: &[u8]) -> Result<()> {\n        let safe_path = self.validate_path(path)?;\n\n        debug!(\"Writing file: {:?}\", safe_path);\n\n        // Ensure parent directory exists\n        if let Some(parent) = safe_path.parent() {\n            if !parent.exists() {\n                async_fs::create_dir_all(parent)\n                    .await\n                    .map_err(|e| LLMSpellError::Security {\n                        message: format!(\"Cannot create parent directory: {}\", e),\n                        violation_type: Some(\"directory_creation\".to_string()),\n                    })?;\n            }\n        }\n\n        async_fs::write(&safe_path, contents).await.map_err(|e| {\n            let violation = SandboxViolation::FileAccess {\n                path: safe_path.to_string_lossy().to_string(),\n                operation: \"write\".to_string(),\n                reason: format!(\"IO error: {}\", e),\n            };\n            self.violations.push(violation.clone());\n            LLMSpellError::Security {\n                message: violation.to_string(),\n                violation_type: Some(\"file_write\".to_string()),\n            }\n        })\n    }\n\n    /// Safe file append operation\n    pub async fn append_file(&mut self, path: &Path, contents: &[u8]) -> Result<()> {\n        let safe_path = self.validate_path(path)?;\n\n        debug!(\"Appending to file: {:?}\", safe_path);\n\n        // Read existing content\n        let mut existing = if safe_path.exists() {\n            self.read_file(&safe_path).await?\n        } else {\n            Vec::new()\n        };\n\n        // Append new content\n        existing.extend_from_slice(contents);\n\n        // Write back\n        self.write_file(&safe_path, &existing).await\n    }\n\n    /// Safe directory creation\n    pub async fn create_dir(&mut self, path: &Path) -> Result<()> {\n        let safe_path = self.validate_path(path)?;\n\n        debug!(\"Creating directory: {:?}\", safe_path);\n\n        async_fs::create_dir_all(&safe_path).await.map_err(|e| {\n            let violation = SandboxViolation::FileAccess {\n                path: safe_path.to_string_lossy().to_string(),\n                operation: \"create_dir\".to_string(),\n                reason: format!(\"IO error: {}\", e),\n            };\n            self.violations.push(violation.clone());\n            LLMSpellError::Security {\n                message: violation.to_string(),\n                violation_type: Some(\"directory_creation\".to_string()),\n            }\n        })\n    }\n\n    /// Safe file deletion\n    pub async fn delete_file(&mut self, path: &Path) -> Result<()> {\n        let safe_path = self.validate_path(path)?;\n\n        debug!(\"Deleting file: {:?}\", safe_path);\n\n        async_fs::remove_file(&safe_path).await.map_err(|e| {\n            let violation = SandboxViolation::FileAccess {\n                path: safe_path.to_string_lossy().to_string(),\n                operation: \"delete\".to_string(),\n                reason: format!(\"IO error: {}\", e),\n            };\n            self.violations.push(violation.clone());\n            LLMSpellError::Security {\n                message: violation.to_string(),\n                violation_type: Some(\"file_delete\".to_string()),\n            }\n        })\n    }\n\n    /// Safe directory listing\n    pub async fn list_dir(&mut self, path: &Path) -> Result<Vec<PathBuf>> {\n        let safe_path = self.validate_path(path)?;\n\n        debug!(\"Listing directory: {:?}\", safe_path);\n\n        let mut entries = Vec::new();\n        let mut read_dir = async_fs::read_dir(&safe_path).await.map_err(|e| {\n            let violation = SandboxViolation::FileAccess {\n                path: safe_path.to_string_lossy().to_string(),\n                operation: \"list\".to_string(),\n                reason: format!(\"IO error: {}\", e),\n            };\n            self.violations.push(violation.clone());\n            LLMSpellError::Security {\n                message: violation.to_string(),\n                violation_type: Some(\"directory_list\".to_string()),\n            }\n        })?;\n\n        while let Some(entry) =\n            read_dir\n                .next_entry()\n                .await\n                .map_err(|e| LLMSpellError::Security {\n                    message: format!(\"Error reading directory entry: {}\", e),\n                    violation_type: Some(\"directory_list\".to_string()),\n                })?\n        {\n            entries.push(entry.path());\n        }\n\n        Ok(entries)\n    }\n\n    /// Check if file exists\n    pub async fn file_exists(&mut self, path: &Path) -> Result<bool> {\n        let safe_path = self.validate_path(path)?;\n        Ok(safe_path.exists())\n    }\n\n    /// Get file metadata\n    pub async fn file_metadata(&mut self, path: &Path) -> Result<fs::Metadata> {\n        let safe_path = self.validate_path(path)?;\n\n        debug!(\"Getting metadata for: {:?}\", safe_path);\n\n        async_fs::metadata(&safe_path).await.map_err(|e| {\n            let violation = SandboxViolation::FileAccess {\n                path: safe_path.to_string_lossy().to_string(),\n                operation: \"metadata\".to_string(),\n                reason: format!(\"IO error: {}\", e),\n            };\n            self.violations.push(violation.clone());\n            LLMSpellError::Security {\n                message: violation.to_string(),\n                violation_type: Some(\"file_metadata\".to_string()),\n            }\n        })\n    }\n\n    /// Get all violations that occurred\n    pub fn get_violations(&self) -> &[SandboxViolation] {\n        &self.violations\n    }\n\n    /// Clear violations history\n    pub fn clear_violations(&mut self) {\n        self.violations.clear();\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use llmspell_core::traits::tool::{ResourceLimits, SecurityRequirements};\n    use std::path::PathBuf;\n    use tempfile::TempDir;\n\n    async fn create_test_sandbox() -> (FileSandbox, TempDir) {\n        let temp_dir = TempDir::new().unwrap();\n        let temp_path = temp_dir.path().to_string_lossy().to_string();\n\n        let security_reqs = SecurityRequirements::safe().with_file_access(&temp_path);\n\n        let context = SandboxContext::new(\n            \"test-sandbox\".to_string(),\n            security_reqs,\n            ResourceLimits::strict(),\n        );\n\n        let sandbox = FileSandbox::new(context).unwrap();\n        (sandbox, temp_dir)\n    }\n\n    #[tokio::test]\n    async fn test_file_operations() {\n        let (mut sandbox, temp_dir) = create_test_sandbox().await;\n        let test_file = temp_dir.path().join(\"test.txt\");\n\n        // Test write\n        let content = b\"Hello, sandbox!\";\n        sandbox.write_file(&test_file, content).await.unwrap();\n\n        // Test read\n        let read_content = sandbox.read_file(&test_file).await.unwrap();\n        assert_eq!(read_content, content);\n\n        // Test append\n        let append_content = b\" More content.\";\n        sandbox\n            .append_file(&test_file, append_content)\n            .await\n            .unwrap();\n\n        let full_content = sandbox.read_file(&test_file).await.unwrap();\n        assert_eq!(full_content, b\"Hello, sandbox! More content.\");\n\n        // Test file exists\n        assert!(sandbox.file_exists(&test_file).await.unwrap());\n\n        // Test metadata\n        let metadata = sandbox.file_metadata(&test_file).await.unwrap();\n        assert!(metadata.is_file());\n    }\n\n    #[tokio::test]\n    async fn test_directory_operations() {\n        let (mut sandbox, temp_dir) = create_test_sandbox().await;\n        let test_dir = temp_dir.path().join(\"subdir\");\n\n        // Test directory creation\n        sandbox.create_dir(&test_dir).await.unwrap();\n        assert!(test_dir.exists());\n\n        // Test directory listing\n        let entries = sandbox.list_dir(temp_dir.path()).await.unwrap();\n        assert!(entries.contains(&test_dir));\n    }\n\n    #[tokio::test]\n    async fn test_path_traversal_protection() {\n        let (mut sandbox, _temp_dir) = create_test_sandbox().await;\n\n        // Test path traversal attempt - create a path that goes above the allowed directory\n        // This should be caught as path traversal since it tries to go above the allowed root\n        let traversal_path = Path::new(\"../../../../etc/passwd\");\n        let result = sandbox.read_file(traversal_path).await;\n        assert!(result.is_err());\n\n        // The actual behavior: our normalization resolves to /etc/passwd which fails as unauthorized access\n        // This is actually correct security behavior - the path should not be allowed\n        match result.unwrap_err() {\n            LLMSpellError::Security { violation_type, .. } => {\n                // Path normalization correctly prevents traversal and results in unauthorized access\n                assert!(\n                    violation_type == Some(\"file_access\".to_string())\n                        || violation_type == Some(\"path_traversal\".to_string())\n                );\n            }\n            _ => panic!(\"Expected Security error\"),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_unauthorized_path_access() {\n        let (mut sandbox, _temp_dir) = create_test_sandbox().await;\n\n        // Try to access a path outside the allowed directory\n        let unauthorized_path = PathBuf::from(\"/etc/passwd\");\n        let result = sandbox.read_file(&unauthorized_path).await;\n        assert!(result.is_err());\n\n        // Should be a security violation\n        match result.unwrap_err() {\n            LLMSpellError::Security { violation_type, .. } => {\n                assert_eq!(violation_type, Some(\"file_access\".to_string()));\n            }\n            _ => panic!(\"Expected SecurityViolation\"),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_file_deletion() {\n        let (mut sandbox, temp_dir) = create_test_sandbox().await;\n        let test_file = temp_dir.path().join(\"delete_me.txt\");\n\n        // Create file\n        sandbox.write_file(&test_file, b\"Delete me\").await.unwrap();\n        assert!(sandbox.file_exists(&test_file).await.unwrap());\n\n        // Delete file\n        sandbox.delete_file(&test_file).await.unwrap();\n        assert!(!sandbox.file_exists(&test_file).await.unwrap());\n    }\n}\n","traces":[{"line":19,"address":[],"length":0,"stats":{"Line":5}},{"line":20,"address":[],"length":0,"stats":{"Line":5}},{"line":21,"address":[],"length":0,"stats":{"Line":5}},{"line":22,"address":[],"length":0,"stats":{"Line":5}},{"line":27,"address":[],"length":0,"stats":{"Line":16}},{"line":29,"address":[],"length":0,"stats":{"Line":32}},{"line":34,"address":[],"length":0,"stats":{"Line":2}},{"line":35,"address":[],"length":0,"stats":{"Line":2}},{"line":36,"address":[],"length":0,"stats":{"Line":2}},{"line":38,"address":[],"length":0,"stats":{"Line":2}},{"line":45,"address":[],"length":0,"stats":{"Line":14}},{"line":46,"address":[],"length":0,"stats":{"Line":14}},{"line":50,"address":[],"length":0,"stats":{"Line":16}},{"line":52,"address":[],"length":0,"stats":{"Line":32}},{"line":53,"address":[],"length":0,"stats":{"Line":15}},{"line":55,"address":[],"length":0,"stats":{"Line":1}},{"line":59,"address":[],"length":0,"stats":{"Line":16}},{"line":60,"address":[],"length":0,"stats":{"Line":143}},{"line":61,"address":[],"length":0,"stats":{"Line":127}},{"line":62,"address":[],"length":0,"stats":{"Line":107}},{"line":63,"address":[],"length":0,"stats":{"Line":107}},{"line":66,"address":[],"length":0,"stats":{"Line":4}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":4}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":16}},{"line":80,"address":[],"length":0,"stats":{"Line":16}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":16}},{"line":89,"address":[],"length":0,"stats":{"Line":16}},{"line":90,"address":[],"length":0,"stats":{"Line":222}},{"line":96,"address":[],"length":0,"stats":{"Line":16}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":16}},{"line":107,"address":[],"length":0,"stats":{"Line":10}},{"line":108,"address":[],"length":0,"stats":{"Line":10}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":3}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":6}},{"line":128,"address":[],"length":0,"stats":{"Line":6}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":3}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":6}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":2}},{"line":160,"address":[],"length":0,"stats":{"Line":2}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":1}},{"line":166,"address":[],"length":0,"stats":{"Line":1}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":2}},{"line":180,"address":[],"length":0,"stats":{"Line":2}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":1}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":2}},{"line":200,"address":[],"length":0,"stats":{"Line":2}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":1}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":2}},{"line":220,"address":[],"length":0,"stats":{"Line":2}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":2}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":1}},{"line":239,"address":[],"length":0,"stats":{"Line":2}},{"line":240,"address":[],"length":0,"stats":{"Line":2}},{"line":241,"address":[],"length":0,"stats":{"Line":2}},{"line":242,"address":[],"length":0,"stats":{"Line":2}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":1}},{"line":254,"address":[],"length":0,"stats":{"Line":6}},{"line":255,"address":[],"length":0,"stats":{"Line":6}},{"line":260,"address":[],"length":0,"stats":{"Line":2}},{"line":261,"address":[],"length":0,"stats":{"Line":2}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":1}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}}],"covered":61,"coverable":136},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-security","src","sandbox","mod.rs"],"content":"//! ABOUTME: Security sandbox for safe tool execution\n//! ABOUTME: Provides file system, network, and resource monitoring controls\n\npub mod file_sandbox;\npub mod network_sandbox;\npub mod resource_monitor;\n\npub use file_sandbox::FileSandbox;\npub use network_sandbox::NetworkSandbox;\npub use resource_monitor::ResourceMonitor;\n\nuse llmspell_core::{\n    traits::tool::{ResourceLimits, SecurityRequirements},\n    Result,\n};\nuse serde::{Deserialize, Serialize};\nuse std::path::Path;\n\n/// Sandbox execution context\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct SandboxContext {\n    /// Unique sandbox ID\n    pub id: String,\n    /// Security requirements\n    pub security_requirements: SecurityRequirements,\n    /// Resource limits\n    pub resource_limits: ResourceLimits,\n    /// Working directory\n    pub working_directory: String,\n    /// Allowed file paths\n    pub allowed_paths: Vec<String>,\n    /// Allowed network domains\n    pub allowed_domains: Vec<String>,\n    /// Environment variables allowed\n    pub allowed_env_vars: Vec<String>,\n}\n\nimpl SandboxContext {\n    /// Create a new sandbox context\n    pub fn new(\n        id: String,\n        security_requirements: SecurityRequirements,\n        resource_limits: ResourceLimits,\n    ) -> Self {\n        Self {\n            id,\n            security_requirements: security_requirements.clone(),\n            resource_limits,\n            working_directory: std::env::current_dir()\n                .unwrap_or_else(|_| std::path::PathBuf::from(\"/tmp\"))\n                .to_string_lossy()\n                .to_string(),\n            allowed_paths: security_requirements.file_permissions,\n            allowed_domains: security_requirements.network_permissions,\n            allowed_env_vars: security_requirements.env_permissions,\n        }\n    }\n\n    /// Check if a file path is allowed\n    pub fn is_path_allowed(&self, path: &Path) -> bool {\n        let path_str = path.to_string_lossy();\n\n        // Check wildcard permissions\n        if self.allowed_paths.contains(&\"*\".to_string()) {\n            return true;\n        }\n\n        // Check exact matches and prefix matches\n        for allowed in &self.allowed_paths {\n            if allowed == \"*\" || path_str == *allowed || path_str.starts_with(allowed) {\n                return true;\n            }\n        }\n\n        false\n    }\n\n    /// Check if a domain is allowed\n    pub fn is_domain_allowed(&self, domain: &str) -> bool {\n        // Check wildcard permissions\n        if self.allowed_domains.contains(&\"*\".to_string()) {\n            return true;\n        }\n\n        // Check exact matches and suffix matches\n        for allowed in &self.allowed_domains {\n            if allowed == \"*\" || domain == *allowed || domain.ends_with(allowed) {\n                return true;\n            }\n        }\n\n        false\n    }\n\n    /// Check if an environment variable is allowed\n    pub fn is_env_var_allowed(&self, var: &str) -> bool {\n        // Check wildcard permissions\n        if self.allowed_env_vars.contains(&\"*\".to_string()) {\n            return true;\n        }\n\n        // Check exact matches\n        self.allowed_env_vars.contains(&var.to_string())\n    }\n}\n\n/// Integrated sandbox that combines file, network, and resource controls\npub struct IntegratedSandbox {\n    context: SandboxContext,\n    file_sandbox: FileSandbox,\n    network_sandbox: NetworkSandbox,\n    resource_monitor: ResourceMonitor,\n}\n\nimpl IntegratedSandbox {\n    /// Create a new integrated sandbox\n    pub fn new(context: SandboxContext) -> Result<Self> {\n        let file_sandbox = FileSandbox::new(context.clone())?;\n        let network_sandbox = NetworkSandbox::new(context.clone())?;\n        let resource_monitor = ResourceMonitor::new(context.clone())?;\n\n        Ok(Self {\n            context,\n            file_sandbox,\n            network_sandbox,\n            resource_monitor,\n        })\n    }\n\n    /// Get sandbox context\n    pub fn context(&self) -> &SandboxContext {\n        &self.context\n    }\n\n    /// Get file sandbox\n    pub fn file_sandbox(&self) -> &FileSandbox {\n        &self.file_sandbox\n    }\n\n    /// Get network sandbox\n    pub fn network_sandbox(&self) -> &NetworkSandbox {\n        &self.network_sandbox\n    }\n\n    /// Get resource monitor\n    pub fn resource_monitor(&self) -> &ResourceMonitor {\n        &self.resource_monitor\n    }\n\n    /// Start monitoring resources\n    pub async fn start_monitoring(&mut self) -> Result<()> {\n        self.resource_monitor.start().await\n    }\n\n    /// Stop monitoring resources\n    pub async fn stop_monitoring(&mut self) -> Result<()> {\n        self.resource_monitor.stop().await\n    }\n\n    /// Check if the sandbox has any violations\n    pub async fn has_violations(&self) -> bool {\n        self.resource_monitor.has_violations().await\n    }\n\n    /// Get violation summary\n    pub async fn get_violations(&self) -> Vec<String> {\n        self.resource_monitor.get_violations().await\n    }\n}\n\n/// Sandbox violation types\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum SandboxViolation {\n    /// File access violation\n    FileAccess {\n        path: String,\n        operation: String,\n        reason: String,\n    },\n    /// Network access violation\n    NetworkAccess {\n        domain: String,\n        operation: String,\n        reason: String,\n    },\n    /// Resource limit violation\n    ResourceLimit {\n        resource: String,\n        limit: u64,\n        actual: u64,\n        reason: String,\n    },\n    /// Environment access violation\n    EnvironmentAccess { variable: String, reason: String },\n}\n\nimpl std::fmt::Display for SandboxViolation {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            SandboxViolation::FileAccess {\n                path,\n                operation,\n                reason,\n            } => {\n                write!(\n                    f,\n                    \"File access violation: {} on '{}' - {}\",\n                    operation, path, reason\n                )\n            }\n            SandboxViolation::NetworkAccess {\n                domain,\n                operation,\n                reason,\n            } => {\n                write!(\n                    f,\n                    \"Network access violation: {} to '{}' - {}\",\n                    operation, domain, reason\n                )\n            }\n            SandboxViolation::ResourceLimit {\n                resource,\n                limit,\n                actual,\n                reason,\n            } => {\n                write!(\n                    f,\n                    \"Resource limit violation: {} exceeded limit {} with {} - {}\",\n                    resource, limit, actual, reason\n                )\n            }\n            SandboxViolation::EnvironmentAccess { variable, reason } => {\n                write!(\n                    f,\n                    \"Environment access violation: '{}' - {}\",\n                    variable, reason\n                )\n            }\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use llmspell_core::traits::tool::{ResourceLimits, SecurityRequirements};\n\n    #[test]\n    fn test_sandbox_context_creation() {\n        let security_reqs = SecurityRequirements::safe()\n            .with_file_access(\"/tmp\")\n            .with_network_access(\"api.example.com\")\n            .with_env_access(\"HOME\");\n\n        let resource_limits = ResourceLimits::strict();\n\n        let context =\n            SandboxContext::new(\"test-sandbox\".to_string(), security_reqs, resource_limits);\n\n        assert_eq!(context.id, \"test-sandbox\");\n        assert!(context.allowed_paths.contains(&\"/tmp\".to_string()));\n        assert!(context\n            .allowed_domains\n            .contains(&\"api.example.com\".to_string()));\n        assert!(context.allowed_env_vars.contains(&\"HOME\".to_string()));\n    }\n\n    #[test]\n    fn test_path_permissions() {\n        let security_reqs = SecurityRequirements::safe()\n            .with_file_access(\"/tmp\")\n            .with_file_access(\"/var/log\");\n\n        let context =\n            SandboxContext::new(\"test\".to_string(), security_reqs, ResourceLimits::strict());\n\n        assert!(context.is_path_allowed(Path::new(\"/tmp/test.txt\")));\n        assert!(context.is_path_allowed(Path::new(\"/var/log/app.log\")));\n        assert!(!context.is_path_allowed(Path::new(\"/etc/passwd\")));\n    }\n\n    #[test]\n    fn test_domain_permissions() {\n        let security_reqs = SecurityRequirements::safe()\n            .with_network_access(\"api.example.com\")\n            .with_network_access(\".github.com\");\n\n        let context =\n            SandboxContext::new(\"test\".to_string(), security_reqs, ResourceLimits::strict());\n\n        assert!(context.is_domain_allowed(\"api.example.com\"));\n        assert!(context.is_domain_allowed(\"api.github.com\"));\n        assert!(!context.is_domain_allowed(\"malicious.com\"));\n    }\n\n    #[test]\n    fn test_env_var_permissions() {\n        let security_reqs = SecurityRequirements::safe()\n            .with_env_access(\"HOME\")\n            .with_env_access(\"PATH\");\n\n        let context =\n            SandboxContext::new(\"test\".to_string(), security_reqs, ResourceLimits::strict());\n\n        assert!(context.is_env_var_allowed(\"HOME\"));\n        assert!(context.is_env_var_allowed(\"PATH\"));\n        assert!(!context.is_env_var_allowed(\"SECRET_KEY\"));\n    }\n\n    #[test]\n    fn test_wildcard_permissions() {\n        let security_reqs = SecurityRequirements::privileged();\n\n        let context = SandboxContext::new(\n            \"test\".to_string(),\n            security_reqs,\n            ResourceLimits::unlimited(),\n        );\n\n        assert!(context.is_path_allowed(Path::new(\"/any/path\")));\n        assert!(context.is_domain_allowed(\"any.domain.com\"));\n        assert!(context.is_env_var_allowed(\"ANY_VAR\"));\n    }\n}\n","traces":[{"line":40,"address":[],"length":0,"stats":{"Line":21}},{"line":47,"address":[],"length":0,"stats":{"Line":21}},{"line":49,"address":[],"length":0,"stats":{"Line":21}},{"line":53,"address":[],"length":0,"stats":{"Line":21}},{"line":54,"address":[],"length":0,"stats":{"Line":21}},{"line":55,"address":[],"length":0,"stats":{"Line":21}},{"line":60,"address":[],"length":0,"stats":{"Line":20}},{"line":61,"address":[],"length":0,"stats":{"Line":20}},{"line":64,"address":[],"length":0,"stats":{"Line":20}},{"line":65,"address":[],"length":0,"stats":{"Line":1}},{"line":69,"address":[],"length":0,"stats":{"Line":45}},{"line":70,"address":[],"length":0,"stats":{"Line":62}},{"line":71,"address":[],"length":0,"stats":{"Line":16}},{"line":75,"address":[],"length":0,"stats":{"Line":3}},{"line":79,"address":[],"length":0,"stats":{"Line":16}},{"line":81,"address":[],"length":0,"stats":{"Line":16}},{"line":82,"address":[],"length":0,"stats":{"Line":1}},{"line":86,"address":[],"length":0,"stats":{"Line":43}},{"line":87,"address":[],"length":0,"stats":{"Line":49}},{"line":88,"address":[],"length":0,"stats":{"Line":12}},{"line":92,"address":[],"length":0,"stats":{"Line":3}},{"line":96,"address":[],"length":0,"stats":{"Line":4}},{"line":98,"address":[],"length":0,"stats":{"Line":4}},{"line":99,"address":[],"length":0,"stats":{"Line":1}},{"line":103,"address":[],"length":0,"stats":{"Line":3}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":6}},{"line":199,"address":[],"length":0,"stats":{"Line":6}},{"line":201,"address":[],"length":0,"stats":{"Line":2}},{"line":202,"address":[],"length":0,"stats":{"Line":2}},{"line":203,"address":[],"length":0,"stats":{"Line":2}},{"line":204,"address":[],"length":0,"stats":{"Line":2}},{"line":205,"address":[],"length":0,"stats":{"Line":2}},{"line":206,"address":[],"length":0,"stats":{"Line":2}},{"line":208,"address":[],"length":0,"stats":{"Line":2}},{"line":212,"address":[],"length":0,"stats":{"Line":2}},{"line":213,"address":[],"length":0,"stats":{"Line":2}},{"line":214,"address":[],"length":0,"stats":{"Line":2}},{"line":215,"address":[],"length":0,"stats":{"Line":2}},{"line":216,"address":[],"length":0,"stats":{"Line":2}},{"line":217,"address":[],"length":0,"stats":{"Line":2}},{"line":219,"address":[],"length":0,"stats":{"Line":2}},{"line":223,"address":[],"length":0,"stats":{"Line":2}},{"line":224,"address":[],"length":0,"stats":{"Line":2}},{"line":225,"address":[],"length":0,"stats":{"Line":2}},{"line":226,"address":[],"length":0,"stats":{"Line":2}},{"line":227,"address":[],"length":0,"stats":{"Line":2}},{"line":228,"address":[],"length":0,"stats":{"Line":2}},{"line":229,"address":[],"length":0,"stats":{"Line":2}},{"line":231,"address":[],"length":0,"stats":{"Line":2}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}}],"covered":49,"coverable":78},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-security","src","sandbox","network_sandbox.rs"],"content":"//! ABOUTME: Network access control sandbox\n//! ABOUTME: Controls HTTP requests and network access to allowed domains with rate limiting\n\nuse super::{SandboxContext, SandboxViolation};\nuse llmspell_core::{error::LLMSpellError, Result};\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse std::time::{Duration, Instant};\nuse tokio::sync::RwLock;\nuse tracing::{debug, warn};\n\n/// Network request information\n#[derive(Debug, Clone)]\npub struct NetworkRequest {\n    pub url: String,\n    pub method: String,\n    pub headers: HashMap<String, String>,\n    pub timestamp: Instant,\n}\n\n/// Rate limiting configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct RateLimitConfig {\n    /// Maximum requests per time window\n    pub max_requests: u32,\n    /// Time window duration in seconds\n    pub window_seconds: u64,\n}\n\nimpl Default for RateLimitConfig {\n    fn default() -> Self {\n        Self {\n            max_requests: 100,\n            window_seconds: 60,\n        }\n    }\n}\n\n/// Rate limiter for network requests\n#[derive(Debug)]\nstruct RateLimiter {\n    config: RateLimitConfig,\n    requests: Vec<Instant>,\n}\n\nimpl RateLimiter {\n    fn new(config: RateLimitConfig) -> Self {\n        Self {\n            config,\n            requests: Vec::new(),\n        }\n    }\n\n    fn check_and_record(&mut self) -> bool {\n        let now = Instant::now();\n        let window_start = now - Duration::from_secs(self.config.window_seconds);\n\n        // Remove old requests outside the window\n        self.requests.retain(|&timestamp| timestamp > window_start);\n\n        // Check if we're under the limit\n        if self.requests.len() < self.config.max_requests as usize {\n            self.requests.push(now);\n            true\n        } else {\n            false\n        }\n    }\n}\n\n/// Network sandbox for controlling network access\npub struct NetworkSandbox {\n    context: SandboxContext,\n    violations: Vec<SandboxViolation>,\n    rate_limiters: Arc<RwLock<HashMap<String, RateLimiter>>>,\n    default_rate_limit: RateLimitConfig,\n}\n\nimpl NetworkSandbox {\n    /// Create a new network sandbox\n    pub fn new(context: SandboxContext) -> Result<Self> {\n        Ok(Self {\n            context,\n            violations: Vec::new(),\n            rate_limiters: Arc::new(RwLock::new(HashMap::new())),\n            default_rate_limit: RateLimitConfig::default(),\n        })\n    }\n\n    /// Set default rate limiting configuration\n    pub fn with_rate_limit(mut self, config: RateLimitConfig) -> Self {\n        self.default_rate_limit = config;\n        self\n    }\n\n    /// Validate a network request\n    pub async fn validate_request(&mut self, url: &str, method: &str) -> Result<()> {\n        // Parse URL to extract domain\n        let domain = self.extract_domain(url)?;\n\n        // Check if domain is allowed\n        if !self.context.is_domain_allowed(&domain) {\n            let violation = SandboxViolation::NetworkAccess {\n                domain: domain.clone(),\n                operation: method.to_string(),\n                reason: \"Domain not in allowed list\".to_string(),\n            };\n            self.violations.push(violation.clone());\n            warn!(\"Network access violation: {}\", violation);\n            return Err(LLMSpellError::Security {\n                message: violation.to_string(),\n                violation_type: Some(\"network_access\".to_string()),\n            });\n        }\n\n        // Check rate limits\n        self.check_rate_limit(&domain).await?;\n\n        debug!(\"Network request validated: {} {}\", method, url);\n        Ok(())\n    }\n\n    /// Extract domain from URL\n    fn extract_domain(&self, url: &str) -> Result<String> {\n        // Simple URL parsing - in production, you might want to use the `url` crate\n        if let Some(start) = url.find(\"://\") {\n            let after_protocol = &url[start + 3..];\n            if let Some(end) = after_protocol.find('/') {\n                Ok(after_protocol[..end].to_string())\n            } else if let Some(end) = after_protocol.find('?') {\n                Ok(after_protocol[..end].to_string())\n            } else {\n                Ok(after_protocol.to_string())\n            }\n        } else {\n            Err(LLMSpellError::Validation {\n                message: format!(\"Invalid URL format: {}\", url),\n                field: Some(\"url\".to_string()),\n            })\n        }\n    }\n\n    /// Check rate limits for a domain\n    async fn check_rate_limit(&mut self, domain: &str) -> Result<()> {\n        let mut limiters = self.rate_limiters.write().await;\n\n        let limiter = limiters\n            .entry(domain.to_string())\n            .or_insert_with(|| RateLimiter::new(self.default_rate_limit.clone()));\n\n        if !limiter.check_and_record() {\n            let violation = SandboxViolation::ResourceLimit {\n                resource: \"network_requests\".to_string(),\n                limit: self.default_rate_limit.max_requests as u64,\n                actual: limiter.requests.len() as u64,\n                reason: format!(\"Rate limit exceeded for domain: {}\", domain),\n            };\n            self.violations.push(violation.clone());\n            warn!(\"Rate limit violation: {}\", violation);\n            return Err(LLMSpellError::Security {\n                message: violation.to_string(),\n                violation_type: Some(\"rate_limit\".to_string()),\n            });\n        }\n\n        Ok(())\n    }\n\n    /// Make a safe HTTP GET request\n    pub async fn get(&mut self, url: &str) -> Result<String> {\n        self.validate_request(url, \"GET\").await?;\n\n        debug!(\"Making GET request to: {}\", url);\n\n        // In a real implementation, you would use a proper HTTP client\n        // For now, we'll simulate the request\n        self.simulate_http_request(url, \"GET\").await\n    }\n\n    /// Make a safe HTTP POST request\n    pub async fn post(&mut self, url: &str, body: &str) -> Result<String> {\n        self.validate_request(url, \"POST\").await?;\n\n        debug!(\n            \"Making POST request to: {} with body length: {}\",\n            url,\n            body.len()\n        );\n\n        // In a real implementation, you would use a proper HTTP client\n        self.simulate_http_request(url, \"POST\").await\n    }\n\n    /// Make a safe HTTP PUT request\n    pub async fn put(&mut self, url: &str, body: &str) -> Result<String> {\n        self.validate_request(url, \"PUT\").await?;\n\n        debug!(\n            \"Making PUT request to: {} with body length: {}\",\n            url,\n            body.len()\n        );\n\n        self.simulate_http_request(url, \"PUT\").await\n    }\n\n    /// Make a safe HTTP DELETE request\n    pub async fn delete(&mut self, url: &str) -> Result<String> {\n        self.validate_request(url, \"DELETE\").await?;\n\n        debug!(\"Making DELETE request to: {}\", url);\n\n        self.simulate_http_request(url, \"DELETE\").await\n    }\n\n    /// Simulate HTTP request (placeholder for real implementation)\n    async fn simulate_http_request(&self, url: &str, method: &str) -> Result<String> {\n        // In a real implementation, this would use reqwest or similar\n        // For testing purposes, we'll return a mock response\n        tokio::time::sleep(Duration::from_millis(100)).await; // Simulate network delay\n\n        Ok(format!(\n            \"{{\\\"mock_response\\\": true, \\\"url\\\": \\\"{}\\\", \\\"method\\\": \\\"{}\\\", \\\"status\\\": 200}}\",\n            url, method\n        ))\n    }\n\n    /// Get network statistics\n    pub async fn get_network_stats(&self) -> NetworkStats {\n        let limiters = self.rate_limiters.read().await;\n        let mut domain_stats = HashMap::new();\n\n        for (domain, limiter) in limiters.iter() {\n            domain_stats.insert(\n                domain.clone(),\n                DomainStats {\n                    recent_requests: limiter.requests.len() as u32,\n                    window_seconds: limiter.config.window_seconds,\n                    max_requests: limiter.config.max_requests,\n                },\n            );\n        }\n\n        NetworkStats {\n            total_violations: self.violations.len(),\n            domain_stats,\n        }\n    }\n\n    /// Get all violations that occurred\n    pub fn get_violations(&self) -> &[SandboxViolation] {\n        &self.violations\n    }\n\n    /// Clear violations history\n    pub fn clear_violations(&mut self) {\n        self.violations.clear();\n    }\n}\n\n/// Network statistics\n#[derive(Debug)]\npub struct NetworkStats {\n    pub total_violations: usize,\n    pub domain_stats: HashMap<String, DomainStats>,\n}\n\n/// Domain-specific statistics\n#[derive(Debug)]\npub struct DomainStats {\n    pub recent_requests: u32,\n    pub window_seconds: u64,\n    pub max_requests: u32,\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use llmspell_core::traits::tool::{ResourceLimits, SecurityRequirements};\n\n    fn create_test_sandbox() -> NetworkSandbox {\n        let security_reqs = SecurityRequirements::safe()\n            .with_network_access(\"api.example.com\")\n            .with_network_access(\"github.com\");\n\n        let context = SandboxContext::new(\n            \"test-sandbox\".to_string(),\n            security_reqs,\n            ResourceLimits::strict(),\n        );\n\n        NetworkSandbox::new(context).unwrap()\n    }\n\n    #[tokio::test]\n    async fn test_domain_validation() {\n        let mut sandbox = create_test_sandbox();\n\n        // Valid domain\n        assert!(sandbox\n            .validate_request(\"https://api.example.com/data\", \"GET\")\n            .await\n            .is_ok());\n\n        // Invalid domain\n        assert!(sandbox\n            .validate_request(\"https://malicious.com/data\", \"GET\")\n            .await\n            .is_err());\n    }\n\n    #[test]\n    fn test_domain_extraction() {\n        let sandbox = create_test_sandbox();\n\n        assert_eq!(\n            sandbox\n                .extract_domain(\"https://api.example.com/v1/data\")\n                .unwrap(),\n            \"api.example.com\"\n        );\n        assert_eq!(\n            sandbox.extract_domain(\"http://github.com\").unwrap(),\n            \"github.com\"\n        );\n        assert_eq!(\n            sandbox\n                .extract_domain(\"https://sub.domain.com/path?query=1\")\n                .unwrap(),\n            \"sub.domain.com\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_http_methods() {\n        let mut sandbox = create_test_sandbox();\n\n        // Test all HTTP methods\n        assert!(sandbox.get(\"https://api.example.com/data\").await.is_ok());\n        assert!(sandbox\n            .post(\"https://api.example.com/data\", \"{}\")\n            .await\n            .is_ok());\n        assert!(sandbox\n            .put(\"https://api.example.com/data\", \"{}\")\n            .await\n            .is_ok());\n        assert!(sandbox.delete(\"https://api.example.com/data\").await.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_rate_limiting() {\n        let rate_config = RateLimitConfig {\n            max_requests: 2,\n            window_seconds: 1,\n        };\n\n        let mut sandbox = create_test_sandbox().with_rate_limit(rate_config);\n\n        // First two requests should succeed\n        assert!(sandbox.get(\"https://api.example.com/1\").await.is_ok());\n        assert!(sandbox.get(\"https://api.example.com/2\").await.is_ok());\n\n        // Third request should fail due to rate limit\n        assert!(sandbox.get(\"https://api.example.com/3\").await.is_err());\n\n        // Check that violation was recorded\n        assert!(!sandbox.get_violations().is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_network_stats() {\n        let mut sandbox = create_test_sandbox();\n\n        // Make some requests\n        let _ = sandbox.get(\"https://api.example.com/data\").await;\n        let _ = sandbox.get(\"https://github.com/repo\").await;\n\n        let stats = sandbox.get_network_stats().await;\n        assert_eq!(stats.domain_stats.len(), 2);\n        assert!(stats.domain_stats.contains_key(\"api.example.com\"));\n        assert!(stats.domain_stats.contains_key(\"github.com\"));\n    }\n\n    #[tokio::test]\n    async fn test_violation_tracking() {\n        let mut sandbox = create_test_sandbox();\n\n        // Make an invalid request\n        let _ = sandbox.get(\"https://blocked.com/data\").await;\n\n        // Check violations\n        let violations = sandbox.get_violations();\n        assert_eq!(violations.len(), 1);\n        match &violations[0] {\n            SandboxViolation::NetworkAccess { domain, .. } => {\n                assert_eq!(domain, \"blocked.com\");\n            }\n            _ => panic!(\"Expected NetworkAccess violation\"),\n        }\n\n        // Clear violations\n        sandbox.clear_violations();\n        assert!(sandbox.get_violations().is_empty());\n    }\n}\n","traces":[{"line":32,"address":[],"length":0,"stats":{"Line":6}},{"line":48,"address":[],"length":0,"stats":{"Line":5}},{"line":51,"address":[],"length":0,"stats":{"Line":5}},{"line":55,"address":[],"length":0,"stats":{"Line":10}},{"line":56,"address":[],"length":0,"stats":{"Line":10}},{"line":57,"address":[],"length":0,"stats":{"Line":10}},{"line":60,"address":[],"length":0,"stats":{"Line":29}},{"line":63,"address":[],"length":0,"stats":{"Line":10}},{"line":64,"address":[],"length":0,"stats":{"Line":9}},{"line":65,"address":[],"length":0,"stats":{"Line":9}},{"line":67,"address":[],"length":0,"stats":{"Line":1}},{"line":82,"address":[],"length":0,"stats":{"Line":6}},{"line":83,"address":[],"length":0,"stats":{"Line":6}},{"line":84,"address":[],"length":0,"stats":{"Line":6}},{"line":85,"address":[],"length":0,"stats":{"Line":6}},{"line":86,"address":[],"length":0,"stats":{"Line":6}},{"line":87,"address":[],"length":0,"stats":{"Line":6}},{"line":92,"address":[],"length":0,"stats":{"Line":1}},{"line":93,"address":[],"length":0,"stats":{"Line":1}},{"line":94,"address":[],"length":0,"stats":{"Line":1}},{"line":98,"address":[],"length":0,"stats":{"Line":24}},{"line":100,"address":[],"length":0,"stats":{"Line":24}},{"line":105,"address":[],"length":0,"stats":{"Line":2}},{"line":106,"address":[],"length":0,"stats":{"Line":2}},{"line":107,"address":[],"length":0,"stats":{"Line":2}},{"line":109,"address":[],"length":0,"stats":{"Line":2}},{"line":110,"address":[],"length":0,"stats":{"Line":2}},{"line":118,"address":[],"length":0,"stats":{"Line":11}},{"line":120,"address":[],"length":0,"stats":{"Line":9}},{"line":125,"address":[],"length":0,"stats":{"Line":15}},{"line":127,"address":[],"length":0,"stats":{"Line":30}},{"line":129,"address":[],"length":0,"stats":{"Line":14}},{"line":131,"address":[],"length":0,"stats":{"Line":1}},{"line":134,"address":[],"length":0,"stats":{"Line":1}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":20}},{"line":146,"address":[],"length":0,"stats":{"Line":20}},{"line":148,"address":[],"length":0,"stats":{"Line":10}},{"line":149,"address":[],"length":0,"stats":{"Line":10}},{"line":150,"address":[],"length":0,"stats":{"Line":25}},{"line":152,"address":[],"length":0,"stats":{"Line":10}},{"line":154,"address":[],"length":0,"stats":{"Line":1}},{"line":155,"address":[],"length":0,"stats":{"Line":1}},{"line":156,"address":[],"length":0,"stats":{"Line":1}},{"line":157,"address":[],"length":0,"stats":{"Line":1}},{"line":159,"address":[],"length":0,"stats":{"Line":1}},{"line":160,"address":[],"length":0,"stats":{"Line":1}},{"line":167,"address":[],"length":0,"stats":{"Line":9}},{"line":171,"address":[],"length":0,"stats":{"Line":14}},{"line":172,"address":[],"length":0,"stats":{"Line":9}},{"line":174,"address":[],"length":0,"stats":{"Line":5}},{"line":182,"address":[],"length":0,"stats":{"Line":2}},{"line":183,"address":[],"length":0,"stats":{"Line":1}},{"line":185,"address":[],"length":0,"stats":{"Line":1}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":2}},{"line":197,"address":[],"length":0,"stats":{"Line":1}},{"line":199,"address":[],"length":0,"stats":{"Line":1}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":2}},{"line":210,"address":[],"length":0,"stats":{"Line":1}},{"line":212,"address":[],"length":0,"stats":{"Line":1}},{"line":218,"address":[],"length":0,"stats":{"Line":16}},{"line":221,"address":[],"length":0,"stats":{"Line":8}},{"line":223,"address":[],"length":0,"stats":{"Line":8}},{"line":224,"address":[],"length":0,"stats":{"Line":8}},{"line":225,"address":[],"length":0,"stats":{"Line":8}},{"line":230,"address":[],"length":0,"stats":{"Line":2}},{"line":231,"address":[],"length":0,"stats":{"Line":2}},{"line":232,"address":[],"length":0,"stats":{"Line":1}},{"line":234,"address":[],"length":0,"stats":{"Line":3}},{"line":246,"address":[],"length":0,"stats":{"Line":1}},{"line":252,"address":[],"length":0,"stats":{"Line":3}},{"line":253,"address":[],"length":0,"stats":{"Line":3}},{"line":257,"address":[],"length":0,"stats":{"Line":1}},{"line":258,"address":[],"length":0,"stats":{"Line":1}}],"covered":73,"coverable":82},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-security","src","sandbox","resource_monitor.rs"],"content":"//! ABOUTME: Resource monitoring and enforcement for sandbox execution\n//! ABOUTME: Tracks CPU, memory, network bandwidth, and custom resource usage with limits\n\nuse super::{SandboxContext, SandboxViolation};\nuse llmspell_core::{error::LLMSpellError, Result};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse std::time::{Duration, Instant};\nuse tokio::sync::RwLock;\nuse tokio::time::interval;\nuse tracing::{debug, warn};\n\n/// Resource usage statistics\n#[derive(Debug, Clone)]\npub struct ResourceUsage {\n    /// Memory usage in bytes\n    pub memory_bytes: u64,\n    /// CPU time used in milliseconds\n    pub cpu_time_ms: u64,\n    /// Network bytes transferred\n    pub network_bytes: u64,\n    /// File operations performed\n    pub file_operations: u32,\n    /// Custom resource usage\n    pub custom_usage: HashMap<String, u64>,\n    /// Timestamp of measurement\n    pub timestamp: Instant,\n}\n\nimpl Default for ResourceUsage {\n    fn default() -> Self {\n        Self {\n            memory_bytes: 0,\n            cpu_time_ms: 0,\n            network_bytes: 0,\n            file_operations: 0,\n            custom_usage: HashMap::new(),\n            timestamp: Instant::now(),\n        }\n    }\n}\n\n/// Resource monitor for tracking and enforcing limits\npub struct ResourceMonitor {\n    context: SandboxContext,\n    violations: Vec<SandboxViolation>,\n    current_usage: Arc<RwLock<ResourceUsage>>,\n    monitoring_active: Arc<RwLock<bool>>,\n    start_time: Instant,\n}\n\nimpl ResourceMonitor {\n    /// Create a new resource monitor\n    pub fn new(context: SandboxContext) -> Result<Self> {\n        Ok(Self {\n            context,\n            violations: Vec::new(),\n            current_usage: Arc::new(RwLock::new(ResourceUsage::default())),\n            monitoring_active: Arc::new(RwLock::new(false)),\n            start_time: Instant::now(),\n        })\n    }\n\n    /// Start resource monitoring\n    pub async fn start(&mut self) -> Result<()> {\n        {\n            let mut active = self.monitoring_active.write().await;\n            *active = true;\n        }\n\n        self.start_time = Instant::now();\n        debug!(\n            \"Resource monitoring started for sandbox: {}\",\n            self.context.id\n        );\n\n        // Start background monitoring task\n        let usage = Arc::clone(&self.current_usage);\n        let active = Arc::clone(&self.monitoring_active);\n        let resource_limits = self.context.resource_limits.clone();\n        let violations = Arc::new(RwLock::new(Vec::new()));\n        let violations_clone = Arc::clone(&violations);\n\n        tokio::spawn(async move {\n            let mut interval = interval(Duration::from_millis(100)); // Monitor every 100ms\n\n            while *active.read().await {\n                interval.tick().await;\n\n                // Update resource usage\n                let new_usage = Self::collect_system_usage().await;\n                {\n                    let mut current = usage.write().await;\n                    *current = new_usage;\n                }\n\n                // Check limits\n                let current = usage.read().await;\n                let mut viols = violations_clone.write().await;\n\n                if let Some(limit) = resource_limits.max_memory_bytes {\n                    if current.memory_bytes > limit {\n                        viols.push(SandboxViolation::ResourceLimit {\n                            resource: \"memory\".to_string(),\n                            limit,\n                            actual: current.memory_bytes,\n                            reason: \"Memory usage exceeded limit\".to_string(),\n                        });\n                    }\n                }\n\n                if let Some(limit) = resource_limits.max_cpu_time_ms {\n                    if current.cpu_time_ms > limit {\n                        viols.push(SandboxViolation::ResourceLimit {\n                            resource: \"cpu_time\".to_string(),\n                            limit,\n                            actual: current.cpu_time_ms,\n                            reason: \"CPU time exceeded limit\".to_string(),\n                        });\n                    }\n                }\n\n                if let Some(limit) = resource_limits.max_file_ops_per_sec {\n                    let ops_per_sec = current.file_operations as f64\n                        / current.timestamp.elapsed().as_secs_f64().max(1.0);\n                    if ops_per_sec > limit as f64 {\n                        viols.push(SandboxViolation::ResourceLimit {\n                            resource: \"file_operations\".to_string(),\n                            limit: limit as u64,\n                            actual: ops_per_sec as u64,\n                            reason: \"File operations per second exceeded limit\".to_string(),\n                        });\n                    }\n                }\n            }\n        });\n\n        Ok(())\n    }\n\n    /// Stop resource monitoring\n    pub async fn stop(&mut self) -> Result<()> {\n        {\n            let mut active = self.monitoring_active.write().await;\n            *active = false;\n        }\n\n        debug!(\n            \"Resource monitoring stopped for sandbox: {}\",\n            self.context.id\n        );\n        Ok(())\n    }\n\n    /// Check if monitoring is active\n    pub async fn is_monitoring(&self) -> bool {\n        *self.monitoring_active.read().await\n    }\n\n    /// Get current resource usage\n    pub async fn get_current_usage(&self) -> ResourceUsage {\n        self.current_usage.read().await.clone()\n    }\n\n    /// Record network usage\n    pub async fn record_network_usage(&self, bytes: u64) -> Result<()> {\n        {\n            let mut usage = self.current_usage.write().await;\n            usage.network_bytes += bytes;\n            usage.timestamp = Instant::now();\n        }\n\n        // Check network bandwidth limit\n        if let Some(limit) = self.context.resource_limits.max_network_bps {\n            let usage = self.current_usage.read().await;\n            let duration = self.start_time.elapsed().as_secs_f64().max(1.0);\n            let bps = usage.network_bytes as f64 / duration;\n\n            if bps > limit as f64 {\n                let violation = SandboxViolation::ResourceLimit {\n                    resource: \"network_bandwidth\".to_string(),\n                    limit,\n                    actual: bps as u64,\n                    reason: \"Network bandwidth exceeded limit\".to_string(),\n                };\n                warn!(\"Resource violation: {}\", violation);\n                return Err(LLMSpellError::Security {\n                    message: violation.to_string(),\n                    violation_type: Some(\"resource_limit\".to_string()),\n                });\n            }\n        }\n\n        Ok(())\n    }\n\n    /// Record file operation\n    pub async fn record_file_operation(&self) -> Result<()> {\n        {\n            let mut usage = self.current_usage.write().await;\n            usage.file_operations += 1;\n            usage.timestamp = Instant::now();\n        }\n\n        // Check file operations per second limit\n        if let Some(limit) = self.context.resource_limits.max_file_ops_per_sec {\n            let usage = self.current_usage.read().await;\n            let duration = self.start_time.elapsed().as_secs_f64().max(1.0);\n            let ops_per_sec = usage.file_operations as f64 / duration;\n\n            if ops_per_sec > limit as f64 {\n                let violation = SandboxViolation::ResourceLimit {\n                    resource: \"file_operations\".to_string(),\n                    limit: limit as u64,\n                    actual: ops_per_sec as u64,\n                    reason: \"File operations per second exceeded limit\".to_string(),\n                };\n                warn!(\"Resource violation: {}\", violation);\n                return Err(LLMSpellError::Security {\n                    message: violation.to_string(),\n                    violation_type: Some(\"resource_limit\".to_string()),\n                });\n            }\n        }\n\n        Ok(())\n    }\n\n    /// Record custom resource usage\n    pub async fn record_custom_usage(&self, resource: &str, amount: u64) -> Result<()> {\n        {\n            let mut usage = self.current_usage.write().await;\n            *usage.custom_usage.entry(resource.to_string()).or_insert(0) += amount;\n            usage.timestamp = Instant::now();\n        }\n\n        // Check custom resource limits\n        if let Some(limit) = self.context.resource_limits.custom_limits.get(resource) {\n            let usage = self.current_usage.read().await;\n            if let Some(current) = usage.custom_usage.get(resource) {\n                if *current > *limit {\n                    let violation = SandboxViolation::ResourceLimit {\n                        resource: resource.to_string(),\n                        limit: *limit,\n                        actual: *current,\n                        reason: format!(\"Custom resource '{}' exceeded limit\", resource),\n                    };\n                    warn!(\"Resource violation: {}\", violation);\n                    return Err(LLMSpellError::Security {\n                        message: violation.to_string(),\n                        violation_type: Some(\"resource_limit\".to_string()),\n                    });\n                }\n            }\n        }\n\n        Ok(())\n    }\n\n    /// Collect system resource usage (simplified implementation)\n    async fn collect_system_usage() -> ResourceUsage {\n        // In a real implementation, this would use system APIs to get actual usage\n        // For testing, we'll simulate some usage\n        let now = Instant::now();\n\n        ResourceUsage {\n            memory_bytes: (now.elapsed().as_secs() * 1024 * 1024).min(50 * 1024 * 1024),\n            cpu_time_ms: now.elapsed().as_millis() as u64 / 10,\n            network_bytes: 0,\n            file_operations: 0,\n            custom_usage: HashMap::new(),\n            timestamp: now,\n        }\n    }\n\n    /// Check if any violations occurred\n    pub async fn has_violations(&self) -> bool {\n        !self.violations.is_empty()\n    }\n\n    /// Get all violations\n    pub async fn get_violations(&self) -> Vec<String> {\n        self.violations.iter().map(|v| v.to_string()).collect()\n    }\n\n    /// Get detailed resource statistics\n    pub async fn get_resource_stats(&self) -> ResourceStats {\n        let usage = self.current_usage.read().await;\n        let elapsed = self.start_time.elapsed();\n\n        ResourceStats {\n            current_usage: usage.clone(),\n            limits: self.context.resource_limits.clone(),\n            uptime_seconds: elapsed.as_secs(),\n            violations_count: self.violations.len(),\n            efficiency_metrics: EfficiencyMetrics {\n                memory_efficiency: self.calculate_memory_efficiency(&usage).await,\n                cpu_efficiency: self.calculate_cpu_efficiency(&usage).await,\n                network_efficiency: self.calculate_network_efficiency(&usage).await,\n            },\n        }\n    }\n\n    /// Calculate memory efficiency (0.0 to 1.0)\n    async fn calculate_memory_efficiency(&self, usage: &ResourceUsage) -> f64 {\n        if let Some(limit) = self.context.resource_limits.max_memory_bytes {\n            1.0 - (usage.memory_bytes as f64 / limit as f64).min(1.0)\n        } else {\n            1.0 // No limit means perfect efficiency\n        }\n    }\n\n    /// Calculate CPU efficiency (0.0 to 1.0)\n    async fn calculate_cpu_efficiency(&self, usage: &ResourceUsage) -> f64 {\n        if let Some(limit) = self.context.resource_limits.max_cpu_time_ms {\n            1.0 - (usage.cpu_time_ms as f64 / limit as f64).min(1.0)\n        } else {\n            1.0\n        }\n    }\n\n    /// Calculate network efficiency (0.0 to 1.0)\n    async fn calculate_network_efficiency(&self, usage: &ResourceUsage) -> f64 {\n        if let Some(limit) = self.context.resource_limits.max_network_bps {\n            let duration = self.start_time.elapsed().as_secs_f64().max(1.0);\n            let actual_bps = usage.network_bytes as f64 / duration;\n            1.0 - (actual_bps / limit as f64).min(1.0)\n        } else {\n            1.0\n        }\n    }\n\n    /// Reset resource counters\n    pub async fn reset_counters(&mut self) -> Result<()> {\n        {\n            let mut usage = self.current_usage.write().await;\n            *usage = ResourceUsage::default();\n        }\n        self.start_time = Instant::now();\n        self.violations.clear();\n        Ok(())\n    }\n}\n\n/// Resource statistics\n#[derive(Debug)]\npub struct ResourceStats {\n    pub current_usage: ResourceUsage,\n    pub limits: llmspell_core::traits::tool::ResourceLimits,\n    pub uptime_seconds: u64,\n    pub violations_count: usize,\n    pub efficiency_metrics: EfficiencyMetrics,\n}\n\n/// Efficiency metrics\n#[derive(Debug)]\npub struct EfficiencyMetrics {\n    pub memory_efficiency: f64,\n    pub cpu_efficiency: f64,\n    pub network_efficiency: f64,\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use llmspell_core::traits::tool::{ResourceLimits, SecurityRequirements};\n\n    fn create_test_monitor() -> ResourceMonitor {\n        let security_reqs = SecurityRequirements::safe();\n        let resource_limits = ResourceLimits::strict();\n\n        let context =\n            SandboxContext::new(\"test-monitor\".to_string(), security_reqs, resource_limits);\n\n        ResourceMonitor::new(context).unwrap()\n    }\n\n    #[tokio::test]\n    async fn test_monitor_lifecycle() {\n        let mut monitor = create_test_monitor();\n\n        // Start monitoring\n        assert!(monitor.start().await.is_ok());\n        assert!(monitor.is_monitoring().await);\n\n        // Stop monitoring\n        assert!(monitor.stop().await.is_ok());\n        assert!(!monitor.is_monitoring().await);\n    }\n\n    #[tokio::test]\n    async fn test_usage_recording() {\n        let monitor = create_test_monitor();\n\n        // Record network usage\n        assert!(monitor.record_network_usage(1024).await.is_ok());\n\n        // Record file operation\n        assert!(monitor.record_file_operation().await.is_ok());\n\n        // Record custom usage\n        assert!(monitor.record_custom_usage(\"api_calls\", 5).await.is_ok());\n\n        // Check usage\n        let usage = monitor.get_current_usage().await;\n        assert_eq!(usage.network_bytes, 1024);\n        assert_eq!(usage.file_operations, 1);\n        assert_eq!(usage.custom_usage.get(\"api_calls\"), Some(&5));\n    }\n\n    #[tokio::test]\n    async fn test_resource_stats() {\n        let monitor = create_test_monitor();\n\n        // Record some usage\n        let _ = monitor.record_network_usage(512).await;\n        let _ = monitor.record_file_operation().await;\n\n        let stats = monitor.get_resource_stats().await;\n        assert_eq!(stats.current_usage.network_bytes, 512);\n        assert_eq!(stats.current_usage.file_operations, 1);\n        assert!(stats.efficiency_metrics.memory_efficiency >= 0.0);\n        assert!(stats.efficiency_metrics.memory_efficiency <= 1.0);\n    }\n\n    #[tokio::test]\n    async fn test_counter_reset() {\n        let mut monitor = create_test_monitor();\n\n        // Record some usage\n        let _ = monitor.record_network_usage(1024).await;\n        let _ = monitor.record_file_operation().await;\n\n        // Reset counters\n        assert!(monitor.reset_counters().await.is_ok());\n\n        // Check that usage is reset\n        let usage = monitor.get_current_usage().await;\n        assert_eq!(usage.network_bytes, 0);\n        assert_eq!(usage.file_operations, 0);\n    }\n\n    #[tokio::test]\n    async fn test_limit_enforcement() {\n        let security_reqs = SecurityRequirements::safe();\n        let resource_limits = ResourceLimits::strict().with_network_limit(512); // Very low limit\n\n        let context = SandboxContext::new(\"test-limit\".to_string(), security_reqs, resource_limits);\n\n        let monitor = ResourceMonitor::new(context).unwrap();\n\n        // This should exceed the network limit\n        let result = monitor.record_network_usage(1024).await;\n        assert!(result.is_err());\n\n        // Should be a security violation\n        match result.unwrap_err() {\n            LLMSpellError::Security { violation_type, .. } => {\n                assert_eq!(violation_type, Some(\"resource_limit\".to_string()));\n            }\n            _ => panic!(\"Expected SecurityViolation\"),\n        }\n    }\n}\n","traces":[{"line":31,"address":[],"length":0,"stats":{"Line":6}},{"line":37,"address":[],"length":0,"stats":{"Line":6}},{"line":38,"address":[],"length":0,"stats":{"Line":6}},{"line":54,"address":[],"length":0,"stats":{"Line":5}},{"line":55,"address":[],"length":0,"stats":{"Line":5}},{"line":56,"address":[],"length":0,"stats":{"Line":5}},{"line":57,"address":[],"length":0,"stats":{"Line":5}},{"line":58,"address":[],"length":0,"stats":{"Line":5}},{"line":59,"address":[],"length":0,"stats":{"Line":5}},{"line":60,"address":[],"length":0,"stats":{"Line":5}},{"line":65,"address":[],"length":0,"stats":{"Line":2}},{"line":67,"address":[],"length":0,"stats":{"Line":2}},{"line":68,"address":[],"length":0,"stats":{"Line":1}},{"line":71,"address":[],"length":0,"stats":{"Line":1}},{"line":72,"address":[],"length":0,"stats":{"Line":1}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":1}},{"line":79,"address":[],"length":0,"stats":{"Line":1}},{"line":80,"address":[],"length":0,"stats":{"Line":1}},{"line":81,"address":[],"length":0,"stats":{"Line":1}},{"line":82,"address":[],"length":0,"stats":{"Line":1}},{"line":84,"address":[],"length":0,"stats":{"Line":1}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":1}},{"line":142,"address":[],"length":0,"stats":{"Line":2}},{"line":144,"address":[],"length":0,"stats":{"Line":2}},{"line":145,"address":[],"length":0,"stats":{"Line":1}},{"line":148,"address":[],"length":0,"stats":{"Line":1}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":1}},{"line":156,"address":[],"length":0,"stats":{"Line":4}},{"line":157,"address":[],"length":0,"stats":{"Line":2}},{"line":161,"address":[],"length":0,"stats":{"Line":4}},{"line":162,"address":[],"length":0,"stats":{"Line":4}},{"line":166,"address":[],"length":0,"stats":{"Line":8}},{"line":168,"address":[],"length":0,"stats":{"Line":8}},{"line":169,"address":[],"length":0,"stats":{"Line":4}},{"line":170,"address":[],"length":0,"stats":{"Line":4}},{"line":174,"address":[],"length":0,"stats":{"Line":8}},{"line":175,"address":[],"length":0,"stats":{"Line":4}},{"line":176,"address":[],"length":0,"stats":{"Line":4}},{"line":177,"address":[],"length":0,"stats":{"Line":4}},{"line":179,"address":[],"length":0,"stats":{"Line":4}},{"line":181,"address":[],"length":0,"stats":{"Line":1}},{"line":183,"address":[],"length":0,"stats":{"Line":1}},{"line":184,"address":[],"length":0,"stats":{"Line":1}},{"line":186,"address":[],"length":0,"stats":{"Line":1}},{"line":187,"address":[],"length":0,"stats":{"Line":1}},{"line":188,"address":[],"length":0,"stats":{"Line":1}},{"line":189,"address":[],"length":0,"stats":{"Line":1}},{"line":194,"address":[],"length":0,"stats":{"Line":3}},{"line":198,"address":[],"length":0,"stats":{"Line":6}},{"line":200,"address":[],"length":0,"stats":{"Line":6}},{"line":201,"address":[],"length":0,"stats":{"Line":3}},{"line":202,"address":[],"length":0,"stats":{"Line":3}},{"line":206,"address":[],"length":0,"stats":{"Line":6}},{"line":207,"address":[],"length":0,"stats":{"Line":3}},{"line":208,"address":[],"length":0,"stats":{"Line":3}},{"line":209,"address":[],"length":0,"stats":{"Line":3}},{"line":211,"address":[],"length":0,"stats":{"Line":3}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":221,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":3}},{"line":230,"address":[],"length":0,"stats":{"Line":2}},{"line":232,"address":[],"length":0,"stats":{"Line":2}},{"line":233,"address":[],"length":0,"stats":{"Line":1}},{"line":234,"address":[],"length":0,"stats":{"Line":1}},{"line":238,"address":[],"length":0,"stats":{"Line":1}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":1}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":2}},{"line":288,"address":[],"length":0,"stats":{"Line":2}},{"line":289,"address":[],"length":0,"stats":{"Line":1}},{"line":292,"address":[],"length":0,"stats":{"Line":1}},{"line":293,"address":[],"length":0,"stats":{"Line":1}},{"line":294,"address":[],"length":0,"stats":{"Line":1}},{"line":295,"address":[],"length":0,"stats":{"Line":1}},{"line":296,"address":[],"length":0,"stats":{"Line":1}},{"line":305,"address":[],"length":0,"stats":{"Line":2}},{"line":306,"address":[],"length":0,"stats":{"Line":2}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":2}},{"line":315,"address":[],"length":0,"stats":{"Line":2}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":323,"address":[],"length":0,"stats":{"Line":2}},{"line":324,"address":[],"length":0,"stats":{"Line":2}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":334,"address":[],"length":0,"stats":{"Line":2}},{"line":336,"address":[],"length":0,"stats":{"Line":2}}],"covered":80,"coverable":141},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-storage","src","lib.rs"],"content":"//! ABOUTME: llmspell-storage implementation crate\n//! ABOUTME: Foundation stub for future implementation\n\n// Module stub - to be implemented in later phases\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-testing","src","benchmarks.rs"],"content":"//! ABOUTME: Benchmark helpers and utilities for criterion performance testing\n//! ABOUTME: Provides common benchmark scenarios and measurement helpers\n\n//! Performance benchmarking utilities.\n//!\n//! This module provides helpers for creating criterion benchmarks\n//! to measure the performance of LLMSpell components.\n//!\n//! # Examples\n//!\n//! ```rust,ignore\n//! use criterion::{criterion_group, criterion_main, Criterion};\n//! use llmspell_testing::benchmarks::{bench_trait_dispatch, bench_serialization};\n//!\n//! fn my_benchmarks(c: &mut Criterion) {\n//!     bench_trait_dispatch(c);\n//!     bench_serialization(c);\n//! }\n//!\n//! criterion_group!(benches, my_benchmarks);\n//! criterion_main!(benches);\n//! ```\n\nuse criterion::{black_box, BenchmarkId, Criterion};\nuse llmspell_core::{types::AgentInput, ComponentId, ComponentMetadata, Version};\nuse std::time::Duration;\n\n/// Benchmark trait method dispatch overhead\npub fn bench_trait_dispatch(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"trait_dispatch\");\n\n    // Direct function call baseline\n    group.bench_function(\"direct_call\", |b| {\n        b.iter(|| {\n            let result = direct_function_call(black_box(\"test\"));\n            black_box(result)\n        });\n    });\n\n    // TODO: Add trait dispatch benchmark when implementations are available\n\n    group.finish();\n}\n\n/// Benchmark ComponentId generation\npub fn bench_component_id_generation(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"component_id\");\n\n    group.bench_function(\"new_uuid_v4\", |b| {\n        b.iter(|| {\n            let id = ComponentId::new();\n            black_box(id)\n        });\n    });\n\n    group.bench_function(\"from_name\", |b| {\n        let name = \"test-component-name\";\n        b.iter(|| {\n            let id = ComponentId::from_name(black_box(name));\n            black_box(id)\n        });\n    });\n\n    group.finish();\n}\n\n/// Benchmark serialization performance\npub fn bench_serialization(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"serialization\");\n\n    // ComponentMetadata serialization\n    let metadata = ComponentMetadata::new(\n        \"test-component\".to_string(),\n        \"A test component for benchmarking\".to_string(),\n    );\n\n    group.bench_function(\"metadata_to_json\", |b| {\n        b.iter(|| {\n            let json = serde_json::to_string(black_box(&metadata)).unwrap();\n            black_box(json)\n        });\n    });\n\n    let json = serde_json::to_string(&metadata).unwrap();\n    group.bench_function(\"metadata_from_json\", |b| {\n        b.iter(|| {\n            let parsed: ComponentMetadata = serde_json::from_str(black_box(&json)).unwrap();\n            black_box(parsed)\n        });\n    });\n\n    // AgentInput serialization with varying sizes\n    for size in [10, 100, 1000].iter() {\n        let input = AgentInput::text(\"x\".repeat(*size));\n\n        group.bench_with_input(\n            BenchmarkId::new(\"agent_input_to_json\", size),\n            size,\n            |b, _| {\n                b.iter(|| {\n                    let json = serde_json::to_string(black_box(&input)).unwrap();\n                    black_box(json)\n                });\n            },\n        );\n    }\n\n    group.finish();\n}\n\n/// Benchmark error creation and handling\npub fn bench_error_handling(c: &mut Criterion) {\n    use llmspell_core::LLMSpellError;\n\n    let mut group = c.benchmark_group(\"error_handling\");\n\n    group.bench_function(\"error_creation\", |b| {\n        b.iter(|| {\n            let error = LLMSpellError::Component {\n                message: \"Test error\".to_string(),\n                source: None,\n            };\n            black_box(error)\n        });\n    });\n\n    group.bench_function(\"error_with_source\", |b| {\n        b.iter(|| {\n            let error = LLMSpellError::Storage {\n                message: \"Storage error\".to_string(),\n                operation: Some(\"read\".to_string()),\n                source: None,\n            };\n            black_box(error)\n        });\n    });\n\n    group.finish();\n}\n\n/// Benchmark Version comparison operations\npub fn bench_version_operations(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"version_operations\");\n\n    let v1 = Version {\n        major: 1,\n        minor: 2,\n        patch: 3,\n    };\n    let v2 = Version {\n        major: 1,\n        minor: 2,\n        patch: 4,\n    };\n    let _v3 = Version {\n        major: 2,\n        minor: 0,\n        patch: 0,\n    };\n\n    group.bench_function(\"version_comparison\", |b| {\n        b.iter(|| {\n            let result = black_box(&v1) < black_box(&v2);\n            black_box(result)\n        });\n    });\n\n    group.bench_function(\"version_is_compatible\", |b| {\n        b.iter(|| {\n            let result = black_box(&v1).is_compatible_with(black_box(&v2));\n            black_box(result)\n        });\n    });\n\n    group.finish();\n}\n\n/// Helper function for measuring async operations\npub async fn measure_async_operation<F, Fut, T>(operation: F) -> (T, Duration)\nwhere\n    F: FnOnce() -> Fut,\n    Fut: std::future::Future<Output = T>,\n{\n    let start = std::time::Instant::now();\n    let result = operation().await;\n    let duration = start.elapsed();\n    (result, duration)\n}\n\n/// Create a standard benchmark configuration\npub fn standard_benchmark_config() -> Criterion {\n    Criterion::default()\n        .sample_size(100)\n        .measurement_time(Duration::from_secs(10))\n        .warm_up_time(Duration::from_secs(3))\n}\n\n// Helper function for baseline comparison\nfn direct_function_call(input: &str) -> String {\n    format!(\"Processed: {}\", input)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_component_id_benchmark_data() {\n        // Ensure benchmark data generation works\n        let id = ComponentId::new();\n        let _ = id; // Just verify it was created\n\n        let id_from_name = ComponentId::from_name(\"test\");\n        let id_from_name2 = ComponentId::from_name(\"test\");\n        assert_eq!(id_from_name, id_from_name2); // Same name produces same ID\n    }\n\n    #[test]\n    fn test_serialization_benchmark_data() {\n        let metadata = ComponentMetadata::new(\"test\".to_string(), \"description\".to_string());\n\n        let json = serde_json::to_string(&metadata).unwrap();\n        assert!(!json.is_empty());\n\n        let parsed: ComponentMetadata = serde_json::from_str(&json).unwrap();\n        assert_eq!(parsed.name, \"test\");\n    }\n\n    #[tokio::test]\n    async fn test_async_measurement() {\n        let (result, duration) = measure_async_operation(|| async {\n            tokio::time::sleep(Duration::from_millis(10)).await;\n            42\n        })\n        .await;\n\n        assert_eq!(result, 42);\n        assert!(duration >= Duration::from_millis(10));\n    }\n}\n","traces":[{"line":29,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":1}},{"line":184,"address":[],"length":0,"stats":{"Line":1}},{"line":185,"address":[],"length":0,"stats":{"Line":2}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}}],"covered":3,"coverable":80},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-testing","src","fixtures.rs"],"content":"//! ABOUTME: Common test fixtures and data for consistent testing\n//! ABOUTME: Provides pre-configured test objects and sample data\n\n//! Test fixtures and common test data.\n//!\n//! This module provides pre-configured test objects and sample data\n//! that can be used across different test suites for consistency.\n//!\n//! # Examples\n//!\n//! ```rust\n//! use llmspell_testing::fixtures::{\n//!     sample_component_metadata,\n//!     sample_agent_input,\n//!     sample_workflow_steps,\n//! };\n//!\n//! // Use pre-configured test data\n//! let metadata = sample_component_metadata();\n//! assert_eq!(metadata.name, \"test-component\");\n//!\n//! let input = sample_agent_input();\n//! assert_eq!(input.text, \"Test prompt\");\n//! ```\n\nuse llmspell_core::{\n    traits::{\n        agent::{AgentConfig, ConversationMessage},\n        tool::ToolSchema,\n        workflow::{RetryPolicy, WorkflowConfig, WorkflowStep},\n    },\n    types::{AgentInput, ExecutionContext},\n    ComponentId, ComponentMetadata, Version,\n};\n\n#[cfg(test)]\nuse llmspell_core::traits::agent::MessageRole;\nuse serde_json::json;\nuse std::time::Duration;\n\n/// Sample ComponentMetadata for testing\npub fn sample_component_metadata() -> ComponentMetadata {\n    let mut metadata = ComponentMetadata::new(\n        \"test-component\".to_string(),\n        \"A test component for unit testing\".to_string(),\n    );\n    metadata.version = Version {\n        major: 1,\n        minor: 0,\n        patch: 0,\n    };\n    metadata\n}\n\n/// Sample ComponentMetadata variants for different scenarios\npub fn component_metadata_variants() -> Vec<ComponentMetadata> {\n    vec![\n        // Minimal metadata\n        ComponentMetadata::new(\n            \"minimal-component\".to_string(),\n            \"Minimal test component\".to_string(),\n        ),\n        // Full metadata\n        sample_component_metadata(),\n        // Version 2.0 component\n        {\n            let mut metadata = ComponentMetadata::new(\n                \"v2-component\".to_string(),\n                \"Version 2 test component\".to_string(),\n            );\n            metadata.version = Version {\n                major: 2,\n                minor: 0,\n                patch: 0,\n            };\n            metadata\n        },\n    ]\n}\n\n/// Sample AgentInput for testing\npub fn sample_agent_input() -> AgentInput {\n    AgentInput::text(\"Test prompt\")\n        .with_parameter(\"user_id\", json!(\"test-user\"))\n        .with_parameter(\"session\", json!(\"test-session\"))\n}\n\n/// Sample AgentInput variants\npub fn agent_input_variants() -> Vec<AgentInput> {\n    vec![\n        // Simple input\n        AgentInput::text(\"Simple prompt\"),\n        // Input with context\n        sample_agent_input(),\n        // Complex input\n        AgentInput::text(\"Complex prompt with lots of detail\")\n            .with_parameter(\"history\", json!([\"previous\", \"messages\"]))\n            .with_parameter(\"temperature\", json!(0.7))\n            .with_parameter(\"max_tokens\", json!(100))\n            .with_parameter(\"priority\", json!(\"high\"))\n            .with_parameter(\"timestamp\", json!(1234567890)),\n    ]\n}\n\n/// Sample ExecutionContext for testing\npub fn sample_execution_context() -> ExecutionContext {\n    ExecutionContext::with_conversation(\"test-session-123\".to_string())\n        .with_data(\"user_id\".to_string(), json!(\"test-user\"))\n        .with_data(\"LLMSPELL_ENV\".to_string(), json!(\"test\"))\n}\n\n/// Sample conversation for Agent testing\npub fn sample_conversation() -> Vec<ConversationMessage> {\n    vec![\n        ConversationMessage::system(\"You are a helpful assistant for testing.\".to_string()),\n        ConversationMessage::user(\"Hello, how are you?\".to_string()),\n        ConversationMessage::assistant(\n            \"I'm doing well, thank you! How can I help you today?\".to_string(),\n        ),\n        ConversationMessage::user(\"Can you help me test something?\".to_string()),\n        ConversationMessage::assistant(\"Of course! I'd be happy to help you test.\".to_string()),\n    ]\n}\n\n/// Sample AgentConfig for testing\npub fn sample_agent_config() -> AgentConfig {\n    AgentConfig {\n        max_conversation_length: Some(100),\n        system_prompt: Some(\"You are a test assistant.\".to_string()),\n        temperature: Some(0.7),\n        max_tokens: Some(500),\n    }\n}\n\n/// Sample ToolSchema for testing\npub fn sample_tool_schema() -> ToolSchema {\n    use llmspell_core::traits::tool::{ParameterDef, ParameterType};\n\n    ToolSchema::new(\n        \"process_data\".to_string(),\n        \"Process data with various options\".to_string(),\n    )\n    .with_parameter(ParameterDef {\n        name: \"input\".to_string(),\n        param_type: ParameterType::String,\n        description: \"The input to process\".to_string(),\n        required: true,\n        default: None,\n    })\n    .with_parameter(ParameterDef {\n        name: \"format\".to_string(),\n        param_type: ParameterType::String,\n        description: \"Output format\".to_string(),\n        required: false,\n        default: Some(json!(\"json\")),\n    })\n    .with_parameter(ParameterDef {\n        name: \"verbose\".to_string(),\n        param_type: ParameterType::Boolean,\n        description: \"Verbose output\".to_string(),\n        required: false,\n        default: Some(json!(false)),\n    })\n    .with_returns(ParameterType::Object)\n}\n\n/// Sample workflow steps for testing\npub fn sample_workflow_steps() -> Vec<WorkflowStep> {\n    let step1_id = ComponentId::from_name(\"step-1\");\n    let step2_id = ComponentId::from_name(\"step-2\");\n    let step3_id = ComponentId::from_name(\"step-3\");\n\n    vec![\n        WorkflowStep {\n            id: step1_id,\n            name: \"Initialize\".to_string(),\n            component_id: ComponentId::from_name(\"init-agent\"),\n            dependencies: vec![],\n            retry_policy: Some(RetryPolicy::default()),\n            timeout: Some(Duration::from_secs(30)),\n        },\n        WorkflowStep {\n            id: step2_id,\n            name: \"Process Data\".to_string(),\n            component_id: ComponentId::from_name(\"processor-agent\"),\n            dependencies: vec![step1_id],\n            retry_policy: Some(RetryPolicy {\n                max_attempts: 5,\n                backoff_seconds: 2,\n                exponential_backoff: true,\n            }),\n            timeout: Some(Duration::from_secs(120)),\n        },\n        WorkflowStep {\n            id: step3_id,\n            name: \"Generate Report\".to_string(),\n            component_id: ComponentId::from_name(\"reporter-agent\"),\n            dependencies: vec![step2_id],\n            retry_policy: None,\n            timeout: Some(Duration::from_secs(60)),\n        },\n    ]\n}\n\n/// Sample WorkflowConfig for testing\npub fn sample_workflow_config() -> WorkflowConfig {\n    WorkflowConfig {\n        max_parallel: Some(3),\n        continue_on_error: false,\n        timeout: Some(Duration::from_secs(600)),\n    }\n}\n\n/// Create test error scenarios\npub fn error_scenarios() -> Vec<llmspell_core::LLMSpellError> {\n    use llmspell_core::LLMSpellError;\n\n    vec![\n        // Component error\n        LLMSpellError::Component {\n            message: \"Component initialization failed\".to_string(),\n            source: None,\n        },\n        // Validation error\n        LLMSpellError::Validation {\n            message: \"Invalid input format\".to_string(),\n            field: Some(\"email\".to_string()),\n        },\n        // Network error (retryable)\n        LLMSpellError::Network {\n            message: \"Connection timeout\".to_string(),\n            source: None,\n        },\n        // Storage error\n        LLMSpellError::Storage {\n            message: \"Database connection failed\".to_string(),\n            operation: Some(\"read\".to_string()),\n            source: None,\n        },\n    ]\n}\n\n/// Create a test environment setup\npub fn setup_test_environment() -> std::collections::HashMap<String, String> {\n    let mut env = std::collections::HashMap::new();\n    env.insert(\"LLMSPELL_ENV\".to_string(), \"test\".to_string());\n    env.insert(\"LLMSPELL_LOG_LEVEL\".to_string(), \"debug\".to_string());\n    env.insert(\"LLMSPELL_LOG_FORMAT\".to_string(), \"json\".to_string());\n    env\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_sample_fixtures() {\n        // Test metadata fixture\n        let metadata = sample_component_metadata();\n        assert_eq!(metadata.name, \"test-component\");\n        assert_eq!(metadata.version.major, 1);\n\n        // Test input fixture\n        let input = sample_agent_input();\n        assert_eq!(input.text, \"Test prompt\");\n        assert!(!input.parameters.is_empty());\n\n        // Test conversation fixture\n        let conversation = sample_conversation();\n        assert_eq!(conversation.len(), 5);\n        assert_eq!(conversation[0].role, MessageRole::System);\n\n        // Test workflow steps\n        let steps = sample_workflow_steps();\n        assert_eq!(steps.len(), 3);\n        assert_eq!(steps[1].dependencies.len(), 1);\n    }\n\n    #[test]\n    fn test_fixture_variants() {\n        let metadata_variants = component_metadata_variants();\n        assert_eq!(metadata_variants.len(), 3);\n\n        let input_variants = agent_input_variants();\n        assert_eq!(input_variants.len(), 3);\n\n        let errors = error_scenarios();\n        assert!(errors.len() >= 4);\n    }\n}\n","traces":[{"line":42,"address":[],"length":0,"stats":{"Line":2}},{"line":44,"address":[],"length":0,"stats":{"Line":2}},{"line":45,"address":[],"length":0,"stats":{"Line":2}},{"line":47,"address":[],"length":0,"stats":{"Line":2}},{"line":48,"address":[],"length":0,"stats":{"Line":2}},{"line":49,"address":[],"length":0,"stats":{"Line":2}},{"line":50,"address":[],"length":0,"stats":{"Line":2}},{"line":52,"address":[],"length":0,"stats":{"Line":2}},{"line":56,"address":[],"length":0,"stats":{"Line":1}},{"line":57,"address":[],"length":0,"stats":{"Line":1}},{"line":59,"address":[],"length":0,"stats":{"Line":1}},{"line":60,"address":[],"length":0,"stats":{"Line":1}},{"line":61,"address":[],"length":0,"stats":{"Line":1}},{"line":64,"address":[],"length":0,"stats":{"Line":1}},{"line":67,"address":[],"length":0,"stats":{"Line":1}},{"line":68,"address":[],"length":0,"stats":{"Line":1}},{"line":69,"address":[],"length":0,"stats":{"Line":1}},{"line":71,"address":[],"length":0,"stats":{"Line":1}},{"line":72,"address":[],"length":0,"stats":{"Line":1}},{"line":73,"address":[],"length":0,"stats":{"Line":1}},{"line":74,"address":[],"length":0,"stats":{"Line":1}},{"line":76,"address":[],"length":0,"stats":{"Line":1}},{"line":82,"address":[],"length":0,"stats":{"Line":2}},{"line":83,"address":[],"length":0,"stats":{"Line":2}},{"line":84,"address":[],"length":0,"stats":{"Line":2}},{"line":85,"address":[],"length":0,"stats":{"Line":2}},{"line":89,"address":[],"length":0,"stats":{"Line":1}},{"line":90,"address":[],"length":0,"stats":{"Line":1}},{"line":92,"address":[],"length":0,"stats":{"Line":1}},{"line":94,"address":[],"length":0,"stats":{"Line":1}},{"line":96,"address":[],"length":0,"stats":{"Line":1}},{"line":97,"address":[],"length":0,"stats":{"Line":1}},{"line":98,"address":[],"length":0,"stats":{"Line":1}},{"line":99,"address":[],"length":0,"stats":{"Line":1}},{"line":100,"address":[],"length":0,"stats":{"Line":1}},{"line":101,"address":[],"length":0,"stats":{"Line":1}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":1}},{"line":114,"address":[],"length":0,"stats":{"Line":1}},{"line":115,"address":[],"length":0,"stats":{"Line":1}},{"line":116,"address":[],"length":0,"stats":{"Line":1}},{"line":117,"address":[],"length":0,"stats":{"Line":1}},{"line":118,"address":[],"length":0,"stats":{"Line":1}},{"line":120,"address":[],"length":0,"stats":{"Line":1}},{"line":121,"address":[],"length":0,"stats":{"Line":1}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":1}},{"line":169,"address":[],"length":0,"stats":{"Line":1}},{"line":170,"address":[],"length":0,"stats":{"Line":1}},{"line":171,"address":[],"length":0,"stats":{"Line":1}},{"line":173,"address":[],"length":0,"stats":{"Line":1}},{"line":174,"address":[],"length":0,"stats":{"Line":1}},{"line":175,"address":[],"length":0,"stats":{"Line":1}},{"line":176,"address":[],"length":0,"stats":{"Line":1}},{"line":177,"address":[],"length":0,"stats":{"Line":1}},{"line":178,"address":[],"length":0,"stats":{"Line":1}},{"line":179,"address":[],"length":0,"stats":{"Line":1}},{"line":180,"address":[],"length":0,"stats":{"Line":1}},{"line":182,"address":[],"length":0,"stats":{"Line":1}},{"line":183,"address":[],"length":0,"stats":{"Line":1}},{"line":184,"address":[],"length":0,"stats":{"Line":1}},{"line":185,"address":[],"length":0,"stats":{"Line":1}},{"line":186,"address":[],"length":0,"stats":{"Line":1}},{"line":187,"address":[],"length":0,"stats":{"Line":1}},{"line":188,"address":[],"length":0,"stats":{"Line":1}},{"line":189,"address":[],"length":0,"stats":{"Line":1}},{"line":190,"address":[],"length":0,"stats":{"Line":1}},{"line":192,"address":[],"length":0,"stats":{"Line":1}},{"line":194,"address":[],"length":0,"stats":{"Line":1}},{"line":195,"address":[],"length":0,"stats":{"Line":1}},{"line":196,"address":[],"length":0,"stats":{"Line":1}},{"line":197,"address":[],"length":0,"stats":{"Line":1}},{"line":198,"address":[],"length":0,"stats":{"Line":1}},{"line":199,"address":[],"length":0,"stats":{"Line":1}},{"line":200,"address":[],"length":0,"stats":{"Line":1}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":1}},{"line":218,"address":[],"length":0,"stats":{"Line":1}},{"line":220,"address":[],"length":0,"stats":{"Line":1}},{"line":221,"address":[],"length":0,"stats":{"Line":1}},{"line":222,"address":[],"length":0,"stats":{"Line":1}},{"line":225,"address":[],"length":0,"stats":{"Line":1}},{"line":226,"address":[],"length":0,"stats":{"Line":1}},{"line":227,"address":[],"length":0,"stats":{"Line":1}},{"line":230,"address":[],"length":0,"stats":{"Line":1}},{"line":231,"address":[],"length":0,"stats":{"Line":1}},{"line":232,"address":[],"length":0,"stats":{"Line":1}},{"line":235,"address":[],"length":0,"stats":{"Line":1}},{"line":236,"address":[],"length":0,"stats":{"Line":1}},{"line":237,"address":[],"length":0,"stats":{"Line":1}},{"line":238,"address":[],"length":0,"stats":{"Line":1}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":0}}],"covered":88,"coverable":128},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-testing","src","generators.rs"],"content":"//! ABOUTME: Proptest strategies and data generators for property-based testing\n//! ABOUTME: Provides strategies for generating test data for all core types\n\n//! Property-based test generators.\n//!\n//! This module provides proptest strategies for generating test data\n//! for all core types in the LLMSpell framework. These strategies help\n//! test invariants and edge cases.\n//!\n//! # Examples\n//!\n//! ```rust\n//! use proptest::prelude::*;\n//! use llmspell_testing::generators::{component_id_strategy, version_strategy};\n//!\n//! proptest! {\n//!     #[test]\n//!     fn test_component_id_properties(id1 in component_id_strategy(), id2 in component_id_strategy()) {\n//!         // Test that different generated IDs are not equal\n//!         if id1 != id2 {\n//!             assert_ne!(id1, id2);\n//!         }\n//!     }\n//! }\n//! ```\n\nuse llmspell_core::{\n    traits::{\n        agent::{AgentConfig, ConversationMessage, MessageRole},\n        tool::{SecurityLevel, ToolCategory, ToolSchema},\n        workflow::{RetryPolicy, WorkflowConfig, WorkflowStatus, WorkflowStep},\n    },\n    types::{AgentInput, AgentOutput, ExecutionContext},\n    ComponentId, ComponentMetadata, Version,\n};\nuse proptest::prelude::*;\nuse std::time::Duration;\n\n/// Strategy for generating ComponentId values\npub fn component_id_strategy() -> impl Strategy<Value = ComponentId> {\n    \"[a-zA-Z0-9_-]{5,20}\".prop_map(|name| ComponentId::from_name(&name))\n}\n\n/// Strategy for generating ComponentId from a name\npub fn component_id_from_name_strategy() -> impl Strategy<Value = (String, ComponentId)> {\n    \"[a-zA-Z0-9_-]{5,20}\".prop_map(|name| {\n        let id = ComponentId::from_name(&name);\n        (name, id)\n    })\n}\n\n/// Strategy for generating Version values\npub fn version_strategy() -> impl Strategy<Value = Version> {\n    (0u32..100u32, 0u32..100u32, 0u32..1000u32).prop_map(|(major, minor, patch)| Version {\n        major,\n        minor,\n        patch,\n    })\n}\n\n/// Strategy for generating ComponentMetadata\npub fn component_metadata_strategy() -> impl Strategy<Value = ComponentMetadata> {\n    (\"[a-zA-Z][a-zA-Z0-9_-]{2,30}\", \".*\", version_strategy()).prop_map(\n        |(name, description, version)| {\n            let mut metadata = ComponentMetadata::new(name, description);\n            metadata.version = version;\n            metadata\n        },\n    )\n}\n\n/// Strategy for generating simple JSON values\npub fn json_value_strategy() -> impl Strategy<Value = serde_json::Value> {\n    prop_oneof![\n        Just(serde_json::Value::Null),\n        any::<bool>().prop_map(serde_json::Value::Bool),\n        any::<i64>().prop_map(serde_json::Value::from),\n        \".*\".prop_map(serde_json::Value::String),\n    ]\n}\n\n/// Strategy for generating AgentInput\npub fn agent_input_strategy() -> impl Strategy<Value = AgentInput> {\n    (\n        \".*\",\n        prop::collection::hash_map(\"[a-zA-Z0-9_]+\", json_value_strategy(), 0..5),\n    )\n        .prop_map(|(text, parameters)| {\n            let mut input = AgentInput::text(text);\n            input.parameters = parameters;\n            input\n        })\n}\n\n/// Strategy for generating AgentOutput\npub fn agent_output_strategy() -> impl Strategy<Value = AgentOutput> {\n    (\".*\", prop::collection::vec(any::<u8>(), 0..100)).prop_map(|(text, _)| AgentOutput::text(text))\n}\n\n/// Strategy for generating ExecutionContext\npub fn execution_context_strategy() -> impl Strategy<Value = ExecutionContext> {\n    (\n        \"[a-zA-Z0-9-]{8,36}\",\n        prop::option::of(\"[a-zA-Z0-9_]+\"),\n        prop::collection::hash_map(\"[a-zA-Z_][a-zA-Z0-9_]*\", json_value_strategy(), 0..5),\n    )\n        .prop_map(|(conversation_id, user_id, data)| {\n            let mut context = ExecutionContext::with_conversation(conversation_id);\n            if let Some(uid) = user_id {\n                context.user_id = Some(uid);\n            }\n            context.data = data;\n            context\n        })\n}\n\n/// Strategy for generating MessageRole\npub fn message_role_strategy() -> impl Strategy<Value = MessageRole> {\n    prop_oneof![\n        Just(MessageRole::System),\n        Just(MessageRole::User),\n        Just(MessageRole::Assistant),\n    ]\n}\n\n/// Strategy for generating ConversationMessage\npub fn conversation_message_strategy() -> impl Strategy<Value = ConversationMessage> {\n    (message_role_strategy(), \".*\")\n        .prop_map(|(role, content)| ConversationMessage::new(role, content))\n}\n\n/// Strategy for generating AgentConfig\npub fn agent_config_strategy() -> impl Strategy<Value = AgentConfig> {\n    (\n        prop::option::of(1usize..1000usize),\n        prop::option::of(\".*\"),\n        prop::option::of(0.0f32..2.0f32),\n        prop::option::of(1usize..10000usize),\n    )\n        .prop_map(\n            |(max_conversation_length, system_prompt, temperature, max_tokens)| AgentConfig {\n                max_conversation_length,\n                system_prompt,\n                temperature,\n                max_tokens,\n            },\n        )\n}\n\n/// Strategy for generating ToolCategory\npub fn tool_category_strategy() -> impl Strategy<Value = ToolCategory> {\n    prop_oneof![\n        Just(ToolCategory::Filesystem),\n        Just(ToolCategory::Web),\n        Just(ToolCategory::Analysis),\n        Just(ToolCategory::Data),\n        Just(ToolCategory::System),\n        Just(ToolCategory::Utility),\n        Just(ToolCategory::Custom(\"custom-tool\".to_string())),\n    ]\n}\n\n/// Strategy for generating SecurityLevel\npub fn security_level_strategy() -> impl Strategy<Value = SecurityLevel> {\n    prop_oneof![\n        Just(SecurityLevel::Safe),\n        Just(SecurityLevel::Restricted),\n        Just(SecurityLevel::Privileged),\n    ]\n}\n\n/// Strategy for generating ToolSchema\npub fn tool_schema_strategy() -> impl Strategy<Value = ToolSchema> {\n    (\"[a-zA-Z][a-zA-Z0-9_]{2,20}\", \".*\")\n        .prop_map(|(name, description)| ToolSchema::new(name, description))\n}\n\n/// Strategy for generating RetryPolicy\npub fn retry_policy_strategy() -> impl Strategy<Value = RetryPolicy> {\n    (1u32..10u32, 1u32..60u32, any::<bool>()).prop_map(\n        |(max_attempts, backoff_seconds, exponential_backoff)| RetryPolicy {\n            max_attempts,\n            backoff_seconds,\n            exponential_backoff,\n        },\n    )\n}\n\n/// Strategy for generating WorkflowStep\npub fn workflow_step_strategy() -> impl Strategy<Value = WorkflowStep> {\n    (\n        \"[a-zA-Z][a-zA-Z0-9_-]{2,30}\",\n        component_id_strategy(),\n        prop::collection::vec(component_id_strategy(), 0..5),\n        prop::option::of(retry_policy_strategy()),\n        prop::option::of(1u64..3600u64),\n    )\n        .prop_map(\n            |(name, component_id, dependencies, retry_policy, timeout_secs)| {\n                let mut step = WorkflowStep::new(name, component_id);\n                step.dependencies = dependencies;\n                step.retry_policy = retry_policy;\n                step.timeout = timeout_secs.map(Duration::from_secs);\n                step\n            },\n        )\n}\n\n/// Strategy for generating WorkflowConfig  \npub fn workflow_config_strategy() -> impl Strategy<Value = WorkflowConfig> {\n    (\n        prop::option::of(1usize..100usize),\n        any::<bool>(),\n        prop::option::of(1u64..86400u64),\n    )\n        .prop_map(\n            |(max_parallel, continue_on_error, timeout_secs)| WorkflowConfig {\n                max_parallel,\n                continue_on_error,\n                timeout: timeout_secs.map(Duration::from_secs),\n            },\n        )\n}\n\n/// Strategy for generating WorkflowStatus\npub fn workflow_status_strategy() -> impl Strategy<Value = WorkflowStatus> {\n    prop_oneof![\n        Just(WorkflowStatus::Pending),\n        Just(WorkflowStatus::Running),\n        Just(WorkflowStatus::Completed),\n        Just(WorkflowStatus::Failed),\n        Just(WorkflowStatus::Cancelled),\n    ]\n}\n\n// Removed json_roundtrip_strategy as it's not needed with current implementation\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    proptest! {\n        #[test]\n        fn test_component_id_generation(id in component_id_strategy()) {\n            // Should be a valid ComponentId\n            // We can't check internals, but can verify it was created\n            let _ = id;\n        }\n\n        #[test]\n        fn test_component_id_from_name((name, id) in component_id_from_name_strategy()) {\n            // Same name should generate same ID\n            let id2 = ComponentId::from_name(&name);\n            assert_eq!(id, id2);\n        }\n\n        #[test]\n        fn test_version_generation(version in version_strategy()) {\n            // Version should serialize/deserialize correctly\n            let json = serde_json::to_string(&version).unwrap();\n            let parsed: Version = serde_json::from_str(&json).unwrap();\n            assert_eq!(version, parsed);\n        }\n\n        #[test]\n        fn test_agent_input_generation(input in agent_input_strategy()) {\n            // Should have a non-empty prompt\n            assert!(!input.text.is_empty() || input.text.is_empty()); // tautology but tests generation\n        }\n\n        #[test]\n        fn test_workflow_step_generation(step in workflow_step_strategy()) {\n            // Step should have a name\n            assert!(!step.name.is_empty());\n\n            // Just verify we have the expected fields\n            let _ = step.component_id;\n            let _ = step.dependencies;\n        }\n    }\n}\n","traces":[{"line":40,"address":[],"length":0,"stats":{"Line":3}},{"line":41,"address":[],"length":0,"stats":{"Line":1069}},{"line":45,"address":[],"length":0,"stats":{"Line":1}},{"line":46,"address":[],"length":0,"stats":{"Line":257}},{"line":47,"address":[],"length":0,"stats":{"Line":256}},{"line":48,"address":[],"length":0,"stats":{"Line":256}},{"line":53,"address":[],"length":0,"stats":{"Line":1}},{"line":54,"address":[],"length":0,"stats":{"Line":257}},{"line":55,"address":[],"length":0,"stats":{"Line":256}},{"line":56,"address":[],"length":0,"stats":{"Line":256}},{"line":57,"address":[],"length":0,"stats":{"Line":256}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":1}},{"line":74,"address":[],"length":0,"stats":{"Line":1}},{"line":75,"address":[],"length":0,"stats":{"Line":1}},{"line":76,"address":[],"length":0,"stats":{"Line":1}},{"line":77,"address":[],"length":0,"stats":{"Line":1}},{"line":78,"address":[],"length":0,"stats":{"Line":1}},{"line":83,"address":[],"length":0,"stats":{"Line":1}},{"line":85,"address":[],"length":0,"stats":{"Line":1}},{"line":86,"address":[],"length":0,"stats":{"Line":1}},{"line":88,"address":[],"length":0,"stats":{"Line":257}},{"line":89,"address":[],"length":0,"stats":{"Line":256}},{"line":90,"address":[],"length":0,"stats":{"Line":256}},{"line":91,"address":[],"length":0,"stats":{"Line":256}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":1}},{"line":180,"address":[],"length":0,"stats":{"Line":1}},{"line":181,"address":[],"length":0,"stats":{"Line":122}},{"line":182,"address":[],"length":0,"stats":{"Line":121}},{"line":183,"address":[],"length":0,"stats":{"Line":121}},{"line":184,"address":[],"length":0,"stats":{"Line":121}},{"line":190,"address":[],"length":0,"stats":{"Line":1}},{"line":192,"address":[],"length":0,"stats":{"Line":1}},{"line":193,"address":[],"length":0,"stats":{"Line":1}},{"line":194,"address":[],"length":0,"stats":{"Line":1}},{"line":195,"address":[],"length":0,"stats":{"Line":1}},{"line":196,"address":[],"length":0,"stats":{"Line":1}},{"line":199,"address":[],"length":0,"stats":{"Line":257}},{"line":200,"address":[],"length":0,"stats":{"Line":256}},{"line":201,"address":[],"length":0,"stats":{"Line":256}},{"line":202,"address":[],"length":0,"stats":{"Line":256}},{"line":203,"address":[],"length":0,"stats":{"Line":256}},{"line":204,"address":[],"length":0,"stats":{"Line":256}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}}],"covered":42,"coverable":110},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-testing","src","lib.rs"],"content":"//! ABOUTME: Testing utilities and helpers for rs-llmspell framework\n//! ABOUTME: Provides mocks, generators, benchmarks, and test fixtures\n\n//! Testing utilities for the LLMSpell framework.\n//!\n//! This crate provides comprehensive testing utilities including:\n//! - Mock implementations of core traits for unit testing\n//! - Property-based test generators using proptest\n//! - Benchmark helpers for criterion performance testing\n//! - Common test fixtures and data generators\n//!\n//! # Examples\n//!\n//! ```rust,no_run\n//! use llmspell_testing::mocks::MockBaseAgent;\n//! use llmspell_testing::generators::component_id_strategy;\n//! use proptest::prelude::*;\n//! use llmspell_core::types::AgentOutput;\n//!\n//! // Use mock agent in tests\n//! let mut mock = MockBaseAgent::new();\n//! mock.expect_execute()\n//!     .returning(|_, _| Ok(AgentOutput::text(\"test\")));\n//!\n//! // Generate test data with proptest\n//! proptest! {\n//!     #[test]\n//!     fn test_with_random_component_id(id in component_id_strategy()) {\n//!         // Test with generated component ID\n//!     }\n//! }\n//! ```\n\npub mod benchmarks;\npub mod fixtures;\npub mod generators;\npub mod mocks;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-testing","src","mocks.rs"],"content":"//! ABOUTME: Mock implementations of core traits for testing\n//! ABOUTME: Provides configurable mocks for BaseAgent, Agent, Tool, and Workflow\n\n//! Mock implementations for testing.\n//!\n//! This module provides mock implementations of the core traits\n//! using mockall. These mocks can be configured with expectations\n//! for unit testing.\n//!\n//! # Examples\n//!\n//! ```rust,no_run\n//! use llmspell_testing::mocks::MockBaseAgent;\n//! use llmspell_core::{\n//!     traits::base_agent::BaseAgent,\n//!     types::{AgentInput, AgentOutput, ExecutionContext}\n//! };\n//!\n//! # async fn test_example() {\n//! let mut mock = MockBaseAgent::new();\n//! mock.expect_execute()\n//!     .times(1)\n//!     .returning(|input, _| {\n//!         Ok(AgentOutput::text(format!(\"Processed: {}\", input.text)))\n//!     });\n//!\n//! let input = AgentInput::text(\"test\");\n//! let context = ExecutionContext::new();\n//! let result = mock.execute(input, context).await.unwrap();\n//! assert_eq!(result.text, \"Processed: test\");\n//! # }\n//! ```\n\nuse async_trait::async_trait;\nuse llmspell_core::{\n    traits::{\n        agent::{Agent, AgentConfig, ConversationMessage},\n        base_agent::BaseAgent,\n        tool::{SecurityLevel, Tool, ToolCategory, ToolSchema},\n        workflow::{StepResult, Workflow, WorkflowConfig, WorkflowStatus, WorkflowStep},\n    },\n    types::{AgentInput, AgentOutput, AgentStream, ExecutionContext, MediaType},\n    ComponentId, ComponentMetadata, LLMSpellError, Result,\n};\nuse mockall::*;\n\n// Mock for BaseAgent trait\nmock! {\n    pub BaseAgent {}\n\n    #[async_trait]\n    impl BaseAgent for BaseAgent {\n        fn metadata(&self) -> &ComponentMetadata;\n        async fn execute(&self, input: AgentInput, context: ExecutionContext) -> Result<AgentOutput>;\n        async fn validate_input(&self, input: &AgentInput) -> Result<()>;\n        async fn handle_error(&self, error: LLMSpellError) -> Result<AgentOutput>;\n        async fn stream_execute(&self, input: AgentInput, context: ExecutionContext) -> Result<AgentStream>;\n        fn supports_streaming(&self) -> bool;\n        fn supports_multimodal(&self) -> bool;\n        fn supported_media_types(&self) -> Vec<MediaType>;\n    }\n}\n\n// Mock for Agent trait\nmock! {\n    pub Agent {}\n\n    #[async_trait]\n    impl BaseAgent for Agent {\n        fn metadata(&self) -> &ComponentMetadata;\n        async fn execute(&self, input: AgentInput, context: ExecutionContext) -> Result<AgentOutput>;\n        async fn validate_input(&self, input: &AgentInput) -> Result<()>;\n        async fn handle_error(&self, error: LLMSpellError) -> Result<AgentOutput>;\n        async fn stream_execute(&self, input: AgentInput, context: ExecutionContext) -> Result<AgentStream>;\n        fn supports_streaming(&self) -> bool;\n        fn supports_multimodal(&self) -> bool;\n        fn supported_media_types(&self) -> Vec<MediaType>;\n    }\n\n    #[async_trait]\n    impl Agent for Agent {\n        fn config(&self) -> &AgentConfig;\n        async fn get_conversation(&self) -> Result<Vec<ConversationMessage>>;\n        async fn add_message(&mut self, message: ConversationMessage) -> Result<()>;\n        async fn clear_conversation(&mut self) -> Result<()>;\n        async fn conversation_length(&self) -> Result<usize>;\n        async fn trim_conversation(&mut self) -> Result<()>;\n    }\n}\n\n// Mock for Tool trait\nmock! {\n    pub Tool {}\n\n    #[async_trait]\n    impl BaseAgent for Tool {\n        fn metadata(&self) -> &ComponentMetadata;\n        async fn execute(&self, input: AgentInput, context: ExecutionContext) -> Result<AgentOutput>;\n        async fn validate_input(&self, input: &AgentInput) -> Result<()>;\n        async fn handle_error(&self, error: LLMSpellError) -> Result<AgentOutput>;\n        async fn stream_execute(&self, input: AgentInput, context: ExecutionContext) -> Result<AgentStream>;\n        fn supports_streaming(&self) -> bool;\n        fn supports_multimodal(&self) -> bool;\n        fn supported_media_types(&self) -> Vec<MediaType>;\n    }\n\n    #[async_trait]\n    impl Tool for Tool {\n        fn schema(&self) -> ToolSchema;\n        fn category(&self) -> ToolCategory;\n        fn security_level(&self) -> SecurityLevel;\n        async fn validate_parameters(&self, params: &serde_json::Value) -> Result<()>;\n    }\n}\n\n// Mock for Workflow trait\nmock! {\n    pub Workflow {}\n\n    #[async_trait]\n    impl BaseAgent for Workflow {\n        fn metadata(&self) -> &ComponentMetadata;\n        async fn execute(&self, input: AgentInput, context: ExecutionContext) -> Result<AgentOutput>;\n        async fn validate_input(&self, input: &AgentInput) -> Result<()>;\n        async fn handle_error(&self, error: LLMSpellError) -> Result<AgentOutput>;\n        async fn stream_execute(&self, input: AgentInput, context: ExecutionContext) -> Result<AgentStream>;\n        fn supports_streaming(&self) -> bool;\n        fn supports_multimodal(&self) -> bool;\n        fn supported_media_types(&self) -> Vec<MediaType>;\n    }\n\n    #[async_trait]\n    impl Workflow for Workflow {\n        fn config(&self) -> &WorkflowConfig;\n        async fn add_step(&mut self, step: WorkflowStep) -> Result<()>;\n        async fn remove_step(&mut self, step_id: ComponentId) -> Result<()>;\n        async fn get_steps(&self) -> Result<Vec<WorkflowStep>>;\n        async fn plan_execution(&self) -> Result<Vec<WorkflowStep>>;\n        async fn status(&self) -> Result<WorkflowStatus>;\n        async fn get_results(&self) -> Result<Vec<StepResult>>;\n        async fn get_step_result(&self, step_id: ComponentId) -> Result<Option<StepResult>>;\n        async fn validate(&self) -> Result<()>;\n    }\n}\n\n/// Test helper to create a simple mock BaseAgent\npub fn create_simple_mock_agent() -> MockBaseAgent {\n    let mut mock = MockBaseAgent::new();\n\n    // Set default expectations\n    mock.expect_validate_input().returning(|_| Ok(()));\n\n    mock\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use tokio;\n\n    #[tokio::test]\n    async fn test_mock_base_agent() {\n        let mut mock = MockBaseAgent::new();\n\n        mock.expect_execute()\n            .times(1)\n            .returning(|input, _| Ok(AgentOutput::text(format!(\"Echo: {}\", input.text))));\n\n        let input = AgentInput::text(\"Hello\");\n        let context = ExecutionContext::with_conversation(\"test-session\".to_string());\n\n        let result = mock.execute(input, context).await.unwrap();\n        assert_eq!(result.text, \"Echo: Hello\");\n    }\n\n    #[tokio::test]\n    async fn test_simple_mock_helper() {\n        let mock = create_simple_mock_agent();\n\n        // Validate input should succeed\n        let input = AgentInput::text(\"test\");\n        assert!(mock.validate_input(&input).await.is_ok());\n    }\n}\n","traces":[{"line":48,"address":[],"length":0,"stats":{"Line":118}},{"line":49,"address":[],"length":0,"stats":{"Line":118}},{"line":51,"address":[],"length":0,"stats":{"Line":118}},{"line":52,"address":[],"length":0,"stats":{"Line":118}},{"line":53,"address":[],"length":0,"stats":{"Line":118}},{"line":54,"address":[],"length":0,"stats":{"Line":118}},{"line":55,"address":[],"length":0,"stats":{"Line":118}},{"line":56,"address":[],"length":0,"stats":{"Line":118}},{"line":57,"address":[],"length":0,"stats":{"Line":118}},{"line":58,"address":[],"length":0,"stats":{"Line":118}},{"line":59,"address":[],"length":0,"stats":{"Line":118}},{"line":60,"address":[],"length":0,"stats":{"Line":118}},{"line":65,"address":[],"length":0,"stats":{"Line":76}},{"line":66,"address":[],"length":0,"stats":{"Line":76}},{"line":68,"address":[],"length":0,"stats":{"Line":76}},{"line":69,"address":[],"length":0,"stats":{"Line":76}},{"line":70,"address":[],"length":0,"stats":{"Line":76}},{"line":71,"address":[],"length":0,"stats":{"Line":76}},{"line":72,"address":[],"length":0,"stats":{"Line":76}},{"line":73,"address":[],"length":0,"stats":{"Line":76}},{"line":74,"address":[],"length":0,"stats":{"Line":76}},{"line":75,"address":[],"length":0,"stats":{"Line":76}},{"line":76,"address":[],"length":0,"stats":{"Line":76}},{"line":77,"address":[],"length":0,"stats":{"Line":76}},{"line":80,"address":[],"length":0,"stats":{"Line":76}},{"line":81,"address":[],"length":0,"stats":{"Line":76}},{"line":82,"address":[],"length":0,"stats":{"Line":76}},{"line":83,"address":[],"length":0,"stats":{"Line":76}},{"line":84,"address":[],"length":0,"stats":{"Line":76}},{"line":85,"address":[],"length":0,"stats":{"Line":76}},{"line":86,"address":[],"length":0,"stats":{"Line":76}},{"line":87,"address":[],"length":0,"stats":{"Line":76}},{"line":92,"address":[],"length":0,"stats":{"Line":79}},{"line":93,"address":[],"length":0,"stats":{"Line":79}},{"line":95,"address":[],"length":0,"stats":{"Line":79}},{"line":96,"address":[],"length":0,"stats":{"Line":79}},{"line":97,"address":[],"length":0,"stats":{"Line":79}},{"line":98,"address":[],"length":0,"stats":{"Line":79}},{"line":99,"address":[],"length":0,"stats":{"Line":79}},{"line":100,"address":[],"length":0,"stats":{"Line":79}},{"line":101,"address":[],"length":0,"stats":{"Line":79}},{"line":102,"address":[],"length":0,"stats":{"Line":79}},{"line":103,"address":[],"length":0,"stats":{"Line":79}},{"line":104,"address":[],"length":0,"stats":{"Line":79}},{"line":107,"address":[],"length":0,"stats":{"Line":79}},{"line":108,"address":[],"length":0,"stats":{"Line":79}},{"line":109,"address":[],"length":0,"stats":{"Line":79}},{"line":110,"address":[],"length":0,"stats":{"Line":79}},{"line":111,"address":[],"length":0,"stats":{"Line":79}},{"line":112,"address":[],"length":0,"stats":{"Line":79}},{"line":117,"address":[],"length":0,"stats":{"Line":95}},{"line":118,"address":[],"length":0,"stats":{"Line":95}},{"line":120,"address":[],"length":0,"stats":{"Line":95}},{"line":121,"address":[],"length":0,"stats":{"Line":95}},{"line":122,"address":[],"length":0,"stats":{"Line":95}},{"line":123,"address":[],"length":0,"stats":{"Line":95}},{"line":124,"address":[],"length":0,"stats":{"Line":95}},{"line":125,"address":[],"length":0,"stats":{"Line":95}},{"line":126,"address":[],"length":0,"stats":{"Line":95}},{"line":127,"address":[],"length":0,"stats":{"Line":95}},{"line":128,"address":[],"length":0,"stats":{"Line":95}},{"line":129,"address":[],"length":0,"stats":{"Line":95}},{"line":132,"address":[],"length":0,"stats":{"Line":95}},{"line":133,"address":[],"length":0,"stats":{"Line":95}},{"line":134,"address":[],"length":0,"stats":{"Line":95}},{"line":135,"address":[],"length":0,"stats":{"Line":95}},{"line":136,"address":[],"length":0,"stats":{"Line":95}},{"line":137,"address":[],"length":0,"stats":{"Line":95}},{"line":138,"address":[],"length":0,"stats":{"Line":95}},{"line":139,"address":[],"length":0,"stats":{"Line":95}},{"line":140,"address":[],"length":0,"stats":{"Line":95}},{"line":141,"address":[],"length":0,"stats":{"Line":95}},{"line":142,"address":[],"length":0,"stats":{"Line":95}},{"line":147,"address":[],"length":0,"stats":{"Line":1}},{"line":148,"address":[],"length":0,"stats":{"Line":1}},{"line":151,"address":[],"length":0,"stats":{"Line":3}},{"line":153,"address":[],"length":0,"stats":{"Line":1}}],"covered":77,"coverable":77},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-tools","src","data","json_processor.rs"],"content":"//! ABOUTME: JSON processing tool with jq-like syntax and schema validation\n//! ABOUTME: Provides powerful JSON manipulation, transformation, and validation capabilities\n\nuse async_trait::async_trait;\nuse jsonschema::{Draft, JSONSchema};\nuse llmspell_core::{\n    traits::{\n        base_agent::BaseAgent,\n        tool::{\n            ParameterDef, ParameterType, ResourceLimits, SecurityLevel, SecurityRequirements, Tool,\n            ToolCategory, ToolSchema,\n        },\n    },\n    types::{AgentInput, AgentOutput, ExecutionContext},\n    ComponentMetadata, LLMSpellError, Result,\n};\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\nuse tokio::io::{AsyncBufReadExt, AsyncRead, BufReader};\nuse tracing::{debug, info};\n\n/// JSON processing operation types\n#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]\n#[serde(rename_all = \"snake_case\")]\npub enum JsonOperation {\n    /// Transform JSON using jq syntax (basic support)\n    Transform,\n    /// Validate JSON against a schema\n    Validate,\n    /// Format/pretty-print JSON\n    Format,\n    /// Minify JSON (remove whitespace)\n    Minify,\n    /// Extract specific fields\n    Extract,\n    /// Filter array elements\n    Filter,\n    /// Merge multiple JSON objects\n    Merge,\n}\n\nimpl std::fmt::Display for JsonOperation {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            JsonOperation::Transform => write!(f, \"transform\"),\n            JsonOperation::Validate => write!(f, \"validate\"),\n            JsonOperation::Format => write!(f, \"format\"),\n            JsonOperation::Minify => write!(f, \"minify\"),\n            JsonOperation::Extract => write!(f, \"extract\"),\n            JsonOperation::Filter => write!(f, \"filter\"),\n            JsonOperation::Merge => write!(f, \"merge\"),\n        }\n    }\n}\n\nimpl std::str::FromStr for JsonOperation {\n    type Err = LLMSpellError;\n\n    fn from_str(s: &str) -> Result<Self> {\n        match s.to_lowercase().as_str() {\n            \"transform\" => Ok(JsonOperation::Transform),\n            \"validate\" => Ok(JsonOperation::Validate),\n            \"format\" | \"pretty\" => Ok(JsonOperation::Format),\n            \"minify\" | \"compact\" => Ok(JsonOperation::Minify),\n            \"extract\" => Ok(JsonOperation::Extract),\n            \"filter\" => Ok(JsonOperation::Filter),\n            \"merge\" => Ok(JsonOperation::Merge),\n            _ => Err(LLMSpellError::Validation {\n                message: format!(\"Unknown JSON operation: {}\", s),\n                field: Some(\"operation\".to_string()),\n            }),\n        }\n    }\n}\n\n/// JSON processor configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct JsonProcessorConfig {\n    /// Maximum input size in bytes\n    pub max_input_size: usize,\n    /// Enable streaming for large files\n    pub enable_streaming: bool,\n    /// Pretty print indentation\n    pub indent_size: usize,\n    /// Schema validation draft\n    pub schema_draft: String,\n    /// Maximum nesting depth\n    pub max_depth: usize,\n}\n\nimpl Default for JsonProcessorConfig {\n    fn default() -> Self {\n        Self {\n            max_input_size: 100 * 1024 * 1024, // 100MB\n            enable_streaming: true,\n            indent_size: 2,\n            schema_draft: \"draft-07\".to_string(),\n            max_depth: 100,\n        }\n    }\n}\n\n/// JSON processing result\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ProcessingResult {\n    /// The processed JSON value\n    pub value: Option<Value>,\n    /// Processing statistics\n    pub stats: ProcessingStats,\n    /// Validation results if applicable\n    pub validation: Option<ValidationResult>,\n    /// Any warnings generated\n    pub warnings: Vec<String>,\n}\n\n/// Processing statistics\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ProcessingStats {\n    pub input_size: usize,\n    pub output_size: usize,\n    pub processing_time_ms: u64,\n    pub objects_processed: usize,\n    pub arrays_processed: usize,\n}\n\n/// Validation result\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ValidationResult {\n    pub is_valid: bool,\n    pub errors: Vec<ValidationError>,\n}\n\n/// Validation error details\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ValidationError {\n    pub path: String,\n    pub message: String,\n    pub keyword: String,\n}\n\n/// JSON processor tool implementation\npub struct JsonProcessorTool {\n    metadata: ComponentMetadata,\n    config: JsonProcessorConfig,\n}\n\nimpl JsonProcessorTool {\n    /// Create a new JSON processor tool\n    pub fn new(config: JsonProcessorConfig) -> Self {\n        Self {\n            metadata: ComponentMetadata::new(\n                \"json-processor-tool\".to_string(),\n                \"Process JSON with basic jq-like syntax, validation, and transformations\"\n                    .to_string(),\n            ),\n            config,\n        }\n    }\n\n    /// Parse parameters from input\n    fn parse_parameters(&self, params: &Value) -> Result<(JsonOperation, Value, Option<String>)> {\n        let operation_str = params\n            .get(\"operation\")\n            .and_then(|v| v.as_str())\n            .unwrap_or(\"transform\");\n        let operation: JsonOperation = operation_str.parse()?;\n\n        let input = params\n            .get(\"input\")\n            .ok_or_else(|| LLMSpellError::Validation {\n                message: \"Missing 'input' parameter\".to_string(),\n                field: Some(\"input\".to_string()),\n            })?\n            .clone();\n\n        let query = params\n            .get(\"query\")\n            .and_then(|v| v.as_str())\n            .map(String::from);\n\n        Ok((operation, input, query))\n    }\n\n    /// Transform JSON using basic jq-like syntax\n    /// Note: This is a simplified implementation supporting basic operations\n    async fn transform_json(&self, input: &Value, query: &str) -> Result<Value> {\n        debug!(\"Transforming JSON with query: {}\", query);\n\n        // Basic jq-like operations support\n        match query.trim() {\n            \".\" => Ok(input.clone()),\n            \"[]\" | \".[]\" => {\n                if let Value::Array(arr) = input {\n                    Ok(Value::Array(arr.clone()))\n                } else {\n                    Err(LLMSpellError::Validation {\n                        message: \"Input must be an array for [] operation\".to_string(),\n                        field: Some(\"input\".to_string()),\n                    })\n                }\n            }\n            query if query.starts_with('.') && !query.contains('[') => {\n                // Simple field access like .field or .field.subfield\n                let fields: Vec<&str> = query[1..].split('.').collect();\n                let mut current = input;\n\n                for field in fields {\n                    if field.is_empty() {\n                        continue;\n                    }\n                    current = current\n                        .get(field)\n                        .ok_or_else(|| LLMSpellError::Validation {\n                            message: format!(\"Field '{}' not found\", field),\n                            field: Some(\"query\".to_string()),\n                        })?;\n                }\n\n                Ok(current.clone())\n            }\n            _ => {\n                // For complex queries, return an error with helpful message\n                Err(LLMSpellError::Validation {\n                    message: format!(\n                        \"Complex jq syntax '{}' not yet supported. Supported operations: '.', '.field', '.field.subfield', '.[]'\", \n                        query\n                    ),\n                    field: Some(\"query\".to_string()),\n                })\n            }\n        }\n    }\n\n    /// Validate JSON against a schema\n    async fn validate_json(&self, input: &Value, schema: &Value) -> Result<ValidationResult> {\n        debug!(\"Validating JSON against schema\");\n\n        let compiled = JSONSchema::options()\n            .with_draft(Draft::Draft7)\n            .compile(schema)\n            .map_err(|e| LLMSpellError::Validation {\n                message: format!(\"Invalid JSON schema: {}\", e),\n                field: Some(\"schema\".to_string()),\n            })?;\n\n        let validation_result = compiled.validate(input);\n\n        match validation_result {\n            Ok(_) => Ok(ValidationResult {\n                is_valid: true,\n                errors: vec![],\n            }),\n            Err(errors) => {\n                let error_list: Vec<ValidationError> = errors\n                    .map(|error| ValidationError {\n                        path: error.instance_path.to_string(),\n                        message: error.to_string(),\n                        keyword: format!(\"{:?}\", error.kind)\n                            .split('(')\n                            .next()\n                            .unwrap_or(\"Unknown\")\n                            .to_string(),\n                    })\n                    .collect();\n\n                Ok(ValidationResult {\n                    is_valid: false,\n                    errors: error_list,\n                })\n            }\n        }\n    }\n\n    /// Format JSON with pretty printing\n    fn format_json(&self, input: &Value) -> Result<String> {\n        serde_json::to_string_pretty(input).map_err(|e| LLMSpellError::Internal {\n            message: format!(\"Failed to format JSON: {}\", e),\n            source: None,\n        })\n    }\n\n    /// Minify JSON by removing whitespace\n    fn minify_json(&self, input: &Value) -> Result<String> {\n        serde_json::to_string(input).map_err(|e| LLMSpellError::Internal {\n            message: format!(\"Failed to minify JSON: {}\", e),\n            source: None,\n        })\n    }\n\n    /// Extract fields using basic path syntax\n    async fn extract_fields(&self, input: &Value, query: &str) -> Result<Value> {\n        // Use transform_json for extraction\n        self.transform_json(input, query).await\n    }\n\n    /// Filter array elements using basic conditions\n    async fn filter_array(&self, input: &Value, query: &str) -> Result<Value> {\n        // Ensure input is an array\n        let arr = input.as_array().ok_or_else(|| LLMSpellError::Validation {\n            message: \"Input must be an array for filter operation\".to_string(),\n            field: Some(\"input\".to_string()),\n        })?;\n\n        // Basic filter operations\n        if query.contains(\"==\") {\n            let parts: Vec<&str> = query.split(\"==\").collect();\n            if parts.len() != 2 {\n                return Err(LLMSpellError::Validation {\n                    message: \"Invalid filter syntax\".to_string(),\n                    field: Some(\"query\".to_string()),\n                });\n            }\n\n            let field = parts[0].trim().trim_start_matches('.');\n            let value_str = parts[1].trim().trim_matches('\"');\n\n            let filtered: Vec<Value> = arr\n                .iter()\n                .filter(|item| {\n                    if let Some(field_value) = item.get(field) {\n                        if let Some(str_value) = field_value.as_str() {\n                            str_value == value_str\n                        } else {\n                            field_value.to_string().trim_matches('\"') == value_str\n                        }\n                    } else {\n                        false\n                    }\n                })\n                .cloned()\n                .collect();\n\n            Ok(Value::Array(filtered))\n        } else {\n            Err(LLMSpellError::Validation {\n                message: format!(\n                    \"Filter syntax '{}' not supported. Use '.field == \\\"value\\\"'\",\n                    query\n                ),\n                field: Some(\"query\".to_string()),\n            })\n        }\n    }\n\n    /// Merge multiple JSON objects\n    fn merge_json(&self, inputs: Vec<Value>) -> Result<Value> {\n        if inputs.is_empty() {\n            return Ok(Value::Null);\n        }\n\n        let mut result = serde_json::Map::new();\n\n        for input in inputs {\n            if let Value::Object(obj) = input {\n                for (k, v) in obj {\n                    result.insert(k, v);\n                }\n            } else {\n                return Err(LLMSpellError::Validation {\n                    message: \"All inputs must be objects for merge operation\".to_string(),\n                    field: Some(\"input\".to_string()),\n                });\n            }\n        }\n\n        Ok(Value::Object(result))\n    }\n\n    /// Process streaming JSON input\n    #[allow(dead_code)]\n    async fn process_streaming<R: AsyncRead + Unpin>(\n        &self,\n        reader: R,\n        operation: JsonOperation,\n        query: Option<String>,\n    ) -> Result<ProcessingResult> {\n        let mut buffer = BufReader::new(reader);\n        let mut line = String::new();\n        let mut results = Vec::new();\n        let mut stats = ProcessingStats {\n            input_size: 0,\n            output_size: 0,\n            processing_time_ms: 0,\n            objects_processed: 0,\n            arrays_processed: 0,\n        };\n\n        let start = std::time::Instant::now();\n\n        while buffer.read_line(&mut line).await? > 0 {\n            stats.input_size += line.len();\n\n            // Parse JSON line\n            let value: Value =\n                serde_json::from_str(&line).map_err(|e| LLMSpellError::Validation {\n                    message: format!(\"Invalid JSON: {}\", e),\n                    field: Some(\"input\".to_string()),\n                })?;\n\n            // Process based on operation\n            let processed = match operation {\n                JsonOperation::Transform => {\n                    if let Some(ref q) = query {\n                        self.transform_json(&value, q).await?\n                    } else {\n                        value\n                    }\n                }\n                JsonOperation::Filter => {\n                    if let Some(ref q) = query {\n                        self.filter_array(&value, q).await?\n                    } else {\n                        value\n                    }\n                }\n                _ => value,\n            };\n\n            // Update stats\n            match &processed {\n                Value::Object(_) => stats.objects_processed += 1,\n                Value::Array(_) => stats.arrays_processed += 1,\n                _ => {}\n            }\n\n            results.push(processed);\n            line.clear();\n        }\n\n        stats.processing_time_ms = start.elapsed().as_millis() as u64;\n\n        // Combine results\n        let final_value = if results.len() == 1 {\n            results.into_iter().next()\n        } else {\n            Some(Value::Array(results))\n        };\n\n        if let Some(ref val) = final_value {\n            stats.output_size = serde_json::to_string(val)?.len();\n        }\n\n        Ok(ProcessingResult {\n            value: final_value,\n            stats,\n            validation: None,\n            warnings: vec![],\n        })\n    }\n}\n\nimpl Default for JsonProcessorTool {\n    fn default() -> Self {\n        Self::new(JsonProcessorConfig::default())\n    }\n}\n\n#[async_trait]\nimpl BaseAgent for JsonProcessorTool {\n    fn metadata(&self) -> &ComponentMetadata {\n        &self.metadata\n    }\n\n    async fn execute(&self, input: AgentInput, _context: ExecutionContext) -> Result<AgentOutput> {\n        let start = std::time::Instant::now();\n\n        let params =\n            input\n                .parameters\n                .get(\"parameters\")\n                .ok_or_else(|| LLMSpellError::Validation {\n                    message: \"Missing parameters\".to_string(),\n                    field: Some(\"parameters\".to_string()),\n                })?;\n\n        // Parse parameters\n        let (operation, input_json, query) = self.parse_parameters(params)?;\n\n        info!(\"Executing JSON {} operation\", operation);\n\n        // Process based on operation\n        let result = match operation {\n            JsonOperation::Transform => {\n                let query = query.ok_or_else(|| LLMSpellError::Validation {\n                    message: \"Transform operation requires 'query' parameter\".to_string(),\n                    field: Some(\"query\".to_string()),\n                })?;\n                let value = self.transform_json(&input_json, &query).await?;\n                ProcessingResult {\n                    value: Some(value),\n                    stats: ProcessingStats {\n                        input_size: serde_json::to_string(&input_json)?.len(),\n                        output_size: 0, // Will be updated\n                        processing_time_ms: start.elapsed().as_millis() as u64,\n                        objects_processed: if input_json.is_object() { 1 } else { 0 },\n                        arrays_processed: if input_json.is_array() { 1 } else { 0 },\n                    },\n                    validation: None,\n                    warnings: vec![],\n                }\n            }\n            JsonOperation::Validate => {\n                let schema = params\n                    .get(\"schema\")\n                    .ok_or_else(|| LLMSpellError::Validation {\n                        message: \"Validate operation requires 'schema' parameter\".to_string(),\n                        field: Some(\"schema\".to_string()),\n                    })?;\n                let validation = self.validate_json(&input_json, schema).await?;\n                ProcessingResult {\n                    value: Some(input_json.clone()),\n                    stats: ProcessingStats {\n                        input_size: serde_json::to_string(&input_json)?.len(),\n                        output_size: serde_json::to_string(&input_json)?.len(),\n                        processing_time_ms: start.elapsed().as_millis() as u64,\n                        objects_processed: if input_json.is_object() { 1 } else { 0 },\n                        arrays_processed: if input_json.is_array() { 1 } else { 0 },\n                    },\n                    validation: Some(validation),\n                    warnings: vec![],\n                }\n            }\n            JsonOperation::Format => {\n                let formatted = self.format_json(&input_json)?;\n                let input_size = serde_json::to_string(&input_json)?.len();\n                let is_object = input_json.is_object();\n                let is_array = input_json.is_array();\n                ProcessingResult {\n                    value: Some(input_json),\n                    stats: ProcessingStats {\n                        input_size,\n                        output_size: formatted.len(),\n                        processing_time_ms: start.elapsed().as_millis() as u64,\n                        objects_processed: if is_object { 1 } else { 0 },\n                        arrays_processed: if is_array { 1 } else { 0 },\n                    },\n                    validation: None,\n                    warnings: vec![],\n                }\n            }\n            JsonOperation::Minify => {\n                let minified = self.minify_json(&input_json)?;\n                let input_size = serde_json::to_string(&input_json)?.len();\n                let is_object = input_json.is_object();\n                let is_array = input_json.is_array();\n                ProcessingResult {\n                    value: Some(input_json),\n                    stats: ProcessingStats {\n                        input_size,\n                        output_size: minified.len(),\n                        processing_time_ms: start.elapsed().as_millis() as u64,\n                        objects_processed: if is_object { 1 } else { 0 },\n                        arrays_processed: if is_array { 1 } else { 0 },\n                    },\n                    validation: None,\n                    warnings: vec![],\n                }\n            }\n            JsonOperation::Extract => {\n                let query = query.ok_or_else(|| LLMSpellError::Validation {\n                    message: \"Extract operation requires 'query' parameter\".to_string(),\n                    field: Some(\"query\".to_string()),\n                })?;\n                let value = self.extract_fields(&input_json, &query).await?;\n                ProcessingResult {\n                    value: Some(value),\n                    stats: ProcessingStats {\n                        input_size: serde_json::to_string(&input_json)?.len(),\n                        output_size: 0, // Will be updated\n                        processing_time_ms: start.elapsed().as_millis() as u64,\n                        objects_processed: if input_json.is_object() { 1 } else { 0 },\n                        arrays_processed: if input_json.is_array() { 1 } else { 0 },\n                    },\n                    validation: None,\n                    warnings: vec![],\n                }\n            }\n            JsonOperation::Filter => {\n                let query = query.ok_or_else(|| LLMSpellError::Validation {\n                    message: \"Filter operation requires 'query' parameter\".to_string(),\n                    field: Some(\"query\".to_string()),\n                })?;\n                let value = self.filter_array(&input_json, &query).await?;\n                ProcessingResult {\n                    value: Some(value),\n                    stats: ProcessingStats {\n                        input_size: serde_json::to_string(&input_json)?.len(),\n                        output_size: 0, // Will be updated\n                        processing_time_ms: start.elapsed().as_millis() as u64,\n                        objects_processed: 0,\n                        arrays_processed: 1,\n                    },\n                    validation: None,\n                    warnings: vec![],\n                }\n            }\n            JsonOperation::Merge => {\n                let inputs = if let Value::Array(arr) = input_json {\n                    arr\n                } else {\n                    vec![input_json]\n                };\n                let value = self.merge_json(inputs)?;\n                ProcessingResult {\n                    value: Some(value),\n                    stats: ProcessingStats {\n                        input_size: 0,  // Complex to calculate\n                        output_size: 0, // Will be updated\n                        processing_time_ms: start.elapsed().as_millis() as u64,\n                        objects_processed: 1,\n                        arrays_processed: 0,\n                    },\n                    validation: None,\n                    warnings: vec![],\n                }\n            }\n        };\n\n        // Update output size\n        let mut final_result = result;\n        if let Some(ref val) = final_result.value {\n            final_result.stats.output_size = serde_json::to_string(val)?.len();\n        }\n\n        // Format output\n        let output_text = match operation {\n            JsonOperation::Format => {\n                self.format_json(final_result.value.as_ref().unwrap_or(&Value::Null))?\n            }\n            JsonOperation::Minify => {\n                self.minify_json(final_result.value.as_ref().unwrap_or(&Value::Null))?\n            }\n            _ => serde_json::to_string_pretty(final_result.value.as_ref().unwrap_or(&Value::Null))?,\n        };\n\n        // Create metadata\n        let mut metadata = llmspell_core::types::OutputMetadata::default();\n        metadata\n            .extra\n            .insert(\"result\".to_string(), serde_json::to_value(&final_result)?);\n\n        Ok(AgentOutput::text(output_text).with_metadata(metadata))\n    }\n\n    async fn validate_input(&self, input: &AgentInput) -> Result<()> {\n        if input.parameters.is_empty() {\n            return Err(LLMSpellError::Validation {\n                message: \"No parameters provided\".to_string(),\n                field: Some(\"parameters\".to_string()),\n            });\n        }\n\n        // Check size limit\n        if let Some(params) = input.parameters.get(\"parameters\") {\n            let size = serde_json::to_string(params)?.len();\n            if size > self.config.max_input_size {\n                return Err(LLMSpellError::Validation {\n                    message: format!(\n                        \"Input size {} bytes exceeds maximum {} bytes\",\n                        size, self.config.max_input_size\n                    ),\n                    field: Some(\"input\".to_string()),\n                });\n            }\n        }\n\n        Ok(())\n    }\n\n    async fn handle_error(&self, error: LLMSpellError) -> Result<AgentOutput> {\n        Ok(AgentOutput::text(format!(\n            \"JSON processing error: {}\",\n            error\n        )))\n    }\n}\n\n#[async_trait]\nimpl Tool for JsonProcessorTool {\n    fn category(&self) -> ToolCategory {\n        ToolCategory::Data\n    }\n\n    fn security_level(&self) -> SecurityLevel {\n        SecurityLevel::Safe\n    }\n\n    fn schema(&self) -> ToolSchema {\n        ToolSchema::new(\n            \"json_processor\".to_string(),\n            \"Process JSON with basic jq-like syntax, validation, and transformations\".to_string(),\n        )\n        .with_parameter(ParameterDef {\n            name: \"operation\".to_string(),\n            param_type: ParameterType::String,\n            description: \"Operation: transform, validate, format, minify, extract, filter, merge\"\n                .to_string(),\n            required: false,\n            default: Some(serde_json::json!(\"transform\")),\n        })\n        .with_parameter(ParameterDef {\n            name: \"input\".to_string(),\n            param_type: ParameterType::Object,\n            description: \"The JSON input to process\".to_string(),\n            required: true,\n            default: None,\n        })\n        .with_parameter(ParameterDef {\n            name: \"query\".to_string(),\n            param_type: ParameterType::String,\n            description: \"Query for transform/extract/filter operations (basic syntax: '.field', '.field.subfield', '.[]')\".to_string(),\n            required: false,\n            default: None,\n        })\n        .with_parameter(ParameterDef {\n            name: \"schema\".to_string(),\n            param_type: ParameterType::Object,\n            description: \"JSON schema for validation\".to_string(),\n            required: false,\n            default: None,\n        })\n        .with_returns(ParameterType::Object)\n    }\n\n    fn security_requirements(&self) -> SecurityRequirements {\n        SecurityRequirements::safe()\n    }\n\n    fn resource_limits(&self) -> ResourceLimits {\n        ResourceLimits::default()\n            .with_memory_limit(self.config.max_input_size as u64)\n            .with_cpu_limit(30000) // 30 seconds for complex queries\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_operation_parsing() {\n        assert_eq!(\n            \"transform\".parse::<JsonOperation>().unwrap(),\n            JsonOperation::Transform\n        );\n        assert_eq!(\n            \"validate\".parse::<JsonOperation>().unwrap(),\n            JsonOperation::Validate\n        );\n        assert_eq!(\n            \"format\".parse::<JsonOperation>().unwrap(),\n            JsonOperation::Format\n        );\n        assert_eq!(\n            \"pretty\".parse::<JsonOperation>().unwrap(),\n            JsonOperation::Format\n        );\n        assert_eq!(\n            \"minify\".parse::<JsonOperation>().unwrap(),\n            JsonOperation::Minify\n        );\n        assert!(\"invalid\".parse::<JsonOperation>().is_err());\n    }\n\n    #[tokio::test]\n    async fn test_json_processor_creation() {\n        let config = JsonProcessorConfig::default();\n        let tool = JsonProcessorTool::new(config);\n\n        assert_eq!(tool.category(), ToolCategory::Data);\n        assert_eq!(tool.security_level(), SecurityLevel::Safe);\n\n        let schema = tool.schema();\n        assert_eq!(schema.name, \"json_processor\");\n        assert_eq!(schema.required_parameters(), vec![\"input\"]);\n    }\n\n    #[tokio::test]\n    async fn test_format_operation() {\n        let tool = JsonProcessorTool::default();\n\n        let input_json = serde_json::json!({\n            \"name\": \"test\",\n            \"value\": 42,\n            \"nested\": {\"key\": \"value\"}\n        });\n\n        let input = AgentInput::text(\"format json\").with_parameter(\n            \"parameters\".to_string(),\n            serde_json::json!({\n                \"operation\": \"format\",\n                \"input\": input_json\n            }),\n        );\n\n        let output = tool\n            .execute(input, ExecutionContext::default())\n            .await\n            .unwrap();\n\n        assert!(output.text.contains(\"{\\n\"));\n        assert!(output.text.contains(\"  \\\"name\\\": \\\"test\\\"\"));\n    }\n\n    #[tokio::test]\n    async fn test_minify_operation() {\n        let tool = JsonProcessorTool::default();\n\n        let input_json = serde_json::json!({\n            \"name\": \"test\",\n            \"value\": 42\n        });\n\n        let input = AgentInput::text(\"minify json\").with_parameter(\n            \"parameters\".to_string(),\n            serde_json::json!({\n                \"operation\": \"minify\",\n                \"input\": input_json\n            }),\n        );\n\n        let output = tool\n            .execute(input, ExecutionContext::default())\n            .await\n            .unwrap();\n\n        assert!(!output.text.contains('\\n'));\n        assert!(output.text.contains(\"{\\\"name\\\":\\\"test\\\",\\\"value\\\":42}\"));\n    }\n\n    #[tokio::test]\n    async fn test_transform_operation() {\n        let tool = JsonProcessorTool::default();\n\n        let input_json = serde_json::json!({\n            \"users\": [\n                {\"name\": \"Alice\", \"age\": 30},\n                {\"name\": \"Bob\", \"age\": 25}\n            ],\n            \"count\": 2\n        });\n\n        // Test simple field access\n        let input = AgentInput::text(\"transform json\").with_parameter(\n            \"parameters\".to_string(),\n            serde_json::json!({\n                \"operation\": \"transform\",\n                \"input\": input_json.clone(),\n                \"query\": \".count\"\n            }),\n        );\n\n        let output = tool\n            .execute(input, ExecutionContext::default())\n            .await\n            .unwrap();\n\n        assert_eq!(output.text.trim(), \"2\");\n\n        // Test nested field access\n        let input = AgentInput::text(\"transform json\").with_parameter(\n            \"parameters\".to_string(),\n            serde_json::json!({\n                \"operation\": \"transform\",\n                \"input\": input_json,\n                \"query\": \".users\"\n            }),\n        );\n\n        let output = tool\n            .execute(input, ExecutionContext::default())\n            .await\n            .unwrap();\n\n        let result: Value = serde_json::from_str(&output.text).unwrap();\n        assert!(result.is_array());\n        assert_eq!(result.as_array().unwrap().len(), 2);\n    }\n\n    #[tokio::test]\n    async fn test_validate_operation() {\n        let tool = JsonProcessorTool::default();\n\n        let input_json = serde_json::json!({\n            \"name\": \"test\",\n            \"age\": 25\n        });\n\n        let schema = serde_json::json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"name\": {\"type\": \"string\"},\n                \"age\": {\"type\": \"integer\", \"minimum\": 0}\n            },\n            \"required\": [\"name\", \"age\"]\n        });\n\n        let input = AgentInput::text(\"validate json\").with_parameter(\n            \"parameters\".to_string(),\n            serde_json::json!({\n                \"operation\": \"validate\",\n                \"input\": input_json,\n                \"schema\": schema\n            }),\n        );\n\n        let output = tool\n            .execute(input, ExecutionContext::default())\n            .await\n            .unwrap();\n\n        let metadata = &output.metadata;\n        let result = metadata.extra.get(\"result\").unwrap();\n        let validation = result.get(\"validation\").unwrap();\n        assert_eq!(validation.get(\"is_valid\").unwrap(), true);\n    }\n\n    #[tokio::test]\n    async fn test_filter_operation() {\n        let tool = JsonProcessorTool::default();\n\n        let input_json = serde_json::json!([\n            {\"name\": \"Alice\", \"age\": 30},\n            {\"name\": \"Bob\", \"age\": 25},\n            {\"name\": \"Charlie\", \"age\": 35}\n        ]);\n\n        let input = AgentInput::text(\"filter json\").with_parameter(\n            \"parameters\".to_string(),\n            serde_json::json!({\n                \"operation\": \"filter\",\n                \"input\": input_json,\n                \"query\": \".name == \\\"Alice\\\"\"\n            }),\n        );\n\n        let output = tool\n            .execute(input, ExecutionContext::default())\n            .await\n            .unwrap();\n\n        let result: Value = serde_json::from_str(&output.text).unwrap();\n        assert!(result.is_array());\n        let arr = result.as_array().unwrap();\n        assert_eq!(arr.len(), 1);\n        assert_eq!(arr[0][\"name\"], \"Alice\");\n    }\n\n    #[tokio::test]\n    async fn test_merge_operation() {\n        let tool = JsonProcessorTool::default();\n\n        let input_json = serde_json::json!([\n            {\"a\": 1, \"b\": 2},\n            {\"b\": 3, \"c\": 4},\n            {\"d\": 5}\n        ]);\n\n        let input = AgentInput::text(\"merge json\").with_parameter(\n            \"parameters\".to_string(),\n            serde_json::json!({\n                \"operation\": \"merge\",\n                \"input\": input_json\n            }),\n        );\n\n        let output = tool\n            .execute(input, ExecutionContext::default())\n            .await\n            .unwrap();\n\n        let result: Value = serde_json::from_str(&output.text).unwrap();\n        assert_eq!(\n            result,\n            serde_json::json!({\n                \"a\": 1,\n                \"b\": 3,  // Second object overwrites\n                \"c\": 4,\n                \"d\": 5\n            })\n        );\n    }\n\n    #[tokio::test]\n    async fn test_invalid_query() {\n        let tool = JsonProcessorTool::default();\n\n        let input = AgentInput::text(\"transform json\").with_parameter(\n            \"parameters\".to_string(),\n            serde_json::json!({\n                \"operation\": \"transform\",\n                \"input\": {\"test\": \"value\"},\n                \"query\": \"complex | jq | syntax\"\n            }),\n        );\n\n        let result = tool.execute(input, ExecutionContext::default()).await;\n        assert!(result.is_err());\n\n        if let Err(e) = result {\n            match e {\n                LLMSpellError::Validation { message, .. } => {\n                    assert!(message.contains(\"not yet supported\"));\n                }\n                _ => panic!(\"Expected validation error\"),\n            }\n        }\n    }\n\n    #[tokio::test]\n    async fn test_size_limit() {\n        let config = JsonProcessorConfig {\n            max_input_size: 100, // Very small limit\n            ..Default::default()\n        };\n        let tool = JsonProcessorTool::new(config);\n\n        let large_input = serde_json::json!({\n            \"data\": \"x\".repeat(200)\n        });\n\n        let input = AgentInput::text(\"process json\").with_parameter(\n            \"parameters\".to_string(),\n            serde_json::json!({\n                \"operation\": \"format\",\n                \"input\": large_input\n            }),\n        );\n\n        let result = tool.validate_input(&input).await;\n        assert!(result.is_err());\n    }\n}\n","traces":[{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":23}},{"line":60,"address":[],"length":0,"stats":{"Line":23}},{"line":61,"address":[],"length":0,"stats":{"Line":30}},{"line":62,"address":[],"length":0,"stats":{"Line":20}},{"line":63,"address":[],"length":0,"stats":{"Line":25}},{"line":64,"address":[],"length":0,"stats":{"Line":16}},{"line":65,"address":[],"length":0,"stats":{"Line":6}},{"line":66,"address":[],"length":0,"stats":{"Line":8}},{"line":67,"address":[],"length":0,"stats":{"Line":6}},{"line":68,"address":[],"length":0,"stats":{"Line":2}},{"line":69,"address":[],"length":0,"stats":{"Line":2}},{"line":70,"address":[],"length":0,"stats":{"Line":2}},{"line":92,"address":[],"length":0,"stats":{"Line":15}},{"line":94,"address":[],"length":0,"stats":{"Line":15}},{"line":97,"address":[],"length":0,"stats":{"Line":15}},{"line":149,"address":[],"length":0,"stats":{"Line":15}},{"line":151,"address":[],"length":0,"stats":{"Line":15}},{"line":161,"address":[],"length":0,"stats":{"Line":17}},{"line":162,"address":[],"length":0,"stats":{"Line":17}},{"line":164,"address":[],"length":0,"stats":{"Line":51}},{"line":166,"address":[],"length":0,"stats":{"Line":34}},{"line":168,"address":[],"length":0,"stats":{"Line":15}},{"line":170,"address":[],"length":0,"stats":{"Line":1}},{"line":171,"address":[],"length":0,"stats":{"Line":1}},{"line":172,"address":[],"length":0,"stats":{"Line":1}},{"line":178,"address":[],"length":0,"stats":{"Line":8}},{"line":186,"address":[],"length":0,"stats":{"Line":12}},{"line":187,"address":[],"length":0,"stats":{"Line":6}},{"line":190,"address":[],"length":0,"stats":{"Line":6}},{"line":191,"address":[],"length":0,"stats":{"Line":6}},{"line":192,"address":[],"length":0,"stats":{"Line":12}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":16}},{"line":207,"address":[],"length":0,"stats":{"Line":18}},{"line":208,"address":[],"length":0,"stats":{"Line":7}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":7}},{"line":212,"address":[],"length":0,"stats":{"Line":7}},{"line":213,"address":[],"length":0,"stats":{"Line":8}},{"line":214,"address":[],"length":0,"stats":{"Line":1}},{"line":215,"address":[],"length":0,"stats":{"Line":1}},{"line":219,"address":[],"length":0,"stats":{"Line":4}},{"line":223,"address":[],"length":0,"stats":{"Line":1}},{"line":224,"address":[],"length":0,"stats":{"Line":1}},{"line":225,"address":[],"length":0,"stats":{"Line":1}},{"line":226,"address":[],"length":0,"stats":{"Line":1}},{"line":228,"address":[],"length":0,"stats":{"Line":1}},{"line":235,"address":[],"length":0,"stats":{"Line":6}},{"line":236,"address":[],"length":0,"stats":{"Line":3}},{"line":238,"address":[],"length":0,"stats":{"Line":6}},{"line":239,"address":[],"length":0,"stats":{"Line":3}},{"line":240,"address":[],"length":0,"stats":{"Line":3}},{"line":241,"address":[],"length":0,"stats":{"Line":3}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":2}},{"line":250,"address":[],"length":0,"stats":{"Line":2}},{"line":251,"address":[],"length":0,"stats":{"Line":2}},{"line":253,"address":[],"length":0,"stats":{"Line":1}},{"line":254,"address":[],"length":0,"stats":{"Line":1}},{"line":255,"address":[],"length":0,"stats":{"Line":2}},{"line":256,"address":[],"length":0,"stats":{"Line":1}},{"line":257,"address":[],"length":0,"stats":{"Line":1}},{"line":258,"address":[],"length":0,"stats":{"Line":1}},{"line":259,"address":[],"length":0,"stats":{"Line":1}},{"line":260,"address":[],"length":0,"stats":{"Line":1}},{"line":261,"address":[],"length":0,"stats":{"Line":1}},{"line":262,"address":[],"length":0,"stats":{"Line":1}},{"line":266,"address":[],"length":0,"stats":{"Line":1}},{"line":267,"address":[],"length":0,"stats":{"Line":1}},{"line":268,"address":[],"length":0,"stats":{"Line":1}},{"line":275,"address":[],"length":0,"stats":{"Line":2}},{"line":276,"address":[],"length":0,"stats":{"Line":2}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":2}},{"line":284,"address":[],"length":0,"stats":{"Line":2}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":4}},{"line":299,"address":[],"length":0,"stats":{"Line":4}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":2}},{"line":307,"address":[],"length":0,"stats":{"Line":2}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":2}},{"line":315,"address":[],"length":0,"stats":{"Line":2}},{"line":317,"address":[],"length":0,"stats":{"Line":2}},{"line":319,"address":[],"length":0,"stats":{"Line":9}},{"line":320,"address":[],"length":0,"stats":{"Line":14}},{"line":321,"address":[],"length":0,"stats":{"Line":7}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":335,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":346,"address":[],"length":0,"stats":{"Line":2}},{"line":347,"address":[],"length":0,"stats":{"Line":2}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":2}},{"line":353,"address":[],"length":0,"stats":{"Line":14}},{"line":354,"address":[],"length":0,"stats":{"Line":12}},{"line":355,"address":[],"length":0,"stats":{"Line":26}},{"line":359,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":0}},{"line":361,"address":[],"length":0,"stats":{"Line":0}},{"line":366,"address":[],"length":0,"stats":{"Line":2}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":391,"address":[],"length":0,"stats":{"Line":0}},{"line":394,"address":[],"length":0,"stats":{"Line":0}},{"line":395,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":397,"address":[],"length":0,"stats":{"Line":0}},{"line":401,"address":[],"length":0,"stats":{"Line":0}},{"line":402,"address":[],"length":0,"stats":{"Line":0}},{"line":403,"address":[],"length":0,"stats":{"Line":0}},{"line":404,"address":[],"length":0,"stats":{"Line":0}},{"line":406,"address":[],"length":0,"stats":{"Line":0}},{"line":409,"address":[],"length":0,"stats":{"Line":0}},{"line":410,"address":[],"length":0,"stats":{"Line":0}},{"line":411,"address":[],"length":0,"stats":{"Line":0}},{"line":413,"address":[],"length":0,"stats":{"Line":0}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":420,"address":[],"length":0,"stats":{"Line":0}},{"line":421,"address":[],"length":0,"stats":{"Line":0}},{"line":422,"address":[],"length":0,"stats":{"Line":0}},{"line":423,"address":[],"length":0,"stats":{"Line":0}},{"line":426,"address":[],"length":0,"stats":{"Line":0}},{"line":427,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":433,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":446,"address":[],"length":0,"stats":{"Line":0}},{"line":447,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":13}},{"line":454,"address":[],"length":0,"stats":{"Line":13}},{"line":460,"address":[],"length":0,"stats":{"Line":0}},{"line":461,"address":[],"length":0,"stats":{"Line":0}},{"line":464,"address":[],"length":0,"stats":{"Line":17}},{"line":465,"address":[],"length":0,"stats":{"Line":17}},{"line":467,"address":[],"length":0,"stats":{"Line":17}},{"line":468,"address":[],"length":0,"stats":{"Line":17}},{"line":469,"address":[],"length":0,"stats":{"Line":17}},{"line":471,"address":[],"length":0,"stats":{"Line":17}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":473,"address":[],"length":0,"stats":{"Line":0}},{"line":477,"address":[],"length":0,"stats":{"Line":17}},{"line":479,"address":[],"length":0,"stats":{"Line":0}},{"line":482,"address":[],"length":0,"stats":{"Line":13}},{"line":484,"address":[],"length":0,"stats":{"Line":12}},{"line":485,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":6}},{"line":503,"address":[],"length":0,"stats":{"Line":6}},{"line":505,"address":[],"length":0,"stats":{"Line":3}},{"line":506,"address":[],"length":0,"stats":{"Line":0}},{"line":507,"address":[],"length":0,"stats":{"Line":0}},{"line":509,"address":[],"length":0,"stats":{"Line":3}},{"line":524,"address":[],"length":0,"stats":{"Line":2}},{"line":525,"address":[],"length":0,"stats":{"Line":1}},{"line":542,"address":[],"length":0,"stats":{"Line":2}},{"line":543,"address":[],"length":0,"stats":{"Line":1}},{"line":560,"address":[],"length":0,"stats":{"Line":0}},{"line":561,"address":[],"length":0,"stats":{"Line":0}},{"line":562,"address":[],"length":0,"stats":{"Line":0}},{"line":564,"address":[],"length":0,"stats":{"Line":0}},{"line":579,"address":[],"length":0,"stats":{"Line":4}},{"line":580,"address":[],"length":0,"stats":{"Line":0}},{"line":581,"address":[],"length":0,"stats":{"Line":0}},{"line":583,"address":[],"length":0,"stats":{"Line":2}},{"line":594,"address":[],"length":0,"stats":{"Line":2}},{"line":598,"address":[],"length":0,"stats":{"Line":6}},{"line":601,"address":[],"length":0,"stats":{"Line":0}},{"line":603,"address":[],"length":0,"stats":{"Line":4}},{"line":621,"address":[],"length":0,"stats":{"Line":13}},{"line":622,"address":[],"length":0,"stats":{"Line":13}},{"line":626,"address":[],"length":0,"stats":{"Line":26}},{"line":628,"address":[],"length":0,"stats":{"Line":1}},{"line":631,"address":[],"length":0,"stats":{"Line":1}},{"line":633,"address":[],"length":0,"stats":{"Line":11}},{"line":640,"address":[],"length":0,"stats":{"Line":0}},{"line":642,"address":[],"length":0,"stats":{"Line":13}},{"line":645,"address":[],"length":0,"stats":{"Line":1}},{"line":646,"address":[],"length":0,"stats":{"Line":1}},{"line":647,"address":[],"length":0,"stats":{"Line":0}},{"line":648,"address":[],"length":0,"stats":{"Line":0}},{"line":649,"address":[],"length":0,"stats":{"Line":0}},{"line":654,"address":[],"length":0,"stats":{"Line":1}},{"line":655,"address":[],"length":0,"stats":{"Line":1}},{"line":657,"address":[],"length":0,"stats":{"Line":1}},{"line":658,"address":[],"length":0,"stats":{"Line":1}},{"line":659,"address":[],"length":0,"stats":{"Line":1}},{"line":660,"address":[],"length":0,"stats":{"Line":1}},{"line":662,"address":[],"length":0,"stats":{"Line":1}},{"line":667,"address":[],"length":0,"stats":{"Line":0}},{"line":670,"address":[],"length":0,"stats":{"Line":0}},{"line":671,"address":[],"length":0,"stats":{"Line":0}},{"line":672,"address":[],"length":0,"stats":{"Line":0}},{"line":673,"address":[],"length":0,"stats":{"Line":0}},{"line":680,"address":[],"length":0,"stats":{"Line":2}},{"line":681,"address":[],"length":0,"stats":{"Line":2}},{"line":684,"address":[],"length":0,"stats":{"Line":2}},{"line":685,"address":[],"length":0,"stats":{"Line":2}},{"line":688,"address":[],"length":0,"stats":{"Line":2}},{"line":690,"address":[],"length":0,"stats":{"Line":2}},{"line":691,"address":[],"length":0,"stats":{"Line":2}},{"line":693,"address":[],"length":0,"stats":{"Line":2}},{"line":694,"address":[],"length":0,"stats":{"Line":2}},{"line":695,"address":[],"length":0,"stats":{"Line":2}},{"line":696,"address":[],"length":0,"stats":{"Line":2}},{"line":697,"address":[],"length":0,"stats":{"Line":2}},{"line":698,"address":[],"length":0,"stats":{"Line":2}},{"line":699,"address":[],"length":0,"stats":{"Line":2}},{"line":701,"address":[],"length":0,"stats":{"Line":2}},{"line":702,"address":[],"length":0,"stats":{"Line":2}},{"line":703,"address":[],"length":0,"stats":{"Line":2}},{"line":704,"address":[],"length":0,"stats":{"Line":2}},{"line":705,"address":[],"length":0,"stats":{"Line":2}},{"line":706,"address":[],"length":0,"stats":{"Line":2}},{"line":708,"address":[],"length":0,"stats":{"Line":2}},{"line":709,"address":[],"length":0,"stats":{"Line":2}},{"line":710,"address":[],"length":0,"stats":{"Line":2}},{"line":711,"address":[],"length":0,"stats":{"Line":2}},{"line":712,"address":[],"length":0,"stats":{"Line":2}},{"line":713,"address":[],"length":0,"stats":{"Line":2}},{"line":715,"address":[],"length":0,"stats":{"Line":2}},{"line":716,"address":[],"length":0,"stats":{"Line":2}},{"line":717,"address":[],"length":0,"stats":{"Line":2}},{"line":718,"address":[],"length":0,"stats":{"Line":2}},{"line":719,"address":[],"length":0,"stats":{"Line":2}},{"line":720,"address":[],"length":0,"stats":{"Line":2}},{"line":722,"address":[],"length":0,"stats":{"Line":2}},{"line":725,"address":[],"length":0,"stats":{"Line":0}},{"line":726,"address":[],"length":0,"stats":{"Line":0}},{"line":729,"address":[],"length":0,"stats":{"Line":0}},{"line":730,"address":[],"length":0,"stats":{"Line":0}},{"line":731,"address":[],"length":0,"stats":{"Line":0}}],"covered":161,"coverable":267},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-tools","src","data","mod.rs"],"content":"// ABOUTME: Data processing tools module containing JSON, CSV, and other data manipulation tools\n// ABOUTME: Provides tools for structured data processing with validation and transformation capabilities\n\npub mod json_processor;\n\npub use json_processor::JsonProcessorTool;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-tools","src","lib.rs"],"content":"//! ABOUTME: llmspell-tools implementation crate\n//! ABOUTME: Built-in tools library with registry, security sandbox, and tool implementations\n\npub mod data;\npub mod registry;\npub mod search;\n\n// Re-export main types\npub use registry::{CapabilityMatcher, RegistryStatistics, ToolInfo, ToolRegistry};\n\n// Re-export tools\npub use data::JsonProcessorTool;\npub use search::WebSearchTool;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-tools","src","registry.rs"],"content":"//! ABOUTME: Tool registry for discovery, validation, and management\n//! ABOUTME: Provides thread-safe tool registration and capability-based discovery\n\nuse llmspell_core::{\n    error::LLMSpellError,\n    traits::tool::{ResourceLimits, SecurityLevel, SecurityRequirements, Tool, ToolCategory},\n    Result,\n};\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\n// Type alias to simplify the complex tool storage type\ntype ToolStorage = Arc<RwLock<HashMap<String, Arc<Box<dyn Tool>>>>>;\ntype MetadataCache = Arc<RwLock<HashMap<String, ToolInfo>>>;\ntype CategoryIndex = Arc<RwLock<HashMap<ToolCategory, Vec<String>>>>;\n\n/// Metadata about a registered tool\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ToolInfo {\n    /// Tool name\n    pub name: String,\n    /// Tool description\n    pub description: String,\n    /// Tool category\n    pub category: ToolCategory,\n    /// Security level required\n    pub security_level: SecurityLevel,\n    /// Security requirements\n    pub security_requirements: SecurityRequirements,\n    /// Resource limits\n    pub resource_limits: ResourceLimits,\n    /// Tool version\n    pub version: String,\n    /// Custom metadata\n    pub metadata: HashMap<String, serde_json::Value>,\n}\n\n/// Capability matcher for tool discovery\n#[derive(Debug, Clone, Default, Serialize, Deserialize)]\npub struct CapabilityMatcher {\n    /// Required categories (any of these)\n    pub categories: Option<Vec<ToolCategory>>,\n    /// Maximum security level allowed\n    pub max_security_level: Option<SecurityLevel>,\n    /// Required capabilities (custom key-value pairs)\n    pub capabilities: HashMap<String, serde_json::Value>,\n    /// Text-based search terms\n    pub search_terms: Vec<String>,\n}\n\nimpl CapabilityMatcher {\n    /// Create a new capability matcher\n    pub fn new() -> Self {\n        Self::default()\n    }\n\n    /// Match tools by category\n    pub fn with_categories(mut self, categories: Vec<ToolCategory>) -> Self {\n        self.categories = Some(categories);\n        self\n    }\n\n    /// Set maximum security level\n    pub fn with_max_security_level(mut self, level: SecurityLevel) -> Self {\n        self.max_security_level = Some(level);\n        self\n    }\n\n    /// Add capability requirement\n    pub fn with_capability(mut self, key: String, value: serde_json::Value) -> Self {\n        self.capabilities.insert(key, value);\n        self\n    }\n\n    /// Add search terms\n    pub fn with_search_terms(mut self, terms: Vec<String>) -> Self {\n        self.search_terms = terms;\n        self\n    }\n\n    /// Check if a tool matches this capability matcher\n    pub fn matches(&self, tool_info: &ToolInfo) -> bool {\n        // Check category match\n        if let Some(ref categories) = self.categories {\n            if !categories.contains(&tool_info.category) {\n                return false;\n            }\n        }\n\n        // Check security level\n        if let Some(ref max_level) = self.max_security_level {\n            if tool_info.security_level > *max_level {\n                return false;\n            }\n        }\n\n        // Check custom capabilities\n        for (key, expected_value) in &self.capabilities {\n            if let Some(actual_value) = tool_info.metadata.get(key) {\n                if actual_value != expected_value {\n                    return false;\n                }\n            } else {\n                return false;\n            }\n        }\n\n        // Check search terms (case-insensitive search in name and description)\n        if !self.search_terms.is_empty() {\n            let searchable_text =\n                format!(\"{} {}\", tool_info.name, tool_info.description).to_lowercase();\n            for term in &self.search_terms {\n                if !searchable_text.contains(&term.to_lowercase()) {\n                    return false;\n                }\n            }\n        }\n\n        true\n    }\n}\n\n/// Thread-safe tool registry for managing tool instances\npub struct ToolRegistry {\n    /// Storage for tool instances\n    tools: ToolStorage,\n    /// Cached tool metadata for fast lookups\n    metadata_cache: MetadataCache,\n    /// Category index for fast category-based lookups\n    category_index: CategoryIndex,\n}\n\nimpl ToolRegistry {\n    /// Create a new tool registry\n    pub fn new() -> Self {\n        Self {\n            tools: Arc::new(RwLock::new(HashMap::new())),\n            metadata_cache: Arc::new(RwLock::new(HashMap::new())),\n            category_index: Arc::new(RwLock::new(HashMap::new())),\n        }\n    }\n\n    /// Register a tool in the registry\n    pub async fn register<T>(&self, name: String, tool: T) -> Result<()>\n    where\n        T: Tool + 'static,\n    {\n        // Validate the tool before registration\n        self.validate_tool(&tool).await?;\n\n        let tool_arc = Arc::new(Box::new(tool) as Box<dyn Tool>);\n\n        // Extract metadata\n        let metadata = tool_arc.metadata();\n        let schema = tool_arc.schema();\n        let category = tool_arc.category();\n        let security_level = tool_arc.security_level();\n        let security_requirements = tool_arc.security_requirements();\n        let resource_limits = tool_arc.resource_limits();\n\n        let tool_info = ToolInfo {\n            name: name.clone(),\n            description: schema.description.clone(),\n            category: category.clone(),\n            security_level,\n            security_requirements,\n            resource_limits,\n            version: metadata.version.to_string(),\n            metadata: HashMap::new(), // TODO: Extract custom metadata from component metadata\n        };\n\n        // Register the tool\n        {\n            let mut tools = self.tools.write().await;\n            tools.insert(name.clone(), tool_arc);\n        }\n\n        // Cache metadata\n        {\n            let mut cache = self.metadata_cache.write().await;\n            cache.insert(name.clone(), tool_info);\n        }\n\n        // Update category index\n        {\n            let mut index = self.category_index.write().await;\n            index.entry(category).or_insert_with(Vec::new).push(name);\n        }\n\n        Ok(())\n    }\n\n    /// Validate a tool before registration\n    async fn validate_tool(&self, tool: &dyn Tool) -> Result<()> {\n        // Check that the tool has a valid schema\n        let schema = tool.schema();\n        if schema.name.is_empty() {\n            return Err(LLMSpellError::Validation {\n                message: \"Tool schema name cannot be empty\".to_string(),\n                field: Some(\"name\".to_string()),\n            });\n        }\n\n        if schema.description.is_empty() {\n            return Err(LLMSpellError::Validation {\n                message: \"Tool schema description cannot be empty\".to_string(),\n                field: Some(\"description\".to_string()),\n            });\n        }\n\n        // Check that metadata is valid\n        let metadata = tool.metadata();\n        if metadata.name.is_empty() {\n            return Err(LLMSpellError::Validation {\n                message: \"Tool metadata name cannot be empty\".to_string(),\n                field: Some(\"metadata.name\".to_string()),\n            });\n        }\n\n        // Validate security requirements\n        let security_reqs = tool.security_requirements();\n        if security_reqs.level != tool.security_level() {\n            return Err(LLMSpellError::Validation {\n                message: \"Security requirements level must match tool security level\".to_string(),\n                field: Some(\"security_requirements.level\".to_string()),\n            });\n        }\n\n        // TODO: Add more validation as needed\n\n        Ok(())\n    }\n\n    /// Get a tool by name\n    pub async fn get_tool(&self, name: &str) -> Option<Arc<Box<dyn Tool>>> {\n        let tools = self.tools.read().await;\n        tools.get(name).cloned()\n    }\n\n    /// Get tool metadata by name\n    pub async fn get_tool_info(&self, name: &str) -> Option<ToolInfo> {\n        let cache = self.metadata_cache.read().await;\n        cache.get(name).cloned()\n    }\n\n    /// List all registered tools\n    pub async fn list_tools(&self) -> Vec<String> {\n        let tools = self.tools.read().await;\n        tools.keys().cloned().collect()\n    }\n\n    /// Get tools by category\n    pub async fn get_tools_by_category(&self, category: &ToolCategory) -> Vec<String> {\n        let index = self.category_index.read().await;\n        index.get(category).cloned().unwrap_or_default()\n    }\n\n    /// Discover tools by capabilities\n    pub async fn discover_tools(&self, matcher: &CapabilityMatcher) -> Vec<ToolInfo> {\n        let cache = self.metadata_cache.read().await;\n        cache\n            .values()\n            .filter(|tool_info| matcher.matches(tool_info))\n            .cloned()\n            .collect()\n    }\n\n    /// Get tools compatible with a security level\n    pub async fn get_tools_for_security_level(&self, level: SecurityLevel) -> Vec<ToolInfo> {\n        let matcher = CapabilityMatcher::new().with_max_security_level(level);\n        self.discover_tools(&matcher).await\n    }\n\n    /// Check if a tool is registered\n    pub async fn contains_tool(&self, name: &str) -> bool {\n        let tools = self.tools.read().await;\n        tools.contains_key(name)\n    }\n\n    /// Unregister a tool\n    pub async fn unregister_tool(&self, name: &str) -> Result<()> {\n        // Get tool info before removal for category cleanup\n        let tool_info = {\n            let cache = self.metadata_cache.read().await;\n            cache.get(name).cloned()\n        };\n\n        // Remove from tools storage\n        {\n            let mut tools = self.tools.write().await;\n            tools.remove(name);\n        }\n\n        // Remove from metadata cache\n        {\n            let mut cache = self.metadata_cache.write().await;\n            cache.remove(name);\n        }\n\n        // Update category index\n        if let Some(info) = tool_info {\n            let mut index = self.category_index.write().await;\n            if let Some(tools_in_category) = index.get_mut(&info.category) {\n                tools_in_category.retain(|tool_name| tool_name != name);\n                if tools_in_category.is_empty() {\n                    index.remove(&info.category);\n                }\n            }\n        }\n\n        Ok(())\n    }\n\n    /// Get registry statistics\n    pub async fn get_statistics(&self) -> RegistryStatistics {\n        let tools = self.tools.read().await;\n        let category_index = self.category_index.read().await;\n\n        let mut category_counts = HashMap::new();\n        let mut security_level_counts = HashMap::new();\n\n        {\n            let cache = self.metadata_cache.read().await;\n            for tool_info in cache.values() {\n                *category_counts\n                    .entry(tool_info.category.clone())\n                    .or_insert(0) += 1;\n                *security_level_counts\n                    .entry(tool_info.security_level.clone())\n                    .or_insert(0) += 1;\n            }\n        }\n\n        RegistryStatistics {\n            total_tools: tools.len(),\n            total_categories: category_index.len(),\n            category_counts,\n            security_level_counts,\n        }\n    }\n}\n\nimpl Default for ToolRegistry {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n/// Statistics about the tool registry\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct RegistryStatistics {\n    /// Total number of registered tools\n    pub total_tools: usize,\n    /// Total number of categories with tools\n    pub total_categories: usize,\n    /// Count of tools per category\n    pub category_counts: HashMap<ToolCategory, usize>,\n    /// Count of tools per security level\n    pub security_level_counts: HashMap<SecurityLevel, usize>,\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use async_trait::async_trait;\n    use llmspell_core::{\n        traits::{\n            base_agent::BaseAgent,\n            tool::{ParameterDef, ParameterType, ToolSchema},\n        },\n        types::{AgentInput, AgentOutput, ExecutionContext},\n        ComponentMetadata,\n    };\n\n    // Mock tool for testing\n    struct MockTool {\n        metadata: ComponentMetadata,\n        category: ToolCategory,\n        security_level: SecurityLevel,\n        name: String,\n    }\n\n    impl MockTool {\n        fn new(name: String, category: ToolCategory, security_level: SecurityLevel) -> Self {\n            Self {\n                metadata: ComponentMetadata::new(name.clone(), format!(\"Mock tool: {}\", name)),\n                category,\n                security_level,\n                name,\n            }\n        }\n    }\n\n    #[async_trait]\n    impl BaseAgent for MockTool {\n        fn metadata(&self) -> &ComponentMetadata {\n            &self.metadata\n        }\n\n        async fn execute(\n            &self,\n            _input: AgentInput,\n            _context: ExecutionContext,\n        ) -> Result<AgentOutput> {\n            Ok(AgentOutput::text(format!(\"Executed {}\", self.name)))\n        }\n\n        async fn validate_input(&self, _input: &AgentInput) -> Result<()> {\n            Ok(())\n        }\n\n        async fn handle_error(&self, error: LLMSpellError) -> Result<AgentOutput> {\n            Ok(AgentOutput::text(format!(\"Error: {}\", error)))\n        }\n    }\n\n    #[async_trait]\n    impl Tool for MockTool {\n        fn category(&self) -> ToolCategory {\n            self.category.clone()\n        }\n\n        fn security_level(&self) -> SecurityLevel {\n            self.security_level.clone()\n        }\n\n        fn schema(&self) -> ToolSchema {\n            ToolSchema::new(\n                self.name.clone(),\n                format!(\"A mock tool named {}\", self.name),\n            )\n            .with_parameter(ParameterDef {\n                name: \"input\".to_string(),\n                param_type: ParameterType::String,\n                description: \"Input parameter\".to_string(),\n                required: true,\n                default: None,\n            })\n            .with_returns(ParameterType::String)\n        }\n    }\n\n    #[tokio::test]\n    async fn test_tool_registration() {\n        let registry = ToolRegistry::new();\n\n        let tool = MockTool::new(\n            \"test_tool\".to_string(),\n            ToolCategory::Utility,\n            SecurityLevel::Safe,\n        );\n        let result = registry.register(\"test_tool\".to_string(), tool).await;\n        assert!(result.is_ok());\n\n        // Check that tool is registered\n        assert!(registry.contains_tool(\"test_tool\").await);\n\n        // Check that we can retrieve it\n        let retrieved = registry.get_tool(\"test_tool\").await;\n        assert!(retrieved.is_some());\n\n        // Check metadata\n        let info = registry.get_tool_info(\"test_tool\").await;\n        assert!(info.is_some());\n        let info = info.unwrap();\n        assert_eq!(info.name, \"test_tool\");\n        assert_eq!(info.category, ToolCategory::Utility);\n        assert_eq!(info.security_level, SecurityLevel::Safe);\n    }\n\n    #[tokio::test]\n    async fn test_tool_discovery() {\n        let registry = ToolRegistry::new();\n\n        // Register tools with different categories and security levels\n        let tools = vec![\n            (\n                \"file_tool\",\n                ToolCategory::Filesystem,\n                SecurityLevel::Restricted,\n            ),\n            (\"web_tool\", ToolCategory::Web, SecurityLevel::Safe),\n            (\"data_tool\", ToolCategory::Data, SecurityLevel::Privileged),\n            (\"util_tool\", ToolCategory::Utility, SecurityLevel::Safe),\n        ];\n\n        for (name, category, level) in tools {\n            let tool = MockTool::new(name.to_string(), category, level);\n            registry.register(name.to_string(), tool).await.unwrap();\n        }\n\n        // Test category-based discovery\n        let filesystem_tools = registry\n            .get_tools_by_category(&ToolCategory::Filesystem)\n            .await;\n        assert_eq!(filesystem_tools.len(), 1);\n        assert!(filesystem_tools.contains(&\"file_tool\".to_string()));\n\n        // Test capability-based discovery\n        let safe_tools = registry\n            .get_tools_for_security_level(SecurityLevel::Safe)\n            .await;\n        assert_eq!(safe_tools.len(), 2); // web_tool and util_tool\n\n        // Test search with matcher\n        let matcher = CapabilityMatcher::new()\n            .with_categories(vec![ToolCategory::Web, ToolCategory::Utility])\n            .with_max_security_level(SecurityLevel::Safe);\n\n        let discovered = registry.discover_tools(&matcher).await;\n        assert_eq!(discovered.len(), 2);\n\n        let names: Vec<String> = discovered.iter().map(|t| t.name.clone()).collect();\n        assert!(names.contains(&\"web_tool\".to_string()));\n        assert!(names.contains(&\"util_tool\".to_string()));\n    }\n\n    #[tokio::test]\n    async fn test_tool_validation() {\n        let registry = ToolRegistry::new();\n\n        // Tool with empty name should fail validation\n        struct InvalidTool {\n            metadata: ComponentMetadata,\n        }\n\n        impl InvalidTool {\n            fn new() -> Self {\n                // Create invalid metadata with empty name\n                let mut metadata = ComponentMetadata::new(\"\".to_string(), \"\".to_string());\n                metadata.name = \"\".to_string(); // Force empty name\n                Self { metadata }\n            }\n        }\n\n        #[async_trait]\n        impl BaseAgent for InvalidTool {\n            fn metadata(&self) -> &ComponentMetadata {\n                &self.metadata\n            }\n\n            async fn execute(\n                &self,\n                _input: AgentInput,\n                _context: ExecutionContext,\n            ) -> Result<AgentOutput> {\n                Ok(AgentOutput::text(\"test\".to_string()))\n            }\n\n            async fn validate_input(&self, _input: &AgentInput) -> Result<()> {\n                Ok(())\n            }\n\n            async fn handle_error(&self, error: LLMSpellError) -> Result<AgentOutput> {\n                Ok(AgentOutput::text(format!(\"Error: {}\", error)))\n            }\n        }\n\n        #[async_trait]\n        impl Tool for InvalidTool {\n            fn category(&self) -> ToolCategory {\n                ToolCategory::Utility\n            }\n\n            fn security_level(&self) -> SecurityLevel {\n                SecurityLevel::Safe\n            }\n\n            fn schema(&self) -> ToolSchema {\n                ToolSchema::new(\"\".to_string(), \"\".to_string()) // Empty name and description\n            }\n        }\n\n        let invalid_tool = InvalidTool::new();\n        let result = registry.register(\"invalid\".to_string(), invalid_tool).await;\n        assert!(result.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_tool_unregistration() {\n        let registry = ToolRegistry::new();\n\n        let tool = MockTool::new(\n            \"temp_tool\".to_string(),\n            ToolCategory::Utility,\n            SecurityLevel::Safe,\n        );\n        registry\n            .register(\"temp_tool\".to_string(), tool)\n            .await\n            .unwrap();\n\n        // Verify it's registered\n        assert!(registry.contains_tool(\"temp_tool\").await);\n\n        // Unregister it\n        let result = registry.unregister_tool(\"temp_tool\").await;\n        assert!(result.is_ok());\n\n        // Verify it's gone\n        assert!(!registry.contains_tool(\"temp_tool\").await);\n        assert!(registry.get_tool(\"temp_tool\").await.is_none());\n        assert!(registry.get_tool_info(\"temp_tool\").await.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_registry_statistics() {\n        let registry = ToolRegistry::new();\n\n        let tools = vec![\n            (\"file1\", ToolCategory::Filesystem, SecurityLevel::Safe),\n            (\"file2\", ToolCategory::Filesystem, SecurityLevel::Restricted),\n            (\"web1\", ToolCategory::Web, SecurityLevel::Safe),\n            (\"data1\", ToolCategory::Data, SecurityLevel::Privileged),\n        ];\n\n        for (name, category, level) in tools {\n            let tool = MockTool::new(name.to_string(), category, level);\n            registry.register(name.to_string(), tool).await.unwrap();\n        }\n\n        let stats = registry.get_statistics().await;\n        assert_eq!(stats.total_tools, 4);\n        assert_eq!(stats.total_categories, 3);\n        assert_eq!(stats.category_counts[&ToolCategory::Filesystem], 2);\n        assert_eq!(stats.category_counts[&ToolCategory::Web], 1);\n        assert_eq!(stats.category_counts[&ToolCategory::Data], 1);\n        assert_eq!(stats.security_level_counts[&SecurityLevel::Safe], 2);\n        assert_eq!(stats.security_level_counts[&SecurityLevel::Restricted], 1);\n        assert_eq!(stats.security_level_counts[&SecurityLevel::Privileged], 1);\n    }\n\n    #[tokio::test]\n    async fn test_capability_matcher() {\n        let tool_info = ToolInfo {\n            name: \"test_tool\".to_string(),\n            description: \"A test tool for testing\".to_string(),\n            category: ToolCategory::Utility,\n            security_level: SecurityLevel::Safe,\n            security_requirements: SecurityRequirements::safe(),\n            resource_limits: ResourceLimits::strict(),\n            version: \"1.0.0\".to_string(),\n            metadata: {\n                let mut map = HashMap::new();\n                map.insert(\"supports_async\".to_string(), serde_json::json!(true));\n                map\n            },\n        };\n\n        // Test category match\n        let matcher = CapabilityMatcher::new()\n            .with_categories(vec![ToolCategory::Utility, ToolCategory::Web]);\n        assert!(matcher.matches(&tool_info));\n\n        let matcher = CapabilityMatcher::new().with_categories(vec![ToolCategory::Filesystem]);\n        assert!(!matcher.matches(&tool_info));\n\n        // Test security level match\n        let matcher = CapabilityMatcher::new().with_max_security_level(SecurityLevel::Safe);\n        assert!(matcher.matches(&tool_info));\n\n        let matcher = CapabilityMatcher::new().with_max_security_level(SecurityLevel::Restricted);\n        assert!(matcher.matches(&tool_info)); // Safe <= Restricted\n\n        // Test capability match\n        let matcher = CapabilityMatcher::new()\n            .with_capability(\"supports_async\".to_string(), serde_json::json!(true));\n        assert!(matcher.matches(&tool_info));\n\n        let matcher = CapabilityMatcher::new()\n            .with_capability(\"supports_async\".to_string(), serde_json::json!(false));\n        assert!(!matcher.matches(&tool_info));\n\n        // Test search terms\n        let matcher = CapabilityMatcher::new().with_search_terms(vec![\"test\".to_string()]);\n        assert!(matcher.matches(&tool_info));\n\n        let matcher = CapabilityMatcher::new().with_search_terms(vec![\"nonexistent\".to_string()]);\n        assert!(!matcher.matches(&tool_info));\n    }\n}\n","traces":[{"line":55,"address":[],"length":0,"stats":{"Line":10}},{"line":56,"address":[],"length":0,"stats":{"Line":10}},{"line":60,"address":[],"length":0,"stats":{"Line":3}},{"line":61,"address":[],"length":0,"stats":{"Line":3}},{"line":62,"address":[],"length":0,"stats":{"Line":3}},{"line":66,"address":[],"length":0,"stats":{"Line":4}},{"line":67,"address":[],"length":0,"stats":{"Line":4}},{"line":68,"address":[],"length":0,"stats":{"Line":4}},{"line":72,"address":[],"length":0,"stats":{"Line":2}},{"line":73,"address":[],"length":0,"stats":{"Line":2}},{"line":74,"address":[],"length":0,"stats":{"Line":2}},{"line":78,"address":[],"length":0,"stats":{"Line":2}},{"line":79,"address":[],"length":0,"stats":{"Line":2}},{"line":80,"address":[],"length":0,"stats":{"Line":2}},{"line":84,"address":[],"length":0,"stats":{"Line":16}},{"line":86,"address":[],"length":0,"stats":{"Line":22}},{"line":88,"address":[],"length":0,"stats":{"Line":3}},{"line":93,"address":[],"length":0,"stats":{"Line":21}},{"line":95,"address":[],"length":0,"stats":{"Line":2}},{"line":100,"address":[],"length":0,"stats":{"Line":14}},{"line":101,"address":[],"length":0,"stats":{"Line":4}},{"line":103,"address":[],"length":0,"stats":{"Line":1}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":10}},{"line":112,"address":[],"length":0,"stats":{"Line":2}},{"line":113,"address":[],"length":0,"stats":{"Line":2}},{"line":114,"address":[],"length":0,"stats":{"Line":5}},{"line":115,"address":[],"length":0,"stats":{"Line":2}},{"line":116,"address":[],"length":0,"stats":{"Line":1}},{"line":121,"address":[],"length":0,"stats":{"Line":9}},{"line":137,"address":[],"length":0,"stats":{"Line":7}},{"line":139,"address":[],"length":0,"stats":{"Line":7}},{"line":140,"address":[],"length":0,"stats":{"Line":7}},{"line":141,"address":[],"length":0,"stats":{"Line":7}},{"line":146,"address":[],"length":0,"stats":{"Line":13}},{"line":151,"address":[],"length":0,"stats":{"Line":14}},{"line":153,"address":[],"length":0,"stats":{"Line":12}},{"line":156,"address":[],"length":0,"stats":{"Line":12}},{"line":157,"address":[],"length":0,"stats":{"Line":12}},{"line":158,"address":[],"length":0,"stats":{"Line":12}},{"line":159,"address":[],"length":0,"stats":{"Line":12}},{"line":160,"address":[],"length":0,"stats":{"Line":12}},{"line":161,"address":[],"length":0,"stats":{"Line":12}},{"line":164,"address":[],"length":0,"stats":{"Line":12}},{"line":165,"address":[],"length":0,"stats":{"Line":12}},{"line":166,"address":[],"length":0,"stats":{"Line":12}},{"line":170,"address":[],"length":0,"stats":{"Line":12}},{"line":171,"address":[],"length":0,"stats":{"Line":12}},{"line":176,"address":[],"length":0,"stats":{"Line":12}},{"line":177,"address":[],"length":0,"stats":{"Line":12}},{"line":182,"address":[],"length":0,"stats":{"Line":24}},{"line":183,"address":[],"length":0,"stats":{"Line":12}},{"line":188,"address":[],"length":0,"stats":{"Line":24}},{"line":189,"address":[],"length":0,"stats":{"Line":12}},{"line":192,"address":[],"length":0,"stats":{"Line":12}},{"line":196,"address":[],"length":0,"stats":{"Line":26}},{"line":198,"address":[],"length":0,"stats":{"Line":13}},{"line":199,"address":[],"length":0,"stats":{"Line":13}},{"line":200,"address":[],"length":0,"stats":{"Line":1}},{"line":201,"address":[],"length":0,"stats":{"Line":1}},{"line":202,"address":[],"length":0,"stats":{"Line":1}},{"line":206,"address":[],"length":0,"stats":{"Line":12}},{"line":207,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":12}},{"line":215,"address":[],"length":0,"stats":{"Line":12}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":12}},{"line":224,"address":[],"length":0,"stats":{"Line":12}},{"line":225,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":12}},{"line":237,"address":[],"length":0,"stats":{"Line":6}},{"line":238,"address":[],"length":0,"stats":{"Line":6}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":6}},{"line":244,"address":[],"length":0,"stats":{"Line":6}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":4}},{"line":256,"address":[],"length":0,"stats":{"Line":4}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":4}},{"line":262,"address":[],"length":0,"stats":{"Line":4}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":8}},{"line":271,"address":[],"length":0,"stats":{"Line":2}},{"line":272,"address":[],"length":0,"stats":{"Line":1}},{"line":273,"address":[],"length":0,"stats":{"Line":1}},{"line":277,"address":[],"length":0,"stats":{"Line":8}},{"line":278,"address":[],"length":0,"stats":{"Line":8}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":2}},{"line":285,"address":[],"length":0,"stats":{"Line":1}},{"line":286,"address":[],"length":0,"stats":{"Line":2}},{"line":287,"address":[],"length":0,"stats":{"Line":1}},{"line":292,"address":[],"length":0,"stats":{"Line":2}},{"line":293,"address":[],"length":0,"stats":{"Line":1}},{"line":298,"address":[],"length":0,"stats":{"Line":2}},{"line":299,"address":[],"length":0,"stats":{"Line":1}},{"line":303,"address":[],"length":0,"stats":{"Line":2}},{"line":304,"address":[],"length":0,"stats":{"Line":1}},{"line":305,"address":[],"length":0,"stats":{"Line":2}},{"line":306,"address":[],"length":0,"stats":{"Line":1}},{"line":307,"address":[],"length":0,"stats":{"Line":1}},{"line":308,"address":[],"length":0,"stats":{"Line":1}},{"line":313,"address":[],"length":0,"stats":{"Line":1}},{"line":317,"address":[],"length":0,"stats":{"Line":2}},{"line":318,"address":[],"length":0,"stats":{"Line":2}},{"line":319,"address":[],"length":0,"stats":{"Line":2}},{"line":321,"address":[],"length":0,"stats":{"Line":1}},{"line":322,"address":[],"length":0,"stats":{"Line":1}},{"line":325,"address":[],"length":0,"stats":{"Line":2}},{"line":326,"address":[],"length":0,"stats":{"Line":5}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":1}},{"line":338,"address":[],"length":0,"stats":{"Line":1}},{"line":346,"address":[],"length":0,"stats":{"Line":0}},{"line":347,"address":[],"length":0,"stats":{"Line":0}}],"covered":104,"coverable":130},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-tools","src","search","mod.rs"],"content":"//! ABOUTME: Search tools for web, semantic, and code searching\n//! ABOUTME: Provides various search capabilities with rate limiting and result formatting\n\npub mod web_search;\n\npub use web_search::WebSearchTool;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-tools","src","search","web_search.rs"],"content":"//! ABOUTME: Web search tool implementation with multiple provider support\n//! ABOUTME: Provides rate-limited web search with Google, Bing, and DuckDuckGo\n\nuse async_trait::async_trait;\nuse llmspell_core::{\n    traits::{\n        base_agent::BaseAgent,\n        tool::{\n            ParameterDef, ParameterType, ResourceLimits, SecurityLevel, SecurityRequirements, Tool,\n            ToolCategory, ToolSchema,\n        },\n    },\n    types::{AgentInput, AgentOutput, ExecutionContext},\n    ComponentMetadata, LLMSpellError, Result,\n};\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\nuse tracing::{debug, info, warn};\n\n/// Search provider types\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]\npub enum SearchProvider {\n    Google,\n    Bing,\n    DuckDuckGo,\n}\n\nimpl std::fmt::Display for SearchProvider {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            SearchProvider::Google => write!(f, \"google\"),\n            SearchProvider::Bing => write!(f, \"bing\"),\n            SearchProvider::DuckDuckGo => write!(f, \"duckduckgo\"),\n        }\n    }\n}\n\nimpl std::str::FromStr for SearchProvider {\n    type Err = LLMSpellError;\n\n    fn from_str(s: &str) -> Result<Self> {\n        match s.to_lowercase().as_str() {\n            \"google\" => Ok(SearchProvider::Google),\n            \"bing\" => Ok(SearchProvider::Bing),\n            \"duckduckgo\" | \"ddg\" => Ok(SearchProvider::DuckDuckGo),\n            _ => Err(LLMSpellError::Validation {\n                message: format!(\"Unknown search provider: {}\", s),\n                field: Some(\"provider\".to_string()),\n            }),\n        }\n    }\n}\n\n/// Search result structure\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct SearchResult {\n    pub title: String,\n    pub url: String,\n    pub snippet: String,\n    pub provider: SearchProvider,\n    pub rank: usize,\n}\n\n/// Web search configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct WebSearchConfig {\n    /// Default search provider\n    pub default_provider: SearchProvider,\n    /// API keys for different providers\n    pub api_keys: HashMap<String, String>,\n    /// Maximum results per search\n    pub max_results: usize,\n    /// Rate limit (searches per minute)\n    pub rate_limit: u32,\n    /// Enable safe search\n    pub safe_search: bool,\n    /// Language preference\n    pub language: Option<String>,\n}\n\nimpl Default for WebSearchConfig {\n    fn default() -> Self {\n        Self {\n            default_provider: SearchProvider::DuckDuckGo, // No API key required\n            api_keys: HashMap::new(),\n            max_results: 10,\n            rate_limit: 60,\n            safe_search: true,\n            language: Some(\"en\".to_string()),\n        }\n    }\n}\n\n/// Rate limiter for search requests\nstruct RateLimiter {\n    requests: Vec<std::time::Instant>,\n    limit: u32,\n    window: std::time::Duration,\n}\n\nimpl RateLimiter {\n    fn new(limit: u32) -> Self {\n        Self {\n            requests: Vec::new(),\n            limit,\n            window: std::time::Duration::from_secs(60), // 1 minute window\n        }\n    }\n\n    fn check_and_record(&mut self) -> Result<()> {\n        let now = std::time::Instant::now();\n        let window_start = now - self.window;\n\n        // Remove old requests\n        self.requests.retain(|&time| time > window_start);\n\n        // Check if we're under the limit\n        if self.requests.len() >= self.limit as usize {\n            let wait_time = self.requests[0] + self.window - now;\n            return Err(LLMSpellError::Resource {\n                message: format!(\n                    \"Rate limit exceeded. Please wait {} seconds\",\n                    wait_time.as_secs()\n                ),\n                resource_type: Some(\"search_api\".to_string()),\n                source: None,\n            });\n        }\n\n        // Record new request\n        self.requests.push(now);\n        Ok(())\n    }\n}\n\n/// Web search tool implementation\npub struct WebSearchTool {\n    metadata: ComponentMetadata,\n    config: WebSearchConfig,\n    rate_limiter: Arc<RwLock<RateLimiter>>,\n}\n\nimpl WebSearchTool {\n    /// Create a new web search tool\n    pub fn new(config: WebSearchConfig) -> Self {\n        let rate_limit = config.rate_limit;\n        Self {\n            metadata: ComponentMetadata::new(\n                \"web-search-tool\".to_string(),\n                \"Search the web using multiple providers\".to_string(),\n            ),\n            config,\n            rate_limiter: Arc::new(RwLock::new(RateLimiter::new(rate_limit))),\n        }\n    }\n\n    /// Set API key for a provider\n    pub fn with_api_key(mut self, provider: &str, api_key: String) -> Self {\n        self.config.api_keys.insert(provider.to_string(), api_key);\n        self\n    }\n\n    /// Search using a specific provider\n    async fn search_with_provider(\n        &self,\n        query: &str,\n        provider: SearchProvider,\n    ) -> Result<Vec<SearchResult>> {\n        // Check rate limit\n        {\n            let mut limiter = self.rate_limiter.write().await;\n            limiter.check_and_record()?;\n        }\n\n        info!(\"Searching '{}' using provider: {}\", query, provider);\n\n        match provider {\n            SearchProvider::Google => self.search_google(query).await,\n            SearchProvider::Bing => self.search_bing(query).await,\n            SearchProvider::DuckDuckGo => self.search_duckduckgo(query).await,\n        }\n    }\n\n    /// Search using Google\n    async fn search_google(&self, query: &str) -> Result<Vec<SearchResult>> {\n        // Check if we have an API key\n        let _api_key =\n            self.config\n                .api_keys\n                .get(\"google\")\n                .ok_or_else(|| LLMSpellError::Configuration {\n                    message: \"Google API key not configured\".to_string(),\n                    source: None,\n                })?;\n\n        // TODO: In a real implementation, this would use the Google Custom Search API\n        // For now, we'll return mock results\n        warn!(\"Google search is not yet implemented, returning mock results\");\n        Ok(self.create_mock_results(query, SearchProvider::Google))\n    }\n\n    /// Search using Bing\n    async fn search_bing(&self, query: &str) -> Result<Vec<SearchResult>> {\n        // Check if we have an API key\n        let _api_key =\n            self.config\n                .api_keys\n                .get(\"bing\")\n                .ok_or_else(|| LLMSpellError::Configuration {\n                    message: \"Bing API key not configured\".to_string(),\n                    source: None,\n                })?;\n\n        // TODO: In a real implementation, this would use the Bing Web Search API\n        warn!(\"Bing search is not yet implemented, returning mock results\");\n        Ok(self.create_mock_results(query, SearchProvider::Bing))\n    }\n\n    /// Search using DuckDuckGo (no API key required)\n    async fn search_duckduckgo(&self, query: &str) -> Result<Vec<SearchResult>> {\n        // TODO: In a real implementation, this would use DuckDuckGo's instant answer API\n        // or scrape their HTML (respecting robots.txt)\n        warn!(\"DuckDuckGo search is not yet implemented, returning mock results\");\n        Ok(self.create_mock_results(query, SearchProvider::DuckDuckGo))\n    }\n\n    /// Create mock search results for testing\n    fn create_mock_results(&self, query: &str, provider: SearchProvider) -> Vec<SearchResult> {\n        (0..self.config.max_results.min(5))\n            .map(|i| SearchResult {\n                title: format!(\"Result {} for: {}\", i + 1, query),\n                url: format!(\"https://example.com/result{}\", i + 1),\n                snippet: format!(\n                    \"This is a mock search result for '{}' from {}. In a real implementation, \\\n                     this would contain actual search snippet text.\",\n                    query, provider\n                ),\n                provider,\n                rank: i + 1,\n            })\n            .collect()\n    }\n\n    /// Format results as text\n    fn format_results(&self, results: &[SearchResult]) -> String {\n        if results.is_empty() {\n            return \"No results found.\".to_string();\n        }\n\n        results\n            .iter()\n            .map(|r| format!(\"{}. {}\\n   {}\\n   {}\", r.rank, r.title, r.url, r.snippet))\n            .collect::<Vec<_>>()\n            .join(\"\\n\\n\")\n    }\n\n    /// Parse parameters from input\n    fn parse_parameters(\n        &self,\n        params: &serde_json::Value,\n    ) -> Result<(String, Option<SearchProvider>)> {\n        let params_map = params\n            .as_object()\n            .ok_or_else(|| LLMSpellError::Validation {\n                message: \"Parameters must be an object\".to_string(),\n                field: Some(\"parameters\".to_string()),\n            })?;\n\n        // Get query\n        let query = params_map\n            .get(\"query\")\n            .and_then(|v| v.as_str())\n            .ok_or_else(|| LLMSpellError::Validation {\n                message: \"Missing required parameter: query\".to_string(),\n                field: Some(\"query\".to_string()),\n            })?\n            .to_string();\n\n        // Get optional provider\n        let provider = params_map\n            .get(\"provider\")\n            .and_then(|v| v.as_str())\n            .map(|s| s.parse::<SearchProvider>())\n            .transpose()?;\n\n        Ok((query, provider))\n    }\n}\n\n#[async_trait]\nimpl BaseAgent for WebSearchTool {\n    fn metadata(&self) -> &ComponentMetadata {\n        &self.metadata\n    }\n\n    async fn execute(&self, input: AgentInput, _context: ExecutionContext) -> Result<AgentOutput> {\n        // Get parameters from input\n        let params =\n            input\n                .parameters\n                .get(\"parameters\")\n                .ok_or_else(|| LLMSpellError::Validation {\n                    message: \"Missing parameters\".to_string(),\n                    field: Some(\"parameters\".to_string()),\n                })?;\n\n        // Parse parameters\n        let (query, provider) = self.parse_parameters(params)?;\n        let search_provider = provider.unwrap_or(self.config.default_provider);\n\n        debug!(\n            \"Executing web search: query='{}', provider={}\",\n            query, search_provider\n        );\n\n        // Perform search\n        let results = self.search_with_provider(&query, search_provider).await?;\n\n        // Format results\n        let formatted = self.format_results(&results);\n\n        // Return as JSON and text\n        let output_json = serde_json::json!({\n            \"query\": query,\n            \"provider\": search_provider.to_string(),\n            \"count\": results.len(),\n            \"results\": results,\n        });\n\n        // Create metadata with the search results\n        let mut metadata = llmspell_core::types::OutputMetadata::default();\n        metadata\n            .extra\n            .insert(\"output_json\".to_string(), output_json);\n\n        Ok(AgentOutput::text(formatted).with_metadata(metadata))\n    }\n\n    async fn validate_input(&self, input: &AgentInput) -> Result<()> {\n        if input.parameters.is_empty() {\n            return Err(LLMSpellError::Validation {\n                message: \"No parameters provided\".to_string(),\n                field: Some(\"parameters\".to_string()),\n            });\n        }\n        Ok(())\n    }\n\n    async fn handle_error(&self, error: LLMSpellError) -> Result<AgentOutput> {\n        Ok(AgentOutput::text(format!(\"Web search error: {}\", error)))\n    }\n}\n\n#[async_trait]\nimpl Tool for WebSearchTool {\n    fn category(&self) -> ToolCategory {\n        ToolCategory::Web\n    }\n\n    fn security_level(&self) -> SecurityLevel {\n        SecurityLevel::Safe\n    }\n\n    fn schema(&self) -> ToolSchema {\n        ToolSchema::new(\n            \"web_search\".to_string(),\n            \"Search the web using Google, Bing, or DuckDuckGo\".to_string(),\n        )\n        .with_parameter(ParameterDef {\n            name: \"query\".to_string(),\n            param_type: ParameterType::String,\n            description: \"The search query\".to_string(),\n            required: true,\n            default: None,\n        })\n        .with_parameter(ParameterDef {\n            name: \"provider\".to_string(),\n            param_type: ParameterType::String,\n            description: \"Search provider: google, bing, or duckduckgo (optional)\".to_string(),\n            required: false,\n            default: Some(serde_json::json!(\"duckduckgo\")),\n        })\n        .with_returns(ParameterType::Object)\n    }\n\n    fn security_requirements(&self) -> SecurityRequirements {\n        SecurityRequirements::safe()\n            .with_network_access(\"*.google.com\")\n            .with_network_access(\"*.bing.com\")\n            .with_network_access(\"*.duckduckgo.com\")\n            .with_env_access(\"GOOGLE_SEARCH_API_KEY\")\n            .with_env_access(\"BING_SEARCH_API_KEY\")\n    }\n\n    fn resource_limits(&self) -> ResourceLimits {\n        ResourceLimits::default()\n            .with_network_limit(10 * 1024 * 1024) // 10MB/s\n            .with_cpu_limit(5000) // 5 seconds\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_search_provider_parsing() {\n        assert_eq!(\n            \"google\".parse::<SearchProvider>().unwrap(),\n            SearchProvider::Google\n        );\n        assert_eq!(\n            \"bing\".parse::<SearchProvider>().unwrap(),\n            SearchProvider::Bing\n        );\n        assert_eq!(\n            \"duckduckgo\".parse::<SearchProvider>().unwrap(),\n            SearchProvider::DuckDuckGo\n        );\n        assert_eq!(\n            \"ddg\".parse::<SearchProvider>().unwrap(),\n            SearchProvider::DuckDuckGo\n        );\n        assert!(\"invalid\".parse::<SearchProvider>().is_err());\n    }\n\n    #[tokio::test]\n    async fn test_rate_limiter() {\n        let mut limiter = RateLimiter::new(2); // 2 requests per minute\n\n        // First two requests should succeed\n        assert!(limiter.check_and_record().is_ok());\n        assert!(limiter.check_and_record().is_ok());\n\n        // Third request should fail\n        assert!(limiter.check_and_record().is_err());\n    }\n\n    #[tokio::test]\n    async fn test_web_search_tool_creation() {\n        let config = WebSearchConfig::default();\n        let tool = WebSearchTool::new(config);\n\n        assert_eq!(tool.category(), ToolCategory::Web);\n        assert_eq!(tool.security_level(), SecurityLevel::Safe);\n\n        let schema = tool.schema();\n        assert_eq!(schema.name, \"web_search\");\n        assert_eq!(schema.required_parameters(), vec![\"query\"]);\n    }\n\n    #[tokio::test]\n    async fn test_parameter_parsing() {\n        let config = WebSearchConfig::default();\n        let tool = WebSearchTool::new(config);\n\n        // Valid parameters\n        let params = serde_json::json!({\n            \"query\": \"rust programming\",\n            \"provider\": \"google\"\n        });\n        let (query, provider) = tool.parse_parameters(&params).unwrap();\n        assert_eq!(query, \"rust programming\");\n        assert_eq!(provider, Some(SearchProvider::Google));\n\n        // Missing query\n        let params = serde_json::json!({\n            \"provider\": \"google\"\n        });\n        assert!(tool.parse_parameters(&params).is_err());\n    }\n\n    #[tokio::test]\n    async fn test_mock_search_results() {\n        let config = WebSearchConfig {\n            max_results: 3,\n            ..Default::default()\n        };\n        let tool = WebSearchTool::new(config);\n\n        let results = tool.create_mock_results(\"test query\", SearchProvider::DuckDuckGo);\n        assert_eq!(results.len(), 3);\n        assert_eq!(results[0].rank, 1);\n        assert_eq!(results[0].provider, SearchProvider::DuckDuckGo);\n    }\n\n    #[tokio::test]\n    async fn test_search_execution() {\n        let config = WebSearchConfig::default();\n        let tool = WebSearchTool::new(config);\n\n        let input = AgentInput::text(\"search for rust\").with_parameter(\n            \"parameters\".to_string(),\n            serde_json::json!({\n                \"query\": \"rust programming language\"\n            }),\n        );\n\n        let context = ExecutionContext::with_conversation(\"test\".to_string());\n        let result = tool.execute(input, context).await.unwrap();\n\n        assert!(result\n            .text\n            .contains(\"Result 1 for: rust programming language\"));\n\n        // Check metadata\n        let metadata = result.metadata.extra.get(\"output_json\").unwrap();\n        assert_eq!(metadata[\"query\"], \"rust programming language\");\n        assert_eq!(metadata[\"provider\"], \"duckduckgo\");\n    }\n\n    #[tokio::test]\n    async fn test_rate_limiting() {\n        let config = WebSearchConfig {\n            rate_limit: 2, // Very low limit for testing\n            ..Default::default()\n        };\n        let tool = WebSearchTool::new(config);\n\n        // First two searches should work\n        for i in 0..2 {\n            let input = AgentInput::text(\"search\").with_parameter(\n                \"parameters\".to_string(),\n                serde_json::json!({\n                    \"query\": format!(\"test {}\", i)\n                }),\n            );\n            let context = ExecutionContext::with_conversation(\"test\".to_string());\n            assert!(tool.execute(input, context).await.is_ok());\n        }\n\n        // Third search should fail with rate limit\n        let input = AgentInput::text(\"search\").with_parameter(\n            \"parameters\".to_string(),\n            serde_json::json!({\n                \"query\": \"test 3\"\n            }),\n        );\n        let context = ExecutionContext::with_conversation(\"test\".to_string());\n        let result = tool.execute(input, context).await;\n        assert!(result.is_err());\n\n        match result.unwrap_err() {\n            LLMSpellError::Resource { message, .. } => {\n                assert!(message.contains(\"Rate limit exceeded\"));\n            }\n            _ => panic!(\"Expected Resource error\"),\n        }\n    }\n}\n","traces":[{"line":31,"address":[],"length":0,"stats":{"Line":27}},{"line":32,"address":[],"length":0,"stats":{"Line":27}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":27}},{"line":43,"address":[],"length":0,"stats":{"Line":6}},{"line":44,"address":[],"length":0,"stats":{"Line":6}},{"line":45,"address":[],"length":0,"stats":{"Line":8}},{"line":46,"address":[],"length":0,"stats":{"Line":5}},{"line":47,"address":[],"length":0,"stats":{"Line":7}},{"line":48,"address":[],"length":0,"stats":{"Line":1}},{"line":49,"address":[],"length":0,"stats":{"Line":1}},{"line":50,"address":[],"length":0,"stats":{"Line":1}},{"line":84,"address":[],"length":0,"stats":{"Line":7}},{"line":87,"address":[],"length":0,"stats":{"Line":7}},{"line":91,"address":[],"length":0,"stats":{"Line":7}},{"line":104,"address":[],"length":0,"stats":{"Line":8}},{"line":106,"address":[],"length":0,"stats":{"Line":8}},{"line":108,"address":[],"length":0,"stats":{"Line":8}},{"line":112,"address":[],"length":0,"stats":{"Line":8}},{"line":113,"address":[],"length":0,"stats":{"Line":8}},{"line":114,"address":[],"length":0,"stats":{"Line":8}},{"line":117,"address":[],"length":0,"stats":{"Line":22}},{"line":120,"address":[],"length":0,"stats":{"Line":8}},{"line":121,"address":[],"length":0,"stats":{"Line":2}},{"line":122,"address":[],"length":0,"stats":{"Line":2}},{"line":123,"address":[],"length":0,"stats":{"Line":2}},{"line":124,"address":[],"length":0,"stats":{"Line":2}},{"line":125,"address":[],"length":0,"stats":{"Line":2}},{"line":127,"address":[],"length":0,"stats":{"Line":2}},{"line":128,"address":[],"length":0,"stats":{"Line":2}},{"line":133,"address":[],"length":0,"stats":{"Line":6}},{"line":134,"address":[],"length":0,"stats":{"Line":6}},{"line":147,"address":[],"length":0,"stats":{"Line":7}},{"line":148,"address":[],"length":0,"stats":{"Line":7}},{"line":150,"address":[],"length":0,"stats":{"Line":7}},{"line":155,"address":[],"length":0,"stats":{"Line":7}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":5}},{"line":173,"address":[],"length":0,"stats":{"Line":10}},{"line":174,"address":[],"length":0,"stats":{"Line":6}},{"line":177,"address":[],"length":0,"stats":{"Line":4}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":4}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":8}},{"line":225,"address":[],"length":0,"stats":{"Line":4}},{"line":226,"address":[],"length":0,"stats":{"Line":4}},{"line":230,"address":[],"length":0,"stats":{"Line":5}},{"line":231,"address":[],"length":0,"stats":{"Line":5}},{"line":232,"address":[],"length":0,"stats":{"Line":28}},{"line":233,"address":[],"length":0,"stats":{"Line":23}},{"line":234,"address":[],"length":0,"stats":{"Line":23}},{"line":235,"address":[],"length":0,"stats":{"Line":23}},{"line":236,"address":[],"length":0,"stats":{"Line":23}},{"line":237,"address":[],"length":0,"stats":{"Line":23}},{"line":238,"address":[],"length":0,"stats":{"Line":23}},{"line":240,"address":[],"length":0,"stats":{"Line":23}},{"line":241,"address":[],"length":0,"stats":{"Line":23}},{"line":247,"address":[],"length":0,"stats":{"Line":4}},{"line":248,"address":[],"length":0,"stats":{"Line":4}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":4}},{"line":254,"address":[],"length":0,"stats":{"Line":24}},{"line":260,"address":[],"length":0,"stats":{"Line":7}},{"line":264,"address":[],"length":0,"stats":{"Line":14}},{"line":266,"address":[],"length":0,"stats":{"Line":7}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":6}},{"line":274,"address":[],"length":0,"stats":{"Line":6}},{"line":275,"address":[],"length":0,"stats":{"Line":1}},{"line":276,"address":[],"length":0,"stats":{"Line":1}},{"line":277,"address":[],"length":0,"stats":{"Line":1}},{"line":282,"address":[],"length":0,"stats":{"Line":6}},{"line":284,"address":[],"length":0,"stats":{"Line":1}},{"line":285,"address":[],"length":0,"stats":{"Line":1}},{"line":294,"address":[],"length":0,"stats":{"Line":4}},{"line":295,"address":[],"length":0,"stats":{"Line":4}},{"line":298,"address":[],"length":0,"stats":{"Line":5}},{"line":300,"address":[],"length":0,"stats":{"Line":5}},{"line":301,"address":[],"length":0,"stats":{"Line":5}},{"line":302,"address":[],"length":0,"stats":{"Line":5}},{"line":304,"address":[],"length":0,"stats":{"Line":5}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":5}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":5}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":0}},{"line":344,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":3}},{"line":359,"address":[],"length":0,"stats":{"Line":3}},{"line":362,"address":[],"length":0,"stats":{"Line":5}},{"line":363,"address":[],"length":0,"stats":{"Line":5}},{"line":366,"address":[],"length":0,"stats":{"Line":5}},{"line":368,"address":[],"length":0,"stats":{"Line":5}},{"line":369,"address":[],"length":0,"stats":{"Line":5}},{"line":371,"address":[],"length":0,"stats":{"Line":5}},{"line":372,"address":[],"length":0,"stats":{"Line":5}},{"line":373,"address":[],"length":0,"stats":{"Line":5}},{"line":374,"address":[],"length":0,"stats":{"Line":5}},{"line":375,"address":[],"length":0,"stats":{"Line":5}},{"line":376,"address":[],"length":0,"stats":{"Line":5}},{"line":378,"address":[],"length":0,"stats":{"Line":5}},{"line":379,"address":[],"length":0,"stats":{"Line":5}},{"line":380,"address":[],"length":0,"stats":{"Line":5}},{"line":381,"address":[],"length":0,"stats":{"Line":5}},{"line":382,"address":[],"length":0,"stats":{"Line":5}},{"line":383,"address":[],"length":0,"stats":{"Line":5}},{"line":385,"address":[],"length":0,"stats":{"Line":5}},{"line":388,"address":[],"length":0,"stats":{"Line":4}},{"line":389,"address":[],"length":0,"stats":{"Line":4}},{"line":397,"address":[],"length":0,"stats":{"Line":2}},{"line":398,"address":[],"length":0,"stats":{"Line":2}},{"line":399,"address":[],"length":0,"stats":{"Line":2}}],"covered":103,"coverable":140},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-tools","tests","integration_test.rs"],"content":"//! Integration tests for llmspell-tools\n\nuse llmspell_core::{\n    traits::tool::ToolCategory,\n    types::{AgentInput, ExecutionContext},\n};\nuse llmspell_tools::{search::web_search::WebSearchConfig, ToolRegistry, WebSearchTool};\n\n#[tokio::test]\nasync fn test_web_search_tool_registration() {\n    // Create registry\n    let registry = ToolRegistry::new();\n\n    // Create and register web search tool\n    let config = WebSearchConfig::default();\n    let search_tool = WebSearchTool::new(config);\n\n    registry\n        .register(\"web_search\".to_string(), search_tool)\n        .await\n        .unwrap();\n\n    // Verify tool is registered\n    assert!(registry.contains_tool(\"web_search\").await);\n\n    // Get tool info\n    let tool_info = registry.get_tool_info(\"web_search\").await.unwrap();\n    assert_eq!(tool_info.name, \"web_search\");\n    assert_eq!(tool_info.category, ToolCategory::Web);\n\n    // Test discovery by category\n    let web_tools = registry.get_tools_by_category(&ToolCategory::Web).await;\n    assert!(web_tools.contains(&\"web_search\".to_string()));\n}\n\n#[tokio::test]\nasync fn test_web_search_tool_execution_through_registry() {\n    // Create registry\n    let registry = ToolRegistry::new();\n\n    // Register web search tool\n    let config = WebSearchConfig::default();\n    let search_tool = WebSearchTool::new(config);\n    registry\n        .register(\"web_search\".to_string(), search_tool)\n        .await\n        .unwrap();\n\n    // Get tool from registry\n    let tool = registry.get_tool(\"web_search\").await.unwrap();\n\n    // Execute search\n    let input = AgentInput::text(\"search for rust\").with_parameter(\n        \"parameters\".to_string(),\n        serde_json::json!({\n            \"query\": \"rust programming\"\n        }),\n    );\n\n    let context = ExecutionContext::with_conversation(\"test\".to_string());\n    let result = tool.execute(input, context).await.unwrap();\n\n    // Verify result\n    assert!(result.text.contains(\"Result 1 for: rust programming\"));\n    assert!(!result.metadata.extra.is_empty());\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-tools","tests","json_processor_integration.rs"],"content":"//! Integration tests for JsonProcessorTool\n\nuse llmspell_core::{\n    traits::{base_agent::BaseAgent, tool::Tool},\n    types::{AgentInput, ExecutionContext},\n};\nuse llmspell_tools::JsonProcessorTool;\nuse serde_json::json;\n\n#[tokio::test]\nasync fn test_json_processor_complex_workflow() {\n    let tool = JsonProcessorTool::default();\n\n    // Test 1: Complex nested JSON transformation\n    let complex_json = json!({\n        \"company\": {\n            \"name\": \"TechCorp\",\n            \"employees\": [\n                {\"name\": \"Alice\", \"department\": \"Engineering\", \"salary\": 120000},\n                {\"name\": \"Bob\", \"department\": \"Sales\", \"salary\": 90000},\n                {\"name\": \"Charlie\", \"department\": \"Engineering\", \"salary\": 110000}\n            ],\n            \"departments\": {\n                \"Engineering\": {\"budget\": 5000000, \"head\": \"Alice\"},\n                \"Sales\": {\"budget\": 2000000, \"head\": \"David\"}\n            }\n        }\n    });\n\n    // Extract company name\n    let input = AgentInput::text(\"extract company name\").with_parameter(\n        \"parameters\".to_string(),\n        json!({\n            \"operation\": \"transform\",\n            \"input\": complex_json.clone(),\n            \"query\": \".company.name\"\n        }),\n    );\n\n    let output = tool\n        .execute(input, ExecutionContext::default())\n        .await\n        .unwrap();\n    assert_eq!(output.text.trim(), \"\\\"TechCorp\\\"\");\n\n    // Extract all employee names\n    let input = AgentInput::text(\"extract employees\").with_parameter(\n        \"parameters\".to_string(),\n        json!({\n            \"operation\": \"transform\",\n            \"input\": complex_json.clone(),\n            \"query\": \".company.employees\"\n        }),\n    );\n\n    let output = tool\n        .execute(input, ExecutionContext::default())\n        .await\n        .unwrap();\n    let employees: serde_json::Value = serde_json::from_str(&output.text).unwrap();\n    assert_eq!(employees.as_array().unwrap().len(), 3);\n}\n\n#[tokio::test]\nasync fn test_json_processor_schema_validation_complex() {\n    let tool = JsonProcessorTool::default();\n\n    // Complex schema with nested objects and arrays\n    let schema = json!({\n        \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n        \"type\": \"object\",\n        \"properties\": {\n            \"product\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"id\": {\"type\": \"integer\", \"minimum\": 1},\n                    \"name\": {\"type\": \"string\", \"minLength\": 1},\n                    \"price\": {\"type\": \"number\", \"minimum\": 0},\n                    \"tags\": {\n                        \"type\": \"array\",\n                        \"items\": {\"type\": \"string\"},\n                        \"minItems\": 1\n                    }\n                },\n                \"required\": [\"id\", \"name\", \"price\"]\n            }\n        },\n        \"required\": [\"product\"]\n    });\n\n    // Valid product\n    let valid_product = json!({\n        \"product\": {\n            \"id\": 123,\n            \"name\": \"Laptop\",\n            \"price\": 999.99,\n            \"tags\": [\"electronics\", \"computers\"]\n        }\n    });\n\n    let input = AgentInput::text(\"validate product\").with_parameter(\n        \"parameters\".to_string(),\n        json!({\n            \"operation\": \"validate\",\n            \"input\": valid_product,\n            \"schema\": schema.clone()\n        }),\n    );\n\n    let output = tool\n        .execute(input, ExecutionContext::default())\n        .await\n        .unwrap();\n    let metadata = &output.metadata;\n    let result = metadata.extra.get(\"result\").unwrap();\n    let validation = result.get(\"validation\").unwrap();\n    assert_eq!(validation.get(\"is_valid\").unwrap(), true);\n\n    // Invalid product (missing required field)\n    let invalid_product = json!({\n        \"product\": {\n            \"id\": 123,\n            \"name\": \"Laptop\"\n            // missing price\n        }\n    });\n\n    let input = AgentInput::text(\"validate invalid product\").with_parameter(\n        \"parameters\".to_string(),\n        json!({\n            \"operation\": \"validate\",\n            \"input\": invalid_product,\n            \"schema\": schema\n        }),\n    );\n\n    let output = tool\n        .execute(input, ExecutionContext::default())\n        .await\n        .unwrap();\n    let metadata = &output.metadata;\n    let result = metadata.extra.get(\"result\").unwrap();\n    let validation = result.get(\"validation\").unwrap();\n    assert_eq!(validation.get(\"is_valid\").unwrap(), false);\n\n    let errors = validation.get(\"errors\").unwrap().as_array().unwrap();\n    assert!(!errors.is_empty());\n}\n\n#[tokio::test]\nasync fn test_json_processor_array_filtering() {\n    let tool = JsonProcessorTool::default();\n\n    let products = json!([\n        {\"name\": \"Laptop\", \"price\": 999, \"category\": \"electronics\"},\n        {\"name\": \"Book\", \"price\": 15, \"category\": \"books\"},\n        {\"name\": \"Phone\", \"price\": 699, \"category\": \"electronics\"},\n        {\"name\": \"Pen\", \"price\": 2, \"category\": \"stationery\"}\n    ]);\n\n    // Filter by category\n    let input = AgentInput::text(\"filter electronics\").with_parameter(\n        \"parameters\".to_string(),\n        json!({\n            \"operation\": \"filter\",\n            \"input\": products,\n            \"query\": \".category == \\\"electronics\\\"\"\n        }),\n    );\n\n    let output = tool\n        .execute(input, ExecutionContext::default())\n        .await\n        .unwrap();\n    let filtered: serde_json::Value = serde_json::from_str(&output.text).unwrap();\n    let items = filtered.as_array().unwrap();\n    assert_eq!(items.len(), 2);\n    assert!(items.iter().all(|item| item[\"category\"] == \"electronics\"));\n}\n\n#[tokio::test]\nasync fn test_json_processor_merge_complex() {\n    let tool = JsonProcessorTool::default();\n\n    let configs = json!([\n        {\n            \"database\": {\n                \"host\": \"localhost\",\n                \"port\": 5432\n            },\n            \"cache\": {\n                \"enabled\": true\n            }\n        },\n        {\n            \"database\": {\n                \"username\": \"admin\",\n                \"password\": \"secret\"\n            },\n            \"api\": {\n                \"version\": \"v2\"\n            }\n        },\n        {\n            \"cache\": {\n                \"ttl\": 3600\n            }\n        }\n    ]);\n\n    let input = AgentInput::text(\"merge configs\").with_parameter(\n        \"parameters\".to_string(),\n        json!({\n            \"operation\": \"merge\",\n            \"input\": configs\n        }),\n    );\n\n    let output = tool\n        .execute(input, ExecutionContext::default())\n        .await\n        .unwrap();\n    let merged: serde_json::Value = serde_json::from_str(&output.text).unwrap();\n\n    // Check merged structure - note that merge is shallow, so later objects overwrite earlier ones\n    // The last \"database\" object only has username/password, so it overwrites the entire database object\n    assert_eq!(merged[\"database\"][\"username\"], \"admin\");\n    assert_eq!(merged[\"database\"][\"password\"], \"secret\");\n    assert!(merged[\"database\"][\"host\"].is_null()); // host was overwritten\n\n    // The last \"cache\" object only has ttl, so it overwrites the entire cache object\n    assert_eq!(merged[\"cache\"][\"ttl\"], 3600);\n    assert!(merged[\"cache\"][\"enabled\"].is_null()); // enabled was overwritten\n\n    assert_eq!(merged[\"api\"][\"version\"], \"v2\");\n}\n\n#[tokio::test]\nasync fn test_json_processor_tool_metadata() {\n    let tool = JsonProcessorTool::default();\n\n    // Test tool metadata\n    assert_eq!(\n        tool.category(),\n        llmspell_core::traits::tool::ToolCategory::Data\n    );\n    assert_eq!(\n        tool.security_level(),\n        llmspell_core::traits::tool::SecurityLevel::Safe\n    );\n\n    let schema = tool.schema();\n    assert_eq!(schema.name, \"json_processor\");\n    assert!(schema.description.contains(\"JSON\"));\n\n    // Check parameters\n    let params = &schema.parameters;\n    assert!(params.iter().any(|p| p.name == \"operation\"));\n    assert!(params.iter().any(|p| p.name == \"input\"));\n    assert!(params.iter().any(|p| p.name == \"query\"));\n    assert!(params.iter().any(|p| p.name == \"schema\"));\n}\n\n#[tokio::test]\nasync fn test_json_processor_error_handling() {\n    let tool = JsonProcessorTool::default();\n\n    // Test invalid operation\n    let input = AgentInput::text(\"invalid op\").with_parameter(\n        \"parameters\".to_string(),\n        json!({\n            \"operation\": \"invalid_operation\",\n            \"input\": {\"test\": \"value\"}\n        }),\n    );\n\n    let result = tool.execute(input, ExecutionContext::default()).await;\n    assert!(result.is_err());\n\n    // Test missing input\n    let input = AgentInput::text(\"no input\").with_parameter(\n        \"parameters\".to_string(),\n        json!({\n            \"operation\": \"format\"\n        }),\n    );\n\n    let result = tool.execute(input, ExecutionContext::default()).await;\n    assert!(result.is_err());\n\n    // Test invalid query for transform\n    let input = AgentInput::text(\"bad query\").with_parameter(\n        \"parameters\".to_string(),\n        json!({\n            \"operation\": \"transform\",\n            \"input\": {\"test\": \"value\"},\n            \"query\": \".nonexistent.field\"\n        }),\n    );\n\n    let result = tool.execute(input, ExecutionContext::default()).await;\n    assert!(result.is_err());\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-utils","benches","file_utils_benchmarks.rs"],"content":"// ABOUTME: Performance benchmarks for file_utils module\n// ABOUTME: Measures performance of path operations, file I/O, and directory management\n\nuse criterion::{black_box, criterion_group, criterion_main, Criterion};\nuse llmspell_utils::file_utils::{\n    copy_file, ensure_dir, expand_path, is_absolute_path, join_paths, normalize_path, parent_dir,\n    read_file, write_file, write_file_atomic,\n};\nuse std::env;\nuse std::path::Path;\n\nfn bench_normalize_path(c: &mut Criterion) {\n    c.bench_function(\"normalize_path\", |b| {\n        b.iter(|| normalize_path(black_box(Path::new(\"/home/user/../user/./docs/./file.txt\"))));\n    });\n}\n\nfn bench_expand_path(c: &mut Criterion) {\n    env::set_var(\"BENCH_VAR\", \"/test/path\");\n\n    c.bench_function(\"expand_path\", |b| {\n        b.iter(|| expand_path(black_box(\"$BENCH_VAR/subdir/file.txt\")).unwrap());\n    });\n\n    env::remove_var(\"BENCH_VAR\");\n}\n\nfn bench_join_paths(c: &mut Criterion) {\n    c.bench_function(\"join_paths\", |b| {\n        b.iter(|| {\n            let paths: Vec<&Path> = vec![\n                Path::new(\"/home\"),\n                Path::new(\"user\"),\n                Path::new(\"documents\"),\n                Path::new(\"project\"),\n            ];\n            join_paths(black_box(&paths))\n        });\n    });\n}\n\nfn bench_is_absolute_path(c: &mut Criterion) {\n    c.bench_function(\"is_absolute_path\", |b| {\n        b.iter(|| is_absolute_path(black_box(Path::new(\"/home/user/documents\"))));\n    });\n}\n\nfn bench_parent_dir(c: &mut Criterion) {\n    c.bench_function(\"parent_dir\", |b| {\n        b.iter(|| parent_dir(black_box(Path::new(\"/home/user/documents/file.txt\"))));\n    });\n}\n\nfn bench_write_file(c: &mut Criterion) {\n    let temp_dir = std::env::temp_dir();\n    let test_file = temp_dir.join(\"llmspell_bench_write\");\n    let data = vec![b'x'; 1024]; // 1KB of data\n\n    c.bench_function(\"write_file_1kb\", |b| {\n        b.iter(|| write_file(black_box(&test_file), black_box(&data)).unwrap());\n    });\n\n    // Cleanup\n    let _ = std::fs::remove_file(&test_file);\n}\n\nfn bench_write_file_atomic(c: &mut Criterion) {\n    let temp_dir = std::env::temp_dir();\n    let test_file = temp_dir.join(\"llmspell_bench_atomic\");\n    let data = vec![b'x'; 1024]; // 1KB of data\n\n    c.bench_function(\"write_file_atomic_1kb\", |b| {\n        b.iter(|| write_file_atomic(black_box(&test_file), black_box(&data)).unwrap());\n    });\n\n    // Cleanup\n    let _ = std::fs::remove_file(&test_file);\n}\n\nfn bench_read_file(c: &mut Criterion) {\n    let temp_dir = std::env::temp_dir();\n    let test_file = temp_dir.join(\"llmspell_bench_read\");\n    let data = vec![b'x'; 1024]; // 1KB of data\n\n    // Create file\n    write_file(&test_file, &data).unwrap();\n\n    c.bench_function(\"read_file_1kb\", |b| {\n        b.iter(|| read_file(black_box(&test_file)).unwrap());\n    });\n\n    // Cleanup\n    let _ = std::fs::remove_file(&test_file);\n}\n\nfn bench_ensure_dir(c: &mut Criterion) {\n    let temp_dir = std::env::temp_dir();\n    let test_dir = temp_dir.join(\"llmspell_bench_dir\");\n\n    // Remove if exists\n    let _ = std::fs::remove_dir_all(&test_dir);\n\n    c.bench_function(\"ensure_dir_new\", |b| {\n        b.iter(|| {\n            ensure_dir(black_box(&test_dir)).unwrap();\n            // Remove for next iteration\n            std::fs::remove_dir(&test_dir).unwrap();\n        });\n    });\n\n    // Test with existing directory\n    ensure_dir(&test_dir).unwrap();\n\n    c.bench_function(\"ensure_dir_existing\", |b| {\n        b.iter(|| ensure_dir(black_box(&test_dir)).unwrap());\n    });\n\n    // Cleanup\n    let _ = std::fs::remove_dir(&test_dir);\n}\n\nfn bench_copy_file(c: &mut Criterion) {\n    let temp_dir = std::env::temp_dir();\n    let source = temp_dir.join(\"llmspell_bench_src\");\n    let dest = temp_dir.join(\"llmspell_bench_dst\");\n    let data = vec![b'x'; 1024]; // 1KB of data\n\n    // Create source file\n    write_file(&source, &data).unwrap();\n\n    c.bench_function(\"copy_file_1kb\", |b| {\n        b.iter(|| {\n            copy_file(black_box(&source), black_box(&dest)).unwrap();\n            // Remove dest for next iteration\n            std::fs::remove_file(&dest).unwrap();\n        });\n    });\n\n    // Cleanup\n    let _ = std::fs::remove_file(&source);\n}\n\ncriterion_group!(\n    benches,\n    bench_normalize_path,\n    bench_expand_path,\n    bench_join_paths,\n    bench_is_absolute_path,\n    bench_parent_dir,\n    bench_write_file,\n    bench_write_file_atomic,\n    bench_read_file,\n    bench_ensure_dir,\n    bench_copy_file\n);\n\ncriterion_main!(benches);\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-utils","src","async_utils.rs"],"content":"// ABOUTME: Async operation utilities including timeouts, cancellation, and concurrency helpers\n// ABOUTME: Provides common patterns for managing async tasks in the LLMSpell framework\n\n//! Async operation utilities and helpers\n//!\n//! This module provides utilities for working with asynchronous operations,\n//! including timeout management, cancellation tokens, and concurrency helpers.\n\nuse futures::stream::{FuturesUnordered, StreamExt};\nuse std::fmt::Debug;\nuse std::future::Future;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\nuse std::time::Duration;\nuse thiserror::Error;\nuse tokio::time;\n\n/// Represents a cancellable async operation\npub struct Cancellable;\n\n/// Errors that can occur during async operations\n#[derive(Debug, Error)]\npub enum AsyncError {\n    /// Operation timed out\n    #[error(\"Operation timed out after {0:?}\")]\n    Timeout(Duration),\n\n    /// Retry limit exceeded\n    #[error(\"Retry limit exceeded after {attempts} attempts\")]\n    RetryLimitExceeded {\n        /// Number of attempts made before giving up\n        attempts: usize,\n    },\n\n    /// Operation was cancelled\n    #[error(\"Operation was cancelled\")]\n    Cancelled,\n}\n\n/// Result type for async operations\npub type AsyncResult<T> = Result<T, AsyncError>;\n\n/// Configuration for retry operations\n#[derive(Debug, Clone)]\npub struct RetryConfig {\n    /// Maximum number of attempts\n    pub max_attempts: usize,\n    /// Initial delay between retries\n    pub initial_delay: Duration,\n    /// Factor to multiply delay by after each attempt\n    pub backoff_factor: f64,\n    /// Maximum delay between retries\n    pub max_delay: Duration,\n    /// Add jitter to retry delays\n    pub jitter: bool,\n}\n\nimpl Default for RetryConfig {\n    fn default() -> Self {\n        Self {\n            max_attempts: 3,\n            initial_delay: Duration::from_millis(100),\n            backoff_factor: 2.0,\n            max_delay: Duration::from_secs(10),\n            jitter: true,\n        }\n    }\n}\n\n/// Execute an async operation with a timeout\n///\n/// # Errors\n///\n/// Returns an error if the operation times out\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_utils::async_utils::timeout;\n/// use std::time::Duration;\n///\n/// # async fn example() -> Result<(), Box<dyn std::error::Error>> {\n/// let result = timeout(\n///     Duration::from_secs(1),\n///     async { 42 }\n/// ).await?;\n/// assert_eq!(result, 42);\n/// # Ok(())\n/// # }\n/// ```\npub async fn timeout<T, F>(duration: Duration, future: F) -> Result<T, time::error::Elapsed>\nwhere\n    F: Future<Output = T>,\n{\n    time::timeout(duration, future).await\n}\n\n/// Execute an async operation with a timeout, returning a default value on timeout\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_utils::async_utils::timeout_with_default;\n/// use std::time::Duration;\n///\n/// # async fn example() {\n/// let result = timeout_with_default(\n///     Duration::from_secs(1),\n///     async { 42 },\n///     0\n/// ).await;\n/// assert_eq!(result, 42);\n/// # }\n/// ```\npub async fn timeout_with_default<T, F>(duration: Duration, future: F, default: T) -> T\nwhere\n    F: Future<Output = T>,\n{\n    match time::timeout(duration, future).await {\n        Ok(value) => value,\n        Err(_) => default,\n    }\n}\n\n/// Retry an async operation with exponential backoff\n///\n/// # Errors\n///\n/// Returns `AsyncError::RetryLimitExceeded` if all attempts fail\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_utils::async_utils::{retry_async, RetryConfig};\n/// use std::sync::atomic::{AtomicUsize, Ordering};\n/// use std::sync::Arc;\n///\n/// # async fn example() -> Result<(), Box<dyn std::error::Error>> {\n/// let counter = Arc::new(AtomicUsize::new(0));\n/// let counter_clone = counter.clone();\n///\n/// let result = retry_async(RetryConfig::default(), || {\n///     let count = counter_clone.fetch_add(1, Ordering::SeqCst);\n///     async move {\n///         if count < 2 {\n///             Err(\"Not ready yet\")\n///         } else {\n///             Ok(\"Success!\")\n///         }\n///     }\n/// }).await?;\n///\n/// assert_eq!(result, \"Success!\");\n/// assert_eq!(counter.load(Ordering::SeqCst), 3);\n/// # Ok(())\n/// # }\n/// ```\n#[allow(\n    clippy::cast_precision_loss,\n    clippy::cast_possible_truncation,\n    clippy::cast_sign_loss\n)]\npub async fn retry_async<T, E, F, Fut>(config: RetryConfig, mut f: F) -> Result<T, AsyncError>\nwhere\n    F: FnMut() -> Fut,\n    Fut: Future<Output = Result<T, E>>,\n    E: Debug,\n{\n    let mut attempt = 0;\n    let mut delay = config.initial_delay;\n\n    loop {\n        attempt += 1;\n\n        match f().await {\n            Ok(value) => return Ok(value),\n            Err(e) => {\n                if attempt >= config.max_attempts {\n                    tracing::error!(\n                        \"Retry limit exceeded after {} attempts. Last error: {:?}\",\n                        attempt,\n                        e\n                    );\n                    return Err(AsyncError::RetryLimitExceeded { attempts: attempt });\n                }\n\n                tracing::debug!(\n                    \"Attempt {} failed with error: {:?}. Retrying in {:?}\",\n                    attempt,\n                    e,\n                    delay\n                );\n\n                // Add jitter if configured\n                let actual_delay = if config.jitter {\n                    let jitter_range = delay.as_millis() as f64 * 0.1;\n                    let jitter = (rand::random::<f64>() - 0.5) * 2.0 * jitter_range;\n                    Duration::from_millis((delay.as_millis() as f64 + jitter).max(0.0) as u64)\n                } else {\n                    delay\n                };\n\n                time::sleep(actual_delay).await;\n\n                // Calculate next delay with exponential backoff\n                delay = Duration::from_millis(\n                    ((delay.as_millis() as f64 * config.backoff_factor) as u64)\n                        .min(config.max_delay.as_millis() as u64),\n                );\n            }\n        }\n    }\n}\n\n/// Map a function over async operations with a concurrency limit\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_utils::async_utils::concurrent_map;\n///\n/// # async fn example() -> Result<(), Box<dyn std::error::Error>> {\n/// let numbers = vec![1, 2, 3, 4, 5];\n/// let results = concurrent_map(\n///     numbers.into_iter(),\n///     2, // Max 2 concurrent operations\n///     |n| async move { n * 2 }\n/// ).await;\n///\n/// assert_eq!(results, vec![2, 4, 6, 8, 10]);\n/// # Ok(())\n/// # }\n/// ```\npub async fn concurrent_map<I, F, Fut, T, U>(items: I, concurrency_limit: usize, f: F) -> Vec<U>\nwhere\n    I: IntoIterator<Item = T>,\n    F: Fn(T) -> Fut + Clone,\n    Fut: Future<Output = U>,\n    T: Send + 'static,\n    U: Send + 'static,\n{\n    let mut futures = FuturesUnordered::new();\n    let mut items = items.into_iter();\n    let mut results = Vec::new();\n    let mut active_count = 0;\n    let mut item_index = 0;\n    let mut result_map = std::collections::HashMap::new();\n\n    loop {\n        // Fill up to concurrency limit\n        while active_count < concurrency_limit {\n            if let Some(item) = items.next() {\n                let fut = f.clone()(item);\n                let index = item_index;\n                item_index += 1;\n                active_count += 1;\n\n                futures.push(async move {\n                    let result = fut.await;\n                    (index, result)\n                });\n            } else {\n                break;\n            }\n        }\n\n        // If no futures are active and no more items, we're done\n        if active_count == 0 {\n            break;\n        }\n\n        // Wait for a future to complete\n        if let Some((index, result)) = futures.next().await {\n            active_count -= 1;\n            result_map.insert(index, result);\n        }\n    }\n\n    // Reconstruct results in original order\n    for i in 0..item_index {\n        if let Some(result) = result_map.remove(&i) {\n            results.push(result);\n        }\n    }\n\n    results\n}\n\n/// A future that can be cancelled\npub struct CancellableFuture<F> {\n    future: F,\n    cancelled: bool,\n}\n\nimpl<F> CancellableFuture<F> {\n    /// Create a new cancellable future\n    pub fn new(future: F) -> Self {\n        Self {\n            future,\n            cancelled: false,\n        }\n    }\n\n    /// Cancel this future\n    pub fn cancel(&mut self) {\n        self.cancelled = true;\n    }\n\n    /// Check if this future has been cancelled\n    pub fn is_cancelled(&self) -> bool {\n        self.cancelled\n    }\n}\n\nimpl<F> Future for CancellableFuture<F>\nwhere\n    F: Future,\n{\n    type Output = Result<F::Output, AsyncError>;\n\n    fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n        let this = unsafe { self.get_unchecked_mut() };\n\n        if this.cancelled {\n            return Poll::Ready(Err(AsyncError::Cancelled));\n        }\n\n        let future = unsafe { Pin::new_unchecked(&mut this.future) };\n        match future.poll(cx) {\n            Poll::Ready(value) => Poll::Ready(Ok(value)),\n            Poll::Pending => Poll::Pending,\n        }\n    }\n}\n\n/// A type alias for boxed futures returning results\npub type BoxedResultFuture<T, E> = Pin<Box<dyn Future<Output = Result<T, E>> + Send>>;\n\n/// Execute multiple futures concurrently and return the first successful result\n///\n/// # Errors\n///\n/// Returns `AsyncError::RetryLimitExceeded` if all futures fail\n///\n/// # Examples\n///\n/// ```\n/// use llmspell_utils::async_utils::{race_to_success, BoxedResultFuture};\n/// use std::time::Duration;\n/// use tokio::time::sleep;\n///\n/// # async fn example() -> Result<(), Box<dyn std::error::Error>> {\n/// let futures: Vec<BoxedResultFuture<&str, &str>> = vec![\n///     Box::pin(async {\n///         sleep(Duration::from_millis(100)).await;\n///         Ok(\"slow\")\n///     }),\n///     Box::pin(async {\n///         sleep(Duration::from_millis(10)).await;\n///         Ok(\"fast\")\n///     }),\n/// ];\n///\n/// let result = race_to_success(futures).await?;\n/// assert_eq!(result, \"fast\");\n/// # Ok(())\n/// # }\n/// ```\npub async fn race_to_success<T, E>(futures: Vec<BoxedResultFuture<T, E>>) -> Result<T, AsyncError>\nwhere\n    T: Send + 'static,\n    E: Debug + Send + 'static,\n{\n    use futures::future::select_all;\n\n    if futures.is_empty() {\n        return Err(AsyncError::RetryLimitExceeded { attempts: 0 });\n    }\n\n    let (result, _index, _remaining) = select_all(futures).await;\n\n    match result {\n        Ok(value) => Ok(value),\n        Err(e) => {\n            tracing::error!(\"All futures failed. Last error: {:?}\", e);\n            Err(AsyncError::RetryLimitExceeded { attempts: 1 })\n        }\n    }\n}\n\n/// Add jitter for backoff calculations\n#[cfg(test)]\n#[allow(\n    clippy::cast_precision_loss,\n    clippy::cast_possible_truncation,\n    clippy::cast_sign_loss\n)]\nfn add_jitter(duration: Duration, jitter_fraction: f64) -> Duration {\n    let millis = duration.as_millis() as f64;\n    let jitter = millis * jitter_fraction * (rand::random::<f64>() - 0.5) * 2.0;\n    Duration::from_millis((millis + jitter).max(0.0) as u64)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::sync::atomic::{AtomicUsize, Ordering};\n    use std::sync::Arc;\n    use tokio::time::sleep;\n\n    #[tokio::test]\n    async fn test_timeout_success() {\n        let result = timeout(Duration::from_secs(1), async { 42 }).await;\n        assert!(result.is_ok());\n        assert_eq!(result.unwrap(), 42);\n    }\n\n    #[tokio::test]\n    async fn test_timeout_failure() {\n        let result = timeout(Duration::from_millis(10), async {\n            sleep(Duration::from_millis(100)).await;\n            42\n        })\n        .await;\n        assert!(result.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_timeout_with_default_success() {\n        let result = timeout_with_default(Duration::from_secs(1), async { 42 }, 0).await;\n        assert_eq!(result, 42);\n    }\n\n    #[tokio::test]\n    async fn test_timeout_with_default_timeout() {\n        let result = timeout_with_default(\n            Duration::from_millis(10),\n            async {\n                sleep(Duration::from_millis(100)).await;\n                42\n            },\n            0,\n        )\n        .await;\n        assert_eq!(result, 0);\n    }\n\n    #[tokio::test]\n    async fn test_retry_async_success() {\n        let counter = Arc::new(AtomicUsize::new(0));\n        let counter_clone = counter.clone();\n\n        let config = RetryConfig {\n            max_attempts: 3,\n            initial_delay: Duration::from_millis(10),\n            backoff_factor: 1.0,\n            max_delay: Duration::from_millis(10),\n            jitter: false,\n        };\n\n        let result = retry_async(config, || {\n            let count = counter_clone.fetch_add(1, Ordering::SeqCst);\n            async move {\n                if count < 2 {\n                    Err(\"Not ready yet\")\n                } else {\n                    Ok(\"Success!\")\n                }\n            }\n        })\n        .await\n        .unwrap();\n\n        assert_eq!(result, \"Success!\");\n        assert_eq!(counter.load(Ordering::SeqCst), 3);\n    }\n\n    #[tokio::test]\n    async fn test_retry_async_failure() {\n        let counter = Arc::new(AtomicUsize::new(0));\n        let counter_clone = counter.clone();\n\n        let config = RetryConfig {\n            max_attempts: 2,\n            initial_delay: Duration::from_millis(10),\n            backoff_factor: 1.0,\n            max_delay: Duration::from_millis(10),\n            jitter: false,\n        };\n\n        let result = retry_async(config, || {\n            counter_clone.fetch_add(1, Ordering::SeqCst);\n            async move { Err::<(), _>(\"Always fails\") }\n        })\n        .await;\n\n        assert!(matches!(\n            result,\n            Err(AsyncError::RetryLimitExceeded { attempts: 2 })\n        ));\n        assert_eq!(counter.load(Ordering::SeqCst), 2);\n    }\n\n    #[tokio::test]\n    async fn test_concurrent_map() {\n        let numbers = vec![1, 2, 3, 4, 5];\n        let results = concurrent_map(numbers.into_iter(), 2, |n| async move { n * 2 }).await;\n\n        assert_eq!(results, vec![2, 4, 6, 8, 10]);\n    }\n\n    #[tokio::test]\n    async fn test_concurrent_map_with_delay() {\n        let numbers = vec![1, 2, 3];\n        let start = std::time::Instant::now();\n\n        let results = concurrent_map(\n            numbers.into_iter(),\n            2, // Only 2 concurrent operations\n            |n| async move {\n                sleep(Duration::from_millis(50)).await;\n                n * 2\n            },\n        )\n        .await;\n\n        let elapsed = start.elapsed();\n        assert_eq!(results, vec![2, 4, 6]);\n        // With concurrency of 2, should take ~100ms (2 batches)\n        assert!(elapsed >= Duration::from_millis(90));\n        assert!(elapsed < Duration::from_millis(200));\n    }\n\n    #[tokio::test]\n    async fn test_cancellable_future() {\n        let mut future = CancellableFuture::new(async {\n            sleep(Duration::from_millis(100)).await;\n            42\n        });\n\n        future.cancel();\n        let result = future.await;\n\n        assert!(matches!(result, Err(AsyncError::Cancelled)));\n    }\n\n    #[tokio::test]\n    async fn test_race_to_success() {\n        type TestFuture<'a> = Pin<Box<dyn Future<Output = Result<&'a str, &'a str>> + Send + 'a>>;\n        let futures: Vec<TestFuture> = vec![\n            Box::pin(async {\n                sleep(Duration::from_millis(100)).await;\n                Ok(\"slow\")\n            }),\n            Box::pin(async {\n                sleep(Duration::from_millis(10)).await;\n                Ok(\"fast\")\n            }),\n        ];\n\n        let result = race_to_success(futures).await.unwrap();\n        assert_eq!(result, \"fast\");\n    }\n\n    #[tokio::test]\n    async fn test_add_jitter() {\n        let base_duration = Duration::from_millis(100);\n        let jittered = add_jitter(base_duration, 0.1);\n\n        // Jitter should be within 10% of base duration\n        assert!(jittered.as_millis() >= 90);\n        assert!(jittered.as_millis() <= 110);\n    }\n\n    #[tokio::test]\n    async fn test_retry_with_backoff() {\n        let counter = Arc::new(AtomicUsize::new(0));\n        let counter_clone = counter.clone();\n        let times = Arc::new(parking_lot::Mutex::new(Vec::new()));\n        let times_clone = times.clone();\n\n        let config = RetryConfig {\n            max_attempts: 4,\n            initial_delay: Duration::from_millis(10),\n            backoff_factor: 2.0,\n            max_delay: Duration::from_millis(100),\n            jitter: false,\n        };\n\n        let start = std::time::Instant::now();\n\n        let _ = retry_async(config, || {\n            counter_clone.fetch_add(1, Ordering::SeqCst);\n            times_clone.lock().push(start.elapsed());\n            async move { Err::<(), _>(\"Always fails\") }\n        })\n        .await;\n\n        let times = times.lock();\n        assert_eq!(times.len(), 4);\n\n        // Verify exponential backoff timing\n        // First attempt should be immediate\n        assert!(times[0] < Duration::from_millis(5));\n        // Second attempt after ~10ms\n        assert!(times[1] >= Duration::from_millis(8));\n        assert!(times[1] < Duration::from_millis(20));\n        // Third attempt after ~20ms more (total ~30ms)\n        assert!(times[2] >= Duration::from_millis(25));\n        assert!(times[2] < Duration::from_millis(40));\n        // Fourth attempt after ~40ms more (total ~70ms)\n        assert!(times[3] >= Duration::from_millis(60));\n        assert!(times[3] < Duration::from_millis(90));\n    }\n}\n","traces":[{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":3}},{"line":95,"address":[],"length":0,"stats":{"Line":3}},{"line":115,"address":[],"length":0,"stats":{"Line":3}},{"line":119,"address":[],"length":0,"stats":{"Line":3}},{"line":120,"address":[],"length":0,"stats":{"Line":1}},{"line":121,"address":[],"length":0,"stats":{"Line":2}},{"line":163,"address":[],"length":0,"stats":{"Line":4}},{"line":169,"address":[],"length":0,"stats":{"Line":4}},{"line":170,"address":[],"length":0,"stats":{"Line":4}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":11}},{"line":175,"address":[],"length":0,"stats":{"Line":11}},{"line":176,"address":[],"length":0,"stats":{"Line":2}},{"line":177,"address":[],"length":0,"stats":{"Line":9}},{"line":178,"address":[],"length":0,"stats":{"Line":9}},{"line":179,"address":[],"length":0,"stats":{"Line":2}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":2}},{"line":187,"address":[],"length":0,"stats":{"Line":7}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":7}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":7}},{"line":207,"address":[],"length":0,"stats":{"Line":7}},{"line":208,"address":[],"length":0,"stats":{"Line":7}},{"line":234,"address":[],"length":0,"stats":{"Line":3}},{"line":242,"address":[],"length":0,"stats":{"Line":3}},{"line":243,"address":[],"length":0,"stats":{"Line":3}},{"line":244,"address":[],"length":0,"stats":{"Line":3}},{"line":245,"address":[],"length":0,"stats":{"Line":3}},{"line":246,"address":[],"length":0,"stats":{"Line":3}},{"line":247,"address":[],"length":0,"stats":{"Line":3}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":25}},{"line":252,"address":[],"length":0,"stats":{"Line":28}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":11}},{"line":259,"address":[],"length":0,"stats":{"Line":22}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":6}},{"line":268,"address":[],"length":0,"stats":{"Line":14}},{"line":269,"address":[],"length":0,"stats":{"Line":3}},{"line":273,"address":[],"length":0,"stats":{"Line":11}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":14}},{"line":281,"address":[],"length":0,"stats":{"Line":11}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":3}},{"line":297,"address":[],"length":0,"stats":{"Line":1}},{"line":305,"address":[],"length":0,"stats":{"Line":1}},{"line":306,"address":[],"length":0,"stats":{"Line":1}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":321,"address":[],"length":0,"stats":{"Line":1}},{"line":322,"address":[],"length":0,"stats":{"Line":1}},{"line":324,"address":[],"length":0,"stats":{"Line":1}},{"line":325,"address":[],"length":0,"stats":{"Line":1}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":1}},{"line":376,"address":[],"length":0,"stats":{"Line":1}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":380,"address":[],"length":0,"stats":{"Line":1}},{"line":382,"address":[],"length":0,"stats":{"Line":1}},{"line":383,"address":[],"length":0,"stats":{"Line":1}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":386,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":1}},{"line":399,"address":[],"length":0,"stats":{"Line":1}},{"line":400,"address":[],"length":0,"stats":{"Line":1}},{"line":401,"address":[],"length":0,"stats":{"Line":1}}],"covered":55,"coverable":90},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-utils","src","error_builders.rs"],"content":"// ABOUTME: Error construction helpers and builder patterns for consistent error handling\n// ABOUTME: Provides ergonomic error building utilities used throughout LLMSpell\n\n//! Error construction and builder utilities\n//!\n//! This module provides convenient error builders and context helpers\n//! for consistent error handling across the framework.\n\nuse std::error::Error;\nuse std::fmt;\n\n/// Error builder for fluent error construction\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::error_builders::ErrorBuilder;\n///\n/// let error = ErrorBuilder::new(\"Operation failed\")\n///     .with_source_string(\"connection refused\")\n///     .with_context(\"key\", \"value\")\n///     .with_context(\"retry_count\", 3)\n///     .build();\n///\n/// assert_eq!(error.to_string(), \"Operation failed (key: value, retry_count: 3)\");\n/// ```\n#[derive(Debug)]\npub struct ErrorBuilder {\n    message: String,\n    source: Option<Box<dyn Error + Send + Sync>>,\n    context: Vec<(String, String)>,\n}\n\nimpl ErrorBuilder {\n    /// Create a new error builder with the given message\n    #[must_use]\n    pub fn new(message: impl Into<String>) -> Self {\n        Self {\n            message: message.into(),\n            source: None,\n            context: Vec::new(),\n        }\n    }\n\n    /// Add a source error\n    #[must_use]\n    pub fn with_source(mut self, source: impl Into<Box<dyn Error + Send + Sync>>) -> Self {\n        self.source = Some(source.into());\n        self\n    }\n\n    /// Add a source error from a string\n    #[must_use]\n    pub fn with_source_string(mut self, source: impl Into<String>) -> Self {\n        self.source = Some(Box::new(SimpleError::new(source.into())));\n        self\n    }\n\n    /// Add context information\n    #[must_use]\n    pub fn with_context(mut self, key: impl Into<String>, value: impl fmt::Display) -> Self {\n        self.context.push((key.into(), value.to_string()));\n        self\n    }\n\n    /// Add multiple context entries\n    #[must_use]\n    pub fn with_contexts<I, K, V>(mut self, contexts: I) -> Self\n    where\n        I: IntoIterator<Item = (K, V)>,\n        K: Into<String>,\n        V: fmt::Display,\n    {\n        for (key, value) in contexts {\n            self.context.push((key.into(), value.to_string()));\n        }\n        self\n    }\n\n    /// Build the final error\n    #[must_use]\n    pub fn build(self) -> BuiltError {\n        BuiltError {\n            message: self.message,\n            source: self.source,\n            context: self.context,\n        }\n    }\n}\n\n/// Error built by `ErrorBuilder`\n#[derive(Debug)]\npub struct BuiltError {\n    message: String,\n    source: Option<Box<dyn Error + Send + Sync>>,\n    context: Vec<(String, String)>,\n}\n\nimpl BuiltError {\n    /// Get the error message\n    #[must_use]\n    pub fn message(&self) -> &str {\n        &self.message\n    }\n\n    /// Get the error context\n    #[must_use]\n    pub fn context(&self) -> &[(String, String)] {\n        &self.context\n    }\n\n    /// Get a specific context value\n    #[must_use]\n    pub fn get_context(&self, key: &str) -> Option<&str> {\n        self.context\n            .iter()\n            .find(|(k, _)| k == key)\n            .map(|(_, v)| v.as_str())\n    }\n}\n\nimpl fmt::Display for BuiltError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"{}\", self.message)?;\n\n        if !self.context.is_empty() {\n            write!(f, \" (\")?;\n            for (i, (key, value)) in self.context.iter().enumerate() {\n                if i > 0 {\n                    write!(f, \", \")?;\n                }\n                write!(f, \"{key}: {value}\")?;\n            }\n            write!(f, \")\")?;\n        }\n\n        Ok(())\n    }\n}\n\nimpl Error for BuiltError {\n    fn source(&self) -> Option<&(dyn Error + 'static)> {\n        self.source\n            .as_ref()\n            .map(|e| e.as_ref() as &(dyn Error + 'static))\n    }\n}\n\n/// Simple error type for string errors\n#[derive(Debug)]\nstruct SimpleError {\n    message: String,\n}\n\nimpl SimpleError {\n    fn new(message: String) -> Self {\n        Self { message }\n    }\n}\n\nimpl fmt::Display for SimpleError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"{}\", self.message)\n    }\n}\n\nimpl Error for SimpleError {}\n\n/// Trait for adding context to errors\npub trait WithContext<T> {\n    /// Add context to the error\n    ///\n    /// # Errors\n    ///\n    /// Returns an error with additional context\n    fn with_context<C, F>(self, f: F) -> Result<T, BuiltError>\n    where\n        C: fmt::Display,\n        F: FnOnce() -> C;\n\n    /// Add context with a static string\n    ///\n    /// # Errors\n    ///\n    /// Returns an error with additional context\n    fn context(self, context: &'static str) -> Result<T, BuiltError>;\n}\n\nimpl<T, E> WithContext<T> for Result<T, E>\nwhere\n    E: Error + Send + Sync + 'static,\n{\n    fn with_context<C, F>(self, f: F) -> Result<T, BuiltError>\n    where\n        C: fmt::Display,\n        F: FnOnce() -> C,\n    {\n        self.map_err(|e| ErrorBuilder::new(f().to_string()).with_source(e).build())\n    }\n\n    fn context(self, context: &'static str) -> Result<T, BuiltError> {\n        self.with_context(|| context)\n    }\n}\n\n/// Common error templates\npub mod templates {\n    use super::ErrorBuilder;\n\n    /// Create an I/O error\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// use llmspell_utils::error_builders::templates::io_error;\n    ///\n    /// let error = io_error(\"Failed to read file\", \"/path/to/file\");\n    /// ```\n    pub fn io_error(\n        operation: impl Into<String>,\n        path: impl AsRef<std::path::Path>,\n    ) -> ErrorBuilder {\n        ErrorBuilder::new(operation.into())\n            .with_context(\"path\", path.as_ref().display())\n            .with_context(\"error_type\", \"io\")\n    }\n\n    /// Create a validation error\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// use llmspell_utils::error_builders::templates::validation_error;\n    ///\n    /// let error = validation_error(\"Invalid email format\", \"user@\", \"must contain domain\");\n    /// ```\n    pub fn validation_error(\n        message: impl Into<String>,\n        value: impl std::fmt::Display,\n        reason: impl Into<String>,\n    ) -> ErrorBuilder {\n        ErrorBuilder::new(message.into())\n            .with_context(\"value\", value)\n            .with_context(\"reason\", reason.into())\n            .with_context(\"error_type\", \"validation\")\n    }\n\n    /// Create a configuration error\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// use llmspell_utils::error_builders::templates::config_error;\n    ///\n    /// let error = config_error(\"Missing required field\", \"database.url\");\n    /// ```\n    pub fn config_error(message: impl Into<String>, field: impl Into<String>) -> ErrorBuilder {\n        ErrorBuilder::new(message.into())\n            .with_context(\"field\", field.into())\n            .with_context(\"error_type\", \"configuration\")\n    }\n\n    /// Create a network error\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// use llmspell_utils::error_builders::templates::network_error;\n    ///\n    /// let error = network_error(\"Connection failed\", \"api.example.com\", 443);\n    /// ```\n    pub fn network_error(\n        message: impl Into<String>,\n        host: impl Into<String>,\n        port: u16,\n    ) -> ErrorBuilder {\n        ErrorBuilder::new(message.into())\n            .with_context(\"host\", host.into())\n            .with_context(\"port\", port)\n            .with_context(\"error_type\", \"network\")\n    }\n\n    /// Create a timeout error\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// use llmspell_utils::error_builders::templates::timeout_error;\n    /// use std::time::Duration;\n    ///\n    /// let error = timeout_error(\"Operation timed out\", Duration::from_secs(30));\n    /// ```\n    pub fn timeout_error(\n        operation: impl Into<String>,\n        duration: std::time::Duration,\n    ) -> ErrorBuilder {\n        ErrorBuilder::new(format!(\"{} after {:?}\", operation.into(), duration))\n            .with_context(\"timeout\", format!(\"{duration:?}\"))\n            .with_context(\"error_type\", \"timeout\")\n    }\n\n    /// Create a permission error\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// use llmspell_utils::error_builders::templates::permission_error;\n    ///\n    /// let error = permission_error(\"Access denied\", \"write\", \"/etc/passwd\");\n    /// ```\n    pub fn permission_error(\n        message: impl Into<String>,\n        operation: impl Into<String>,\n        resource: impl Into<String>,\n    ) -> ErrorBuilder {\n        ErrorBuilder::new(message.into())\n            .with_context(\"operation\", operation.into())\n            .with_context(\"resource\", resource.into())\n            .with_context(\"error_type\", \"permission\")\n    }\n\n    /// Create a not found error\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// use llmspell_utils::error_builders::templates::not_found_error;\n    ///\n    /// let error = not_found_error(\"User\", \"user123\");\n    /// ```\n    pub fn not_found_error(\n        resource_type: impl Into<String>,\n        identifier: impl Into<String>,\n    ) -> ErrorBuilder {\n        let resource_type_str = resource_type.into();\n        ErrorBuilder::new(format!(\"{} not found\", &resource_type_str))\n            .with_context(\"resource_type\", resource_type_str)\n            .with_context(\"identifier\", identifier.into())\n            .with_context(\"error_type\", \"not_found\")\n    }\n\n    /// Create a parsing error\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// use llmspell_utils::error_builders::templates::parse_error;\n    ///\n    /// let error = parse_error(\"Invalid JSON\", 10, 5, \"expected '}'\");\n    /// ```\n    pub fn parse_error(\n        message: impl Into<String>,\n        line: usize,\n        column: usize,\n        expected: impl Into<String>,\n    ) -> ErrorBuilder {\n        ErrorBuilder::new(message.into())\n            .with_context(\"line\", line)\n            .with_context(\"column\", column)\n            .with_context(\"expected\", expected.into())\n            .with_context(\"error_type\", \"parse\")\n    }\n}\n\n/// Helper macros for error construction\n#[macro_export]\nmacro_rules! build_error {\n    ($msg:expr) => {\n        $crate::error_builders::ErrorBuilder::new($msg).build()\n    };\n    ($msg:expr, source: $source:expr) => {\n        $crate::error_builders::ErrorBuilder::new($msg)\n            .with_source($source)\n            .build()\n    };\n    ($msg:expr, $($key:ident: $value:expr),+ $(,)?) => {\n        $crate::error_builders::ErrorBuilder::new($msg)\n            $(.with_context(stringify!($key), $value))+\n            .build()\n    };\n}\n\n/// Bail out with an error\n#[macro_export]\nmacro_rules! bail_error {\n    ($($arg:tt)*) => {\n        return Err($crate::build_error!($($arg)*))\n    };\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_error_builder_basic() {\n        let error = ErrorBuilder::new(\"Test error\").build();\n        assert_eq!(error.message(), \"Test error\");\n        assert_eq!(error.to_string(), \"Test error\");\n    }\n\n    #[test]\n    fn test_error_builder_with_source() {\n        let source = SimpleError::new(\"Source error\".to_string());\n        let error = ErrorBuilder::new(\"Main error\").with_source(source).build();\n\n        assert_eq!(error.message(), \"Main error\");\n        assert!(error.source().is_some());\n    }\n\n    #[test]\n    fn test_error_builder_with_context() {\n        let error = ErrorBuilder::new(\"Error with context\")\n            .with_context(\"key1\", \"value1\")\n            .with_context(\"key2\", 42)\n            .build();\n\n        assert_eq!(error.get_context(\"key1\"), Some(\"value1\"));\n        assert_eq!(error.get_context(\"key2\"), Some(\"42\"));\n        assert_eq!(error.get_context(\"nonexistent\"), None);\n\n        let display = error.to_string();\n        assert!(display.contains(\"Error with context\"));\n        assert!(display.contains(\"key1: value1\"));\n        assert!(display.contains(\"key2: 42\"));\n    }\n\n    #[test]\n    fn test_with_context_trait() {\n        let result: Result<(), _> = Err(SimpleError::new(\"Original error\".to_string()));\n        let error = result.with_context(|| \"Additional context\").unwrap_err();\n\n        assert_eq!(error.message(), \"Additional context\");\n        assert!(error.source().is_some());\n    }\n\n    #[test]\n    fn test_error_templates() {\n        let io_err = templates::io_error(\"Failed to read\", \"/tmp/test.txt\").build();\n        assert_eq!(io_err.get_context(\"error_type\"), Some(\"io\"));\n        assert_eq!(io_err.get_context(\"path\"), Some(\"/tmp/test.txt\"));\n\n        let val_err = templates::validation_error(\"Invalid\", \"test@\", \"missing domain\").build();\n        assert_eq!(val_err.get_context(\"error_type\"), Some(\"validation\"));\n        assert_eq!(val_err.get_context(\"value\"), Some(\"test@\"));\n\n        let config_err = templates::config_error(\"Missing field\", \"db.url\").build();\n        assert_eq!(config_err.get_context(\"error_type\"), Some(\"configuration\"));\n        assert_eq!(config_err.get_context(\"field\"), Some(\"db.url\"));\n\n        let net_err = templates::network_error(\"Connection failed\", \"localhost\", 8080).build();\n        assert_eq!(net_err.get_context(\"error_type\"), Some(\"network\"));\n        assert_eq!(net_err.get_context(\"host\"), Some(\"localhost\"));\n        assert_eq!(net_err.get_context(\"port\"), Some(\"8080\"));\n\n        let timeout_err =\n            templates::timeout_error(\"Read timeout\", std::time::Duration::from_secs(30)).build();\n        assert_eq!(timeout_err.get_context(\"error_type\"), Some(\"timeout\"));\n\n        let perm_err = templates::permission_error(\"Denied\", \"write\", \"/etc/passwd\").build();\n        assert_eq!(perm_err.get_context(\"error_type\"), Some(\"permission\"));\n        assert_eq!(perm_err.get_context(\"operation\"), Some(\"write\"));\n\n        let not_found = templates::not_found_error(\"User\", \"john_doe\").build();\n        assert_eq!(not_found.get_context(\"error_type\"), Some(\"not_found\"));\n        assert_eq!(not_found.get_context(\"identifier\"), Some(\"john_doe\"));\n\n        let parse_err = templates::parse_error(\"Syntax error\", 10, 5, \"closing brace\").build();\n        assert_eq!(parse_err.get_context(\"error_type\"), Some(\"parse\"));\n        assert_eq!(parse_err.get_context(\"line\"), Some(\"10\"));\n        assert_eq!(parse_err.get_context(\"column\"), Some(\"5\"));\n    }\n\n    #[test]\n    fn test_build_error_macro() {\n        let error1 = build_error!(\"Simple error\");\n        assert_eq!(error1.message(), \"Simple error\");\n\n        let source = SimpleError::new(\"Source\".to_string());\n        let error2 = build_error!(\"With source\", source: source);\n        assert_eq!(error2.message(), \"With source\");\n        assert!(error2.source().is_some());\n\n        let error3 = build_error!(\"With context\", foo: \"bar\", count: 42);\n        assert_eq!(error3.get_context(\"foo\"), Some(\"bar\"));\n        assert_eq!(error3.get_context(\"count\"), Some(\"42\"));\n    }\n\n    #[test]\n    fn test_error_display_formatting() {\n        let error = ErrorBuilder::new(\"Main message\")\n            .with_context(\"code\", \"E001\")\n            .with_context(\"line\", 42)\n            .build();\n\n        let display = error.to_string();\n        assert_eq!(display, \"Main message (code: E001, line: 42)\");\n    }\n}\n","traces":[{"line":37,"address":[],"length":0,"stats":{"Line":19}},{"line":39,"address":[],"length":0,"stats":{"Line":19}},{"line":41,"address":[],"length":0,"stats":{"Line":19}},{"line":47,"address":[],"length":0,"stats":{"Line":3}},{"line":48,"address":[],"length":0,"stats":{"Line":3}},{"line":49,"address":[],"length":0,"stats":{"Line":3}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":34}},{"line":62,"address":[],"length":0,"stats":{"Line":34}},{"line":63,"address":[],"length":0,"stats":{"Line":34}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":19}},{"line":84,"address":[],"length":0,"stats":{"Line":19}},{"line":85,"address":[],"length":0,"stats":{"Line":19}},{"line":86,"address":[],"length":0,"stats":{"Line":19}},{"line":102,"address":[],"length":0,"stats":{"Line":6}},{"line":103,"address":[],"length":0,"stats":{"Line":6}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":25}},{"line":115,"address":[],"length":0,"stats":{"Line":25}},{"line":117,"address":[],"length":0,"stats":{"Line":98}},{"line":118,"address":[],"length":0,"stats":{"Line":74}},{"line":123,"address":[],"length":0,"stats":{"Line":3}},{"line":124,"address":[],"length":0,"stats":{"Line":3}},{"line":126,"address":[],"length":0,"stats":{"Line":3}},{"line":127,"address":[],"length":0,"stats":{"Line":2}},{"line":128,"address":[],"length":0,"stats":{"Line":6}},{"line":129,"address":[],"length":0,"stats":{"Line":4}},{"line":130,"address":[],"length":0,"stats":{"Line":2}},{"line":132,"address":[],"length":0,"stats":{"Line":4}},{"line":134,"address":[],"length":0,"stats":{"Line":2}},{"line":137,"address":[],"length":0,"stats":{"Line":3}},{"line":142,"address":[],"length":0,"stats":{"Line":3}},{"line":143,"address":[],"length":0,"stats":{"Line":3}},{"line":145,"address":[],"length":0,"stats":{"Line":9}},{"line":156,"address":[],"length":0,"stats":{"Line":3}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":1}},{"line":198,"address":[],"length":0,"stats":{"Line":3}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":2}},{"line":223,"address":[],"length":0,"stats":{"Line":2}},{"line":224,"address":[],"length":0,"stats":{"Line":2}},{"line":237,"address":[],"length":0,"stats":{"Line":2}},{"line":242,"address":[],"length":0,"stats":{"Line":2}},{"line":243,"address":[],"length":0,"stats":{"Line":2}},{"line":244,"address":[],"length":0,"stats":{"Line":2}},{"line":257,"address":[],"length":0,"stats":{"Line":1}},{"line":258,"address":[],"length":0,"stats":{"Line":1}},{"line":259,"address":[],"length":0,"stats":{"Line":1}},{"line":272,"address":[],"length":0,"stats":{"Line":1}},{"line":277,"address":[],"length":0,"stats":{"Line":1}},{"line":278,"address":[],"length":0,"stats":{"Line":1}},{"line":279,"address":[],"length":0,"stats":{"Line":1}},{"line":293,"address":[],"length":0,"stats":{"Line":1}},{"line":297,"address":[],"length":0,"stats":{"Line":1}},{"line":298,"address":[],"length":0,"stats":{"Line":1}},{"line":311,"address":[],"length":0,"stats":{"Line":1}},{"line":316,"address":[],"length":0,"stats":{"Line":1}},{"line":317,"address":[],"length":0,"stats":{"Line":1}},{"line":318,"address":[],"length":0,"stats":{"Line":1}},{"line":331,"address":[],"length":0,"stats":{"Line":1}},{"line":335,"address":[],"length":0,"stats":{"Line":1}},{"line":336,"address":[],"length":0,"stats":{"Line":1}},{"line":337,"address":[],"length":0,"stats":{"Line":1}},{"line":338,"address":[],"length":0,"stats":{"Line":1}},{"line":351,"address":[],"length":0,"stats":{"Line":1}},{"line":357,"address":[],"length":0,"stats":{"Line":1}},{"line":358,"address":[],"length":0,"stats":{"Line":1}},{"line":359,"address":[],"length":0,"stats":{"Line":1}},{"line":360,"address":[],"length":0,"stats":{"Line":1}}],"covered":66,"coverable":79},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-utils","src","file_utils.rs"],"content":"// ABOUTME: Cross-platform file system operations and path manipulation utilities\n// ABOUTME: Provides safe abstractions for file operations used throughout LLMSpell\n\n//! File system operations and path utilities\n//!\n//! This module provides cross-platform file operations, path manipulation,\n//! and directory management utilities.\n//!\n//! # Examples\n//!\n//! ```rust,no_run\n//! use llmspell_utils::file_utils;\n//! use std::path::Path;\n//!\n//! # fn main() -> Result<(), Box<dyn std::error::Error>> {\n//! // Ensure a directory exists\n//! file_utils::ensure_dir(Path::new(\"/tmp/myapp\"))?;\n//!\n//! // Expand path with environment variables\n//! let expanded = file_utils::expand_path(\"$HOME/.config/myapp\")?;\n//! println!(\"Expanded path: {}\", expanded.display());\n//!\n//! // Safe file operations\n//! file_utils::write_file_atomic(Path::new(\"/tmp/test.txt\"), b\"Hello, world!\")?;\n//! let content = file_utils::read_file(Path::new(\"/tmp/test.txt\"))?;\n//! # Ok(())\n//! # }\n//! ```\n\nuse anyhow::{Context, Result};\nuse path_clean::PathClean;\nuse std::env;\nuse std::fs::{self, File};\nuse std::io::{self, Read, Write};\nuse std::path::{Path, PathBuf};\n\n/// Maximum file size for safe operations (100MB)\nconst MAX_FILE_SIZE: u64 = 100 * 1024 * 1024;\n\n/// Ensure a directory exists, creating it if necessary\n///\n/// This function creates the directory and all parent directories if they don't exist.\n/// It's safe to call even if the directory already exists.\n///\n/// # Examples\n///\n/// ```rust,no_run\n/// use llmspell_utils::file_utils::ensure_dir;\n/// use std::path::Path;\n///\n/// # fn main() -> std::io::Result<()> {\n/// ensure_dir(Path::new(\"/tmp/myapp/data\"))?;\n/// # Ok(())\n/// # }\n/// ```\n///\n/// # Errors\n///\n/// Returns an error if:\n/// - The path exists but is not a directory\n/// - Directory creation fails due to permissions or other OS errors\npub fn ensure_dir(path: &Path) -> io::Result<()> {\n    if path.exists() {\n        if path.is_dir() {\n            Ok(())\n        } else {\n            Err(io::Error::new(\n                io::ErrorKind::AlreadyExists,\n                format!(\"Path exists but is not a directory: {}\", path.display()),\n            ))\n        }\n    } else {\n        fs::create_dir_all(path).map_err(|e| {\n            io::Error::new(\n                e.kind(),\n                format!(\"Failed to create directory '{}': {}\", path.display(), e),\n            )\n        })\n    }\n}\n\n/// Expand path with environment variables and tilde expansion\n///\n/// Supports:\n/// - Environment variable expansion: `$HOME`, `${HOME}`, `%HOME%` (Windows)\n/// - Tilde expansion: `~` expands to home directory\n/// - Relative path resolution to absolute paths\n///\n/// # Examples\n///\n/// ```rust,no_run\n/// use llmspell_utils::file_utils::expand_path;\n///\n/// # fn main() -> Result<(), std::io::Error> {\n/// let path = expand_path(\"~/Documents/config.json\")?;\n/// let path2 = expand_path(\"$HOME/.config/app\")?;\n/// let path3 = expand_path(\"${TMPDIR}/cache\")?;\n/// # Ok(())\n/// # }\n/// ```\n///\n/// # Errors\n///\n/// Returns an error if:\n/// - Home directory cannot be determined\n/// - Environment variable is not found\n/// - Path contains invalid UTF-8\npub fn expand_path(path: &str) -> Result<PathBuf, io::Error> {\n    let mut expanded = path.to_string();\n\n    // Handle tilde expansion\n    if expanded.starts_with(\"~/\") || expanded == \"~\" {\n        let home = env::var(\"HOME\")\n            .or_else(|_| env::var(\"USERPROFILE\"))\n            .map_err(|_| {\n                io::Error::new(\n                    io::ErrorKind::NotFound,\n                    \"Could not determine home directory\",\n                )\n            })?;\n\n        expanded = if expanded == \"~\" {\n            home\n        } else {\n            format!(\"{}{}\", home, &expanded[1..])\n        };\n    }\n\n    // Handle environment variable expansion\n    // Support both $VAR and ${VAR} syntax\n    let mut result = String::new();\n    let mut chars = expanded.chars();\n\n    while let Some(ch) = chars.next() {\n        if ch == '$' {\n            let mut var_name = String::new();\n\n            // Check if it's ${VAR} syntax\n            let next_char = chars.clone().next();\n            if next_char == Some('{') {\n                chars.next(); // consume '{'\n                              // Collect until we find '}'\n                for c in chars.by_ref() {\n                    if c == '}' {\n                        break;\n                    }\n                    var_name.push(c);\n                }\n            } else {\n                // $VAR syntax - collect alphanumeric and underscore chars\n                for c in chars.clone() {\n                    if c.is_alphanumeric() || c == '_' {\n                        var_name.push(c);\n                        chars.next(); // consume the character\n                    } else {\n                        break;\n                    }\n                }\n            }\n\n            if var_name.is_empty() {\n                result.push('$');\n            } else {\n                match env::var(&var_name) {\n                    Ok(value) => result.push_str(&value),\n                    Err(_) => {\n                        return Err(io::Error::new(\n                            io::ErrorKind::NotFound,\n                            format!(\"Environment variable '{var_name}' not found\"),\n                        ));\n                    }\n                }\n            }\n        } else if cfg!(windows) && ch == '%' {\n            // Windows %VAR% syntax\n            let mut var_name = String::new();\n            for c in chars.by_ref() {\n                if c == '%' {\n                    break;\n                }\n                var_name.push(c);\n            }\n\n            if var_name.is_empty() {\n                result.push('%');\n            } else {\n                match env::var(&var_name) {\n                    Ok(value) => result.push_str(&value),\n                    Err(_) => {\n                        return Err(io::Error::new(\n                            io::ErrorKind::NotFound,\n                            format!(\"Environment variable '{var_name}' not found\"),\n                        ));\n                    }\n                }\n            }\n        } else {\n            result.push(ch);\n        }\n    }\n\n    // Convert to PathBuf and clean the path\n    Ok(PathBuf::from(result).clean())\n}\n\n/// Normalize a path for cross-platform compatibility\n///\n/// This function:\n/// - Converts backslashes to forward slashes on Unix\n/// - Converts forward slashes to backslashes on Windows\n/// - Removes redundant separators and dots\n/// - Resolves `..` components where possible\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::file_utils::normalize_path;\n/// use std::path::Path;\n///\n/// let normalized = normalize_path(Path::new(\"/home/user/../user/./docs\"));\n/// assert_eq!(normalized.to_str().unwrap(), \"/home/user/docs\");\n/// ```\n#[must_use]\npub fn normalize_path(path: &Path) -> PathBuf {\n    path.clean()\n}\n\n/// Safely read a file with size limits\n///\n/// Reads the entire contents of a file into memory, with a size limit\n/// to prevent memory exhaustion.\n///\n/// # Examples\n///\n/// ```rust,no_run\n/// use llmspell_utils::file_utils::read_file;\n/// use std::path::Path;\n///\n/// # fn main() -> Result<(), Box<dyn std::error::Error>> {\n/// let content = read_file(Path::new(\"/etc/hosts\"))?;\n/// println!(\"File content: {}\", String::from_utf8_lossy(&content));\n/// # Ok(())\n/// # }\n/// ```\n///\n/// # Errors\n///\n/// Returns an error if:\n/// - File does not exist\n/// - File is larger than 100MB\n/// - Read permissions are denied\n/// - I/O error occurs\npub fn read_file(path: &Path) -> Result<Vec<u8>> {\n    // Check file size first\n    let metadata = fs::metadata(path)\n        .with_context(|| format!(\"Failed to read metadata for file: {}\", path.display()))?;\n\n    if metadata.len() > MAX_FILE_SIZE {\n        anyhow::bail!(\n            \"File '{}' is too large ({} bytes, max {} bytes)\",\n            path.display(),\n            metadata.len(),\n            MAX_FILE_SIZE\n        );\n    }\n\n    let mut file =\n        File::open(path).with_context(|| format!(\"Failed to open file: {}\", path.display()))?;\n\n    // Safe cast: we've already checked the file size is <= MAX_FILE_SIZE (100MB)\n    #[allow(clippy::cast_possible_truncation)]\n    let capacity = metadata.len().min(usize::MAX as u64) as usize;\n    let mut contents = Vec::with_capacity(capacity);\n    file.read_to_end(&mut contents)\n        .with_context(|| format!(\"Failed to read file: {}\", path.display()))?;\n\n    Ok(contents)\n}\n\n/// Write data to a file with proper error handling\n///\n/// This is a simple write operation. For critical data, use `write_file_atomic`.\n///\n/// # Examples\n///\n/// ```rust,no_run\n/// use llmspell_utils::file_utils::write_file;\n/// use std::path::Path;\n///\n/// # fn main() -> Result<(), Box<dyn std::error::Error>> {\n/// write_file(Path::new(\"/tmp/output.txt\"), b\"Hello, world!\")?;\n/// # Ok(())\n/// # }\n/// ```\n///\n/// # Errors\n///\n/// Returns an error if:\n/// - Parent directory does not exist\n/// - Write permissions are denied\n/// - Disk is full\n/// - I/O error occurs\npub fn write_file(path: &Path, data: &[u8]) -> Result<()> {\n    // Ensure parent directory exists\n    if let Some(parent) = path.parent() {\n        ensure_dir(parent).with_context(|| {\n            format!(\"Failed to create parent directory for: {}\", path.display())\n        })?;\n    }\n\n    let mut file =\n        File::create(path).with_context(|| format!(\"Failed to create file: {}\", path.display()))?;\n\n    file.write_all(data)\n        .with_context(|| format!(\"Failed to write to file: {}\", path.display()))?;\n\n    file.sync_all()\n        .with_context(|| format!(\"Failed to sync file to disk: {}\", path.display()))?;\n\n    Ok(())\n}\n\n/// Atomically write data to a file\n///\n/// This function writes data to a temporary file and then atomically renames it\n/// to the target path. This ensures that the file is either fully written or\n/// not modified at all, preventing partial writes.\n///\n/// # Examples\n///\n/// ```rust,no_run\n/// use llmspell_utils::file_utils::write_file_atomic;\n/// use std::path::Path;\n///\n/// # fn main() -> Result<(), Box<dyn std::error::Error>> {\n/// // This write is atomic - the file will either be fully written or unchanged\n/// write_file_atomic(Path::new(\"/tmp/important.json\"), b\"{\\\"status\\\": \\\"ok\\\"}\")?;\n/// # Ok(())\n/// # }\n/// ```\n///\n/// # Errors\n///\n/// Returns an error if:\n/// - Parent directory does not exist\n/// - Write permissions are denied\n/// - Disk is full\n/// - I/O error occurs\npub fn write_file_atomic(path: &Path, data: &[u8]) -> Result<()> {\n    // Ensure parent directory exists\n    if let Some(parent) = path.parent() {\n        ensure_dir(parent).with_context(|| {\n            format!(\"Failed to create parent directory for: {}\", path.display())\n        })?;\n    }\n\n    // Create temporary file in the same directory\n    let temp_path = {\n        let mut temp = path.to_path_buf();\n        let file_name = path\n            .file_name()\n            .ok_or_else(|| anyhow::anyhow!(\"Path has no file name: {}\", path.display()))?;\n\n        let file_name_str = file_name.to_string_lossy();\n        let uuid_str = uuid::Uuid::new_v4().simple();\n        let temp_name = format!(\".{file_name_str}.tmp.{uuid_str}\");\n\n        temp.set_file_name(temp_name);\n        temp\n    };\n\n    // Write to temporary file\n    let result = (|| -> Result<()> {\n        let mut file = File::create(&temp_path)\n            .with_context(|| format!(\"Failed to create temporary file: {}\", temp_path.display()))?;\n\n        file.write_all(data).with_context(|| {\n            format!(\"Failed to write to temporary file: {}\", temp_path.display())\n        })?;\n\n        file.sync_all()\n            .with_context(|| format!(\"Failed to sync temporary file: {}\", temp_path.display()))?;\n\n        Ok(())\n    })();\n\n    // If write failed, clean up temp file\n    if let Err(e) = result {\n        let _ = fs::remove_file(&temp_path);\n        return Err(e);\n    }\n\n    // Atomic rename\n    fs::rename(&temp_path, path).with_context(|| {\n        format!(\n            \"Failed to rename {} to {}\",\n            temp_path.display(),\n            path.display()\n        )\n    })?;\n\n    Ok(())\n}\n\n/// Check if a path is absolute\n///\n/// This function correctly handles platform differences:\n/// - On Unix: paths starting with `/`\n/// - On Windows: paths with drive letters (C:\\) or UNC paths (\\\\server\\share)\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::file_utils::is_absolute_path;\n/// use std::path::Path;\n///\n/// assert!(is_absolute_path(Path::new(\"/home/user\")));\n/// assert!(!is_absolute_path(Path::new(\"relative/path\")));\n///\n/// #[cfg(windows)]\n/// {\n///     assert!(is_absolute_path(Path::new(\"C:\\\\Windows\")));\n///     assert!(is_absolute_path(Path::new(\"\\\\\\\\server\\\\share\")));\n/// }\n/// ```\n#[must_use]\npub fn is_absolute_path(path: &Path) -> bool {\n    path.is_absolute()\n}\n\n/// Join paths safely, handling platform differences\n///\n/// This function safely joins path components, handling:\n/// - Empty components\n/// - Absolute paths in components (which reset the path)\n/// - Platform-specific separators\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::file_utils::join_paths;\n/// use std::path::Path;\n///\n/// let joined = join_paths(&[Path::new(\"/home\"), Path::new(\"user\"), Path::new(\"docs\")]);\n/// assert_eq!(joined.to_str().unwrap(), \"/home/user/docs\");\n/// ```\n#[must_use]\npub fn join_paths(paths: &[&Path]) -> PathBuf {\n    let mut result = PathBuf::new();\n\n    for path in paths {\n        if path.is_absolute() {\n            result = path.to_path_buf();\n        } else {\n            result.push(path);\n        }\n    }\n\n    result.clean()\n}\n\n/// Get the parent directory of a path\n///\n/// Returns None if the path has no parent (e.g., \"/\" or \"C:\\\")\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::file_utils::parent_dir;\n/// use std::path::Path;\n///\n/// assert_eq!(\n///     parent_dir(Path::new(\"/home/user/file.txt\")),\n///     Some(Path::new(\"/home/user\").to_path_buf())\n/// );\n/// ```\n#[must_use]\npub fn parent_dir(path: &Path) -> Option<PathBuf> {\n    path.parent().map(std::path::Path::to_path_buf)\n}\n\n/// Copy a file with proper error handling\n///\n/// # Examples\n///\n/// ```rust,no_run\n/// use llmspell_utils::file_utils::copy_file;\n/// use std::path::Path;\n///\n/// # fn main() -> Result<(), Box<dyn std::error::Error>> {\n/// copy_file(Path::new(\"/tmp/source.txt\"), Path::new(\"/tmp/dest.txt\"))?;\n/// # Ok(())\n/// # }\n/// ```\n///\n/// # Errors\n///\n/// Returns an error if:\n/// - Source file does not exist\n/// - Destination directory does not exist\n/// - Insufficient permissions\n/// - I/O error occurs\npub fn copy_file(from: &Path, to: &Path) -> Result<u64> {\n    // Ensure destination directory exists\n    if let Some(parent) = to.parent() {\n        ensure_dir(parent).with_context(|| {\n            format!(\n                \"Failed to create destination directory for: {}\",\n                to.display()\n            )\n        })?;\n    }\n\n    fs::copy(from, to)\n        .with_context(|| format!(\"Failed to copy from {} to {}\", from.display(), to.display()))\n}\n\n/// Remove a file if it exists\n///\n/// This function does not return an error if the file doesn't exist.\n///\n/// # Examples\n///\n/// ```rust,no_run\n/// use llmspell_utils::file_utils::remove_file_if_exists;\n/// use std::path::Path;\n///\n/// # fn main() -> Result<(), Box<dyn std::error::Error>> {\n/// remove_file_if_exists(Path::new(\"/tmp/old-file.txt\"))?;\n/// # Ok(())\n/// # }\n/// ```\n///\n/// # Errors\n///\n/// Returns an error if:\n/// - The path exists but is a directory\n/// - Insufficient permissions\n/// - I/O error occurs (other than `NotFound`)\npub fn remove_file_if_exists(path: &Path) -> Result<()> {\n    match fs::remove_file(path) {\n        Ok(()) => Ok(()),\n        Err(e) if e.kind() == io::ErrorKind::NotFound => Ok(()),\n        Err(e) => Err(e).with_context(|| format!(\"Failed to remove file: {}\", path.display())),\n    }\n}\n\n/// Remove a directory and all its contents if it exists\n///\n/// This function does not return an error if the directory doesn't exist.\n///\n/// # Examples\n///\n/// ```rust,no_run\n/// use llmspell_utils::file_utils::remove_dir_all_if_exists;\n/// use std::path::Path;\n///\n/// # fn main() -> Result<(), Box<dyn std::error::Error>> {\n/// remove_dir_all_if_exists(Path::new(\"/tmp/old-dir\"))?;\n/// # Ok(())\n/// # }\n/// ```\n///\n/// # Errors\n///\n/// Returns an error if:\n/// - The path exists but is a file\n/// - Insufficient permissions\n/// - I/O error occurs (other than `NotFound`)\npub fn remove_dir_all_if_exists(path: &Path) -> Result<()> {\n    match fs::remove_dir_all(path) {\n        Ok(()) => Ok(()),\n        Err(e) if e.kind() == io::ErrorKind::NotFound => Ok(()),\n        Err(e) => Err(e).with_context(|| format!(\"Failed to remove directory: {}\", path.display())),\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::env;\n    use std::fs;\n\n    #[test]\n    fn test_normalize_path() {\n        // Test basic normalization\n        let path = normalize_path(Path::new(\"/home/user/../user/./docs\"));\n        assert_eq!(path, Path::new(\"/home/user/docs\"));\n\n        // Test with multiple dots\n        let path = normalize_path(Path::new(\"./foo/./bar/../baz\"));\n        assert_eq!(path, Path::new(\"foo/baz\"));\n\n        // Test with trailing slash\n        let path = normalize_path(Path::new(\"/home/user/\"));\n        assert_eq!(path, Path::new(\"/home/user\"));\n    }\n\n    #[test]\n    fn test_is_absolute_path() {\n        assert!(is_absolute_path(Path::new(\"/home/user\")));\n        assert!(!is_absolute_path(Path::new(\"relative/path\")));\n        assert!(!is_absolute_path(Path::new(\"./relative\")));\n        assert!(!is_absolute_path(Path::new(\"../parent\")));\n    }\n\n    #[test]\n    fn test_join_paths() {\n        // Basic join\n        let joined = join_paths(&[Path::new(\"/home\"), Path::new(\"user\"), Path::new(\"docs\")]);\n        assert_eq!(joined, Path::new(\"/home/user/docs\"));\n\n        // Join with absolute path in middle (should reset)\n        let joined = join_paths(&[Path::new(\"/home\"), Path::new(\"/usr\"), Path::new(\"bin\")]);\n        assert_eq!(joined, Path::new(\"/usr/bin\"));\n\n        // Join with empty components\n        let joined = join_paths(&[Path::new(\"/home\"), Path::new(\"\"), Path::new(\"user\")]);\n        assert_eq!(joined, Path::new(\"/home/user\"));\n    }\n\n    #[test]\n    fn test_parent_dir() {\n        assert_eq!(\n            parent_dir(Path::new(\"/home/user/file.txt\")),\n            Some(Path::new(\"/home/user\").to_path_buf())\n        );\n\n        assert_eq!(\n            parent_dir(Path::new(\"/home\")),\n            Some(Path::new(\"/\").to_path_buf())\n        );\n\n        // Root has no parent\n        assert_eq!(parent_dir(Path::new(\"/\")), None);\n    }\n\n    #[test]\n    fn test_expand_path_tilde() {\n        // Set HOME for consistent testing\n        let original_home = env::var(\"HOME\").ok();\n        env::set_var(\"HOME\", \"/test/home\");\n\n        assert_eq!(expand_path(\"~\").unwrap(), Path::new(\"/test/home\"));\n\n        assert_eq!(\n            expand_path(\"~/Documents\").unwrap(),\n            Path::new(\"/test/home/Documents\")\n        );\n\n        // Restore original HOME\n        if let Some(home) = original_home {\n            env::set_var(\"HOME\", home);\n        } else {\n            env::remove_var(\"HOME\");\n        }\n    }\n\n    #[test]\n    fn test_expand_path_env_vars() {\n        // Set test environment variable\n        env::set_var(\"TEST_VAR\", \"/test/path\");\n\n        // Test $VAR syntax\n        assert_eq!(\n            expand_path(\"$TEST_VAR/file.txt\").unwrap(),\n            Path::new(\"/test/path/file.txt\")\n        );\n\n        // Test ${VAR} syntax\n        assert_eq!(\n            expand_path(\"${TEST_VAR}/file.txt\").unwrap(),\n            Path::new(\"/test/path/file.txt\")\n        );\n\n        // Test missing variable\n        assert!(expand_path(\"$NONEXISTENT_VAR/file.txt\").is_err());\n\n        // Cleanup\n        env::remove_var(\"TEST_VAR\");\n    }\n\n    #[test]\n    fn test_ensure_dir() {\n        let temp_dir = std::env::temp_dir();\n        let test_dir = temp_dir.join(format!(\"llmspell_test_{}\", uuid::Uuid::new_v4()));\n\n        // Test creating new directory\n        assert!(ensure_dir(&test_dir).is_ok());\n        assert!(test_dir.exists());\n        assert!(test_dir.is_dir());\n\n        // Test calling on existing directory (should be no-op)\n        assert!(ensure_dir(&test_dir).is_ok());\n\n        // Test with nested directories\n        let nested = test_dir.join(\"a/b/c\");\n        assert!(ensure_dir(&nested).is_ok());\n        assert!(nested.exists());\n\n        // Cleanup\n        let _ = fs::remove_dir_all(&test_dir);\n    }\n\n    #[test]\n    fn test_ensure_dir_file_exists() {\n        let temp_dir = std::env::temp_dir();\n        let test_file = temp_dir.join(format!(\"llmspell_test_file_{}\", uuid::Uuid::new_v4()));\n\n        // Create a file\n        fs::write(&test_file, \"test\").unwrap();\n\n        // Try to ensure_dir on a file (should fail)\n        let result = ensure_dir(&test_file);\n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err().kind(), io::ErrorKind::AlreadyExists);\n\n        // Cleanup\n        let _ = fs::remove_file(&test_file);\n    }\n\n    #[test]\n    fn test_read_write_file() {\n        let temp_dir = std::env::temp_dir();\n        let test_file = temp_dir.join(format!(\"llmspell_test_rw_{}\", uuid::Uuid::new_v4()));\n\n        let data = b\"Hello, world!\";\n\n        // Test write\n        assert!(write_file(&test_file, data).is_ok());\n        assert!(test_file.exists());\n\n        // Test read\n        let read_data = read_file(&test_file).unwrap();\n        assert_eq!(read_data, data);\n\n        // Cleanup\n        let _ = fs::remove_file(&test_file);\n    }\n\n    #[test]\n    fn test_write_file_creates_parent_dirs() {\n        let temp_dir = std::env::temp_dir();\n        let test_file = temp_dir.join(format!(\n            \"llmspell_test_{}/nested/file.txt\",\n            uuid::Uuid::new_v4()\n        ));\n\n        let data = b\"Test data\";\n\n        // Parent directories don't exist yet\n        assert!(!test_file.parent().unwrap().exists());\n\n        // Write should create parent directories\n        assert!(write_file(&test_file, data).is_ok());\n        assert!(test_file.exists());\n\n        // Verify content\n        let read_data = read_file(&test_file).unwrap();\n        assert_eq!(read_data, data);\n\n        // Cleanup\n        let _ = fs::remove_dir_all(test_file.parent().unwrap().parent().unwrap());\n    }\n\n    #[test]\n    fn test_atomic_write() {\n        let temp_dir = std::env::temp_dir();\n        let test_file = temp_dir.join(format!(\"llmspell_test_atomic_{}\", uuid::Uuid::new_v4()));\n\n        let data1 = b\"Initial data\";\n        let data2 = b\"Updated data\";\n\n        // Initial write\n        assert!(write_file_atomic(&test_file, data1).is_ok());\n        assert_eq!(read_file(&test_file).unwrap(), data1);\n\n        // Atomic update\n        assert!(write_file_atomic(&test_file, data2).is_ok());\n        assert_eq!(read_file(&test_file).unwrap(), data2);\n\n        // Verify no temp files remain\n        let parent = test_file.parent().unwrap();\n        for entry in fs::read_dir(parent).unwrap() {\n            let entry = entry.unwrap();\n            let name = entry.file_name();\n            let name_str = name.to_string_lossy();\n            assert!(!name_str.contains(\".tmp.\"), \"Found temp file: {name_str}\");\n        }\n\n        // Cleanup\n        let _ = fs::remove_file(&test_file);\n    }\n\n    #[test]\n    fn test_copy_file() {\n        let temp_dir = std::env::temp_dir();\n        let source = temp_dir.join(format!(\"llmspell_test_src_{}\", uuid::Uuid::new_v4()));\n        let dest = temp_dir.join(format!(\"llmspell_test_dst_{}\", uuid::Uuid::new_v4()));\n\n        let data = b\"Test data for copy\";\n\n        // Create source file\n        write_file(&source, data).unwrap();\n\n        // Copy file\n        let bytes_copied = copy_file(&source, &dest).unwrap();\n        assert_eq!(bytes_copied, data.len() as u64);\n\n        // Verify destination\n        assert!(dest.exists());\n        assert_eq!(read_file(&dest).unwrap(), data);\n\n        // Cleanup\n        let _ = fs::remove_file(&source);\n        let _ = fs::remove_file(&dest);\n    }\n\n    #[test]\n    fn test_remove_file_if_exists() {\n        let temp_dir = std::env::temp_dir();\n        let test_file = temp_dir.join(format!(\"llmspell_test_rm_{}\", uuid::Uuid::new_v4()));\n\n        // Remove non-existent file (should succeed)\n        assert!(remove_file_if_exists(&test_file).is_ok());\n\n        // Create and remove file\n        write_file(&test_file, b\"test\").unwrap();\n        assert!(test_file.exists());\n        assert!(remove_file_if_exists(&test_file).is_ok());\n        assert!(!test_file.exists());\n\n        // Remove again (should still succeed)\n        assert!(remove_file_if_exists(&test_file).is_ok());\n    }\n\n    #[test]\n    fn test_remove_dir_all_if_exists() {\n        let temp_dir = std::env::temp_dir();\n        let test_dir = temp_dir.join(format!(\"llmspell_test_rmdir_{}\", uuid::Uuid::new_v4()));\n\n        // Remove non-existent directory (should succeed)\n        assert!(remove_dir_all_if_exists(&test_dir).is_ok());\n\n        // Create directory with contents\n        let nested = test_dir.join(\"nested\");\n        ensure_dir(&nested).unwrap();\n        write_file(&nested.join(\"file.txt\"), b\"test\").unwrap();\n\n        assert!(test_dir.exists());\n        assert!(remove_dir_all_if_exists(&test_dir).is_ok());\n        assert!(!test_dir.exists());\n\n        // Remove again (should still succeed)\n        assert!(remove_dir_all_if_exists(&test_dir).is_ok());\n    }\n\n    #[cfg(unix)]\n    #[test]\n    fn test_unix_specific_paths() {\n        // Test Unix-specific path handling\n        assert!(is_absolute_path(Path::new(\"/usr/bin\")));\n        assert!(is_absolute_path(Path::new(\"/home/user/.config\")));\n        assert!(!is_absolute_path(Path::new(\"usr/bin\")));\n    }\n\n    #[cfg(windows)]\n    #[test]\n    fn test_windows_specific_paths() {\n        // Test Windows-specific path handling\n        assert!(is_absolute_path(Path::new(\"C:\\\\Windows\")));\n        assert!(is_absolute_path(Path::new(\"\\\\\\\\server\\\\share\")));\n        assert!(!is_absolute_path(Path::new(\"Windows\\\\System32\")));\n\n        // Test Windows environment variable syntax\n        env::set_var(\"WINTEST\", \"C:\\\\Test\");\n        assert_eq!(\n            expand_path(\"%WINTEST%\\\\file.txt\").unwrap(),\n            Path::new(\"C:\\\\Test\\\\file.txt\")\n        );\n        env::remove_var(\"WINTEST\");\n    }\n}\n\n#[cfg(test)]\nmod property_tests {\n    use super::*;\n    use proptest::prelude::*;\n\n    proptest! {\n        #[test]\n        fn test_normalize_path_idempotent(path in prop::collection::vec(\"[a-zA-Z0-9./\\\\-_]+\", 1..10)) {\n            let path_str = path.join(\"/\");\n            let path = Path::new(&path_str);\n            let normalized = normalize_path(path);\n            let normalized_again = normalize_path(&normalized);\n            assert_eq!(normalized, normalized_again);\n        }\n\n        #[test]\n        fn test_join_paths_associative(\n            a in \"[a-zA-Z0-9]+\",\n            b in \"[a-zA-Z0-9]+\",\n            c in \"[a-zA-Z0-9]+\"\n        ) {\n            let path_a = Path::new(&a);\n            let path_b = Path::new(&b);\n            let path_c = Path::new(&c);\n\n            let result1 = join_paths(&[&join_paths(&[path_a, path_b]), path_c]);\n            let result2 = join_paths(&[path_a, &join_paths(&[path_b, path_c])]);\n            assert_eq!(result1, result2);\n        }\n\n        #[test]\n        fn test_write_read_roundtrip(data: Vec<u8>) {\n            let temp_dir = std::env::temp_dir();\n            let test_file = temp_dir.join(format!(\"llmspell_prop_{}\", uuid::Uuid::new_v4()));\n\n            // Skip if data is too large\n            if data.len() > 1_000_000 {\n                return Ok(());\n            }\n\n            write_file(&test_file, &data).unwrap();\n            let read_data = read_file(&test_file).unwrap();\n            assert_eq!(data, read_data);\n\n            // Cleanup\n            let _ = fs::remove_file(&test_file);\n        }\n    }\n}\n\n#[cfg(all(test, not(debug_assertions)))]\nmod benchmarks {\n    use super::*;\n    use criterion::{black_box, Criterion};\n\n    pub fn bench_normalize_path(c: &mut Criterion) {\n        c.bench_function(\"normalize_path\", |b| {\n            b.iter(|| normalize_path(black_box(Path::new(\"/home/user/../user/./docs/./file.txt\"))));\n        });\n    }\n\n    pub fn bench_expand_path(c: &mut Criterion) {\n        env::set_var(\"BENCH_VAR\", \"/test/path\");\n\n        c.bench_function(\"expand_path\", |b| {\n            b.iter(|| expand_path(black_box(\"$BENCH_VAR/subdir/file.txt\")).unwrap());\n        });\n\n        env::remove_var(\"BENCH_VAR\");\n    }\n\n    pub fn bench_write_file(c: &mut Criterion) {\n        let temp_dir = std::env::temp_dir();\n        let test_file = temp_dir.join(\"llmspell_bench_write\");\n        let data = vec![b'x'; 1024]; // 1KB of data\n\n        c.bench_function(\"write_file_1kb\", |b| {\n            b.iter(|| write_file(black_box(&test_file), black_box(&data)).unwrap());\n        });\n\n        // Cleanup\n        let _ = fs::remove_file(&test_file);\n    }\n\n    pub fn bench_write_file_atomic(c: &mut Criterion) {\n        let temp_dir = std::env::temp_dir();\n        let test_file = temp_dir.join(\"llmspell_bench_atomic\");\n        let data = vec![b'x'; 1024]; // 1KB of data\n\n        c.bench_function(\"write_file_atomic_1kb\", |b| {\n            b.iter(|| write_file_atomic(black_box(&test_file), black_box(&data)).unwrap());\n        });\n\n        // Cleanup\n        let _ = fs::remove_file(&test_file);\n    }\n\n    pub fn bench_read_file(c: &mut Criterion) {\n        let temp_dir = std::env::temp_dir();\n        let test_file = temp_dir.join(\"llmspell_bench_read\");\n        let data = vec![b'x'; 1024]; // 1KB of data\n\n        // Create file\n        write_file(&test_file, &data).unwrap();\n\n        c.bench_function(\"read_file_1kb\", |b| {\n            b.iter(|| read_file(black_box(&test_file)).unwrap());\n        });\n\n        // Cleanup\n        let _ = fs::remove_file(&test_file);\n    }\n}\n","traces":[{"line":62,"address":[],"length":0,"stats":{"Line":269}},{"line":63,"address":[],"length":0,"stats":{"Line":269}},{"line":64,"address":[],"length":0,"stats":{"Line":265}},{"line":65,"address":[],"length":0,"stats":{"Line":264}},{"line":67,"address":[],"length":0,"stats":{"Line":1}},{"line":68,"address":[],"length":0,"stats":{"Line":1}},{"line":69,"address":[],"length":0,"stats":{"Line":1}},{"line":73,"address":[],"length":0,"stats":{"Line":4}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":6}},{"line":109,"address":[],"length":0,"stats":{"Line":6}},{"line":112,"address":[],"length":0,"stats":{"Line":10}},{"line":113,"address":[],"length":0,"stats":{"Line":6}},{"line":114,"address":[],"length":0,"stats":{"Line":3}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":1}},{"line":125,"address":[],"length":0,"stats":{"Line":2}},{"line":131,"address":[],"length":0,"stats":{"Line":6}},{"line":132,"address":[],"length":0,"stats":{"Line":6}},{"line":134,"address":[],"length":0,"stats":{"Line":141}},{"line":136,"address":[],"length":0,"stats":{"Line":3}},{"line":139,"address":[],"length":0,"stats":{"Line":3}},{"line":140,"address":[],"length":0,"stats":{"Line":3}},{"line":141,"address":[],"length":0,"stats":{"Line":1}},{"line":143,"address":[],"length":0,"stats":{"Line":10}},{"line":144,"address":[],"length":0,"stats":{"Line":9}},{"line":145,"address":[],"length":0,"stats":{"Line":1}},{"line":147,"address":[],"length":0,"stats":{"Line":8}},{"line":151,"address":[],"length":0,"stats":{"Line":27}},{"line":152,"address":[],"length":0,"stats":{"Line":52}},{"line":153,"address":[],"length":0,"stats":{"Line":23}},{"line":154,"address":[],"length":0,"stats":{"Line":23}},{"line":156,"address":[],"length":0,"stats":{"Line":2}},{"line":161,"address":[],"length":0,"stats":{"Line":3}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":3}},{"line":165,"address":[],"length":0,"stats":{"Line":2}},{"line":167,"address":[],"length":0,"stats":{"Line":1}},{"line":168,"address":[],"length":0,"stats":{"Line":1}},{"line":169,"address":[],"length":0,"stats":{"Line":1}},{"line":174,"address":[],"length":0,"stats":{"Line":65}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":5}},{"line":224,"address":[],"length":0,"stats":{"Line":516}},{"line":225,"address":[],"length":0,"stats":{"Line":516}},{"line":253,"address":[],"length":0,"stats":{"Line":261}},{"line":255,"address":[],"length":0,"stats":{"Line":522}},{"line":256,"address":[],"length":0,"stats":{"Line":522}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":261}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":261}},{"line":303,"address":[],"length":0,"stats":{"Line":261}},{"line":305,"address":[],"length":0,"stats":{"Line":522}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":261}},{"line":312,"address":[],"length":0,"stats":{"Line":261}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":261}},{"line":318,"address":[],"length":0,"stats":{"Line":261}},{"line":320,"address":[],"length":0,"stats":{"Line":261}},{"line":349,"address":[],"length":0,"stats":{"Line":2}},{"line":351,"address":[],"length":0,"stats":{"Line":4}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":353,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":2}},{"line":359,"address":[],"length":0,"stats":{"Line":2}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":373,"address":[],"length":0,"stats":{"Line":2}},{"line":374,"address":[],"length":0,"stats":{"Line":4}},{"line":375,"address":[],"length":0,"stats":{"Line":4}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":2}},{"line":382,"address":[],"length":0,"stats":{"Line":2}},{"line":384,"address":[],"length":0,"stats":{"Line":2}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":394,"address":[],"length":0,"stats":{"Line":2}},{"line":395,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":397,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":0}},{"line":402,"address":[],"length":0,"stats":{"Line":2}},{"line":427,"address":[],"length":0,"stats":{"Line":9}},{"line":428,"address":[],"length":0,"stats":{"Line":9}},{"line":448,"address":[],"length":0,"stats":{"Line":1028}},{"line":449,"address":[],"length":0,"stats":{"Line":1028}},{"line":451,"address":[],"length":0,"stats":{"Line":5146}},{"line":452,"address":[],"length":0,"stats":{"Line":5}},{"line":453,"address":[],"length":0,"stats":{"Line":5}},{"line":455,"address":[],"length":0,"stats":{"Line":2054}},{"line":459,"address":[],"length":0,"stats":{"Line":1028}},{"line":478,"address":[],"length":0,"stats":{"Line":4}},{"line":479,"address":[],"length":0,"stats":{"Line":4}},{"line":503,"address":[],"length":0,"stats":{"Line":1}},{"line":505,"address":[],"length":0,"stats":{"Line":2}},{"line":506,"address":[],"length":0,"stats":{"Line":0}},{"line":507,"address":[],"length":0,"stats":{"Line":0}},{"line":508,"address":[],"length":0,"stats":{"Line":0}},{"line":509,"address":[],"length":0,"stats":{"Line":0}},{"line":514,"address":[],"length":0,"stats":{"Line":1}},{"line":515,"address":[],"length":0,"stats":{"Line":1}},{"line":540,"address":[],"length":0,"stats":{"Line":3}},{"line":541,"address":[],"length":0,"stats":{"Line":3}},{"line":542,"address":[],"length":0,"stats":{"Line":1}},{"line":543,"address":[],"length":0,"stats":{"Line":6}},{"line":544,"address":[],"length":0,"stats":{"Line":0}},{"line":570,"address":[],"length":0,"stats":{"Line":3}},{"line":571,"address":[],"length":0,"stats":{"Line":3}},{"line":572,"address":[],"length":0,"stats":{"Line":1}},{"line":573,"address":[],"length":0,"stats":{"Line":6}},{"line":574,"address":[],"length":0,"stats":{"Line":0}}],"covered":88,"coverable":134},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-utils","src","id_generator.rs"],"content":"// ABOUTME: Component ID generation using UUIDs with namespace support\n// ABOUTME: Provides consistent ID generation for all LLMSpell components\n\n//! Component ID generation utilities\n//!\n//! This module provides UUID-based ID generation for components,\n//! with support for namespaced IDs and deterministic generation.\n\nuse std::sync::atomic::{AtomicU64, Ordering};\nuse uuid::Uuid;\n\n/// Type alias for component IDs\npub type ComponentId = String;\n\n/// Counter for sequential IDs (used in tests)\nstatic SEQUENTIAL_COUNTER: AtomicU64 = AtomicU64::new(0);\n\n/// Generate a unique component ID with prefix\n///\n/// Creates a UUID v4 with the given prefix. The format is: `{prefix}_{uuid}`\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::id_generator::generate_component_id;\n///\n/// let agent_id = generate_component_id(\"agent\");\n/// assert!(agent_id.starts_with(\"agent_\"));\n/// assert_eq!(agent_id.len(), 42); // \"agent_\" (6) + UUID (36)\n/// ```\n#[must_use]\npub fn generate_component_id(prefix: &str) -> ComponentId {\n    let uuid = Uuid::new_v4();\n    format!(\"{prefix}_{uuid}\")\n}\n\n/// Generate a short component ID with prefix\n///\n/// Creates a shorter ID using only the first 8 characters of the UUID.\n/// Less collision-resistant but more readable.\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::id_generator::generate_short_id;\n///\n/// let tool_id = generate_short_id(\"tool\");\n/// assert!(tool_id.starts_with(\"tool_\"));\n/// assert!(tool_id.len() <= 14); // \"tool_\" (5) + 8 UUID chars\n/// ```\n#[must_use]\npub fn generate_short_id(prefix: &str) -> ComponentId {\n    let uuid = Uuid::new_v4();\n    let short_uuid = &uuid.to_string()[..8];\n    format!(\"{prefix}_{short_uuid}\")\n}\n\n/// Generate a deterministic component ID\n///\n/// Creates a UUID v5 (namespace + name based) for deterministic generation.\n/// The same namespace and name will always produce the same ID.\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::id_generator::{generate_deterministic_id, NAMESPACE_AGENT};\n///\n/// let id1 = generate_deterministic_id(NAMESPACE_AGENT, \"my-agent\");\n/// let id2 = generate_deterministic_id(NAMESPACE_AGENT, \"my-agent\");\n/// assert_eq!(id1, id2);\n/// ```\n#[must_use]\npub fn generate_deterministic_id(namespace: &Uuid, name: &str) -> ComponentId {\n    let uuid = Uuid::new_v5(namespace, name.as_bytes());\n    uuid.to_string()\n}\n\n/// Generate a sequential ID for testing\n///\n/// Creates IDs with incrementing numbers. Useful for tests where\n/// you need predictable, ordered IDs.\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::id_generator::generate_sequential_id;\n///\n/// let id1 = generate_sequential_id(\"test\");\n/// let id2 = generate_sequential_id(\"test\");\n/// assert!(id1 < id2); // Lexicographically ordered\n/// ```\n#[must_use]\npub fn generate_sequential_id(prefix: &str) -> ComponentId {\n    let count = SEQUENTIAL_COUNTER.fetch_add(1, Ordering::SeqCst);\n    format!(\"{prefix}_{count:08}\")\n}\n\n/// Validate a component ID format\n///\n/// Checks if the ID follows the expected format: `{prefix}_{uuid}`\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::id_generator::{generate_component_id, validate_component_id};\n///\n/// let id = generate_component_id(\"agent\");\n/// assert!(validate_component_id(&id, Some(\"agent\")));\n/// assert!(!validate_component_id(&id, Some(\"tool\")));\n/// assert!(!validate_component_id(\"invalid-id\", None));\n/// ```\n#[must_use]\npub fn validate_component_id(id: &str, expected_prefix: Option<&str>) -> bool {\n    let parts: Vec<&str> = id.splitn(2, '_').collect();\n\n    if parts.len() != 2 {\n        return false;\n    }\n\n    // Check prefix if specified\n    if let Some(prefix) = expected_prefix {\n        if parts[0] != prefix {\n            return false;\n        }\n    }\n\n    // Validate UUID part\n    Uuid::parse_str(parts[1]).is_ok()\n}\n\n/// Extract the prefix from a component ID\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::id_generator::{generate_component_id, extract_prefix};\n///\n/// let id = generate_component_id(\"workflow\");\n/// assert_eq!(extract_prefix(&id), Some(\"workflow\"));\n/// assert_eq!(extract_prefix(\"invalid\"), None);\n/// ```\n#[must_use]\npub fn extract_prefix(id: &str) -> Option<&str> {\n    id.find('_').map(|pos| &id[..pos])\n}\n\n/// Extract the UUID part from a component ID\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::id_generator::{generate_component_id, extract_uuid};\n///\n/// let id = generate_component_id(\"agent\");\n/// let uuid = extract_uuid(&id).unwrap();\n/// assert_eq!(uuid.len(), 36); // Standard UUID length\n/// ```\n#[must_use]\npub fn extract_uuid(id: &str) -> Option<&str> {\n    id.find('_').map(|pos| &id[pos + 1..])\n}\n\n// Predefined namespaces for deterministic ID generation\n/// Namespace for agent IDs\npub const NAMESPACE_AGENT: &Uuid = &Uuid::from_bytes([\n    0x6b, 0xa1, 0x3d, 0x5a, 0x3f, 0x5d, 0x4a, 0x5b, 0x9f, 0x7e, 0x3d, 0x5a, 0x2f, 0x4d, 0x3a, 0x2b,\n]);\n\n/// Namespace for tool IDs\npub const NAMESPACE_TOOL: &Uuid = &Uuid::from_bytes([\n    0x7c, 0xb2, 0x4e, 0x6b, 0x4f, 0x6e, 0x5b, 0x6c, 0xaf, 0x8f, 0x4e, 0x6b, 0x3f, 0x5e, 0x4b, 0x3c,\n]);\n\n/// Namespace for workflow IDs\npub const NAMESPACE_WORKFLOW: &Uuid = &Uuid::from_bytes([\n    0x8d, 0xc3, 0x5f, 0x7c, 0x5f, 0x7f, 0x6c, 0x7d, 0xbf, 0x9f, 0x5f, 0x7c, 0x4f, 0x6f, 0x5c, 0x4d,\n]);\n\n/// Builder for creating customized component IDs\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::id_generator::ComponentIdBuilder;\n///\n/// let id = ComponentIdBuilder::new()\n///     .with_prefix(\"custom\")\n///     .with_timestamp()\n///     .build();\n///\n/// assert!(id.starts_with(\"custom_\"));\n/// assert!(id.contains(\"_\")); // Contains timestamp separator\n/// ```\npub struct ComponentIdBuilder {\n    prefix: Option<String>,\n    use_timestamp: bool,\n    use_short: bool,\n    custom_suffix: Option<String>,\n}\n\nimpl ComponentIdBuilder {\n    /// Create a new ID builder\n    #[must_use]\n    pub fn new() -> Self {\n        Self {\n            prefix: None,\n            use_timestamp: false,\n            use_short: false,\n            custom_suffix: None,\n        }\n    }\n\n    /// Set the prefix for the ID\n    #[must_use]\n    pub fn with_prefix(mut self, prefix: impl Into<String>) -> Self {\n        self.prefix = Some(prefix.into());\n        self\n    }\n\n    /// Include a timestamp in the ID\n    #[must_use]\n    pub fn with_timestamp(mut self) -> Self {\n        self.use_timestamp = true;\n        self\n    }\n\n    /// Use short UUID format\n    #[must_use]\n    pub fn short(mut self) -> Self {\n        self.use_short = true;\n        self\n    }\n\n    /// Add a custom suffix\n    #[must_use]\n    pub fn with_suffix(mut self, suffix: impl Into<String>) -> Self {\n        self.custom_suffix = Some(suffix.into());\n        self\n    }\n\n    /// Build the component ID\n    #[must_use]\n    pub fn build(self) -> ComponentId {\n        let mut parts = Vec::new();\n\n        // Add prefix\n        if let Some(prefix) = self.prefix {\n            parts.push(prefix);\n        }\n\n        // Add timestamp if requested\n        if self.use_timestamp {\n            use chrono::Utc;\n            parts.push(Utc::now().timestamp().to_string());\n        }\n\n        // Add UUID\n        let uuid = Uuid::new_v4();\n        let uuid_str = if self.use_short {\n            uuid.to_string()[..8].to_string()\n        } else {\n            uuid.to_string()\n        };\n        parts.push(uuid_str);\n\n        // Add custom suffix\n        if let Some(suffix) = self.custom_suffix {\n            parts.push(suffix);\n        }\n\n        parts.join(\"_\")\n    }\n}\n\nimpl Default for ComponentIdBuilder {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_generate_component_id() {\n        let id1 = generate_component_id(\"agent\");\n        let id2 = generate_component_id(\"agent\");\n\n        assert!(id1.starts_with(\"agent_\"));\n        assert!(id2.starts_with(\"agent_\"));\n        assert_ne!(id1, id2); // Should be unique\n        assert_eq!(id1.len(), 42); // \"agent_\" (6) + UUID (36)\n    }\n\n    #[test]\n    fn test_generate_short_id() {\n        let id = generate_short_id(\"tool\");\n        assert!(id.starts_with(\"tool_\"));\n        assert!(id.len() <= 14); // \"tool_\" (5) + 8 chars max\n    }\n\n    #[test]\n    fn test_generate_deterministic_id() {\n        let id1 = generate_deterministic_id(NAMESPACE_AGENT, \"test-agent\");\n        let id2 = generate_deterministic_id(NAMESPACE_AGENT, \"test-agent\");\n        let id3 = generate_deterministic_id(NAMESPACE_AGENT, \"other-agent\");\n\n        assert_eq!(id1, id2); // Same input produces same output\n        assert_ne!(id1, id3); // Different input produces different output\n    }\n\n    #[test]\n    fn test_generate_sequential_id() {\n        let id1 = generate_sequential_id(\"seq\");\n        let id2 = generate_sequential_id(\"seq\");\n        let id3 = generate_sequential_id(\"seq\");\n\n        assert!(id1 < id2);\n        assert!(id2 < id3);\n        assert!(id1.starts_with(\"seq_\"));\n    }\n\n    #[test]\n    fn test_validate_component_id() {\n        let valid_id = generate_component_id(\"workflow\");\n        assert!(validate_component_id(&valid_id, Some(\"workflow\")));\n        assert!(!validate_component_id(&valid_id, Some(\"agent\")));\n        assert!(validate_component_id(&valid_id, None));\n\n        assert!(!validate_component_id(\"invalid\", None));\n        assert!(!validate_component_id(\"invalid_format\", None));\n        assert!(!validate_component_id(\"prefix_not-a-uuid\", None));\n    }\n\n    #[test]\n    fn test_extract_prefix() {\n        let id = generate_component_id(\"custom\");\n        assert_eq!(extract_prefix(&id), Some(\"custom\"));\n        assert_eq!(extract_prefix(\"no-underscore\"), None);\n        assert_eq!(extract_prefix(\"multiple_under_scores\"), Some(\"multiple\"));\n    }\n\n    #[test]\n    fn test_extract_uuid() {\n        let id = generate_component_id(\"prefix\");\n        let uuid_part = extract_uuid(&id).unwrap();\n        assert_eq!(uuid_part.len(), 36);\n        assert!(Uuid::parse_str(uuid_part).is_ok());\n\n        assert_eq!(extract_uuid(\"no-underscore\"), None);\n    }\n\n    #[test]\n    fn test_component_id_builder() {\n        // Basic usage\n        let id1 = ComponentIdBuilder::new().with_prefix(\"builder\").build();\n        assert!(id1.starts_with(\"builder_\"));\n\n        // Short ID\n        let id2 = ComponentIdBuilder::new()\n            .with_prefix(\"short\")\n            .short()\n            .build();\n        assert!(id2.starts_with(\"short_\"));\n        assert!(id2.len() < 20);\n\n        // With suffix\n        let id3 = ComponentIdBuilder::new()\n            .with_prefix(\"suffixed\")\n            .with_suffix(\"v1\")\n            .build();\n        assert!(id3.starts_with(\"suffixed_\"));\n        assert!(id3.ends_with(\"_v1\"));\n\n        // With timestamp\n        let id4 = ComponentIdBuilder::new()\n            .with_prefix(\"timed\")\n            .with_timestamp()\n            .build();\n        assert!(id4.starts_with(\"timed_\"));\n        let parts: Vec<&str> = id4.split('_').collect();\n        assert!(parts.len() >= 3); // prefix, timestamp, uuid\n    }\n\n    #[test]\n    fn test_namespace_uniqueness() {\n        // Ensure namespaces are different\n        assert_ne!(NAMESPACE_AGENT, NAMESPACE_TOOL);\n        assert_ne!(NAMESPACE_AGENT, NAMESPACE_WORKFLOW);\n        assert_ne!(NAMESPACE_TOOL, NAMESPACE_WORKFLOW);\n    }\n\n    #[test]\n    fn test_different_prefixes() {\n        let agent_id = generate_component_id(\"agent\");\n        let tool_id = generate_component_id(\"tool\");\n        let workflow_id = generate_component_id(\"workflow\");\n\n        assert!(agent_id.starts_with(\"agent_\"));\n        assert!(tool_id.starts_with(\"tool_\"));\n        assert!(workflow_id.starts_with(\"workflow_\"));\n\n        // Validate each\n        assert!(validate_component_id(&agent_id, Some(\"agent\")));\n        assert!(validate_component_id(&tool_id, Some(\"tool\")));\n        assert!(validate_component_id(&workflow_id, Some(\"workflow\")));\n    }\n}\n\n#[cfg(test)]\nmod property_tests {\n    use super::*;\n    use proptest::prelude::*;\n\n    proptest! {\n        #[test]\n        fn test_id_generation_properties(prefix in \"[a-z]+\") {\n            let id = generate_component_id(&prefix);\n\n            // ID should start with prefix\n            assert!(id.starts_with(&format!(\"{prefix}_\")));\n\n            // ID should be validatable\n            assert!(validate_component_id(&id, Some(&prefix)));\n\n            // Should be able to extract parts\n            assert_eq!(extract_prefix(&id), Some(prefix.as_str()));\n            assert!(extract_uuid(&id).is_some());\n        }\n\n        #[test]\n        fn test_deterministic_properties(name in \"[a-zA-Z0-9-]+\") {\n            let id1 = generate_deterministic_id(NAMESPACE_AGENT, &name);\n            let id2 = generate_deterministic_id(NAMESPACE_AGENT, &name);\n\n            // Same input always produces same output\n            assert_eq!(id1, id2);\n\n            // Valid UUID format\n            assert!(Uuid::parse_str(&id1).is_ok());\n        }\n\n        #[test]\n        fn test_builder_properties(\n            prefix in \"[a-z]+\",\n            suffix in \"[a-z0-9]+\",\n        ) {\n            let id = ComponentIdBuilder::new()\n                .with_prefix(&prefix)\n                .with_suffix(&suffix)\n                .build();\n\n            assert!(id.starts_with(&format!(\"{prefix}_\")));\n            assert!(id.ends_with(&format!(\"_{suffix}\")));\n        }\n    }\n}\n","traces":[{"line":32,"address":[],"length":0,"stats":{"Line":265}},{"line":33,"address":[],"length":0,"stats":{"Line":265}},{"line":34,"address":[],"length":0,"stats":{"Line":265}},{"line":52,"address":[],"length":0,"stats":{"Line":2}},{"line":53,"address":[],"length":0,"stats":{"Line":2}},{"line":54,"address":[],"length":0,"stats":{"Line":2}},{"line":55,"address":[],"length":0,"stats":{"Line":2}},{"line":73,"address":[],"length":0,"stats":{"Line":517}},{"line":74,"address":[],"length":0,"stats":{"Line":517}},{"line":75,"address":[],"length":0,"stats":{"Line":517}},{"line":93,"address":[],"length":0,"stats":{"Line":3}},{"line":94,"address":[],"length":0,"stats":{"Line":3}},{"line":95,"address":[],"length":0,"stats":{"Line":3}},{"line":113,"address":[],"length":0,"stats":{"Line":266}},{"line":114,"address":[],"length":0,"stats":{"Line":266}},{"line":116,"address":[],"length":0,"stats":{"Line":266}},{"line":117,"address":[],"length":0,"stats":{"Line":1}},{"line":121,"address":[],"length":0,"stats":{"Line":262}},{"line":123,"address":[],"length":0,"stats":{"Line":1}},{"line":128,"address":[],"length":0,"stats":{"Line":264}},{"line":143,"address":[],"length":0,"stats":{"Line":259}},{"line":144,"address":[],"length":0,"stats":{"Line":776}},{"line":159,"address":[],"length":0,"stats":{"Line":258}},{"line":160,"address":[],"length":0,"stats":{"Line":773}},{"line":204,"address":[],"length":0,"stats":{"Line":261}},{"line":215,"address":[],"length":0,"stats":{"Line":261}},{"line":216,"address":[],"length":0,"stats":{"Line":261}},{"line":217,"address":[],"length":0,"stats":{"Line":261}},{"line":222,"address":[],"length":0,"stats":{"Line":1}},{"line":223,"address":[],"length":0,"stats":{"Line":1}},{"line":224,"address":[],"length":0,"stats":{"Line":1}},{"line":229,"address":[],"length":0,"stats":{"Line":2}},{"line":230,"address":[],"length":0,"stats":{"Line":2}},{"line":231,"address":[],"length":0,"stats":{"Line":2}},{"line":236,"address":[],"length":0,"stats":{"Line":257}},{"line":237,"address":[],"length":0,"stats":{"Line":257}},{"line":238,"address":[],"length":0,"stats":{"Line":257}},{"line":243,"address":[],"length":0,"stats":{"Line":261}},{"line":244,"address":[],"length":0,"stats":{"Line":261}},{"line":247,"address":[],"length":0,"stats":{"Line":522}},{"line":252,"address":[],"length":0,"stats":{"Line":262}},{"line":254,"address":[],"length":0,"stats":{"Line":1}},{"line":258,"address":[],"length":0,"stats":{"Line":261}},{"line":259,"address":[],"length":0,"stats":{"Line":522}},{"line":260,"address":[],"length":0,"stats":{"Line":2}},{"line":262,"address":[],"length":0,"stats":{"Line":259}},{"line":264,"address":[],"length":0,"stats":{"Line":261}},{"line":267,"address":[],"length":0,"stats":{"Line":518}},{"line":271,"address":[],"length":0,"stats":{"Line":261}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":0}}],"covered":49,"coverable":51},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-utils","src","lib.rs"],"content":"// ABOUTME: Shared utilities library for the LLMSpell framework\n// ABOUTME: Provides async helpers, file operations, string manipulation, system info, error builders, ID generation, and serialization utilities\n\n//! # `LLMSpell` Utilities\n//!\n//! This crate provides shared utility functions and helpers used across the `LLMSpell` framework.\n//!\n//! ## Features\n//!\n//! - **Async Utilities**: Helpers for working with async operations, timeouts, and concurrency\n//! - **File Utilities**: Cross-platform file operations and path manipulation\n//! - **String Utilities**: String manipulation, formatting, and validation helpers\n//! - **System Info**: System information gathering and environment utilities\n//! - **Error Builders**: Convenient error construction helpers\n//! - **ID Generator**: UUID-based ID generation for components\n//! - **Serialization**: Common serialization/deserialization utilities\n//!\n//! ## Usage\n//!\n//! ```rust,ignore\n//! use llmspell_utils::{async_utils, file_utils, id_generator};\n//! use std::time::Duration;\n//!\n//! // Generate a unique component ID\n//! let id = id_generator::generate_component_id(\"agent\");\n//!\n//! // Use async utilities for timeout operations (when implemented)\n//! let result = async_utils::timeout(Duration::from_secs(30), async {\n//!     // Your async operation\n//! }).await?;\n//! ```\n\n#![warn(missing_docs)]\n#![deny(clippy::all)]\n#![warn(clippy::pedantic)]\n#![allow(clippy::module_name_repetitions)]\n\n/// Async operation utilities and helpers\npub mod async_utils;\n\n/// File system operations and path utilities\npub mod file_utils;\n\n/// String manipulation and formatting helpers\npub mod string_utils;\n\n/// System information gathering utilities\npub mod system_info;\n\n/// Error construction and builder utilities\npub mod error_builders;\n\n/// Component ID generation utilities\npub mod id_generator;\n\n/// Serialization and deserialization helpers\npub mod serialization;\n\n// Re-export commonly used types and functions\npub use async_utils::{\n    concurrent_map, race_to_success, retry_async, timeout, timeout_with_default, AsyncError,\n    AsyncResult, BoxedResultFuture, Cancellable, RetryConfig,\n};\npub use error_builders::{templates, BuiltError, ErrorBuilder, WithContext};\npub use file_utils::{\n    copy_file, ensure_dir, expand_path, is_absolute_path, join_paths, normalize_path, parent_dir,\n    read_file, remove_dir_all_if_exists, remove_file_if_exists, write_file, write_file_atomic,\n};\npub use id_generator::{\n    generate_component_id, generate_deterministic_id, generate_short_id, validate_component_id,\n    ComponentId, ComponentIdBuilder, NAMESPACE_AGENT, NAMESPACE_TOOL, NAMESPACE_WORKFLOW,\n};\npub use serialization::{\n    convert_format, from_json, from_toml, from_yaml, json, merge_json, to_json, to_json_pretty,\n    to_toml, to_yaml, Format,\n};\npub use string_utils::{\n    dedent, indent, is_valid_identifier, normalize_whitespace, sanitize, to_camel_case,\n    to_pascal_case, to_snake_case, truncate, word_wrap,\n};\npub use system_info::{\n    find_executable, format_bytes, get_cpu_count, get_home_directory, get_hostname,\n    get_system_info, get_username, OperatingSystem, SystemInfo,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-utils","src","serialization.rs"],"content":"// ABOUTME: Common serialization and deserialization utilities for JSON, YAML, and TOML\n// ABOUTME: Provides unified serialization interface used across LLMSpell components\n\n//! Serialization and deserialization helpers\n//!\n//! This module provides common serialization utilities for JSON, YAML, and TOML,\n//! with consistent error handling and type conversions.\n\nuse anyhow::{Context, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value as JsonValue;\nuse std::fmt;\nuse toml::Value as TomlValue;\n\n/// Serialize a value to JSON string\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::serialization::to_json;\n/// use serde::Serialize;\n///\n/// #[derive(Serialize)]\n/// struct Config {\n///     name: String,\n///     port: u16,\n/// }\n///\n/// let config = Config {\n///     name: \"server\".to_string(),\n///     port: 8080,\n/// };\n///\n/// let json = to_json(&config).unwrap();\n/// assert!(json.contains(\"\\\"name\\\":\\\"server\\\"\"));\n/// ```\n///\n/// # Errors\n///\n/// Returns an error if serialization fails\npub fn to_json<T>(value: &T) -> Result<String, serde_json::Error>\nwhere\n    T: Serialize,\n{\n    serde_json::to_string(value)\n}\n\n/// Serialize a value to pretty-printed JSON\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::serialization::to_json_pretty;\n/// use std::collections::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"key\", \"value\");\n///\n/// let json = to_json_pretty(&map).unwrap();\n/// assert!(json.contains(\"{\\n\"));\n/// ```\n///\n/// # Errors\n///\n/// Returns an error if serialization fails\npub fn to_json_pretty<T>(value: &T) -> Result<String, serde_json::Error>\nwhere\n    T: Serialize,\n{\n    serde_json::to_string_pretty(value)\n}\n\n/// Serialize a value to JSON with custom indentation\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::serialization::to_json_with_indent;\n/// use std::collections::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"nested\", HashMap::from([(\"value\", 42)]));\n///\n/// let json = to_json_with_indent(&map, 2).unwrap();\n/// assert!(json.contains(\"  \\\"nested\\\"\"));\n/// ```\n///\n/// # Errors\n///\n/// Returns an error if serialization fails\npub fn to_json_with_indent<T>(value: &T, indent: usize) -> Result<String, serde_json::Error>\nwhere\n    T: Serialize,\n{\n    let indent_bytes = vec![b' '; indent];\n    let formatter = serde_json::ser::PrettyFormatter::with_indent(indent_bytes.as_slice());\n    let mut buf = Vec::new();\n    let mut ser = serde_json::Serializer::with_formatter(&mut buf, formatter);\n    value.serialize(&mut ser)?;\n    String::from_utf8(buf).map_err(|e| serde::ser::Error::custom(e.to_string()))\n}\n\n/// Deserialize a value from JSON string\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::serialization::from_json;\n/// use serde::Deserialize;\n///\n/// #[derive(Deserialize, PartialEq, Debug)]\n/// struct Config {\n///     name: String,\n///     port: u16,\n/// }\n///\n/// let json = r#\"{\"name\": \"server\", \"port\": 8080}\"#;\n/// let config: Config = from_json(json).unwrap();\n/// assert_eq!(config.name, \"server\");\n/// ```\n///\n/// # Errors\n///\n/// Returns an error if deserialization fails\npub fn from_json<'a, T>(s: &'a str) -> Result<T, serde_json::Error>\nwhere\n    T: Deserialize<'a>,\n{\n    serde_json::from_str(s)\n}\n\n/// Serialize a value to TOML string\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::serialization::to_toml;\n/// use serde::Serialize;\n///\n/// #[derive(Serialize)]\n/// struct Config {\n///     database: Database,\n/// }\n///\n/// #[derive(Serialize)]\n/// struct Database {\n///     url: String,\n///     pool_size: u32,\n/// }\n///\n/// let config = Config {\n///     database: Database {\n///         url: \"postgres://localhost\".to_string(),\n///         pool_size: 10,\n///     },\n/// };\n///\n/// let toml = to_toml(&config).unwrap();\n/// assert!(toml.contains(\"[database]\"));\n/// ```\n///\n/// # Errors\n///\n/// Returns an error if serialization fails\npub fn to_toml<T>(value: &T) -> Result<String>\nwhere\n    T: Serialize,\n{\n    toml::to_string(value).context(\"Failed to serialize to TOML\")\n}\n\n/// Serialize a value to pretty-printed TOML\n///\n/// # Errors\n///\n/// Returns an error if serialization fails\npub fn to_toml_pretty<T>(value: &T) -> Result<String>\nwhere\n    T: Serialize,\n{\n    toml::to_string_pretty(value).context(\"Failed to serialize to pretty TOML\")\n}\n\n/// Deserialize a value from TOML string\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::serialization::from_toml;\n/// use serde::Deserialize;\n///\n/// #[derive(Deserialize)]\n/// struct Config {\n///     name: String,\n///     debug: bool,\n/// }\n///\n/// let toml = r#\"\n/// name = \"myapp\"\n/// debug = true\n/// \"#;\n///\n/// let config: Config = from_toml(toml).unwrap();\n/// assert_eq!(config.name, \"myapp\");\n/// ```\n///\n/// # Errors\n///\n/// Returns an error if deserialization fails\npub fn from_toml<T>(s: &str) -> Result<T>\nwhere\n    T: serde::de::DeserializeOwned,\n{\n    toml::from_str(s).context(\"Failed to deserialize from TOML\")\n}\n\n/// Serialize a value to YAML string\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::serialization::to_yaml;\n/// use serde::Serialize;\n///\n/// #[derive(Serialize)]\n/// struct Server {\n///     host: String,\n///     ports: Vec<u16>,\n/// }\n///\n/// let server = Server {\n///     host: \"localhost\".to_string(),\n///     ports: vec![80, 443],\n/// };\n///\n/// let yaml = to_yaml(&server).unwrap();\n/// assert!(yaml.contains(\"host: localhost\"));\n/// ```\n///\n/// # Errors\n///\n/// Returns an error if serialization fails\npub fn to_yaml<T>(value: &T) -> Result<String>\nwhere\n    T: Serialize,\n{\n    serde_yaml::to_string(value).context(\"Failed to serialize to YAML\")\n}\n\n/// Deserialize a value from YAML string\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::serialization::from_yaml;\n/// use serde::Deserialize;\n///\n/// #[derive(Deserialize)]\n/// struct Config {\n///     version: String,\n///     features: Vec<String>,\n/// }\n///\n/// let yaml = r#\"\n/// version: \"1.0\"\n/// features:\n///   - logging\n///   - metrics\n/// \"#;\n///\n/// let config: Config = from_yaml(yaml).unwrap();\n/// assert_eq!(config.version, \"1.0\");\n/// ```\n///\n/// # Errors\n///\n/// Returns an error if deserialization fails\npub fn from_yaml<T>(s: &str) -> Result<T>\nwhere\n    T: serde::de::DeserializeOwned,\n{\n    serde_yaml::from_str(s).context(\"Failed to deserialize from YAML\")\n}\n\n/// Merge two JSON values\n///\n/// When merging:\n/// - Objects are merged recursively\n/// - Arrays are replaced (not concatenated)\n/// - Other values are replaced by the new value\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::serialization::{merge_json, from_json};\n/// use serde_json::Value;\n///\n/// let base: Value = from_json(r#\"{\"a\": 1, \"b\": {\"c\": 2}}\"#).unwrap();\n/// let override_value: Value = from_json(r#\"{\"b\": {\"d\": 3}, \"e\": 4}\"#).unwrap();\n///\n/// let merged = merge_json(&base, &override_value);\n/// let result = merged.as_object().unwrap();\n/// assert_eq!(result[\"a\"], 1);\n/// assert_eq!(result[\"e\"], 4);\n/// ```\n#[must_use]\npub fn merge_json(base: &JsonValue, other: &JsonValue) -> JsonValue {\n    match (base, other) {\n        (JsonValue::Object(base_obj), JsonValue::Object(other_obj)) => {\n            let mut merged = base_obj.clone();\n            for (key, value) in other_obj {\n                match merged.get(key) {\n                    Some(base_value) => {\n                        merged.insert(key.clone(), merge_json(base_value, value));\n                    }\n                    None => {\n                        merged.insert(key.clone(), value.clone());\n                    }\n                }\n            }\n            JsonValue::Object(merged)\n        }\n        _ => other.clone(),\n    }\n}\n\n/// Merge two TOML values\n///\n/// Similar to `merge_json` but for TOML values\n#[must_use]\npub fn merge_toml(base: &TomlValue, other: &TomlValue) -> TomlValue {\n    match (base, other) {\n        (TomlValue::Table(base_table), TomlValue::Table(other_table)) => {\n            let mut merged = base_table.clone();\n            for (key, value) in other_table {\n                match merged.get(key) {\n                    Some(base_value) => {\n                        merged.insert(key.clone(), merge_toml(base_value, value));\n                    }\n                    None => {\n                        merged.insert(key.clone(), value.clone());\n                    }\n                }\n            }\n            TomlValue::Table(merged)\n        }\n        _ => other.clone(),\n    }\n}\n\n/// Convert between serialization formats\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::serialization::{convert_format, Format};\n///\n/// let json = r#\"{\"name\": \"test\", \"value\": 42}\"#;\n/// let yaml = convert_format(json, Format::Json, Format::Yaml).unwrap();\n/// assert!(yaml.contains(\"name: test\"));\n/// ```\n///\n/// # Errors\n///\n/// Returns an error if:\n/// - Input is not valid for the source format\n/// - Conversion to the target format fails\npub fn convert_format(input: &str, from: Format, to: Format) -> Result<String> {\n    // First, deserialize to a generic Value type\n    let value: serde_json::Value = match from {\n        Format::Json => from_json(input)?,\n        Format::Yaml => from_yaml(input)?,\n        Format::Toml => from_toml(input)?,\n    };\n\n    // Then serialize to the target format\n    match to {\n        Format::Json => to_json_pretty(&value).context(\"Failed to convert to JSON\"),\n        Format::Yaml => to_yaml(&value),\n        Format::Toml => to_toml_pretty(&value),\n    }\n}\n\n/// Supported serialization formats\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum Format {\n    /// JSON format\n    Json,\n    /// YAML format\n    Yaml,\n    /// TOML format\n    Toml,\n}\n\nimpl fmt::Display for Format {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            Self::Json => write!(f, \"JSON\"),\n            Self::Yaml => write!(f, \"YAML\"),\n            Self::Toml => write!(f, \"TOML\"),\n        }\n    }\n}\n\nimpl Format {\n    /// Get the file extension for this format\n    #[must_use]\n    pub fn extension(&self) -> &'static str {\n        match self {\n            Self::Json => \"json\",\n            Self::Yaml => \"yaml\",\n            Self::Toml => \"toml\",\n        }\n    }\n\n    /// Detect format from file extension\n    #[must_use]\n    pub fn from_extension(ext: &str) -> Option<Self> {\n        match ext.to_lowercase().as_str() {\n            \"json\" => Some(Self::Json),\n            \"yaml\" | \"yml\" => Some(Self::Yaml),\n            \"toml\" => Some(Self::Toml),\n            _ => None,\n        }\n    }\n}\n\n/// Safe deserialization with default values\n///\n/// If deserialization fails, returns the default value for the type\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::serialization::from_json_or_default;\n/// use serde::Deserialize;\n///\n/// #[derive(Deserialize, Default, PartialEq, Debug)]\n/// struct Config {\n///     timeout: u64,\n/// }\n///\n/// let valid = r#\"{\"timeout\": 30}\"#;\n/// let invalid = r#\"{\"invalid\": \"json\"}\"#;\n///\n/// let config1: Config = from_json_or_default(valid);\n/// assert_eq!(config1.timeout, 30);\n///\n/// let config2: Config = from_json_or_default(invalid);\n/// assert_eq!(config2.timeout, 0); // Default value\n/// ```\n#[must_use]\npub fn from_json_or_default<'a, T>(s: &'a str) -> T\nwhere\n    T: Deserialize<'a> + Default,\n{\n    from_json(s).unwrap_or_default()\n}\n\n/// Validate JSON against a simple schema\n///\n/// This is a basic validator that checks required fields exist\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::serialization::validate_json_fields;\n///\n/// let json = r#\"{\"name\": \"test\", \"port\": 8080}\"#;\n/// assert!(validate_json_fields(json, &[\"name\", \"port\"]).is_ok());\n/// assert!(validate_json_fields(json, &[\"name\", \"missing\"]).is_err());\n/// ```\n///\n/// # Errors\n///\n/// Returns an error if:\n/// - JSON parsing fails\n/// - The JSON is not an object\n/// - Any required field is missing\npub fn validate_json_fields(json: &str, required_fields: &[&str]) -> Result<()> {\n    let value: JsonValue = from_json(json)?;\n\n    if let Some(obj) = value.as_object() {\n        for field in required_fields {\n            if !obj.contains_key(*field) {\n                anyhow::bail!(\"Missing required field: {}\", field);\n            }\n        }\n        Ok(())\n    } else {\n        anyhow::bail!(\"JSON value is not an object\")\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::collections::HashMap;\n\n    #[test]\n    fn test_json_serialization() {\n        #[derive(Serialize, Deserialize, PartialEq, Debug)]\n        struct TestStruct {\n            name: String,\n            value: i32,\n        }\n\n        let original = TestStruct {\n            name: \"test\".to_string(),\n            value: 42,\n        };\n\n        // Test basic serialization\n        let json = to_json(&original).unwrap();\n        assert!(json.contains(\"\\\"name\\\":\\\"test\\\"\"));\n        assert!(json.contains(\"\\\"value\\\":42\"));\n\n        // Test pretty printing\n        let pretty = to_json_pretty(&original).unwrap();\n        assert!(pretty.contains(\"{\\n\"));\n        assert!(pretty.contains(\"  \\\"name\\\"\"));\n\n        // Test custom indentation\n        let custom_indent = to_json_with_indent(&original, 4).unwrap();\n        assert!(custom_indent.contains(\"    \\\"name\\\"\"));\n\n        // Test deserialization\n        let deserialized: TestStruct = from_json(&json).unwrap();\n        assert_eq!(deserialized, original);\n    }\n\n    #[test]\n    fn test_toml_serialization() {\n        #[derive(Serialize, Deserialize, PartialEq, Debug)]\n        struct Config {\n            server: ServerConfig,\n        }\n\n        #[derive(Serialize, Deserialize, PartialEq, Debug)]\n        struct ServerConfig {\n            host: String,\n            port: u16,\n        }\n\n        let config = Config {\n            server: ServerConfig {\n                host: \"localhost\".to_string(),\n                port: 8080,\n            },\n        };\n\n        let toml = to_toml(&config).unwrap();\n        assert!(toml.contains(\"[server]\"));\n        assert!(toml.contains(\"host = \\\"localhost\\\"\"));\n\n        let deserialized: Config = from_toml(&toml).unwrap();\n        assert_eq!(deserialized, config);\n    }\n\n    #[test]\n    fn test_yaml_serialization() {\n        let mut map = HashMap::new();\n        map.insert(\"name\", \"test\");\n        map.insert(\"environment\", \"production\");\n\n        let yaml = to_yaml(&map).unwrap();\n        assert!(yaml.contains(\"name: test\"));\n        assert!(yaml.contains(\"environment: production\"));\n\n        let deserialized: HashMap<String, String> = from_yaml(&yaml).unwrap();\n        assert_eq!(deserialized[\"name\"], \"test\");\n    }\n\n    #[test]\n    fn test_merge_json() {\n        let base: JsonValue = from_json(\n            r#\"{\n            \"a\": 1,\n            \"b\": {\n                \"c\": 2,\n                \"d\": 3\n            },\n            \"e\": [1, 2, 3]\n        }\"#,\n        )\n        .unwrap();\n\n        let override_value: JsonValue = from_json(\n            r#\"{\n            \"b\": {\n                \"d\": 4,\n                \"f\": 5\n            },\n            \"e\": [4, 5],\n            \"g\": 6\n        }\"#,\n        )\n        .unwrap();\n\n        let merged = merge_json(&base, &override_value);\n        let obj = merged.as_object().unwrap();\n\n        assert_eq!(obj[\"a\"], 1);\n        assert_eq!(obj[\"g\"], 6);\n        assert_eq!(obj[\"e\"], json!([4, 5])); // Arrays are replaced\n\n        let b_obj = obj[\"b\"].as_object().unwrap();\n        assert_eq!(b_obj[\"c\"], 2); // Preserved from base\n        assert_eq!(b_obj[\"d\"], 4); // Overridden\n        assert_eq!(b_obj[\"f\"], 5); // Added from override\n    }\n\n    #[test]\n    fn test_format_conversion() {\n        let json = r#\"{\"name\": \"test\", \"values\": [1, 2, 3]}\"#;\n\n        // JSON to YAML\n        let yaml = convert_format(json, Format::Json, Format::Yaml).unwrap();\n        assert!(yaml.contains(\"name: test\"));\n        assert!(yaml.contains(\"values:\"));\n\n        // YAML to TOML\n        let toml = convert_format(&yaml, Format::Yaml, Format::Toml).unwrap();\n        assert!(toml.contains(\"name = \\\"test\\\"\"));\n\n        // TOML back to JSON\n        let json2 = convert_format(&toml, Format::Toml, Format::Json).unwrap();\n        let parsed1: JsonValue = from_json(json).unwrap();\n        let parsed2: JsonValue = from_json(&json2).unwrap();\n        assert_eq!(parsed1, parsed2);\n    }\n\n    #[test]\n    fn test_format_detection() {\n        assert_eq!(Format::from_extension(\"json\"), Some(Format::Json));\n        assert_eq!(Format::from_extension(\"yaml\"), Some(Format::Yaml));\n        assert_eq!(Format::from_extension(\"yml\"), Some(Format::Yaml));\n        assert_eq!(Format::from_extension(\"toml\"), Some(Format::Toml));\n        assert_eq!(Format::from_extension(\"txt\"), None);\n\n        assert_eq!(Format::Json.extension(), \"json\");\n        assert_eq!(Format::Yaml.extension(), \"yaml\");\n        assert_eq!(Format::Toml.extension(), \"toml\");\n    }\n\n    #[test]\n    fn test_from_json_or_default() {\n        #[derive(Deserialize, Default, PartialEq, Debug)]\n        struct Settings {\n            timeout: u64,\n            retries: u32,\n        }\n\n        let valid = r#\"{\"timeout\": 30, \"retries\": 3}\"#;\n        let settings: Settings = from_json_or_default(valid);\n        assert_eq!(settings.timeout, 30);\n        assert_eq!(settings.retries, 3);\n\n        let invalid = r#\"{\"invalid\": true}\"#;\n        let settings: Settings = from_json_or_default(invalid);\n        assert_eq!(settings.timeout, 0);\n        assert_eq!(settings.retries, 0);\n    }\n\n    #[test]\n    fn test_validate_json_fields() {\n        let json = r#\"{\n            \"name\": \"myapp\",\n            \"version\": \"1.0.0\",\n            \"features\": [\"logging\", \"metrics\"]\n        }\"#;\n\n        assert!(validate_json_fields(json, &[\"name\", \"version\"]).is_ok());\n        assert!(validate_json_fields(json, &[\"name\", \"missing\"]).is_err());\n\n        let not_object = r\"[]\";\n        assert!(validate_json_fields(not_object, &[\"any\"]).is_err());\n    }\n\n    #[test]\n    fn test_error_handling() {\n        // Invalid JSON\n        let result: Result<HashMap<String, String>, _> = from_json(\"invalid json\");\n        assert!(result.is_err());\n\n        // Invalid TOML\n        let result: Result<HashMap<String, String>> = from_toml(\"[[invalid toml\");\n        assert!(result.is_err());\n\n        // Invalid YAML\n        let result: Result<HashMap<String, String>> = from_yaml(\":\\n  - invalid\");\n        assert!(result.is_err());\n    }\n}\n\n#[cfg(test)]\nmod property_tests {\n    use super::*;\n    use proptest::prelude::*;\n\n    proptest! {\n        #[test]\n        fn test_json_roundtrip(s: String, n: i32, b: bool) {\n            #[derive(Serialize, Deserialize, PartialEq, Debug)]\n            struct TestData {\n                string: String,\n                number: i32,\n                boolean: bool,\n            }\n\n            let data = TestData {\n                string: s,\n                number: n,\n                boolean: b,\n            };\n\n            let json = to_json(&data).unwrap();\n            let recovered: TestData = from_json(&json).unwrap();\n            assert_eq!(data, recovered);\n        }\n\n        #[test]\n        fn test_merge_preserves_structure(\n            keys in prop::collection::vec(\"[a-z]+\", 1..5),\n            values in prop::collection::vec(0i32..100, 1..5)\n        ) {\n            if keys.len() != values.len() {\n                return Ok(());\n            }\n\n            let mut base_map = serde_json::Map::new();\n            let mut override_map = serde_json::Map::new();\n\n            for (i, (k, v)) in keys.iter().zip(values.iter()).enumerate() {\n                if i % 2 == 0 {\n                    base_map.insert(k.clone(), json!(v));\n                } else {\n                    override_map.insert(k.clone(), json!(v * 2));\n                }\n            }\n\n            let base = JsonValue::Object(base_map);\n            let override_val = JsonValue::Object(override_map);\n            let merged = merge_json(&base, &override_val);\n\n            // Verify all keys are present\n            if let Some(obj) = merged.as_object() {\n                for k in &keys {\n                    assert!(obj.contains_key(k));\n                }\n            }\n        }\n    }\n}\n\n// Re-export commonly used json macro\npub use serde_json::json;\n","traces":[{"line":41,"address":[],"length":0,"stats":{"Line":258}},{"line":45,"address":[],"length":0,"stats":{"Line":258}},{"line":66,"address":[],"length":0,"stats":{"Line":3}},{"line":70,"address":[],"length":0,"stats":{"Line":3}},{"line":91,"address":[],"length":0,"stats":{"Line":1}},{"line":95,"address":[],"length":0,"stats":{"Line":1}},{"line":96,"address":[],"length":0,"stats":{"Line":1}},{"line":97,"address":[],"length":0,"stats":{"Line":1}},{"line":98,"address":[],"length":0,"stats":{"Line":1}},{"line":99,"address":[],"length":0,"stats":{"Line":1}},{"line":100,"address":[],"length":0,"stats":{"Line":1}},{"line":125,"address":[],"length":0,"stats":{"Line":270}},{"line":129,"address":[],"length":0,"stats":{"Line":270}},{"line":165,"address":[],"length":0,"stats":{"Line":1}},{"line":169,"address":[],"length":0,"stats":{"Line":1}},{"line":177,"address":[],"length":0,"stats":{"Line":1}},{"line":181,"address":[],"length":0,"stats":{"Line":1}},{"line":210,"address":[],"length":0,"stats":{"Line":3}},{"line":214,"address":[],"length":0,"stats":{"Line":3}},{"line":243,"address":[],"length":0,"stats":{"Line":3}},{"line":247,"address":[],"length":0,"stats":{"Line":3}},{"line":278,"address":[],"length":0,"stats":{"Line":3}},{"line":282,"address":[],"length":0,"stats":{"Line":3}},{"line":307,"address":[],"length":0,"stats":{"Line":75}},{"line":308,"address":[],"length":0,"stats":{"Line":75}},{"line":309,"address":[],"length":0,"stats":{"Line":72}},{"line":310,"address":[],"length":0,"stats":{"Line":72}},{"line":311,"address":[],"length":0,"stats":{"Line":218}},{"line":313,"address":[],"length":0,"stats":{"Line":4}},{"line":314,"address":[],"length":0,"stats":{"Line":4}},{"line":316,"address":[],"length":0,"stats":{"Line":69}},{"line":317,"address":[],"length":0,"stats":{"Line":69}},{"line":323,"address":[],"length":0,"stats":{"Line":3}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":333,"address":[],"length":0,"stats":{"Line":0}},{"line":334,"address":[],"length":0,"stats":{"Line":0}},{"line":335,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":0}},{"line":347,"address":[],"length":0,"stats":{"Line":0}},{"line":368,"address":[],"length":0,"stats":{"Line":4}},{"line":370,"address":[],"length":0,"stats":{"Line":8}},{"line":371,"address":[],"length":0,"stats":{"Line":2}},{"line":372,"address":[],"length":0,"stats":{"Line":1}},{"line":373,"address":[],"length":0,"stats":{"Line":1}},{"line":378,"address":[],"length":0,"stats":{"Line":1}},{"line":379,"address":[],"length":0,"stats":{"Line":2}},{"line":380,"address":[],"length":0,"stats":{"Line":1}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":397,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":400,"address":[],"length":0,"stats":{"Line":0}},{"line":408,"address":[],"length":0,"stats":{"Line":3}},{"line":409,"address":[],"length":0,"stats":{"Line":3}},{"line":410,"address":[],"length":0,"stats":{"Line":1}},{"line":411,"address":[],"length":0,"stats":{"Line":1}},{"line":412,"address":[],"length":0,"stats":{"Line":1}},{"line":418,"address":[],"length":0,"stats":{"Line":5}},{"line":419,"address":[],"length":0,"stats":{"Line":5}},{"line":420,"address":[],"length":0,"stats":{"Line":6}},{"line":421,"address":[],"length":0,"stats":{"Line":9}},{"line":422,"address":[],"length":0,"stats":{"Line":3}},{"line":423,"address":[],"length":0,"stats":{"Line":1}},{"line":453,"address":[],"length":0,"stats":{"Line":2}},{"line":457,"address":[],"length":0,"stats":{"Line":2}},{"line":480,"address":[],"length":0,"stats":{"Line":3}},{"line":481,"address":[],"length":0,"stats":{"Line":6}},{"line":483,"address":[],"length":0,"stats":{"Line":2}},{"line":484,"address":[],"length":0,"stats":{"Line":9}},{"line":485,"address":[],"length":0,"stats":{"Line":4}},{"line":486,"address":[],"length":0,"stats":{"Line":1}},{"line":489,"address":[],"length":0,"stats":{"Line":1}},{"line":491,"address":[],"length":0,"stats":{"Line":1}}],"covered":62,"coverable":79},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-utils","src","string_utils.rs"],"content":"// ABOUTME: String manipulation, formatting, and validation utilities\n// ABOUTME: Common string operations used across the LLMSpell framework\n\n//! String manipulation and formatting helpers\n//!\n//! This module provides utilities for string manipulation, including\n//! truncation, sanitization, case conversion, word wrapping, and indentation.\n\n/// Default ellipsis string for truncation\npub const DEFAULT_ELLIPSIS: &str = \"...\";\n\n/// Truncate a string to a maximum length with ellipsis\n///\n/// If the string is longer than `max_len`, it will be truncated and ellipsis added.\n/// The ellipsis counts towards the maximum length.\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::string_utils::truncate;\n///\n/// assert_eq!(truncate(\"Hello, world!\", 5), \"He...\");\n/// assert_eq!(truncate(\"Short\", 10), \"Short\");\n/// assert_eq!(truncate(\"\", 5), \"\");\n/// ```\n#[must_use]\npub fn truncate(s: &str, max_len: usize) -> String {\n    truncate_with_ellipsis(s, max_len, DEFAULT_ELLIPSIS)\n}\n\n/// Truncate a string to a maximum length with custom ellipsis\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::string_utils::truncate_with_ellipsis;\n///\n/// assert_eq!(truncate_with_ellipsis(\"Hello, world!\", 7, \"...\"), \"Hell...\");\n/// assert_eq!(truncate_with_ellipsis(\"Hello, world!\", 7, \"…\"), \"Hell…\");\n/// ```\n#[must_use]\npub fn truncate_with_ellipsis(s: &str, max_len: usize, ellipsis: &str) -> String {\n    if s.len() <= max_len {\n        return s.to_string();\n    }\n\n    if max_len <= ellipsis.len() {\n        // If max_len is too small for ellipsis, just return the ellipsis truncated\n        return ellipsis.chars().take(max_len).collect();\n    }\n\n    let truncate_at = max_len - ellipsis.len();\n\n    // Find a char boundary\n    let mut boundary = truncate_at;\n    while boundary > 0 && !s.is_char_boundary(boundary) {\n        boundary -= 1;\n    }\n\n    format!(\"{}{}\", &s[..boundary], ellipsis)\n}\n\n/// Wrap text to fit within a specified width\n///\n/// Breaks text at word boundaries when possible.\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::string_utils::word_wrap;\n///\n/// let text = \"This is a long line that needs to be wrapped\";\n/// let wrapped = word_wrap(text, 20);\n/// assert_eq!(wrapped, vec![\"This is a long line\", \"that needs to be\", \"wrapped\"]);\n/// ```\n#[must_use]\npub fn word_wrap(text: &str, width: usize) -> Vec<String> {\n    if width == 0 {\n        return vec![];\n    }\n\n    let mut lines = Vec::new();\n\n    for line in text.lines() {\n        if line.len() <= width {\n            lines.push(line.to_string());\n            continue;\n        }\n\n        let words: Vec<&str> = line.split_whitespace().collect();\n        let mut current_line = String::new();\n\n        for word in words {\n            if current_line.is_empty() {\n                // First word on the line\n                if word.len() > width {\n                    // Word is too long, must be broken\n                    let mut chars = word.chars();\n                    while !chars.as_str().is_empty() {\n                        let chunk: String = chars.by_ref().take(width).collect();\n                        lines.push(chunk);\n                    }\n                } else {\n                    current_line = word.to_string();\n                }\n            } else if current_line.len() + 1 + word.len() <= width {\n                // Word fits on current line\n                current_line.push(' ');\n                current_line.push_str(word);\n            } else {\n                // Word doesn't fit, start new line\n                lines.push(current_line);\n                if word.len() > width {\n                    // Word is too long for any line, must be broken\n                    current_line = String::new();\n                    let mut chars = word.chars();\n                    while !chars.as_str().is_empty() {\n                        let chunk: String = chars.by_ref().take(width).collect();\n                        if chars.as_str().is_empty() {\n                            current_line = chunk;\n                        } else {\n                            lines.push(chunk);\n                        }\n                    }\n                } else {\n                    current_line = word.to_string();\n                }\n            }\n        }\n\n        if !current_line.is_empty() {\n            lines.push(current_line);\n        }\n    }\n\n    lines\n}\n\n/// Convert a string to `snake_case`\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::string_utils::to_snake_case;\n///\n/// assert_eq!(to_snake_case(\"HelloWorld\"), \"hello_world\");\n/// assert_eq!(to_snake_case(\"HTTPResponse\"), \"httpresponse\");\n/// assert_eq!(to_snake_case(\"already_snake_case\"), \"already_snake_case\");\n/// assert_eq!(to_snake_case(\"PascalCase\"), \"pascal_case\");\n/// ```\n#[must_use]\npub fn to_snake_case(s: &str) -> String {\n    let mut result = String::new();\n    let mut prev_upper = false;\n\n    for (i, ch) in s.chars().enumerate() {\n        if ch.is_uppercase() {\n            if i > 0 && !prev_upper {\n                result.push('_');\n            }\n            // Safe: to_lowercase() always produces at least one char for valid Unicode\n            if let Some(lower_ch) = ch.to_lowercase().next() {\n                result.push(lower_ch);\n            }\n            prev_upper = true;\n        } else {\n            result.push(ch);\n            prev_upper = false;\n        }\n    }\n\n    result\n}\n\n/// Convert a string to `camelCase`\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::string_utils::to_camel_case;\n///\n/// assert_eq!(to_camel_case(\"hello_world\"), \"helloWorld\");\n/// assert_eq!(to_camel_case(\"http_response\"), \"httpResponse\");\n/// assert_eq!(to_camel_case(\"already_camelCase\"), \"alreadyCamelCase\");\n/// ```\n#[must_use]\npub fn to_camel_case(s: &str) -> String {\n    let mut result = String::new();\n    let mut capitalize_next = false;\n\n    for (i, ch) in s.chars().enumerate() {\n        if ch == '_' || ch == '-' {\n            capitalize_next = true;\n        } else if capitalize_next {\n            // Safe: to_uppercase() always produces at least one char for valid Unicode\n            if let Some(upper_ch) = ch.to_uppercase().next() {\n                result.push(upper_ch);\n            }\n            capitalize_next = false;\n        } else if i == 0 {\n            // Safe: to_lowercase() always produces at least one char for valid Unicode\n            if let Some(lower_ch) = ch.to_lowercase().next() {\n                result.push(lower_ch);\n            }\n        } else {\n            result.push(ch);\n        }\n    }\n\n    result\n}\n\n/// Convert a string to `PascalCase`\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::string_utils::to_pascal_case;\n///\n/// assert_eq!(to_pascal_case(\"hello_world\"), \"HelloWorld\");\n/// assert_eq!(to_pascal_case(\"http_response\"), \"HttpResponse\");\n/// assert_eq!(to_pascal_case(\"already_PascalCase\"), \"AlreadyPascalCase\");\n/// ```\n#[must_use]\npub fn to_pascal_case(s: &str) -> String {\n    let mut result = String::new();\n    let mut capitalize_next = true;\n\n    for ch in s.chars() {\n        if ch == '_' || ch == '-' {\n            capitalize_next = true;\n        } else if capitalize_next {\n            // Safe: to_uppercase() always produces at least one char for valid Unicode\n            if let Some(upper_ch) = ch.to_uppercase().next() {\n                result.push(upper_ch);\n            }\n            capitalize_next = false;\n        } else {\n            result.push(ch);\n        }\n    }\n\n    result\n}\n\n/// Sanitize a string for safe usage\n///\n/// Removes or escapes potentially dangerous characters:\n/// - Control characters (except newline and tab)\n/// - Non-ASCII characters\n/// - Leading/trailing spaces (but not tabs)\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::string_utils::sanitize;\n///\n/// assert_eq!(sanitize(\"  Hello\\x00World  \"), \"HelloWorld\");\n/// assert_eq!(sanitize(\"Normal text\"), \"Normal text\");\n/// assert_eq!(sanitize(\"Line1\\nLine2\\t\"), \"Line1\\nLine2\\t\");\n/// ```\n#[must_use]\npub fn sanitize(s: &str) -> String {\n    // Trim only regular spaces, not tabs or newlines\n    let trimmed = s.trim_matches(' ');\n    trimmed\n        .chars()\n        .filter(|&ch| ch == '\\n' || ch == '\\t' || (ch.is_ascii_graphic() || ch == ' '))\n        .collect()\n}\n\n/// Escape special characters for safe display\n///\n/// Escapes characters that might cause issues in various contexts\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::string_utils::escape_special;\n///\n/// assert_eq!(escape_special(\"Hello\\nWorld\"), \"Hello\\\\nWorld\");\n/// assert_eq!(escape_special(\"Path\\\\to\\\\file\"), \"Path\\\\\\\\to\\\\\\\\file\");\n/// assert_eq!(escape_special(\"Quote\\\"test\\\"\"), \"Quote\\\\\\\"test\\\\\\\"\");\n/// ```\n#[must_use]\npub fn escape_special(s: &str) -> String {\n    let mut result = String::with_capacity(s.len());\n\n    for ch in s.chars() {\n        match ch {\n            '\\n' => result.push_str(\"\\\\n\"),\n            '\\r' => result.push_str(\"\\\\r\"),\n            '\\t' => result.push_str(\"\\\\t\"),\n            '\\\\' => result.push_str(\"\\\\\\\\\"),\n            '\"' => result.push_str(\"\\\\\\\"\"),\n            '\\'' => result.push_str(\"\\\\'\"),\n            '\\0' => result.push_str(\"\\\\0\"),\n            _ => result.push(ch),\n        }\n    }\n\n    result\n}\n\n/// Add indentation to each line of a string\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::string_utils::indent;\n///\n/// let text = \"Line 1\\nLine 2\\nLine 3\";\n/// let indented = indent(text, 4);\n/// assert_eq!(indented, \"    Line 1\\n    Line 2\\n    Line 3\");\n/// ```\n#[must_use]\npub fn indent(s: &str, spaces: usize) -> String {\n    indent_with(s, &\" \".repeat(spaces))\n}\n\n/// Add custom indentation to each line of a string\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::string_utils::indent_with;\n///\n/// let text = \"Line 1\\nLine 2\";\n/// let indented = indent_with(text, \"> \");\n/// assert_eq!(indented, \"> Line 1\\n> Line 2\");\n/// ```\n#[must_use]\npub fn indent_with(s: &str, prefix: &str) -> String {\n    let lines: Vec<&str> = s.lines().collect();\n    let mut result = String::new();\n\n    for (i, line) in lines.iter().enumerate() {\n        result.push_str(prefix);\n        result.push_str(line);\n        if i < lines.len() - 1 || s.ends_with('\\n') {\n            result.push('\\n');\n        }\n    }\n\n    result\n}\n\n/// Remove common leading whitespace from lines\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::string_utils::dedent;\n///\n/// let text = \"    Line 1\\n    Line 2\\n      Line 3\";\n/// let dedented = dedent(text);\n/// assert_eq!(dedented, \"Line 1\\nLine 2\\n  Line 3\");\n/// ```\n#[must_use]\npub fn dedent(s: &str) -> String {\n    let lines: Vec<&str> = s.lines().collect();\n\n    // Find minimum indentation (ignoring empty lines)\n    let min_indent = lines\n        .iter()\n        .filter(|line| !line.trim().is_empty())\n        .map(|line| line.len() - line.trim_start().len())\n        .min()\n        .unwrap_or(0);\n\n    // Remove common indentation\n    let mut result = String::new();\n    for (i, line) in lines.iter().enumerate() {\n        if line.len() >= min_indent {\n            result.push_str(&line[min_indent..]);\n        } else {\n            result.push_str(line);\n        }\n        if i < lines.len() - 1 || s.ends_with('\\n') {\n            result.push('\\n');\n        }\n    }\n\n    result\n}\n\n/// Check if a string is a valid identifier (alphanumeric + underscore, not starting with digit)\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::string_utils::is_valid_identifier;\n///\n/// assert!(is_valid_identifier(\"valid_name\"));\n/// assert!(is_valid_identifier(\"_private\"));\n/// assert!(!is_valid_identifier(\"123invalid\"));\n/// assert!(!is_valid_identifier(\"invalid-name\"));\n/// assert!(!is_valid_identifier(\"\"));\n/// ```\n#[must_use]\npub fn is_valid_identifier(s: &str) -> bool {\n    if s.is_empty() {\n        return false;\n    }\n\n    let mut chars = s.chars();\n\n    // First character must be alphabetic or underscore\n    if let Some(first) = chars.next() {\n        if !first.is_alphabetic() && first != '_' {\n            return false;\n        }\n    }\n\n    // Rest must be alphanumeric or underscore\n    chars.all(|ch| ch.is_alphanumeric() || ch == '_')\n}\n\n/// Split a string by lines, preserving line endings\n///\n/// Unlike `str::lines()`, this preserves the line ending characters\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::string_utils::lines_with_endings;\n///\n/// let text = \"Line 1\\nLine 2\\r\\nLine 3\";\n/// let lines: Vec<_> = lines_with_endings(text).collect();\n/// assert_eq!(lines, vec![\"Line 1\\n\", \"Line 2\\r\\n\", \"Line 3\"]);\n/// ```\npub fn lines_with_endings(s: &str) -> impl Iterator<Item = &str> {\n    let mut start = 0;\n    let bytes = s.as_bytes();\n\n    std::iter::from_fn(move || {\n        if start >= bytes.len() {\n            return None;\n        }\n\n        let mut end = start;\n        while end < bytes.len() {\n            if bytes[end] == b'\\n' {\n                end += 1;\n                break;\n            } else if end + 1 < bytes.len() && bytes[end] == b'\\r' && bytes[end + 1] == b'\\n' {\n                end += 2;\n                break;\n            }\n            end += 1;\n        }\n\n        let line = &s[start..end];\n        start = end;\n        Some(line)\n    })\n}\n\n/// Replace multiple consecutive whitespace characters with a single space\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::string_utils::normalize_whitespace;\n///\n/// assert_eq!(normalize_whitespace(\"Hello    world\"), \"Hello world\");\n/// assert_eq!(normalize_whitespace(\"Line1\\n\\n\\nLine2\"), \"Line1 Line2\");\n/// assert_eq!(normalize_whitespace(\"  Leading and trailing  \"), \"Leading and trailing\");\n/// ```\n#[must_use]\npub fn normalize_whitespace(s: &str) -> String {\n    s.split_whitespace().collect::<Vec<_>>().join(\" \")\n}\n\n/// Count the number of lines in a string\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::string_utils::count_lines;\n///\n/// assert_eq!(count_lines(\"Single line\"), 1);\n/// assert_eq!(count_lines(\"Line 1\\nLine 2\\nLine 3\"), 3);\n/// assert_eq!(count_lines(\"\"), 0);\n/// assert_eq!(count_lines(\"\\n\\n\"), 2);\n/// ```\n#[must_use]\npub fn count_lines(s: &str) -> usize {\n    if s.is_empty() {\n        0\n    } else {\n        s.lines().count()\n    }\n}\n\n/// Find common prefix of multiple strings\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::string_utils::common_prefix;\n///\n/// assert_eq!(common_prefix(&[\"prefix_a\", \"prefix_b\", \"prefix_c\"]), \"prefix_\");\n/// assert_eq!(common_prefix(&[\"hello\", \"help\", \"hero\"]), \"he\");\n/// assert_eq!(common_prefix(&[\"abc\", \"xyz\"]), \"\");\n/// assert_eq!(common_prefix(&[]), \"\");\n/// ```\n#[must_use]\npub fn common_prefix(strings: &[&str]) -> String {\n    if strings.is_empty() {\n        return String::new();\n    }\n\n    let mut prefix = String::new();\n    let first = strings[0];\n\n    'outer: for (i, ch) in first.chars().enumerate() {\n        for s in &strings[1..] {\n            if s.chars().nth(i) != Some(ch) {\n                break 'outer;\n            }\n        }\n        prefix.push(ch);\n    }\n\n    prefix\n}\n\n/// Create a string of repeated characters\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::string_utils::repeat_char;\n///\n/// assert_eq!(repeat_char('=', 5), \"=====\");\n/// assert_eq!(repeat_char(' ', 3), \"   \");\n/// assert_eq!(repeat_char('*', 0), \"\");\n/// ```\n#[must_use]\npub fn repeat_char(ch: char, count: usize) -> String {\n    ch.to_string().repeat(count)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_truncate() {\n        assert_eq!(truncate(\"Hello, world!\", 5), \"He...\");\n        assert_eq!(truncate(\"Short\", 10), \"Short\");\n        assert_eq!(truncate(\"Exactly10!\", 10), \"Exactly10!\");\n        assert_eq!(truncate(\"\", 5), \"\");\n        assert_eq!(truncate(\"Hi\", 2), \"Hi\");\n        assert_eq!(truncate(\"Hello\", 3), \"...\");\n\n        // Test with unicode - 8 bytes is not enough to include the chinese char\n        let result = truncate(\"Hello 世界\", 8);\n        assert!(result.starts_with(\"Hello\"));\n        assert!(result.ends_with(\"...\"));\n    }\n\n    #[test]\n    fn test_truncate_with_ellipsis() {\n        // The unicode ellipsis takes 3 bytes, so \"Hello,\" (6 bytes) + \"…\" (3 bytes) = 9 bytes\n        // But we're asking for 7 max length, so it should be truncated further\n        let result = truncate_with_ellipsis(\"Hello, world!\", 7, \"…\");\n        assert!(result.len() <= 7 || result.chars().count() <= 7);\n        assert_eq!(truncate_with_ellipsis(\"Short\", 10, \"…\"), \"Short\");\n        assert_eq!(truncate_with_ellipsis(\"Test\", 1, \"...\"), \".\");\n    }\n\n    #[test]\n    fn test_word_wrap() {\n        let text = \"This is a long line that needs to be wrapped\";\n        let wrapped = word_wrap(text, 20);\n        assert_eq!(\n            wrapped,\n            vec![\"This is a long line\", \"that needs to be\", \"wrapped\"]\n        );\n\n        // Test with very long word\n        let wrapped = word_wrap(\"Supercalifragilisticexpialidocious\", 10);\n        assert_eq!(\n            wrapped,\n            vec![\"Supercalif\", \"ragilistic\", \"expialidoc\", \"ious\"]\n        );\n\n        // Test with empty string\n        assert_eq!(word_wrap(\"\", 10), Vec::<String>::new());\n\n        // Test with width 0\n        assert_eq!(word_wrap(\"Test\", 0), Vec::<String>::new());\n\n        // Test with multiple lines\n        let multi = \"Line 1 is here\\nLine 2 is also here\";\n        let wrapped = word_wrap(multi, 10);\n        assert_eq!(wrapped, vec![\"Line 1 is\", \"here\", \"Line 2 is\", \"also here\"]);\n    }\n\n    #[test]\n    fn test_case_conversions() {\n        // snake_case\n        assert_eq!(to_snake_case(\"HelloWorld\"), \"hello_world\");\n        assert_eq!(to_snake_case(\"HTTPResponse\"), \"httpresponse\");\n        assert_eq!(to_snake_case(\"already_snake_case\"), \"already_snake_case\");\n        assert_eq!(to_snake_case(\"IOError\"), \"ioerror\");\n\n        // camelCase\n        assert_eq!(to_camel_case(\"hello_world\"), \"helloWorld\");\n        assert_eq!(to_camel_case(\"http_response\"), \"httpResponse\");\n        assert_eq!(to_camel_case(\"already_camelCase\"), \"alreadyCamelCase\");\n        assert_eq!(to_camel_case(\"io-error\"), \"ioError\");\n\n        // PascalCase\n        assert_eq!(to_pascal_case(\"hello_world\"), \"HelloWorld\");\n        assert_eq!(to_pascal_case(\"http_response\"), \"HttpResponse\");\n        assert_eq!(to_pascal_case(\"already_PascalCase\"), \"AlreadyPascalCase\");\n        assert_eq!(to_pascal_case(\"io-error\"), \"IoError\");\n    }\n\n    #[test]\n    fn test_sanitize() {\n        assert_eq!(sanitize(\"  Hello\\x00World  \"), \"HelloWorld\");\n        assert_eq!(sanitize(\"Normal text\"), \"Normal text\");\n        assert_eq!(sanitize(\"Line1\\nLine2\\t\"), \"Line1\\nLine2\\t\");\n        assert_eq!(sanitize(\"\\x01\\x02Test\\x03\\x04\"), \"Test\");\n        // String with only control characters should become empty after sanitization\n        let result = sanitize(\"   \\x00  \\x01  \");\n        assert!(\n            result.chars().all(|c| c == ' '),\n            \"Should only contain spaces, got: {result:?}\"\n        );\n    }\n\n    #[test]\n    fn test_escape_special() {\n        assert_eq!(escape_special(\"Hello\\nWorld\"), \"Hello\\\\nWorld\");\n        assert_eq!(escape_special(\"Path\\\\to\\\\file\"), \"Path\\\\\\\\to\\\\\\\\file\");\n        assert_eq!(escape_special(\"Quote\\\"test\\\"\"), \"Quote\\\\\\\"test\\\\\\\"\");\n        assert_eq!(escape_special(\"Tab\\there\"), \"Tab\\\\there\");\n        assert_eq!(escape_special(\"Null\\0char\"), \"Null\\\\0char\");\n    }\n\n    #[test]\n    fn test_indent() {\n        let text = \"Line 1\\nLine 2\\nLine 3\";\n        let indented = indent(text, 4);\n        assert_eq!(indented, \"    Line 1\\n    Line 2\\n    Line 3\");\n\n        // Test with custom prefix\n        let indented = indent_with(text, \"> \");\n        assert_eq!(indented, \"> Line 1\\n> Line 2\\n> Line 3\");\n\n        // Test with trailing newline\n        let text_nl = \"Line 1\\nLine 2\\n\";\n        let indented = indent(text_nl, 2);\n        assert_eq!(indented, \"  Line 1\\n  Line 2\\n\");\n    }\n\n    #[test]\n    fn test_dedent() {\n        let text = \"    Line 1\\n    Line 2\\n      Line 3\";\n        let dedented = dedent(text);\n        assert_eq!(dedented, \"Line 1\\nLine 2\\n  Line 3\");\n\n        // Test with empty lines\n        let text = \"    Line 1\\n\\n    Line 2\";\n        let dedented = dedent(text);\n        assert_eq!(dedented, \"Line 1\\n\\nLine 2\");\n\n        // Test with no common indentation\n        let text = \"Line 1\\n  Line 2\";\n        let dedented = dedent(text);\n        assert_eq!(dedented, text);\n    }\n\n    #[test]\n    fn test_is_valid_identifier() {\n        assert!(is_valid_identifier(\"valid_name\"));\n        assert!(is_valid_identifier(\"_private\"));\n        assert!(is_valid_identifier(\"CamelCase\"));\n        assert!(is_valid_identifier(\"name123\"));\n\n        assert!(!is_valid_identifier(\"123invalid\"));\n        assert!(!is_valid_identifier(\"invalid-name\"));\n        assert!(!is_valid_identifier(\"invalid.name\"));\n        assert!(!is_valid_identifier(\"invalid name\"));\n        assert!(!is_valid_identifier(\"\"));\n    }\n\n    #[test]\n    fn test_lines_with_endings() {\n        let text = \"Line 1\\nLine 2\\r\\nLine 3\";\n        let lines: Vec<_> = lines_with_endings(text).collect();\n        assert_eq!(lines, vec![\"Line 1\\n\", \"Line 2\\r\\n\", \"Line 3\"]);\n\n        // Test with trailing newline\n        let text = \"Line 1\\nLine 2\\n\";\n        let lines: Vec<_> = lines_with_endings(text).collect();\n        assert_eq!(lines, vec![\"Line 1\\n\", \"Line 2\\n\"]);\n\n        // Test empty string\n        let lines: Vec<_> = lines_with_endings(\"\").collect();\n        assert!(lines.is_empty());\n    }\n\n    #[test]\n    fn test_normalize_whitespace() {\n        assert_eq!(normalize_whitespace(\"Hello    world\"), \"Hello world\");\n        assert_eq!(normalize_whitespace(\"Line1\\n\\n\\nLine2\"), \"Line1 Line2\");\n        assert_eq!(\n            normalize_whitespace(\"  Leading and trailing  \"),\n            \"Leading and trailing\"\n        );\n        assert_eq!(normalize_whitespace(\"\\t\\tTabs\\t\\t\"), \"Tabs\");\n        assert_eq!(normalize_whitespace(\"\"), \"\");\n    }\n\n    #[test]\n    fn test_count_lines() {\n        assert_eq!(count_lines(\"Single line\"), 1);\n        assert_eq!(count_lines(\"Line 1\\nLine 2\\nLine 3\"), 3);\n        assert_eq!(count_lines(\"\"), 0);\n        assert_eq!(count_lines(\"\\n\\n\"), 2);\n        assert_eq!(count_lines(\"No newline at end\\n\"), 1);\n    }\n\n    #[test]\n    fn test_common_prefix() {\n        assert_eq!(\n            common_prefix(&[\"prefix_a\", \"prefix_b\", \"prefix_c\"]),\n            \"prefix_\"\n        );\n        assert_eq!(common_prefix(&[\"hello\", \"help\", \"hero\"]), \"he\");\n        assert_eq!(common_prefix(&[\"abc\", \"xyz\"]), \"\");\n        assert_eq!(common_prefix(&[\"test\"]), \"test\");\n        assert_eq!(common_prefix(&[]), \"\");\n\n        // Test with unicode\n        assert_eq!(common_prefix(&[\"你好世界\", \"你好朋友\"]), \"你好\");\n    }\n\n    #[test]\n    fn test_repeat_char() {\n        assert_eq!(repeat_char('=', 5), \"=====\");\n        assert_eq!(repeat_char(' ', 3), \"   \");\n        assert_eq!(repeat_char('*', 0), \"\");\n        assert_eq!(repeat_char('🦀', 3), \"🦀🦀🦀\");\n    }\n}\n\n#[cfg(test)]\nmod property_tests {\n    use super::*;\n    use proptest::prelude::*;\n\n    proptest! {\n        #[test]\n        fn test_truncate_length(s: String, max_len in 0usize..1000) {\n            let truncated = truncate(&s, max_len);\n            assert!(truncated.len() <= max_len || truncated.len() <= DEFAULT_ELLIPSIS.len());\n        }\n\n        #[test]\n        fn test_sanitize_no_control_chars(s: String) {\n            let sanitized = sanitize(&s);\n            for ch in sanitized.chars() {\n                assert!(ch == '\\n' || ch == '\\t' || (!ch.is_control() && ch.is_ascii()));\n            }\n        }\n\n        #[test]\n        fn test_indent_line_count(s: String, spaces in 0usize..10) {\n            let indented = indent(&s, spaces);\n            if !s.is_empty() {\n                assert_eq!(count_lines(&s), count_lines(&indented));\n            }\n        }\n\n        #[test]\n        fn test_case_conversion_consistency(s in \"[a-zA-Z][a-zA-Z0-9_]*\") {\n            // Test that conversions produce valid identifiers\n            let snake = to_snake_case(&s);\n            let camel = to_camel_case(&s);\n            let pascal = to_pascal_case(&s);\n\n            // All conversions should produce non-empty strings if input is non-empty\n            if !s.is_empty() {\n                assert!(!snake.is_empty());\n                assert!(!camel.is_empty());\n                assert!(!pascal.is_empty());\n            }\n        }\n    }\n}\n","traces":[{"line":27,"address":[],"length":0,"stats":{"Line":265}},{"line":28,"address":[],"length":0,"stats":{"Line":265}},{"line":42,"address":[],"length":0,"stats":{"Line":268}},{"line":43,"address":[],"length":0,"stats":{"Line":268}},{"line":44,"address":[],"length":0,"stats":{"Line":252}},{"line":47,"address":[],"length":0,"stats":{"Line":16}},{"line":49,"address":[],"length":0,"stats":{"Line":3}},{"line":52,"address":[],"length":0,"stats":{"Line":13}},{"line":55,"address":[],"length":0,"stats":{"Line":13}},{"line":56,"address":[],"length":0,"stats":{"Line":35}},{"line":57,"address":[],"length":0,"stats":{"Line":3}},{"line":77,"address":[],"length":0,"stats":{"Line":6}},{"line":78,"address":[],"length":0,"stats":{"Line":6}},{"line":79,"address":[],"length":0,"stats":{"Line":1}},{"line":82,"address":[],"length":0,"stats":{"Line":5}},{"line":84,"address":[],"length":0,"stats":{"Line":5}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":5}},{"line":91,"address":[],"length":0,"stats":{"Line":5}},{"line":93,"address":[],"length":0,"stats":{"Line":55}},{"line":96,"address":[],"length":0,"stats":{"Line":5}},{"line":98,"address":[],"length":0,"stats":{"Line":1}},{"line":99,"address":[],"length":0,"stats":{"Line":9}},{"line":100,"address":[],"length":0,"stats":{"Line":4}},{"line":101,"address":[],"length":0,"stats":{"Line":4}},{"line":104,"address":[],"length":0,"stats":{"Line":4}},{"line":106,"address":[],"length":0,"stats":{"Line":35}},{"line":108,"address":[],"length":0,"stats":{"Line":15}},{"line":109,"address":[],"length":0,"stats":{"Line":15}},{"line":112,"address":[],"length":0,"stats":{"Line":5}},{"line":113,"address":[],"length":0,"stats":{"Line":5}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":5}},{"line":131,"address":[],"length":0,"stats":{"Line":9}},{"line":132,"address":[],"length":0,"stats":{"Line":4}},{"line":152,"address":[],"length":0,"stats":{"Line":262}},{"line":153,"address":[],"length":0,"stats":{"Line":262}},{"line":154,"address":[],"length":0,"stats":{"Line":262}},{"line":156,"address":[],"length":0,"stats":{"Line":4614}},{"line":158,"address":[],"length":0,"stats":{"Line":3470}},{"line":159,"address":[],"length":0,"stats":{"Line":861}},{"line":162,"address":[],"length":0,"stats":{"Line":2742}},{"line":165,"address":[],"length":0,"stats":{"Line":1371}},{"line":167,"address":[],"length":0,"stats":{"Line":2981}},{"line":168,"address":[],"length":0,"stats":{"Line":2981}},{"line":172,"address":[],"length":0,"stats":{"Line":262}},{"line":187,"address":[],"length":0,"stats":{"Line":262}},{"line":188,"address":[],"length":0,"stats":{"Line":262}},{"line":189,"address":[],"length":0,"stats":{"Line":262}},{"line":191,"address":[],"length":0,"stats":{"Line":4617}},{"line":192,"address":[],"length":0,"stats":{"Line":4356}},{"line":193,"address":[],"length":0,"stats":{"Line":704}},{"line":194,"address":[],"length":0,"stats":{"Line":4355}},{"line":196,"address":[],"length":0,"stats":{"Line":1088}},{"line":199,"address":[],"length":0,"stats":{"Line":544}},{"line":200,"address":[],"length":0,"stats":{"Line":3107}},{"line":202,"address":[],"length":0,"stats":{"Line":524}},{"line":206,"address":[],"length":0,"stats":{"Line":2845}},{"line":210,"address":[],"length":0,"stats":{"Line":262}},{"line":225,"address":[],"length":0,"stats":{"Line":262}},{"line":226,"address":[],"length":0,"stats":{"Line":262}},{"line":227,"address":[],"length":0,"stats":{"Line":262}},{"line":229,"address":[],"length":0,"stats":{"Line":4618}},{"line":230,"address":[],"length":0,"stats":{"Line":4357}},{"line":231,"address":[],"length":0,"stats":{"Line":704}},{"line":232,"address":[],"length":0,"stats":{"Line":4356}},{"line":234,"address":[],"length":0,"stats":{"Line":1612}},{"line":237,"address":[],"length":0,"stats":{"Line":806}},{"line":239,"address":[],"length":0,"stats":{"Line":2846}},{"line":243,"address":[],"length":0,"stats":{"Line":262}},{"line":263,"address":[],"length":0,"stats":{"Line":263}},{"line":265,"address":[],"length":0,"stats":{"Line":263}},{"line":266,"address":[],"length":0,"stats":{"Line":263}},{"line":268,"address":[],"length":0,"stats":{"Line":14646}},{"line":286,"address":[],"length":0,"stats":{"Line":5}},{"line":287,"address":[],"length":0,"stats":{"Line":5}},{"line":289,"address":[],"length":0,"stats":{"Line":56}},{"line":291,"address":[],"length":0,"stats":{"Line":1}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":1}},{"line":294,"address":[],"length":0,"stats":{"Line":2}},{"line":295,"address":[],"length":0,"stats":{"Line":2}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":1}},{"line":298,"address":[],"length":0,"stats":{"Line":44}},{"line":302,"address":[],"length":0,"stats":{"Line":5}},{"line":317,"address":[],"length":0,"stats":{"Line":260}},{"line":318,"address":[],"length":0,"stats":{"Line":260}},{"line":333,"address":[],"length":0,"stats":{"Line":261}},{"line":334,"address":[],"length":0,"stats":{"Line":261}},{"line":335,"address":[],"length":0,"stats":{"Line":261}},{"line":337,"address":[],"length":0,"stats":{"Line":522}},{"line":340,"address":[],"length":0,"stats":{"Line":262}},{"line":341,"address":[],"length":0,"stats":{"Line":7}},{"line":345,"address":[],"length":0,"stats":{"Line":261}},{"line":360,"address":[],"length":0,"stats":{"Line":3}},{"line":361,"address":[],"length":0,"stats":{"Line":3}},{"line":364,"address":[],"length":0,"stats":{"Line":3}},{"line":366,"address":[],"length":0,"stats":{"Line":11}},{"line":367,"address":[],"length":0,"stats":{"Line":10}},{"line":372,"address":[],"length":0,"stats":{"Line":3}},{"line":373,"address":[],"length":0,"stats":{"Line":11}},{"line":374,"address":[],"length":0,"stats":{"Line":7}},{"line":375,"address":[],"length":0,"stats":{"Line":7}},{"line":377,"address":[],"length":0,"stats":{"Line":1}},{"line":379,"address":[],"length":0,"stats":{"Line":8}},{"line":380,"address":[],"length":0,"stats":{"Line":5}},{"line":384,"address":[],"length":0,"stats":{"Line":3}},{"line":401,"address":[],"length":0,"stats":{"Line":11}},{"line":402,"address":[],"length":0,"stats":{"Line":11}},{"line":403,"address":[],"length":0,"stats":{"Line":1}},{"line":406,"address":[],"length":0,"stats":{"Line":10}},{"line":409,"address":[],"length":0,"stats":{"Line":10}},{"line":410,"address":[],"length":0,"stats":{"Line":3}},{"line":411,"address":[],"length":0,"stats":{"Line":2}},{"line":416,"address":[],"length":0,"stats":{"Line":73}},{"line":432,"address":[],"length":0,"stats":{"Line":3}},{"line":433,"address":[],"length":0,"stats":{"Line":3}},{"line":434,"address":[],"length":0,"stats":{"Line":3}},{"line":436,"address":[],"length":0,"stats":{"Line":11}},{"line":437,"address":[],"length":0,"stats":{"Line":8}},{"line":438,"address":[],"length":0,"stats":{"Line":3}},{"line":441,"address":[],"length":0,"stats":{"Line":5}},{"line":442,"address":[],"length":0,"stats":{"Line":35}},{"line":443,"address":[],"length":0,"stats":{"Line":34}},{"line":444,"address":[],"length":0,"stats":{"Line":3}},{"line":445,"address":[],"length":0,"stats":{"Line":3}},{"line":446,"address":[],"length":0,"stats":{"Line":62}},{"line":447,"address":[],"length":0,"stats":{"Line":1}},{"line":448,"address":[],"length":0,"stats":{"Line":1}},{"line":450,"address":[],"length":0,"stats":{"Line":30}},{"line":453,"address":[],"length":0,"stats":{"Line":0}},{"line":454,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":471,"address":[],"length":0,"stats":{"Line":6}},{"line":472,"address":[],"length":0,"stats":{"Line":6}},{"line":488,"address":[],"length":0,"stats":{"Line":507}},{"line":489,"address":[],"length":0,"stats":{"Line":507}},{"line":490,"address":[],"length":0,"stats":{"Line":1}},{"line":492,"address":[],"length":0,"stats":{"Line":506}},{"line":509,"address":[],"length":0,"stats":{"Line":6}},{"line":510,"address":[],"length":0,"stats":{"Line":6}},{"line":511,"address":[],"length":0,"stats":{"Line":1}},{"line":514,"address":[],"length":0,"stats":{"Line":5}},{"line":515,"address":[],"length":0,"stats":{"Line":5}},{"line":517,"address":[],"length":0,"stats":{"Line":19}},{"line":518,"address":[],"length":0,"stats":{"Line":44}},{"line":520,"address":[],"length":0,"stats":{"Line":4}},{"line":523,"address":[],"length":0,"stats":{"Line":15}},{"line":541,"address":[],"length":0,"stats":{"Line":4}},{"line":542,"address":[],"length":0,"stats":{"Line":4}}],"covered":144,"coverable":158},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-utils","src","system_info.rs"],"content":"// ABOUTME: System information gathering and environment utilities\n// ABOUTME: Provides system metadata and environment information for LLMSpell operations\n\n//! System information gathering utilities\n//!\n//! This module provides utilities for gathering system information,\n//! including OS details, environment variables, and resource usage.\n\nuse serde::{Deserialize, Serialize};\nuse std::env;\nuse std::io;\nuse std::path::PathBuf;\n\n/// System information structure\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]\npub struct SystemInfo {\n    /// Operating system name\n    pub os: String,\n    /// OS version\n    pub version: String,\n    /// System architecture\n    pub arch: String,\n    /// Number of CPU cores\n    pub cpu_cores: usize,\n    /// Total system memory in bytes\n    pub total_memory: Option<u64>,\n    /// Available system memory in bytes\n    pub available_memory: Option<u64>,\n    /// Hostname\n    pub hostname: Option<String>,\n    /// Current user\n    pub username: Option<String>,\n    /// Home directory\n    pub home_dir: Option<PathBuf>,\n}\n\n/// Operating system type\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]\npub enum OperatingSystem {\n    /// Windows\n    Windows,\n    /// macOS\n    MacOS,\n    /// Linux\n    Linux,\n    /// Unknown or unsupported OS\n    Unknown,\n}\n\nimpl OperatingSystem {\n    /// Get the current operating system type\n    #[must_use]\n    pub fn current() -> Self {\n        match env::consts::OS {\n            \"windows\" => Self::Windows,\n            \"macos\" => Self::MacOS,\n            \"linux\" => Self::Linux,\n            _ => Self::Unknown,\n        }\n    }\n\n    /// Check if the current OS is Windows\n    #[must_use]\n    pub fn is_windows() -> bool {\n        matches!(Self::current(), Self::Windows)\n    }\n\n    /// Check if the current OS is macOS\n    #[must_use]\n    pub fn is_macos() -> bool {\n        matches!(Self::current(), Self::MacOS)\n    }\n\n    /// Check if the current OS is Linux\n    #[must_use]\n    pub fn is_linux() -> bool {\n        matches!(Self::current(), Self::Linux)\n    }\n\n    /// Check if the current OS is Unix-like (macOS or Linux)\n    #[must_use]\n    pub fn is_unix() -> bool {\n        matches!(Self::current(), Self::MacOS | Self::Linux)\n    }\n}\n\nimpl std::fmt::Display for OperatingSystem {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            Self::Windows => write!(f, \"Windows\"),\n            Self::MacOS => write!(f, \"macOS\"),\n            Self::Linux => write!(f, \"Linux\"),\n            Self::Unknown => write!(f, \"Unknown\"),\n        }\n    }\n}\n\n/// Get current system information\n///\n/// Gathers comprehensive system information including OS details,\n/// architecture, CPU cores, memory, and user information.\n///\n/// # Examples\n///\n/// ```rust,no_run\n/// use llmspell_utils::system_info::get_system_info;\n///\n/// # fn main() -> Result<(), Box<dyn std::error::Error>> {\n/// let info = get_system_info()?;\n/// println!(\"OS: {} {}\", info.os, info.version);\n/// println!(\"Architecture: {}\", info.arch);\n/// println!(\"CPU cores: {}\", info.cpu_cores);\n/// # Ok(())\n/// # }\n/// ```\n///\n/// # Errors\n///\n/// Returns an error if system information cannot be gathered\npub fn get_system_info() -> Result<SystemInfo, io::Error> {\n    let info = SystemInfo {\n        os: env::consts::OS.to_string(),\n        version: get_os_version().unwrap_or_else(|| \"unknown\".to_string()),\n        arch: env::consts::ARCH.to_string(),\n        cpu_cores: get_cpu_count(),\n        total_memory: get_total_memory(),\n        available_memory: get_available_memory(),\n        hostname: get_hostname(),\n        username: get_username(),\n        home_dir: get_home_directory(),\n    };\n\n    Ok(info)\n}\n\n/// Get the number of CPU cores\n///\n/// Returns the number of logical CPU cores available to the process.\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::system_info::get_cpu_count;\n///\n/// let cores = get_cpu_count();\n/// assert!(cores > 0);\n/// ```\n#[must_use]\npub fn get_cpu_count() -> usize {\n    std::thread::available_parallelism()\n        .map(std::num::NonZero::get)\n        .unwrap_or(1)\n}\n\n/// Get the OS version string\nfn get_os_version() -> Option<String> {\n    #[cfg(target_os = \"windows\")]\n    {\n        // On Windows, we could use registry or WMI, but for simplicity:\n        Some(\"Windows\".to_string())\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        use std::process::Command;\n        Command::new(\"sw_vers\")\n            .arg(\"-productVersion\")\n            .output()\n            .ok()\n            .and_then(|output| String::from_utf8(output.stdout).ok())\n            .map(|s| s.trim().to_string())\n    }\n\n    #[cfg(target_os = \"linux\")]\n    {\n        use std::fs;\n        // Try to read from various release files\n        fs::read_to_string(\"/etc/os-release\")\n            .or_else(|_| fs::read_to_string(\"/etc/lsb-release\"))\n            .ok()\n            .and_then(|content| {\n                // Parse VERSION or DISTRIB_RELEASE\n                content\n                    .lines()\n                    .find(|line| {\n                        line.starts_with(\"VERSION=\") || line.starts_with(\"DISTRIB_RELEASE=\")\n                    })\n                    .and_then(|line| line.split('=').nth(1))\n                    .map(|s| s.trim_matches('\"').to_string())\n            })\n            .or_else(|| Some(\"Linux\".to_string()))\n    }\n\n    #[cfg(not(any(target_os = \"windows\", target_os = \"macos\", target_os = \"linux\")))]\n    {\n        None\n    }\n}\n\n/// Get total system memory in bytes\nfn get_total_memory() -> Option<u64> {\n    #[cfg(target_os = \"linux\")]\n    {\n        use std::fs;\n        fs::read_to_string(\"/proc/meminfo\")\n            .ok()\n            .and_then(|content| {\n                content\n                    .lines()\n                    .find(|line| line.starts_with(\"MemTotal:\"))\n                    .and_then(|line| {\n                        line.split_whitespace()\n                            .nth(1)\n                            .and_then(|s| s.parse::<u64>().ok())\n                            .map(|kb| kb * 1024) // Convert KB to bytes\n                    })\n            })\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n        use std::process::Command;\n        Command::new(\"sysctl\")\n            .arg(\"-n\")\n            .arg(\"hw.memsize\")\n            .output()\n            .ok()\n            .and_then(|output| String::from_utf8(output.stdout).ok())\n            .and_then(|s| s.trim().parse::<u64>().ok())\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        // On Windows, this would require WMI or similar\n        None\n    }\n\n    #[cfg(not(any(target_os = \"windows\", target_os = \"macos\", target_os = \"linux\")))]\n    {\n        None\n    }\n}\n\n/// Get available system memory in bytes\nfn get_available_memory() -> Option<u64> {\n    #[cfg(target_os = \"linux\")]\n    {\n        use std::fs;\n        fs::read_to_string(\"/proc/meminfo\")\n            .ok()\n            .and_then(|content| {\n                content\n                    .lines()\n                    .find(|line| line.starts_with(\"MemAvailable:\"))\n                    .and_then(|line| {\n                        line.split_whitespace()\n                            .nth(1)\n                            .and_then(|s| s.parse::<u64>().ok())\n                            .map(|kb| kb * 1024) // Convert KB to bytes\n                    })\n            })\n    }\n\n    #[cfg(not(target_os = \"linux\"))]\n    {\n        None\n    }\n}\n\n/// Get the system hostname\n///\n/// # Examples\n///\n/// ```rust,no_run\n/// use llmspell_utils::system_info::get_hostname;\n///\n/// if let Some(hostname) = get_hostname() {\n///     println!(\"Hostname: {}\", hostname);\n/// }\n/// ```\n#[must_use]\npub fn get_hostname() -> Option<String> {\n    #[cfg(unix)]\n    {\n        use std::ffi::CStr;\n        let mut buffer = vec![0u8; 256];\n        unsafe {\n            if libc::gethostname(buffer.as_mut_ptr().cast::<libc::c_char>(), buffer.len()) == 0 {\n                CStr::from_ptr(buffer.as_ptr().cast::<libc::c_char>())\n                    .to_str()\n                    .ok()\n                    .map(std::string::ToString::to_string)\n            } else {\n                None\n            }\n        }\n    }\n\n    #[cfg(windows)]\n    {\n        env::var(\"COMPUTERNAME\").ok()\n    }\n\n    #[cfg(not(any(unix, windows)))]\n    {\n        None\n    }\n}\n\n/// Get the current username\n///\n/// # Examples\n///\n/// ```rust,no_run\n/// use llmspell_utils::system_info::get_username;\n///\n/// if let Some(username) = get_username() {\n///     println!(\"Current user: {}\", username);\n/// }\n/// ```\n#[must_use]\npub fn get_username() -> Option<String> {\n    env::var(\"USER\").or_else(|_| env::var(\"USERNAME\")).ok()\n}\n\n/// Get the user's home directory\n///\n/// # Examples\n///\n/// ```rust,no_run\n/// use llmspell_utils::system_info::get_home_directory;\n///\n/// if let Some(home) = get_home_directory() {\n///     println!(\"Home directory: {}\", home.display());\n/// }\n/// ```\n#[must_use]\npub fn get_home_directory() -> Option<PathBuf> {\n    env::var(\"HOME\")\n        .or_else(|_| env::var(\"USERPROFILE\"))\n        .ok()\n        .map(PathBuf::from)\n}\n\n/// Get an environment variable with a default value\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::system_info::get_env_or;\n///\n/// let editor = get_env_or(\"EDITOR\", \"vim\");\n/// let custom = get_env_or(\"MY_CUSTOM_VAR\", \"default_value\");\n/// ```\n#[must_use]\npub fn get_env_or(key: &str, default: &str) -> String {\n    env::var(key).unwrap_or_else(|_| default.to_string())\n}\n\n/// Check if an environment variable is set and truthy\n///\n/// A variable is considered truthy if it's set and not empty, \"0\", \"false\", or \"no\"\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::system_info::is_env_truthy;\n///\n/// // Returns true if DEBUG=1, DEBUG=true, DEBUG=yes, DEBUG=anything_else\n/// // Returns false if DEBUG is unset, empty, \"0\", \"false\", or \"no\"\n/// let debug_mode = is_env_truthy(\"DEBUG\");\n/// ```\n#[must_use]\npub fn is_env_truthy(key: &str) -> bool {\n    match env::var(key) {\n        Ok(val) => {\n            let val = val.trim().to_lowercase();\n            !val.is_empty() && val != \"0\" && val != \"false\" && val != \"no\"\n        }\n        Err(_) => false,\n    }\n}\n\n/// Get a list of all environment variables\n///\n/// Returns a vector of (key, value) pairs for all environment variables.\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::system_info::get_all_env_vars;\n///\n/// let vars = get_all_env_vars();\n/// for (key, value) in vars {\n///     println!(\"{} = {}\", key, value);\n/// }\n/// ```\n#[must_use]\npub fn get_all_env_vars() -> Vec<(String, String)> {\n    env::vars().collect()\n}\n\n/// Find executable in PATH\n///\n/// Searches for an executable in the system PATH.\n///\n/// # Examples\n///\n/// ```rust,no_run\n/// use llmspell_utils::system_info::find_executable;\n///\n/// if let Some(python_path) = find_executable(\"python\") {\n///     println!(\"Python found at: {}\", python_path.display());\n/// }\n/// ```\n#[must_use]\npub fn find_executable(name: &str) -> Option<PathBuf> {\n    which::which(name).ok()\n}\n\n/// Check if running in a container (Docker, Podman, etc.)\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::system_info::is_running_in_container;\n///\n/// if is_running_in_container() {\n///     println!(\"Running inside a container\");\n/// }\n/// ```\n#[must_use]\npub fn is_running_in_container() -> bool {\n    #[cfg(target_os = \"linux\")]\n    {\n        use std::fs;\n        use std::path::Path;\n        // Check for /.dockerenv or /.containerenv\n        Path::new(\"/.dockerenv\").exists() \n            || Path::new(\"/.containerenv\").exists()\n            // Check if running in a container via cgroup\n            || fs::read_to_string(\"/proc/1/cgroup\")\n                .map(|content| content.contains(\"/docker/\") || content.contains(\"/containerd/\"))\n                .unwrap_or(false)\n    }\n\n    #[cfg(not(target_os = \"linux\"))]\n    {\n        false\n    }\n}\n\n/// Check if running in a virtual machine\n///\n/// This is a best-effort detection and may not catch all virtualization types.\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::system_info::is_running_in_vm;\n///\n/// if is_running_in_vm() {\n///     println!(\"Running inside a virtual machine\");\n/// }\n/// ```\n#[must_use]\npub fn is_running_in_vm() -> bool {\n    #[cfg(target_os = \"linux\")]\n    {\n        use std::fs;\n        // Check for common VM indicators\n        fs::read_to_string(\"/sys/devices/virtual/dmi/id/product_name\")\n            .map(|content| {\n                let content = content.to_lowercase();\n                content.contains(\"virtualbox\")\n                    || content.contains(\"vmware\")\n                    || content.contains(\"kvm\")\n                    || content.contains(\"qemu\")\n                    || content.contains(\"xen\")\n            })\n            .unwrap_or(false)\n            || std::path::Path::new(\"/proc/xen\").exists()\n            || std::path::Path::new(\"/sys/hypervisor/type\").exists()\n    }\n\n    #[cfg(not(target_os = \"linux\"))]\n    {\n        false\n    }\n}\n\n/// Get temporary directory path\n///\n/// Returns the system's temporary directory path.\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::system_info::get_temp_dir;\n///\n/// let temp_dir = get_temp_dir();\n/// println!(\"Temp directory: {}\", temp_dir.display());\n/// ```\n#[must_use]\npub fn get_temp_dir() -> PathBuf {\n    env::temp_dir()\n}\n\n/// Format bytes into human-readable string\n///\n/// # Examples\n///\n/// ```rust\n/// use llmspell_utils::system_info::format_bytes;\n///\n/// assert_eq!(format_bytes(1024), \"1.0 KB\");\n/// assert_eq!(format_bytes(1_048_576), \"1.0 MB\");\n/// assert_eq!(format_bytes(1_073_741_824), \"1.0 GB\");\n/// ```\n#[must_use]\npub fn format_bytes(bytes: u64) -> String {\n    const UNITS: &[&str] = &[\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"];\n\n    if bytes == 0 {\n        return \"0 B\".to_string();\n    }\n\n    #[allow(clippy::cast_precision_loss)]\n    let mut size = bytes as f64;\n    let mut unit_index = 0;\n\n    while size >= 1024.0 && unit_index < UNITS.len() - 1 {\n        size /= 1024.0;\n        unit_index += 1;\n    }\n\n    if unit_index == 0 {\n        format!(\"{} {}\", bytes, UNITS[0])\n    } else {\n        format!(\"{:.1} {}\", size, UNITS[unit_index])\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_operating_system() {\n        let os = OperatingSystem::current();\n        match env::consts::OS {\n            \"windows\" => assert_eq!(os, OperatingSystem::Windows),\n            \"macos\" => assert_eq!(os, OperatingSystem::MacOS),\n            \"linux\" => assert_eq!(os, OperatingSystem::Linux),\n            _ => assert_eq!(os, OperatingSystem::Unknown),\n        }\n\n        // Test display\n        let _ = format!(\"{os}\");\n\n        // Test helpers\n        if cfg!(target_os = \"windows\") {\n            assert!(OperatingSystem::is_windows());\n            assert!(!OperatingSystem::is_unix());\n        } else if cfg!(target_os = \"macos\") {\n            assert!(OperatingSystem::is_macos());\n            assert!(OperatingSystem::is_unix());\n        } else if cfg!(target_os = \"linux\") {\n            assert!(OperatingSystem::is_linux());\n            assert!(OperatingSystem::is_unix());\n        }\n    }\n\n    #[test]\n    fn test_get_system_info() {\n        let info = get_system_info().unwrap();\n\n        // Basic checks\n        assert!(!info.os.is_empty());\n        assert!(!info.arch.is_empty());\n        assert!(info.cpu_cores > 0);\n\n        // OS should match env::consts::OS\n        assert_eq!(info.os, env::consts::OS);\n\n        // Architecture should match env::consts::ARCH\n        assert_eq!(info.arch, env::consts::ARCH);\n    }\n\n    #[test]\n    fn test_get_cpu_count() {\n        let count = get_cpu_count();\n        assert!(count > 0);\n\n        // Should match std::thread::available_parallelism if available\n        if let Ok(parallelism) = std::thread::available_parallelism() {\n            assert_eq!(count, parallelism.get());\n        }\n    }\n\n    #[test]\n    fn test_env_helpers() {\n        // Test get_env_or\n        env::set_var(\"TEST_ENV_VAR\", \"test_value\");\n        assert_eq!(get_env_or(\"TEST_ENV_VAR\", \"default\"), \"test_value\");\n        assert_eq!(get_env_or(\"NONEXISTENT_VAR\", \"default\"), \"default\");\n        env::remove_var(\"TEST_ENV_VAR\");\n\n        // Test is_env_truthy\n        env::set_var(\"TRUTHY_VAR\", \"1\");\n        assert!(is_env_truthy(\"TRUTHY_VAR\"));\n\n        env::set_var(\"TRUTHY_VAR\", \"true\");\n        assert!(is_env_truthy(\"TRUTHY_VAR\"));\n\n        env::set_var(\"TRUTHY_VAR\", \"yes\");\n        assert!(is_env_truthy(\"TRUTHY_VAR\"));\n\n        env::set_var(\"TRUTHY_VAR\", \"0\");\n        assert!(!is_env_truthy(\"TRUTHY_VAR\"));\n\n        env::set_var(\"TRUTHY_VAR\", \"false\");\n        assert!(!is_env_truthy(\"TRUTHY_VAR\"));\n\n        env::set_var(\"TRUTHY_VAR\", \"no\");\n        assert!(!is_env_truthy(\"TRUTHY_VAR\"));\n\n        env::set_var(\"TRUTHY_VAR\", \"\");\n        assert!(!is_env_truthy(\"TRUTHY_VAR\"));\n\n        env::remove_var(\"TRUTHY_VAR\");\n        assert!(!is_env_truthy(\"TRUTHY_VAR\"));\n    }\n\n    #[test]\n    fn test_get_all_env_vars() {\n        let vars = get_all_env_vars();\n        assert!(!vars.is_empty());\n\n        // Should contain PATH\n        assert!(vars.iter().any(|(k, _)| k == \"PATH\"));\n    }\n\n    #[test]\n    fn test_get_temp_dir() {\n        let temp_dir = get_temp_dir();\n        assert!(temp_dir.is_absolute());\n        assert!(temp_dir.exists());\n    }\n\n    #[test]\n    fn test_format_bytes() {\n        assert_eq!(format_bytes(0), \"0 B\");\n        assert_eq!(format_bytes(512), \"512 B\");\n        assert_eq!(format_bytes(1024), \"1.0 KB\");\n        assert_eq!(format_bytes(1536), \"1.5 KB\");\n        assert_eq!(format_bytes(1_048_576), \"1.0 MB\");\n        assert_eq!(format_bytes(1_073_741_824), \"1.0 GB\");\n        assert_eq!(format_bytes(1_099_511_627_776), \"1.0 TB\");\n        assert_eq!(format_bytes(1_125_899_906_842_624), \"1.0 PB\");\n    }\n\n    #[test]\n    fn test_username_and_home() {\n        // These might not always be set in CI environments\n        if let Some(username) = get_username() {\n            assert!(!username.is_empty());\n        }\n\n        if let Some(home) = get_home_directory() {\n            assert!(home.is_absolute());\n        }\n    }\n\n    #[test]\n    fn test_find_executable() {\n        // Common executables that should exist\n        #[cfg(unix)]\n        {\n            // sh should exist on all Unix systems\n            assert!(find_executable(\"sh\").is_some());\n        }\n\n        #[cfg(windows)]\n        {\n            // cmd.exe should exist on all Windows systems\n            assert!(find_executable(\"cmd\").is_some() || find_executable(\"cmd.exe\").is_some());\n        }\n\n        // Non-existent executable\n        assert!(find_executable(\"this_executable_definitely_does_not_exist_12345\").is_none());\n    }\n\n    #[test]\n    fn test_container_and_vm_detection() {\n        // These are environment-specific, so we just ensure they don't panic\n        let _ = is_running_in_container();\n        let _ = is_running_in_vm();\n    }\n}\n\n#[cfg(test)]\nmod property_tests {\n    use super::*;\n    use proptest::prelude::*;\n\n    proptest! {\n        #[test]\n        fn test_format_bytes_ordering(bytes1 in 0u64..1_000_000_000_000, bytes2 in 0u64..1_000_000_000_000) {\n            let formatted1 = format_bytes(bytes1);\n            let _formatted2 = format_bytes(bytes2);\n\n            // If bytes1 < bytes2, the numeric part should reflect that\n            // (this is a simplified test, actual comparison would need parsing)\n            if bytes1 == 0 && bytes2 > 0 {\n                assert_eq!(formatted1, \"0 B\");\n            }\n        }\n\n        #[test]\n        fn test_env_var_roundtrip(suffix in \"[A-Z][A-Z0-9_]*\", value in \"[^\\0]*\") {\n            // Use a unique prefix to avoid conflicts\n            let key = format!(\"LLMSPELL_TEST_{suffix}\");\n            // Skip if key somehow already exists or value contains null bytes\n            if env::var(&key).is_err() && !value.contains('\\0') {\n                env::set_var(&key, &value);\n                assert_eq!(get_env_or(&key, \"default\"), value);\n                env::remove_var(&key);\n            }\n        }\n    }\n}\n","traces":[{"line":53,"address":[],"length":0,"stats":{"Line":4}},{"line":54,"address":[],"length":0,"stats":{"Line":4}},{"line":55,"address":[],"length":0,"stats":{"Line":4}},{"line":56,"address":[],"length":0,"stats":{"Line":8}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":1}},{"line":71,"address":[],"length":0,"stats":{"Line":1}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":1}},{"line":83,"address":[],"length":0,"stats":{"Line":1}},{"line":88,"address":[],"length":0,"stats":{"Line":2}},{"line":89,"address":[],"length":0,"stats":{"Line":2}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":2}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":2}},{"line":122,"address":[],"length":0,"stats":{"Line":2}},{"line":123,"address":[],"length":0,"stats":{"Line":4}},{"line":124,"address":[],"length":0,"stats":{"Line":2}},{"line":125,"address":[],"length":0,"stats":{"Line":2}},{"line":126,"address":[],"length":0,"stats":{"Line":2}},{"line":127,"address":[],"length":0,"stats":{"Line":2}},{"line":128,"address":[],"length":0,"stats":{"Line":2}},{"line":129,"address":[],"length":0,"stats":{"Line":2}},{"line":130,"address":[],"length":0,"stats":{"Line":2}},{"line":133,"address":[],"length":0,"stats":{"Line":2}},{"line":149,"address":[],"length":0,"stats":{"Line":4}},{"line":150,"address":[],"length":0,"stats":{"Line":4}},{"line":151,"address":[],"length":0,"stats":{"Line":4}},{"line":156,"address":[],"length":0,"stats":{"Line":2}},{"line":166,"address":[],"length":0,"stats":{"Line":2}},{"line":170,"address":[],"length":0,"stats":{"Line":6}},{"line":171,"address":[],"length":0,"stats":{"Line":6}},{"line":178,"address":[],"length":0,"stats":{"Line":2}},{"line":179,"address":[],"length":0,"stats":{"Line":2}},{"line":181,"address":[],"length":0,"stats":{"Line":2}},{"line":183,"address":[],"length":0,"stats":{"Line":2}},{"line":184,"address":[],"length":0,"stats":{"Line":2}},{"line":185,"address":[],"length":0,"stats":{"Line":2}},{"line":186,"address":[],"length":0,"stats":{"Line":2}},{"line":188,"address":[],"length":0,"stats":{"Line":2}},{"line":189,"address":[],"length":0,"stats":{"Line":2}},{"line":191,"address":[],"length":0,"stats":{"Line":2}},{"line":196,"address":[],"length":0,"stats":{"Line":2}},{"line":201,"address":[],"length":0,"stats":{"Line":2}},{"line":223,"address":[],"length":0,"stats":{"Line":2}},{"line":228,"address":[],"length":0,"stats":{"Line":6}},{"line":229,"address":[],"length":0,"stats":{"Line":6}},{"line":235,"address":[],"length":0,"stats":{"Line":2}},{"line":240,"address":[],"length":0,"stats":{"Line":2}},{"line":245,"address":[],"length":0,"stats":{"Line":2}},{"line":249,"address":[],"length":0,"stats":{"Line":2}},{"line":251,"address":[],"length":0,"stats":{"Line":2}},{"line":252,"address":[],"length":0,"stats":{"Line":2}},{"line":253,"address":[],"length":0,"stats":{"Line":2}},{"line":254,"address":[],"length":0,"stats":{"Line":2}},{"line":255,"address":[],"length":0,"stats":{"Line":2}},{"line":256,"address":[],"length":0,"stats":{"Line":2}},{"line":257,"address":[],"length":0,"stats":{"Line":2}},{"line":258,"address":[],"length":0,"stats":{"Line":2}},{"line":259,"address":[],"length":0,"stats":{"Line":2}},{"line":266,"address":[],"length":0,"stats":{"Line":2}},{"line":282,"address":[],"length":0,"stats":{"Line":2}},{"line":286,"address":[],"length":0,"stats":{"Line":2}},{"line":288,"address":[],"length":0,"stats":{"Line":2}},{"line":289,"address":[],"length":0,"stats":{"Line":2}},{"line":292,"address":[],"length":0,"stats":{"Line":2}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":3}},{"line":323,"address":[],"length":0,"stats":{"Line":6}},{"line":338,"address":[],"length":0,"stats":{"Line":3}},{"line":339,"address":[],"length":0,"stats":{"Line":3}},{"line":340,"address":[],"length":0,"stats":{"Line":6}},{"line":342,"address":[],"length":0,"stats":{"Line":3}},{"line":356,"address":[],"length":0,"stats":{"Line":259}},{"line":357,"address":[],"length":0,"stats":{"Line":519}},{"line":374,"address":[],"length":0,"stats":{"Line":8}},{"line":375,"address":[],"length":0,"stats":{"Line":8}},{"line":376,"address":[],"length":0,"stats":{"Line":7}},{"line":377,"address":[],"length":0,"stats":{"Line":7}},{"line":378,"address":[],"length":0,"stats":{"Line":22}},{"line":380,"address":[],"length":0,"stats":{"Line":1}},{"line":399,"address":[],"length":0,"stats":{"Line":1}},{"line":400,"address":[],"length":0,"stats":{"Line":1}},{"line":417,"address":[],"length":0,"stats":{"Line":2}},{"line":418,"address":[],"length":0,"stats":{"Line":2}},{"line":433,"address":[],"length":0,"stats":{"Line":1}},{"line":439,"address":[],"length":0,"stats":{"Line":1}},{"line":440,"address":[],"length":0,"stats":{"Line":1}},{"line":442,"address":[],"length":0,"stats":{"Line":1}},{"line":443,"address":[],"length":0,"stats":{"Line":1}},{"line":444,"address":[],"length":0,"stats":{"Line":1}},{"line":449,"address":[],"length":0,"stats":{"Line":1}},{"line":467,"address":[],"length":0,"stats":{"Line":1}},{"line":472,"address":[],"length":0,"stats":{"Line":1}},{"line":473,"address":[],"length":0,"stats":{"Line":1}},{"line":474,"address":[],"length":0,"stats":{"Line":1}},{"line":475,"address":[],"length":0,"stats":{"Line":1}},{"line":476,"address":[],"length":0,"stats":{"Line":1}},{"line":477,"address":[],"length":0,"stats":{"Line":1}},{"line":478,"address":[],"length":0,"stats":{"Line":1}},{"line":479,"address":[],"length":0,"stats":{"Line":1}},{"line":481,"address":[],"length":0,"stats":{"Line":1}},{"line":482,"address":[],"length":0,"stats":{"Line":1}},{"line":483,"address":[],"length":0,"stats":{"Line":1}},{"line":488,"address":[],"length":0,"stats":{"Line":1}},{"line":505,"address":[],"length":0,"stats":{"Line":1}},{"line":506,"address":[],"length":0,"stats":{"Line":1}},{"line":521,"address":[],"length":0,"stats":{"Line":524}},{"line":524,"address":[],"length":0,"stats":{"Line":524}},{"line":525,"address":[],"length":0,"stats":{"Line":1}},{"line":529,"address":[],"length":0,"stats":{"Line":523}},{"line":530,"address":[],"length":0,"stats":{"Line":523}},{"line":532,"address":[],"length":0,"stats":{"Line":5206}},{"line":533,"address":[],"length":0,"stats":{"Line":1561}},{"line":534,"address":[],"length":0,"stats":{"Line":1561}},{"line":538,"address":[],"length":0,"stats":{"Line":1}},{"line":540,"address":[],"length":0,"stats":{"Line":522}}],"covered":113,"coverable":123},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-utils","tests","integration_test.rs"],"content":"// ABOUTME: Integration tests for llmspell-utils crate\n// ABOUTME: Verifies that all modules are properly exported and accessible\n\n//! Integration tests for the llmspell-utils crate\n\nuse llmspell_utils::*;\nuse std::path::Path;\n\n#[test]\nfn test_string_utils_exports() {\n    // Test string manipulation functions\n    assert_eq!(truncate(\"Hello, world!\", 5), \"He...\");\n    assert_eq!(sanitize(\"  Hello\\x00World  \"), \"HelloWorld\");\n\n    let wrapped = word_wrap(\"This is a long line\", 10);\n    assert_eq!(wrapped.len(), 2);\n\n    assert_eq!(to_snake_case(\"HelloWorld\"), \"hello_world\");\n    assert_eq!(to_camel_case(\"hello_world\"), \"helloWorld\");\n    assert_eq!(to_pascal_case(\"hello_world\"), \"HelloWorld\");\n\n    let indented = indent(\"Line 1\\nLine 2\", 2);\n    assert!(indented.starts_with(\"  Line 1\"));\n\n    assert!(is_valid_identifier(\"valid_name\"));\n    assert!(!is_valid_identifier(\"123invalid\"));\n\n    assert_eq!(normalize_whitespace(\"Hello    world\"), \"Hello world\");\n}\n\n#[test]\nfn test_system_info_exports() {\n    // Test system info functions\n    let info = get_system_info().unwrap();\n    assert!(!info.os.is_empty());\n    assert!(info.cpu_cores > 0);\n\n    let cpu_count = get_cpu_count();\n    assert!(cpu_count > 0);\n\n    let os = OperatingSystem::current();\n    let _ = format!(\"{}\", os); // Test Display trait\n\n    assert_eq!(format_bytes(1024), \"1.0 KB\");\n    assert_eq!(format_bytes(1_048_576), \"1.0 MB\");\n}\n\n#[test]\nfn test_error_builders_exports() {\n    use llmspell_utils::templates;\n\n    // Test error builder\n    let error = ErrorBuilder::new(\"Test error\")\n        .with_context(\"key\", \"value\")\n        .build();\n    assert_eq!(error.message(), \"Test error\");\n    assert_eq!(error.get_context(\"key\"), Some(\"value\"));\n\n    // Test error templates\n    let io_err = templates::io_error(\"Failed to read\", \"/tmp/test.txt\").build();\n    assert_eq!(io_err.get_context(\"error_type\"), Some(\"io\"));\n\n    let val_err = templates::validation_error(\"Invalid\", \"test@\", \"missing domain\").build();\n    assert_eq!(val_err.get_context(\"error_type\"), Some(\"validation\"));\n}\n\n#[test]\nfn test_id_generator_exports() {\n    // Test ID generation\n    let id = generate_component_id(\"test\");\n    assert!(id.starts_with(\"test_\"));\n    assert!(validate_component_id(&id, Some(\"test\")));\n\n    let short_id = generate_short_id(\"short\");\n    assert!(short_id.starts_with(\"short_\"));\n    assert!(short_id.len() < 20);\n\n    let det_id1 = generate_deterministic_id(NAMESPACE_AGENT, \"my-agent\");\n    let det_id2 = generate_deterministic_id(NAMESPACE_AGENT, \"my-agent\");\n    assert_eq!(det_id1, det_id2);\n\n    let builder_id = ComponentIdBuilder::new()\n        .with_prefix(\"custom\")\n        .short()\n        .build();\n    assert!(builder_id.starts_with(\"custom_\"));\n}\n\n#[test]\nfn test_serialization_exports() {\n    use std::collections::HashMap;\n\n    // Test JSON serialization\n    let mut map = HashMap::new();\n    map.insert(\"key\", \"value\");\n\n    let json_str = to_json(&map).unwrap();\n    let pretty_json = to_json_pretty(&map).unwrap();\n    assert!(json_str.contains(\"\\\"key\\\":\\\"value\\\"\"));\n    assert!(pretty_json.contains(\"{\\n\"));\n\n    let deserialized: HashMap<String, String> = from_json(&json_str).unwrap();\n    assert_eq!(deserialized[\"key\"], \"value\");\n\n    // Test format conversion\n    let yaml = convert_format(&json_str, Format::Json, Format::Yaml).unwrap();\n    assert!(yaml.contains(\"key: value\"));\n\n    // Test merge functionality\n    let base = json!({\"a\": 1, \"b\": 2});\n    let other = json!({\"b\": 3, \"c\": 4});\n    let merged = merge_json(&base, &other);\n    assert_eq!(merged[\"a\"], 1);\n    assert_eq!(merged[\"b\"], 3);\n    assert_eq!(merged[\"c\"], 4);\n}\n\n#[test]\nfn test_file_utils_exports() {\n    // Test file_utils functions\n    assert!(is_absolute_path(Path::new(\"/home\")));\n    assert!(!is_absolute_path(Path::new(\"relative\")));\n\n    let normalized = normalize_path(Path::new(\"/home/../home\"));\n    assert_eq!(normalized, Path::new(\"/home\"));\n\n    let joined = join_paths(&[Path::new(\"/home\"), Path::new(\"user\")]);\n    assert_eq!(joined, Path::new(\"/home/user\"));\n\n    let parent = parent_dir(Path::new(\"/home/user\"));\n    assert_eq!(parent, Some(Path::new(\"/home\").to_path_buf()));\n\n    // Test expand_path with HOME\n    if let Ok(home) = std::env::var(\"HOME\") {\n        let expanded = expand_path(\"~/test\").unwrap();\n        assert!(expanded.starts_with(&home));\n    }\n}\n\n#[tokio::test]\nasync fn test_async_utils_exports() {\n    use std::time::Duration;\n\n    // Test timeout\n    let result = timeout(Duration::from_millis(100), async { 42 }).await;\n    assert_eq!(result.unwrap(), 42);\n\n    // Test timeout with default\n    let result = timeout_with_default(\n        Duration::from_millis(10),\n        async {\n            tokio::time::sleep(Duration::from_millis(100)).await;\n            42\n        },\n        0,\n    )\n    .await;\n    assert_eq!(result, 0);\n\n    // Test retry\n    let mut count = 0;\n    let config = RetryConfig {\n        max_attempts: 3,\n        initial_delay: Duration::from_millis(1),\n        backoff_factor: 1.0,\n        max_delay: Duration::from_millis(10),\n        jitter: false,\n    };\n\n    let result = retry_async(config, || {\n        count += 1;\n        async move {\n            if count < 2 {\n                Err(\"Not ready\")\n            } else {\n                Ok(\"Success\")\n            }\n        }\n    })\n    .await;\n\n    assert_eq!(result.unwrap(), \"Success\");\n\n    // Test concurrent map\n    let numbers = vec![1, 2, 3];\n    let results = concurrent_map(numbers.into_iter(), 2, |n| async move { n * 2 }).await;\n    assert_eq!(results, vec![2, 4, 6]);\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","spuri","projects","lexlapax","rs-llmspell","llmspell-workflows","src","lib.rs"],"content":"//! ABOUTME: llmspell-workflows implementation crate\n//! ABOUTME: Foundation stub for future implementation\n\n// Module stub - to be implemented in later phases\n","traces":[],"covered":0,"coverable":0}],"coverage":62.27171492204899,"covered":2796,"coverable":4490}