# LLM Feature Layer
# Cloud LLM providers (OpenAI, Anthropic, Gemini)

[profile]
name = "Cloud LLM Features"
description = "OpenAI, Anthropic, and Gemini cloud provider support"

# Provider configuration
[providers]
default_provider = "openai"

[providers.openai]
name = "openai"
provider_type = "openai"
enabled = true
api_key_env = "OPENAI_API_KEY"
default_model = "gpt-4"
max_tokens = 4096
timeout_seconds = 120

[providers.anthropic]
name = "anthropic"
provider_type = "anthropic"
enabled = true
api_key_env = "ANTHROPIC_API_KEY"
default_model = "claude-3-5-sonnet-20240620"
max_tokens = 8192
timeout_seconds = 120

[providers.gemini]
name = "gemini"
provider_type = "gemini"
enabled = false  # Gemini not yet implemented in rig.rs
api_key_env = "GEMINI_API_KEY"
default_model = "gemini-1.5-pro"
max_tokens = 8192
timeout_seconds = 120
