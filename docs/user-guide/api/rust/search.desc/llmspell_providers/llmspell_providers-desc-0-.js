searchState.loadedDescShard("llmspell_providers", 0, "ABOUTME: llmspell-providers implementation crate ABOUTME: …\nABOUTME: Provider abstraction layer defining capabilities …\nABOUTME: ModelSpecifier for parsing provider/model syntax …\nABOUTME: Rig provider implementation for LLM completions …\nCapabilities that a provider might support\nConfiguration for a provider instance\nFactory function type for creating provider instances\nTrait for LLM provider implementations\nType alias for provider instance storage\nProvider manager for handling multiple provider instances\nProvider registry for managing available providers\nAPI key or authentication token\nSupported model names\nList all available provider types\nGet list of registered provider names\nGet the provider’s capabilities\nExecute a completion request\nExecute a streaming completion request\nCreate a provider instance\nCreate and initialize a provider from a ModelSpecifier\nProvider-specific configuration\nProvider-specific features\nAPI endpoint URL (if applicable)\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nLoad configuration from environment variables\nGet the default provider instance\nGet a provider instance\nInitialize a provider instance\nGenerate hierarchical provider instance name Format: “…\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nList all initialized providers\nMaximum context window size in tokens\nMaximum output tokens\nMaximum retries for failed requests\nGet current model\nModel to use\nGet provider name\nProvider name (e.g., “openai”, “anthropic”, “…\nCreate a new provider registry\nCreate a new provider manager\nCreate a new provider configuration\nCreate a new provider configuration with explicit provider …\nProvider type (e.g., “openai”, “anthropic”, “…\nQuery capabilities of a provider\nRegister a provider factory\nRegister a provider factory\nSet the default provider\nWhether the provider supports multimodal content (images, …\nWhether the provider supports streaming responses\nRequest timeout in seconds\nValidate the provider configuration and connectivity\nSpecification for a model with optional provider and base …\nOptional base URL override\nReturns the argument unchanged.\nCheck if this specifier has a base URL override\nCheck if this specifier has a provider\nCalls <code>U::from(self)</code>.\nThe model name (e.g., “gpt-4”, “claude-3-sonnet”)\nCreate a new ModelSpecifier with just a model name\nParse a model specification string\nParse a model specification with an optional base URL …\nThe provider name (e.g., “openai”, “anthropic”)\nGet the provider name, or return a default\nCreate a new ModelSpecifier with provider, model, and base …\nCreate a new ModelSpecifier with provider and model\nRig provider implementation\nFactory function for creating Rig providers\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreate a new Rig provider instance")