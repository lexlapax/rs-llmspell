# RAG System Guide - Phase 8

**Status**: Production-Ready  
**Version**: 0.8.0  
**Last Updated**: December 2024  
**Purpose**: Complete guide to LLMSpell's Retrieval-Augmented Generation system

> **ğŸ“‹ Comprehensive Reference**: This document consolidates all RAG documentation including architecture, HNSW tuning, multi-tenancy, and operational guidance.

---

## Table of Contents

1. [System Overview](#system-overview)
2. [Architecture](#architecture)
3. [HNSW Configuration](#hnsw-configuration)
4. [Multi-Tenant Design](#multi-tenant-design)
5. [API Reference](#api-reference)
6. [Performance Tuning](#performance-tuning)
7. [Integration Patterns](#integration-patterns)
8. [Operational Guide](#operational-guide)

---

## System Overview

### Key Achievements

Phase 8 delivers a complete, enterprise-ready RAG system:

- **Performance**: 8ms vector search on 100K+ vectors
- **Scalability**: Tested to 100K vectors per tenant, 1M+ total
- **Multi-tenancy**: 3% overhead for complete tenant isolation
- **Embeddings**: OpenAI text-embedding-3-small (384 dimensions)
- **Algorithm**: HNSW (Hierarchical Navigable Small World)
- **Security**: Row-level security with namespace isolation

### Component Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   RAG System Components                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  User Layer:                                                â”‚
â”‚  â”œâ”€â”€ Lua Scripts (RAG global object)                        â”‚
â”‚  â”œâ”€â”€ Two-parameter API (primary, options)                   â”‚
â”‚  â””â”€â”€ Multi-tenant by default                                â”‚
â”‚                                                              â”‚
â”‚  Core Components:                                            â”‚
â”‚  â”œâ”€â”€ llmspell-rag (2,847 LOC)     - Pipeline orchestration â”‚
â”‚  â”œâ”€â”€ llmspell-storage (1,956 LOC)  - HNSW vector storage   â”‚
â”‚  â”œâ”€â”€ llmspell-tenancy (1,534 LOC)  - Multi-tenant manager  â”‚
â”‚  â””â”€â”€ llmspell-security             - Access control         â”‚
â”‚                                                              â”‚
â”‚  Infrastructure:                                             â”‚
â”‚  â”œâ”€â”€ OpenAI Embeddings             - text-embedding-3-small â”‚
â”‚  â”œâ”€â”€ StateScope Integration        - Tenant isolation       â”‚
â”‚  â””â”€â”€ Session Integration           - Artifact storage       â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Architecture

### Core Architecture Pattern

```rust
// Builder-based pipeline construction
let rag = RAGPipelineBuilder::new()
    .with_embedding_provider(EmbeddingProviderType::OpenAI)
    .with_vector_storage(storage)
    .with_tenant_manager(tenant_manager)
    .with_security_policies(policies)
    .with_hnsw_config(HNSWConfig::balanced())
    .build()?;
```

### Data Flow Architecture

#### Ingestion Pipeline
```
Document â†’ Chunking â†’ Embedding â†’ Vector Storage â†’ Index Update
    â†“         â†“          â†“            â†“              â†“
[PDF/TXT] [512 tokens] [384 dims] [HNSW Index] [Namespace]
          [Overlap:64] [OpenAI]   [Tenant-scoped] [Metrics]
```

#### Retrieval Pipeline
```
Query â†’ Embedding â†’ Vector Search â†’ Security Filter â†’ Results
  â†“        â†“            â†“               â†“              â†“
[Text] [384 dims] [HNSW Search] [Tenant Filter] [Ranked]
       [Cached]    [<10ms]       [RLS Policies]  [Metadata]
```

### Component Responsibilities

#### llmspell-rag
- Pipeline orchestration and coordination
- Document chunking strategies (token-aware, semantic)
- Embedding provider abstraction
- Result ranking and metadata boosting
- Session and state integration

#### llmspell-storage
- HNSW algorithm implementation (hnsw_rs crate)
- Vector persistence with MessagePack
- Namespace-based multi-tenancy
- Distance metrics (Cosine, Euclidean, InnerProduct)
- Index optimization and maintenance

#### llmspell-tenancy
- Tenant isolation and namespace management
- Usage tracking and metrics collection
- Cost calculation (embeddings, searches, storage)
- Resource limits and quota enforcement
- Audit logging for compliance

---

## HNSW Configuration

### Core Parameters

#### m (Number of Connections)
- **Purpose**: Bi-directional links per node
- **Range**: 2-100 (typical: 12-48)
- **Trade-off**: Higher = better recall, more memory
```toml
# Recommendations by dataset size
m = 12  # Small (<10K vectors)
m = 16  # Medium (10K-100K) - DEFAULT
m = 32  # Large (>100K)
m = 48  # Accuracy-critical
```

#### ef_construction (Construction Search Width)
- **Purpose**: Dynamic list size during index building
- **Range**: m to 1000 (typical: 100-500)
- **Trade-off**: Higher = better index quality, slower construction
```toml
ef_construction = 50   # Speed-optimized
ef_construction = 200  # Balanced - DEFAULT
ef_construction = 500  # Accuracy-optimized
```

#### ef_search (Search Width)
- **Purpose**: Dynamic list size during search
- **Range**: 1 to unlimited (typical: 50-300)
- **Trade-off**: Higher = better recall, slower search
```toml
ef_search = 25   # Real-time queries
ef_search = 50   # Balanced - DEFAULT
ef_search = 300  # High accuracy
```

### Preset Configurations

#### Speed-Optimized
```toml
[rag.vector_storage.hnsw]
m = 8
ef_construction = 50
ef_search = 25
parallel_batch_size = 256
# ~85% recall at very high speed
```

#### Balanced (Default)
```toml
[rag.vector_storage.hnsw]
m = 16
ef_construction = 200
ef_search = 50
parallel_batch_size = 128
# ~95% recall with good speed
```

#### Accuracy-Optimized
```toml
[rag.vector_storage.hnsw]
m = 48
ef_construction = 500
ef_search = 300
parallel_batch_size = 32
# ~99% recall at lower speed
```

### Distance Metrics

```rust
pub enum DistanceMetric {
    Cosine,        // Text embeddings (normalized) - DEFAULT
    Euclidean,     // Spatial data, image features
    InnerProduct,  // Recommendation systems (fastest)
    Manhattan,     // Grid data, categorical features
}
```

### Memory Usage Calculation

```
Memory = vectors Ã— dimensions Ã— 4 + vectors Ã— m Ã— 2 Ã— 8 + overhead

Examples:
- 100K vectors, 384 dims, m=16: ~180MB
- 1M vectors, 768 dims, m=32: ~3.5GB
- 10M vectors, 1536 dims, m=48: ~62GB
```

---

## Multi-Tenant Design

### Tenant Isolation Architecture

```rust
// Namespace-based isolation pattern
pub struct TenantContext {
    tenant_id: String,
    namespace: String,  // "tenant:acme-corp"
    scope: StateScope,  // Custom("tenant:acme-corp")
    policies: Vec<SecurityPolicy>,
}

// Every operation is tenant-aware
impl VectorStorage {
    async fn search_tenant(
        &self,
        query: &VectorQuery,
        tenant_id: &str,
    ) -> Result<Vec<VectorResult>> {
        let scope = StateScope::Custom(format!("tenant:{}", tenant_id));
        self.search_scoped(query, &scope).await
    }
}
```

### Usage Tracking

```rust
pub struct TenantUsageMetrics {
    pub embeddings_generated: u64,    // API calls
    pub embedding_tokens: u64,        // Token count
    pub searches_performed: u64,      // Search count
    pub documents_indexed: u64,       // Document count
    pub storage_bytes: u64,           // Storage used
    pub embedding_cost_cents: u64,    // Calculated cost
    pub last_activity: DateTime<Utc>, // For TTL
}
```

### Resource Limits

```rust
pub struct TenantLimits {
    pub max_vectors: Option<u64>,        // e.g., 100,000
    pub max_storage_bytes: Option<u64>,  // e.g., 1GB
    pub max_searches_per_day: Option<u64>,
    pub monthly_cost_limit_cents: Option<u64>,
}
```

### Security Boundaries

```rust
// Row-level security enforcement
impl SecurityPolicy for TenantIsolationPolicy {
    async fn evaluate(&self, context: &OperationContext) -> AccessDecision {
        match &context.tenant_id {
            Some(id) => {
                let filter = SecurityFilter::tenant_namespace(id);
                AccessDecision::AllowWithFilters(vec![filter])
            }
            None => AccessDecision::Deny("No tenant context".into())
        }
    }
}
```

---

## API Reference

### Lua Script API

#### Basic Operations
```lua
-- Document ingestion
RAG.ingest(document, options)
-- document: string or table with content and metadata
-- options: {tenant_id, chunk_size, overlap, strategy}

-- Vector search
results = RAG.search(query, options)
-- query: search string
-- options: {tenant_id, k, threshold, filters}

-- Get statistics
stats = RAG.get_stats(namespace, scope)
```

#### Multi-Tenant Operations
```lua
-- Tenant-scoped ingestion
RAG.ingest(doc, {
    scope = "tenant",
    scope_id = "acme-corp",
    chunk_size = 512,
    overlap = 64
})

-- Tenant-scoped search
results = RAG.search(query, {
    scope = "tenant",
    scope_id = "acme-corp",
    k = 10,
    threshold = 0.8
})
```

#### Session-Scoped Operations
```lua
-- Create session collection with TTL
RAG.create_session_collection(session_id, ttl_seconds)

-- Session-scoped operations
RAG.ingest(doc, {
    scope = "session",
    scope_id = session_id
})

results = RAG.search(query, {
    scope = "session",
    scope_id = session_id,
    k = 5
})
```

### Rust Core API

```rust
// Vector storage trait
#[async_trait]
pub trait VectorStorage: Send + Sync {
    async fn store(&self, entry: VectorEntry) -> Result<String>;
    async fn search(&self, query: VectorQuery) -> Result<Vec<VectorResult>>;
    async fn delete(&self, id: &str) -> Result<bool>;
    async fn get_stats(&self) -> Result<StorageStats>;
    async fn clear(&self) -> Result<()>;
    async fn persist(&self) -> Result<()>;
}

// HNSW-specific operations
#[async_trait]
pub trait HNSWStorage: VectorStorage {
    fn configure_hnsw(&mut self, config: HNSWConfig);
    async fn optimize_index(&self) -> Result<()>;
    async fn create_namespace(&self, namespace: &str) -> Result<()>;
}
```

---

## Performance Tuning

### Tuning Workflow

1. **Start with presets**: Use `HNSWConfig::balanced()`
2. **Measure baseline**: Track recall, latency, memory
3. **Adjust for use case**:
   - Faster search? Reduce ef_search
   - Better recall? Increase m and ef_construction
   - Memory constrained? Reduce m
4. **Test with production data**: Use representative queries
5. **Monitor in production**: Track P50/P95/P99 latencies

### Performance Benchmarks

#### Search Latency (100K vectors, 384 dimensions)
| Configuration | Recall@10 | P95 Latency |
|--------------|-----------|-------------|
| Speed        | 85%       | 0.5ms       |
| Balanced     | 95%       | 2ms         |
| Accuracy     | 99%       | 10ms        |

#### Insertion Throughput
| Batch Size | Vectors/sec | Memory Peak |
|------------|-------------|-------------|
| 32         | 5,000       | +10%        |
| 128        | 15,000      | +25%        |
| 256        | 20,000      | +40%        |

### Common Issues and Solutions

#### High Memory Usage
```toml
# Reduce m (biggest impact)
m = 8  # From 16
# Enable future memory mapping
enable_mmap = true
# Use smaller embeddings
embedding_model = "text-embedding-3-small"  # 384 dims
```

#### Poor Recall
```toml
# Increase construction quality
ef_construction = 400  # From 200
# Increase search width
ef_search = 100  # From 50
# Increase connectivity
m = 32  # From 16
```

#### Slow Insertion
```toml
# Reduce construction effort
ef_construction = 100  # From 200
# Increase batch size
parallel_batch_size = 256  # From 128
# Use more threads
num_threads = 8  # From 4
```

---

## Integration Patterns

### State System Integration

```rust
// Automatic StateScope integration
let scope = StateScope::Custom("tenant:acme".to_string());
let entry = VectorEntry::new(id, embedding)
    .with_scope(scope.clone())
    .with_metadata(metadata);

storage.store_scoped(entry, &scope).await?;
```

### Session Integration

```rust
// Session-aware RAG with automatic cleanup
let session_rag = SessionAwareRAGPipeline::new(
    rag_pipeline,
    session_manager
);

// Results stored as session artifacts
let result = session_rag.search_with_session(
    &session_id,
    &query
).await?;
```

### Hook System Integration

```rust
// RAG events for monitoring
hook_manager.emit_async(RAGEvent::SearchPerformed {
    tenant_id: tenant_id.clone(),
    query_hash: hash(&query),
    result_count: results.len(),
    latency_ms: elapsed.as_millis(),
}).await;
```

### Provider Integration

```rust
// Multi-provider support (future)
let factory = EmbeddingFactoryBuilder::new()
    .with_provider(1536, EmbeddingProviderType::OpenAI)
    .with_provider(384, EmbeddingProviderType::Local(model))
    .build();
```

---

## Operational Guide

### Deployment Checklist

#### Prerequisites
- [ ] OpenAI API key configured
- [ ] Sufficient memory for vector index
- [ ] Storage backend configured
- [ ] Multi-tenant policies defined

#### Configuration
```toml
[rag]
enabled = true
embedding_provider = "openai"
embedding_cache_size = 10000

[rag.embeddings.openai]
model = "text-embedding-3-small"
dimensions = 384
batch_size = 32

[rag.vector_storage]
backend = "hnsw"
persist_path = "/var/lib/llmspell/vectors"

[rag.vector_storage.hnsw]
m = 16
ef_construction = 200
ef_search = 50
max_elements = 1000000
distance_metric = "cosine"
```

### Monitoring

#### Key Metrics
```yaml
rag_metrics:
  - vector_count_by_tenant
  - search_latency_p95
  - embedding_api_errors
  - index_memory_usage
  - cache_hit_rate
  - tenant_quota_usage
```

#### Health Checks
```rust
// RAG system health check
async fn check_rag_health() -> HealthStatus {
    let checks = vec![
        storage.is_ready(),
        embedding_provider.is_available(),
        tenant_manager.is_operational(),
    ];
    
    if checks.all_ok() {
        HealthStatus::Healthy
    } else {
        HealthStatus::Degraded(details)
    }
}
```

### Troubleshooting

#### Common Issues

**"Vector search returns no results"**
- Check tenant context is set correctly
- Verify documents were ingested to same tenant
- Check similarity threshold isn't too high
- Verify embedding dimensions match

**"Embedding API rate limited"**
- Implement exponential backoff
- Increase batch sizes
- Enable embedding cache
- Consider local embeddings

**"Memory usage growing"**
- Check index size vs max_elements
- Review m parameter (reduce if needed)
- Enable memory mapping (future)
- Implement TTL for session vectors

**"Cross-tenant data leakage"**
- Verify namespace isolation
- Check security policies
- Review audit logs
- Validate StateScope usage

### Maintenance Tasks

#### Regular Operations
```lua
-- RAG operations are performed via script API, not CLI commands
-- Create maintenance scripts for regular operations:

-- optimize_index.lua (monthly)
local stats = RAG.get_stats("default", nil)
print("Collection stats:", json.encode(stats))

-- cleanup_sessions.lua (daily)
-- Session cleanup happens automatically based on TTL configuration

-- export_metrics.lua (weekly)
local collections = RAG.list_collections()
for _, collection in ipairs(collections) do
    local stats = RAG.get_stats(collection, nil)
    print(collection .. " metrics:", json.encode(stats))
end

-- Note: RAG operations are script-context operations, not CLI commands
-- Use llmspell run <script.lua> to execute maintenance scripts
```

#### Capacity Planning
```yaml
capacity_guidelines:
  per_tenant:
    vectors: 100000
    storage: 200MB
    searches_per_day: 10000
  
  system_total:
    tenants: 1000
    vectors: 100M
    memory: 200GB
    storage: 200GB
```

---

## Migration Path

### From Mock RAG
```lua
-- Old (mock)
local result = RAG.search("query")  -- Returns mock data

-- New (Phase 8)
local result = RAG.search("query", {
    k = 10,
    scope = "tenant",
    scope_id = "acme"
})  -- Returns real vector search results
```

### Adding to Existing System
1. Enable in configuration
2. Ingest existing documents
3. Configure HNSW parameters
4. Set up tenant contexts
5. Monitor performance

### Future Enhancements (Phase 9+)

- **Local Embeddings**: BGE-M3, E5, ColBERT
- **Multi-Provider**: Cohere, Voyage AI, Google
- **Hybrid Search**: Vector + keyword combination
- **Memory Mapping**: Support for 10M+ vectors
- **GPU Acceleration**: CUDA support for operations
- **Distributed Index**: Horizontal scaling

---

*This comprehensive guide consolidates all RAG system documentation for LLMSpell v0.8.0, validated against Phase 8 implementation.*